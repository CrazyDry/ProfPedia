Model Selection for Gaussian Mixture Models

  This paper is concerned with an important issue in finite mixture modelling,the selection of the number of mixing components. We propose a new penalizedlikelihood method for model selection of finite multivariate Gaussian mixturemodels. The proposed method is shown to be statistically consistent indetermining of the number of components. A modified EM algorithm is developedto simultaneously select the number of components and to estimate the mixingweights, i.e. the mixing probabilities, and unknown parameters of Gaussiandistributions. Simulations and a real data analysis are presented to illustratethe performance of the proposed method.

A Distributional Representation Model For Collaborative Filtering

  In this paper, we propose a very concise deep learning approach forcollaborative filtering that jointly models distributional representation forusers and items. The proposed framework obtains better performance whencompared against current state-of-art algorithms and that made thedistributional representation model a promising direction for further researchin the collaborative filtering.

Stroke-based Character Reconstruction

  Background elimination for noisy character images or character images fromreal scene is still a challenging problem, due to the bewildering backgrounds,uneven illumination, low resolution and different distortions. We propose astroke-based character reconstruction(SCR) method that use a weighted quadraticBezier curve(WQBC) to represent strokes of a character. Only training on oursynthetic data, our stroke extractor can achieve excellent reconstructioneffect in real scenes. Meanwhile. It can also help achieve great ability indefending adversarial attacks of character recognizers.

Learning to Paint with Model-based Deep Reinforcement Learning

  We show how to teach machines to paint like human painters, who can use a fewstrokes to create fantastic paintings. By combining the neural renderer andmodel-based Deep Reinforcement Learning (DRL), our agent can decomposetexture-rich images into strokes and make long-term plans. For each stroke, theagent directly determines the position and color of the stroke. Excellentvisual effect can be achieved using hundreds of strokes. The training processdoes not require experience of human painting or stroke tracking data.

Are Tensor Decomposition Solutions Unique? On the global convergence of  HOSVD and ParaFac algorithms

  For tensor decompositions such as HOSVD and ParaFac, the objective functionsare nonconvex. This implies, theoretically, there exists a large number oflocal optimas: starting from different starting point, the iteratively improvedsolution will converge to different local solutions. This non-uniquenesspresent a stability and reliability problem for image compression andretrieval. In this paper, we present the results of a comprehensiveinvestigation of this problem. We found that although all tensor decompositionalgorithms fail to reach a unique global solution on random data and severelyscrambled data; surprisingly however, on all real life several data sets (evenwith substantial scramble and occlusions), HOSVD always produce the uniqueglobal solution in the parameter region suitable to practical applications,while ParaFac produce non-unique solutions. We provide an eigenvalue based rulefor the assessing the solution uniqueness.

Terabit optical OFDM superchannel transmission via coherent carriers of  a hybrid chip-scale soliton frequency comb

  We demonstrate seamless channel multiplexing and high bitrate superchanneltransmission of coherent optical orthogonal-frequency-division-multiplexing(CO-OFDM) data signals utilizing a dissipative Kerr soliton (DKS) frequencycomb generated in an on-chip microcavity. Aided by comb line multiplicationthrough Nyquist pulse modulation, the high stability and mutual coherence amongmode-locked Kerr comb lines are exploited for the first time to eliminate theguard intervals between communication channels and achieve full spectraldensity bandwidth utilization. Spectral efficiency as high as 2.625 bit/Hz/s isobtained for 180 CO-OFDM bands encoded with 12.75 Gbaud 8-QAM data, adding upto total bitrate of 6.885 Tb/s within 2.295 THz frequency comb bandwidth. Ourstudy confirms that high coherence is the key superiority of Kerr solitonfrequency combs over independent laser diodes, as a multi-spectral coherentlaser source for high-bandwidth high-spectral-density transmission networks.

Query Answering with Inconsistent Existential Rules under Stable Model  Semantics

  Traditional inconsistency-tolerent query answering in ontology-based dataaccess relies on selecting maximal components of an ABox/database which areconsistent with the ontology. However, some rules in ontologies might beunreliable if they are extracted from ontology learning or written byunskillful knowledge engineers. In this paper we present a framework ofhandling inconsistent existential rules under stable model semantics, which isdefined by a notion called rule repairs to select maximal components of theexistential rules. Surprisingly, for R-acyclic existential rules withR-stratified or guarded existential rules with stratified negations, both thedata complexity and combined complexity of query answering under the rule{repair semantics} remain the same as that under the conventional queryanswering semantics. This leads us to propose several approaches to handle therule {repair semantics} by calling answer set programming solvers. Anexperimental evaluation shows that these approaches have good scalability ofquery answering under rule repairs on realistic cases.

Six-wave mixing induced by free-carrier plasma in silicon nanowire  waveguides

  Nonlinear wave mixing in mesoscopic silicon structures is a fundamentalnonlinear process with broad impact and applications. Silicon nanowirewaveguides, in particular, have large third-order Kerr nonlinearity, enablingsalient and abundant four-wave-mixing dynamics and functionalities. Besides theKerr effect, in silicon waveguides two-photon absorption generates highfree-carrier densities, with corresponding fifth-order nonlinearity in theforms of free-carrier dispersion and free-carrier absorption. However, whetherthese fifth-order free-carrier nonlinear effects can lead to six-wave-mixingdynamics still remains an open question until now. Here we report thedemonstration of free-carrier-induced six-wave mixing in silicon nanowires.Unique features, including inverse detuning dependence of six-wave-mixingefficiency and its higher sensitivity to pump power, are originally observedand verfied by analytical prediction and numerical modeling. Additionally,asymmetric sideband generation is observed for different laser detunings,resulting from the phase-sensitive interactions between free-carriersix-wave-mixing and Kerr four-wave-mixing dynamics. These discoveries provide anew path for nonlinear multi-wave interactions in nanoscale platforms.

Continuous monitoring of membrane protein micro-domain association  during cell signaling

  Central to understanding membrane bound cell signaling is to quantify how themembrane ultra-structure consisting of transient spatial domains modulatessignaling and how the signaling influences this ultra-structure. Yet, measuringthe association of membrane proteins with domains in living, intact cells posesconsiderable challenges. Here, we describe a non-destructive method to quantifyprotein-lipid domain and protein cytoskeleton interactions in single, intactcells enabling continuous monitoring of the protein domains interaction overtime during signaling.

Tunable single-photon frequency conversion in a Sagnac interferometer

  We study the single-photon frequency conversion of a five-level emittercoupled to a Sagnac interferometer. We show that the unity conversionefficiency can be achieved either in resonance or off-resonance case under theideal condition. In particular, the frequency of the output photon can becontrolled by the frequencies and Rabi frequencies of the external drivingfields.

Clinical Information Extraction via Convolutional Neural Network

  We report an implementation of a clinical information extraction tool thatleverages deep neural network to annotate event spans and their attributes fromraw clinical notes and pathology reports. Our approach uses context words andtheir part-of-speech tags and shape information as features. Then we hiretemporal (1D) convolutional neural network to learn hidden featurerepresentations. Finally, we use Multilayer Perceptron (MLP) to predict eventspans. The empirical evaluation demonstrates that our approach significantlyoutperforms baselines.

Linear absorption coefficient of in-plane graphene on a silicon  microring resonator

  We demonstrate that linear absorption coefficient (LAC) of a graphene-siliconhybrid waveguide (GSHW) is determined by the optical transmission spectra of agraphene coated symmetrically coupled add-drop silicon microring resonator(SC-ADSMR), of which the value is around 0.23 dB/um. In contrast to thetraditional cut-back method, the measured results are not dependent on thecoupling efficiency of the fiber tip and the waveguide. Moreover, precisionevaluation of graphene coated silicon microring resonator (SMR) is crucial forthe optoelectronic devices targeting for compact footprint and low powerconsumption.

Leveraging Deep Neural Networks and Knowledge Graphs for Entity  Disambiguation

  Entity Disambiguation aims to link mentions of ambiguous entities to aknowledge base (e.g., Wikipedia). Modeling topical coherence is crucial forthis task based on the assumption that information from the same semanticcontext tends to belong to the same topic. This paper presents a novel deepsemantic relatedness model (DSRM) based on deep neural networks (DNN) andsemantic knowledge graphs (KGs) to measure entity semantic relatedness fortopical coherence modeling. The DSRM is directly trained on large-scale KGs andit maps heterogeneous types of knowledge of an entity from KGs to numericalfeature vectors in a latent space such that the distance between twosemantically-related entities is minimized. Compared with the state-of-the-artrelatedness approach proposed by (Milne and Witten, 2008a), the DSRM obtains19.4% and 24.5% reductions in entity disambiguation errors on two publiclyavailable datasets respectively.

Face Aging Effect Simulation using Hidden Factor Analysis Joint Sparse  Representation

  Face aging simulation has received rising investigations nowadays, whereas itstill remains a challenge to generate convincing and natural age-progressedface images. In this paper, we present a novel approach to such an issue byusing hidden factor analysis joint sparse representation. In contrast to themajority of tasks in the literature that handle the facial texture integrally,the proposed aging approach separately models the person-specific facialproperties that tend to be stable in a relatively long period and theage-specific clues that change gradually over time. It then merely transformsthe age component to a target age group via sparse reconstruction, yieldingaging effects, which is finally combined with the identity component to achievethe aged face. Experiments are carried out on three aging databases, and theresults achieved clearly demonstrate the effectiveness and robustness of theproposed method in rendering a face with aging effects. Additionally, a seriesof evaluations prove its validity with respect to identity preservation andaging effect generation.

Zero-Shot Transfer Learning for Event Extraction

  Most previous event extraction studies have relied heavily on featuresderived from annotated event mentions, thus cannot be applied to new eventtypes without annotation effort. In this work, we take a fresh look at eventextraction and model it as a grounding problem. We design a transferable neuralarchitecture, mapping event mentions and types jointly into a shared semanticspace using structural and compositional neural networks, where the type ofeach event mention can be determined by the closest of all candidate types . Byleveraging (1)~available manual annotations for a small set of existing eventtypes and (2)~existing event ontologies, our framework applies to new eventtypes without requiring additional annotation. Experiments on both existingevent types (e.g., ACE, ERE) and new event types (e.g., FrameNet) demonstratethe effectiveness of our approach. \textit{Without any manual annotations} for23 new event types, our zero-shot framework achieved performance comparable toa state-of-the-art supervised model which is trained from the annotations of500 event mentions.

Improving Slot Filling Performance with Attentive Neural Networks on  Dependency Structures

  Slot Filling (SF) aims to extract the values of certain types of attributes(or slots, such as person:cities\_of\_residence) for a given entity from alarge collection of source documents. In this paper we propose an effective DNNarchitecture for SF with the following new strategies: (1). Take a regularizeddependency graph instead of a raw sentence as input to DNN, to compress thewide contexts between query and candidate filler; (2). Incorporate twoattention mechanisms: local attention learned from query and candidate filler,and global attention learned from external knowledge bases, to guide the modelto better select indicative contexts to determine slot type. Experiments showthat this framework outperforms state-of-the-art on both relation extraction(16\% absolute F-score gain) and slot filling validation for each individualsystem (up to 8.5\% absolute F-score gain).

Learning Phrase Embeddings from Paraphrases with GRUs

  Learning phrase representations has been widely explored in many NaturalLanguage Processing (NLP) tasks (e.g., Sentiment Analysis, Machine Translation)and has shown promising improvements. Previous studies either learnnon-compositional phrase representations with general word embedding learningtechniques or learn compositional phrase representations based on syntacticstructures, which either require huge amounts of human annotations or cannot beeasily generalized to all phrases. In this work, we propose to take advantageof large-scaled paraphrase database and present a pair-wise gated recurrentunits (pairwise-GRU) framework to generate compositional phraserepresentations. Our framework can be re-used to generate representations forany phrases. Experimental results show that our framework achievesstate-of-the-art results on several phrase similarity tasks.

Linear networks based speaker adaptation for speech synthesis

  Speaker adaptation methods aim to create fair quality synthesis speech voicefont for target speakers while only limited resources available. Recently, asdeep neural networks based statistical parametric speech synthesis (SPSS)methods become dominant in SPSS TTS back-end modeling, speaker adaptation underthe neural network based SPSS framework has also became an important task. Inthis paper, linear networks (LN) is inserted in multiple neural network layersand fine-tuned together with output layer for best speaker adaptationperformance. When adaptation data is extremely small, the low-rank plusdiagonal(LRPD) decomposition for LN is employed to make the adapted voice morestable. Speaker adaptation experiments are conducted under a range ofadaptation utterances numbers. Moreover, speaker adaptation from 1) female tofemale, 2) male to female and 3) female to male are investigated. Objectivemeasurement and subjective tests show that LN with LRPD decomposition performsmost stable when adaptation data is extremely limited, and our best speakeradaptation (SA) model with only 200 adaptation utterances achieves comparablequality with speaker dependent (SD) model trained with 1000 utterances, in bothnaturalness and similarity to target speaker.

Multi-lingual Common Semantic Space Construction via Cluster-consistent  Word Embedding

  We construct a multilingual common semantic space based on distributionalsemantics, where words from multiple languages are projected into a sharedspace to enable knowledge and resource transfer across languages. Beyond wordalignment, we introduce multiple cluster-level alignments and enforce the wordclusters to be consistently distributed across multiple languages. We exploitthree signals for clustering: (1) neighbor words in the monolingual wordembedding space; (2) character-level information; and (3) linguistic properties(e.g., apposition, locative suffix) derived from linguistic structure knowledgebases available for thousands of languages. We introduce a newcluster-consistent correlational neural network to construct the commonsemantic space by aligning words as well as clusters. Intrinsic evaluation onmonolingual and multilingual QVEC tasks shows our approach achievessignificantly higher correlation with linguistic features than state-of-the-artmulti-lingual embedding learning methods do. Using low-resource language nametagging as a case study for extrinsic evaluation, our approach achieves up to24.5\% absolute F-score gain over the state of the art.

Emulating many-body localization with a superconducting quantum  processor

  The law of statistical physics dictates that generic closed quantum many-bodysystems initialized in nonequilibrium will thermalize under their own dynamics.However, the emergence of many-body localization (MBL) owing to the interplaybetween interaction and disorder, which is in stark contrast to Andersonlocalization that only addresses noninteracting particles in the presence ofdisorder, greatly challenges this concept because it prevents the systems fromevolving to the ergodic thermalized state. One critical evidence of MBL is thelong-time logarithmic growth of entanglement entropy, and a direct observationof it is still elusive due to the experimental challenges in multiqubitsingle-shot measurement and quantum state tomography. Here we present anexperiment of fully emulating the MBL dynamics with a 10-qubit superconductingquantum processor, which represents a spin-1/2 XY model featuring programmabledisorder and long-range spin-spin interactions. We provide essential signaturesof MBL, such as the imbalance due to the initial nonequilibrium, the violationof eigenstate thermalization hypothesis, and, more importantly, the directevidence of the long-time logarithmic growth of entanglement entropy. Ourresults lay solid foundations for precisely simulating the intriguing physicsof quantum many-body systems on the platform of large-scale multiqubitsuperconducting quantum processors.

Faster Gradient-Free Proximal Stochastic Methods for Nonconvex Nonsmooth  Optimization

  Proximal gradient method has been playing an important role to solve manymachine learning tasks, especially for the nonsmooth problems. However, in somemachine learning problems such as the bandit model and the black-box learningproblem, proximal gradient method could fail because the explicit gradients ofthese problems are difficult or infeasible to obtain. The gradient-free(zeroth-order) method can address these problems because only the objectivefunction values are required in the optimization. Recently, the firstzeroth-order proximal stochastic algorithm was proposed to solve the nonconvexnonsmooth problems. However, its convergence rate is $O(\frac{1}{\sqrt{T}})$for the nonconvex problems, which is significantly slower than the bestconvergence rate $O(\frac{1}{T})$ of the zeroth-order stochastic algorithm,where $T$ is the iteration number. To fill this gap, in the paper, we propose aclass of faster zeroth-order proximal stochastic methods with the variancereduction techniques of SVRG and SAGA, which are denoted as ZO-ProxSVRG andZO-ProxSAGA, respectively. In theoretical analysis, we address the mainchallenge that an unbiased estimate of the true gradient does not hold in thezeroth-order case, which was required in previous theoretical analysis of bothSVRG and SAGA. Moreover, we prove that both ZO-ProxSVRG and ZO-ProxSAGAalgorithms have $O(\frac{1}{T})$ convergence rates. Finally, the experimentalresults verify that our algorithms have a faster convergence rate than theexisting zeroth-order proximal stochastic algorithm.

Dark Matter Results From 54-Ton-Day Exposure of PandaX-II Experiment

  We report a new search of weakly interacting massive particles (WIMPs) usingthe combined low background data sets in 2016 and 2017 from the PandaX-IIexperiment in China. The latest data set contains a new exposure of 77.1 liveday, with the background reduced to a level of 0.8$\times10^{-3}$ evt/kg/day,improved by a factor of 2.5 in comparison to the previous run in 2016. Noexcess events were found above the expected background. With a total exposureof 5.4$\times10^4$ kg day, the most stringent upper limit on spin-independentWIMP-nucleon cross section was set for a WIMP with mass larger than 100GeV/c$^2$, with the lowest exclusion at 8.6$\times10^{-47}$ cm$^2$ at 40GeV/c$^2$.

Constraining Dark Matter Models with a Light Mediator from PandaX-II  Experiment

  We search for nuclear recoil signals of dark matter models with a lightmediator in PandaX-II, a direct detection experiment in China Jinpingunderground Laboratory. Using data collected in 2016 and 2017 runs,corresponding to a total exposure of 54 ton day, we set upper limits on thezero-momentum dark matter-nucleon cross section. These limits have a strongdependence on the mediator mass when it is comparable to or below the typicalmomentum transfer. We apply our results to constrain self-interacting darkmatter models with a light mediator mixing with standard model particles, andset strong limits on the model parameter space for the dark matter mass rangingfrom $5~{\rm GeV}$ to $10~{\rm TeV}$.

Dark matter direct search sensitivity of the PandaX-4T experiment

  The PandaX-4T experiment, a four-ton scale dark matter direct detectionexperiment, is being planned at the China Jinping Underground Laboratory. Inthis paper we present a simulation study of the expected background in thisexperiment. In a 2.8-ton fiducial mass and the signal region between 1 to 10keV electron equivalent energy, the total electron recoil background is foundto be 4.9x10^{-5} /(kg day keV). The nuclear recoil background in the sameregion is 2.8x10^{-7}/(kg day keV). With an exposure of 5.6 ton-years, thesensitivity of PandaX-4T could reach a minimum spin-independent darkmatter-nucleon cross section of 6x10^{-48} cm^{2} at a dark matter mass of 40GeV/c^{2}.

PandaX-II Constraints on Spin-Dependent WIMP-Nucleon Effective  Interactions

  We present PandaX-II constraints on candidate WIMP-nucleon effectiveinteractions involving the nucleon or WIMP spin, including, in addition tostandard axial spin-dependent (SD) scattering, various couplings among vectorand axial currents, magnetic and electric dipole moments, and tensorinteractions. The data set corresponding to a total exposure of 54-ton-days isreanalyzed to determine constraints as a function of the WIMP mass and isospincoupling. We obtain WIMP-nucleon cross section bounds of $\rm 1.6 \times10^{-41} cm^2$ and $\rm 9.0 \times 10^{-42} cm^2$ ($90\%$ c.l.) forneutron-only SD and tensor coupling, respectively, for a mass $M_\mathrm{WIMP}\sim {\rm 40~GeV}/c^2$. The SD limits are the best currently available for$M_\mathrm{WIMP} > {\rm 40~GeV}/c^2$. We show that PandaX-II has reached asensitivity sufficient to probe a variety of other candidate spin-dependentinteractions at the weak scale.

Building a Fine-Grained Entity Typing System Overnight for a New X (X =  Language, Domain, Genre)

  Recent research has shown great progress on fine-grained entity typing. Mostexisting methods require pre-defining a set of types and training a multi-classclassifier from a large labeled data set based on multi-level linguisticfeatures. They are thus limited to certain domains, genres and languages. Inthis paper, we propose a novel unsupervised entity typing framework bycombining symbolic and distributional semantics. We start from learning generalembeddings for each entity mention, compose the embeddings of specific contextsusing linguistic structures, link the mention to knowledge bases and learn itsrelated knowledge representations. Then we develop a novel joint hierarchicalclustering and linking algorithm to type all mentions using theserepresentations. This framework doesn't rely on any annotated data, predefinedtyping schema, or hand-crafted features, therefore it can be quickly adapted toa new domain, genre and language. Furthermore, it has great flexibility atincorporating linguistic structures (e.g., Abstract Meaning Representation(AMR), dependency relations) to improve specific context representation.Experiments on genres (news and discussion forum) show comparable performancewith state-of-the-art supervised typing systems trained from a large amount oflabeled data. Results on various languages (English, Chinese, Japanese, Hausa,and Yoruba) and domains (general and biomedical) demonstrate the portability ofour framework.

Optimization of synchronization in gradient clustered networks

  We consider complex clustered networks with a gradient structure, where sizesof the clusters are distributed unevenly. Such networks describe more closelyactual networks in biophysical systems and in technological applications thanprevious models. Theoretical analysis predicts that the networksynchronizability can be optimized by the strength of the gradient field butonly when the gradient field points from large to small clusters. A remarkablefinding is that, if the gradient field is sufficiently strong,synchronizability of the network is mainly determined by the properties of thesubnetworks in the two largest clusters. These results are verified bynumerical eigenvalue analysis and by direct simulation of synchronizationdynamics on coupled-oscillator networks.

An Iterative Locally Linear Embedding Algorithm

  Local Linear embedding (LLE) is a popular dimension reduction method. In thispaper, we first show LLE with nonnegative constraint is equivalent to thewidely used Laplacian embedding. We further propose to iterate the two steps inLLE repeatedly to improve the results. Thirdly, we relax the kNN constraint ofLLE and present a sparse similarity learning algorithm. The final Iterative LLEcombines these three improvements. Extensive experiment results show thatiterative LLE algorithm significantly improve both classification andclustering results.

The Complexity of Planar Boolean #CSP with Complex Weights

  We prove a complexity dichotomy theorem for symmetric complex-weightedBoolean #CSP when the constraint graph of the input must be planar. Theproblems that are #P-hard over general graphs but tractable over planar graphsare precisely those with a holographic reduction to matchgates. Thisgeneralizes a theorem of Cai, Lu, and Xia for the case of real weights. We alsoobtain a dichotomy theorem for a symmetric arity 4 signature with complexweights in the planar Holant framework, which we use in the proof of our #CSPdichotomy. In particular, we reduce the problem of evaluating the Tuttepolynomial of a planar graph at the point (3,3) to counting the number ofEulerian orientations over planar 4-regular graphs to show the latter is#P-hard. This strengthens a theorem by Huang and Lu to the planar setting. Ourproof techniques combine new ideas with refinements and extensions of existingtechniques. These include planar pairings, the recursive unary construction,the anti-gadget technique, and pinning in the Hadamard basis.

Improved Spectral Clustering via Embedded Label Propagation

  Spectral clustering is a key research topic in the field of machine learningand data mining. Most of the existing spectral clustering algorithms are builtupon Gaussian Laplacian matrices, which are sensitive to parameters. We proposea novel parameter free, distance consistent Locally Linear Embedding. Theproposed distance consistent LLE promises that edges between closer data pointshave greater weight.Furthermore, we propose a novel improved spectralclustering via embedded label propagation. Our algorithm is built upon twoadvancements of the state of the art:1) label propagation,which propagates anode\'s labels to neighboring nodes according to their proximity; and 2)manifold learning, which has been widely used in its capacity to leverage themanifold structure of data points. First we perform standard spectralclustering on original data and assign each cluster to k nearest data points.Next, we propagate labels through dense, unlabeled data regions. Extensiveexperiments with various datasets validate the superiority of the proposedalgorithm compared to current state of the art spectral algorithms.

Theoretic Analysis and Extremely Easy Algorithms for Domain Adaptive  Feature Learning

  Domain adaptation problems arise in a variety of applications, where atraining dataset from the \textit{source} domain and a test dataset from the\textit{target} domain typically follow different distributions. The primarydifficulty in designing effective learning models to solve such problems liesin how to bridge the gap between the source and target distributions. In thispaper, we provide comprehensive analysis of feature learning algorithms used inconjunction with linear classifiers for domain adaptation. Our analysis showsthat in order to achieve good adaptation performance, the second moments of thesource domain distribution and target domain distribution should be similar.Based on our new analysis, a novel extremely easy feature learning algorithmfor domain adaptation is proposed. Furthermore, our algorithm is extended byleveraging multiple layers, leading to a deep linear model. We evaluate theeffectiveness of the proposed algorithms in terms of domain adaptation tasks onthe Amazon review dataset and the spam dataset from the ECML/PKDD 2006discovery challenge.

A Novel Method of Encoded Multiplexing Readout for Micro-pattern Gas  Detectors

  The requirement of a large number of electronic channels poses a bigchallenge for Micro-pattern Gas Detector (MPGD) to achieve good spatialresolution. By using the redundancy that at least two neighboring strips recordthe signal of a particle, a novel method of encoded multiplexing readout forMPGDs is presented in this paper. The method offers a feasible andeasily-extensible way of encoding and decoding, and can significantly reducethe number of readout channels. A verification test was carried out on a 5*5cm2 Thick Gas Electron Multiplier (THGEM) detector using a 8 keV Cu X-raysource with 100um slit, where 166 strips are read out by 21 encoded readoutchannels. The test results show a good linearity in its position response, andthe spatial resolution root-mean-square (RMS) of the test system is about 260{\mu}m. This method has an attractive potential to build large area detectorsand can be easily adapted to other detectors like MPGDs.

Non-Greedy L21-Norm Maximization for Principal Component Analysis

  Principal Component Analysis (PCA) is one of the most important unsupervisedmethods to handle high-dimensional data. However, due to the high computationalcomplexity of its eigen decomposition solution, it hard to apply PCA to thelarge-scale data with high dimensionality. Meanwhile, the squared L2-norm basedobjective makes it sensitive to data outliers. In recent research, the L1-normmaximization based PCA method was proposed for efficient computation and beingrobust to outliers. However, this work used a greedy strategy to solve theeigen vectors. Moreover, the L1-norm maximization based objective may not bethe correct robust PCA formulation, because it loses the theoretical connectionto the minimization of data reconstruction error, which is one of the mostimportant intuitions and goals of PCA. In this paper, we propose to maximizethe L21-norm based robust PCA objective, which is theoretically connected tothe minimization of reconstruction error. More importantly, we propose theefficient non-greedy optimization algorithms to solve our objective and themore general L21-norm maximization problem with theoretically guaranteedconvergence. Experimental results on real world data sets show theeffectiveness of the proposed method for principal component analysis.

Enhancing Sentence Relation Modeling with Auxiliary Character-level  Embedding

  Neural network based approaches for sentence relation modeling automaticallygenerate hidden matching features from raw sentence pairs. However, the qualityof matching feature representation may not be satisfied due to complex semanticrelations such as entailment or contradiction. To address this challenge, wepropose a new deep neural network architecture that jointly leveragepre-trained word embedding and auxiliary character embedding to learn sentencemeanings. The two kinds of word sequence representations as inputs intomulti-layer bidirectional LSTM to learn enhanced sentence representation. Afterthat, we construct matching features followed by another temporal CNN to learnhigh-level hidden matching feature representations. Experimental resultsdemonstrate that our approach consistently outperforms the existing methods onstandard evaluation datasets.

Asynchronous Stochastic Gradient Descent with Variance Reduction for  Non-Convex Optimization

  We provide the first theoretical analysis on the convergence rate of theasynchronous stochastic variance reduced gradient (SVRG) descent algorithm onnon-convex optimization. Recent studies have shown that the asynchronousstochastic gradient descent (SGD) based algorithms with variance reductionconverge with a linear convergent rate on convex problems. However, there is nowork to analyze asynchronous SGD with variance reduction technique onnon-convex problem. In this paper, we study two asynchronous parallelimplementations of SVRG: one is on a distributed memory system and the other ison a shared memory system. We provide the theoretical analysis that bothalgorithms can obtain a convergence rate of $O(1/T)$, and linear speed up isachievable if the number of workers is upper bounded. V1,v2,v3 have beenwithdrawn due to reference issue, please refer the newest version v4.

Distributed Asynchronous Dual Free Stochastic Dual Coordinate Ascent

  The primal-dual distributed optimization methods have broad large-scalemachine learning applications. Previous primal-dual distributed methods are notapplicable when the dual formulation is not available, e.g. thesum-of-non-convex objectives. Moreover, these algorithms and theoreticalanalysis are based on the fundamental assumption that the computing speeds ofmultiple machines in a cluster are similar. However, the straggler problem isan unavoidable practical issue in the distributed system because of theexistence of slow machines. Therefore, the total computational time of thedistributed optimization methods is highly dependent on the slowest machine. Inthis paper, we address these two issues by proposing distributed asynchronousdual free stochastic dual coordinate ascent algorithm for distributedoptimization. Our method does not need the dual formulation of the targetproblem in the optimization. We tackle the straggler problem throughasynchronous communication and the negative effect of slow machines issignificantly alleviated. We also analyze the convergence rate of our methodand prove the linear convergence rate even if the individual functions inobjective are non-convex. Experiments on both convex and non-convex lossfunctions are used to validate our statements.

Bidirectional Long-Short Term Memory for Video Description

  Video captioning has been attracting broad research attention in multimediacommunity. However, most existing approaches either ignore temporal informationamong video frames or just employ local contextual temporal knowledge. In thiswork, we propose a novel video captioning framework, termed as\emph{Bidirectional Long-Short Term Memory} (BiLSTM), which deeply capturesbidirectional global temporal structure in video. Specifically, we first devisea joint visual modelling approach to encode video data by combining a forwardLSTM pass, a backward LSTM pass, together with visual features fromConvolutional Neural Networks (CNNs). Then, we inject the derived videorepresentation into the subsequent language model for initialization. Thebenefits are in two folds: 1) comprehensively preserving sequential and visualinformation; and 2) adaptively learning dense visual features and sparsesemantic representations for videos and sentences, respectively. We verify theeffectiveness of our proposed video captioning framework on a commonly-usedbenchmark, i.e., Microsoft Video Description (MSVD) corpus, and theexperimental results demonstrate that the superiority of the proposed approachas compared to several state-of-the-art methods.

Decoupled Asynchronous Proximal Stochastic Gradient Descent with  Variance Reduction

  In the era of big data, optimizing large scale machine learning problemsbecomes a challenging task and draws significant attention. Asynchronousoptimization algorithms come out as a promising solution. Recently, decoupledasynchronous proximal stochastic gradient descent (DAP-SGD) is proposed tominimize a composite function. It is claimed to be able to off-loads thecomputation bottleneck from server to workers by allowing workers to evaluatethe proximal operators, therefore, server just need to do element-wiseoperations. However, it still suffers from slow convergence rate because of thevariance of stochastic gradient is nonzero. In this paper, we propose a fastermethod, decoupled asynchronous proximal stochastic variance reduced gradientdescent method (DAP-SVRG). We prove that our method has linear convergence forstrongly convex problem. Large-scale experiments are also conducted in thispaper, and results demonstrate our theoretical analysis.

A Closed Form Solution to Multi-View Low-Rank Regression

  Real life data often includes information from different channels. Forexample, in computer vision, we can describe an image using different imagefeatures, such as pixel intensity, color, HOG, GIST feature, SIFT features,etc.. These different aspects of the same objects are often called multi-view(or multi-modal) data. Low-rank regression model has been proved to be aneffective learning mechanism by exploring the low-rank structure of real lifedata. But previous low-rank regression model only works on single view data. Inthis paper, we propose a multi-view low-rank regression model by imposinglow-rank constraints on multi-view regression model. Most importantly, weprovide a closed-form solution to the multi-view low-rank regression model.Extensive experiments on 4 multi-view datasets show that the multi-viewlow-rank regression model outperforms single-view regression model and revealsthat multi-view low-rank structure is very helpful.

Asynchronous Stochastic Block Coordinate Descent with Variance Reduction

  Asynchronous parallel implementations for stochastic optimization havereceived huge successes in theory and practice recently. Asynchronousimplementations with lock-free are more efficient than the one with writing orreading lock. In this paper, we focus on a composite objective functionconsisting of a smooth convex function $f$ and a block separable convexfunction, which widely exists in machine learning and computer vision. Wepropose an asynchronous stochastic block coordinate descent algorithm with theaccelerated technology of variance reduction (AsySBCDVR), which are withlock-free in the implementation and analysis. AsySBCDVR is particularlyimportant because it can scale well with the sample size and dimensionsimultaneously. We prove that AsySBCDVR achieves a linear convergence rate whenthe function $f$ is with the optimal strong convexity property, and a sublinearrate when $f$ is with the general convexity. More importantly, a near-linearspeedup on a parallel system with shared memory can be obtained.

Zeroth-order Asynchronous Doubly Stochastic Algorithm with Variance  Reduction

  Zeroth-order (derivative-free) optimization attracts a lot of attention inmachine learning, because explicit gradient calculations may be computationallyexpensive or infeasible. To handle large scale problems both in volume anddimension, recently asynchronous doubly stochastic zeroth-order algorithms wereproposed. The convergence rate of existing asynchronous doubly stochasticzeroth order algorithms is $O(\frac{1}{\sqrt{T}})$ (also for the sequentialstochastic zeroth-order optimization algorithms). In this paper, we focus onthe finite sums of smooth but not necessarily convex functions, and propose anasynchronous doubly stochastic zeroth-order optimization algorithm using theaccelerated technology of variance reduction (AsyDSZOVR). Rigorous theoreticalanalysis show that the convergence rate can be improved from$O(\frac{1}{\sqrt{T}})$ the best result of existing algorithms to$O(\frac{1}{T})$. Also our theoretical results is an improvement to the ones ofthe sequential stochastic zeroth-order optimization algorithms.

Inexact Proximal Gradient Methods for Non-convex and Non-smooth  Optimization

  In machine learning research, the proximal gradient methods are popular forsolving various optimization problems with non-smooth regularization. Inexactproximal gradient methods are extremely important when exactly solving theproximal operator is time-consuming, or the proximal operator does not have ananalytic solution. However, existing inexact proximal gradient methods onlyconsider convex problems. The knowledge of inexact proximal gradient methods inthe non-convex setting is very limited. % Moreover, for some machine learningmodels, there is still no proposed solver for exactly solving the proximaloperator. To address this challenge, in this paper, we first propose threeinexact proximal gradient algorithms, including the basic version andNesterov's accelerated version. After that, we provide the theoretical analysisto the basic and Nesterov's accelerated versions. The theoretical results showthat our inexact proximal gradient algorithms can have the same convergencerates as the ones of exact proximal gradient algorithms in the non-convexsetting.  Finally, we show the applications of our inexact proximal gradient algorithmson three representative non-convex learning problems. All experimental resultsconfirm the superiority of our new inexact proximal gradient algorithms.

Real-time dynamics and cross-correlation gating spectroscopy of  free-carrier Drude slow-light solitons

  Optical solitons-stable waves balancing delicately between nonlinearities anddispersive effects-have advanced the field of ultrafast optics and dynamics,with contributions spanning supercontinuum generation and soliton fission, tooptical event horizon, Hawking radiation, and optical rogue waves, amongstothers. Here we investigate picojoule soliton dynamics in silicon slow-lightphotonic-bandgap waveguides under the influence of Drude-modeled free-carrierinduced nonlinear effects. Using real-time and single shot amplified dispersiveFourier transform spectroscopy simultaneously with high-fidelitycross-correlation frequency-resolved optical gating at femtojoule sensitivityand femtosecond resolution, we examine the soliton stability limits, thesoliton dynamics including free-carrier quartic slow-light scaling andacceleration, and the Drude electron-hole-plasma induced perturbations onCherenkov radiation and modulation instability. Our real-time single shot andtime-averaged cross-correlation measurements are matched with our detailedtheoretical modeling, examining the reduced group velocity free-carrierkinetics on solitons at picojoule.

Consecutive Insulator-Metal-Insulator Phase Transitions of Vanadium  Dioxide by Hydrogen Doping

  We report modulation of a reversible phase transition in VO2 films byhydrogen doping. A metallic phase and a new insulating phase are successivelyobserved at room temperature as the doping concentration increases. It issuggested that the polarized charges from doped hydrogens play an importantrole. These charges gradually occupy V3d-O2p hybridized orbitals andconsequently modulate the filling of the VO2 crystal conduction band-edgestates, which eventually evolve into new valence band-edge states. Thisdemonstrates the exceptional sensitivity of VO2 electronic properties toelectron concentration and orbital occupancy, providing key information for thephase transition mechanism.

Unsupervised Learning of Mixture Regression Models for Longitudinal Data

  This paper is concerned with learning of mixture regression models forindividuals that are measured repeatedly. The adjective "unsupervised" impliesthat the number of mixing components is unknown and has to be determined,ideally by data driven tools. For this purpose, a novel penalized method isproposed to simultaneously select the number of mixing components and toestimate the mixing proportions and unknown parameters in the models. Theproposed method is capable of handling both continuous and discrete responsesby only requiring the first two moment conditions of the model distribution. Itis shown to be consistent in both selecting the number of components andestimating the mixing proportions and unknown regression parameters. Further, amodified EM algorithm is developed to seamlessly integrate model selection andestimation. Simulation studies are conducted to evaluate the finite sampleperformance of the proposed procedure. And it is further illustrated via ananalysis of a primary biliary cirrhosis data set.

Accelerated Method for Stochastic Composition Optimization with  Nonsmooth Regularization

  Stochastic composition optimization draws much attention recently and hasbeen successful in many emerging applications of machine learning, statisticalanalysis, and reinforcement learning. In this paper, we focus on thecomposition problem with nonsmooth regularization penalty. Previous workseither have slow convergence rate or do not provide complete convergenceanalysis for the general problem. In this paper, we tackle these two issues byproposing a new stochastic composition optimization method for compositionproblem with nonsmooth regularization penalty. In our method, we apply variancereduction technique to accelerate the speed of convergence. To the best of ourknowledge, our method admits the fastest convergence rate for stochasticcomposition optimization: for strongly convex composition problem, ouralgorithm is proved to admit linear convergence; for general compositionproblem, our algorithm significantly improves the state-of-the-art convergencerate from $O(T^{-1/2})$ to $O((n_1+n_2)^{{2}/{3}}T^{-1})$. Finally, we applyour proposed algorithm to portfolio management and policy evaluation inreinforcement learning. Experimental results verify our theoretical analysis.

Entity-aware Image Caption Generation

  Current image captioning approaches generate descriptions which lack specificinformation, such as named entities that are involved in the images. In thispaper we propose a new task which aims to generate informative image captions,given images and hashtags as input. We propose a simple but effective approachto tackle this problem. We first train a convolutional neural networks - longshort term memory networks (CNN-LSTM) model to generate a template captionbased on the input image. Then we use a knowledge graph based collectiveinference algorithm to fill in the template with specific named entitiesretrieved via the hashtags. Experiments on a new benchmark dataset collectedfrom Flickr show that our model generates news-style image descriptions withmuch richer information. Our model outperforms unimodal baselines significantlywith various evaluation metrics.

Decoupled Parallel Backpropagation with Convergence Guarantee

  Backpropagation algorithm is indispensable for the training of feedforwardneural networks. It requires propagating error gradients sequentially from theoutput layer all the way back to the input layer. The backward locking inbackpropagation algorithm constrains us from updating network layers inparallel and fully leveraging the computing resources. Recently, severalalgorithms have been proposed for breaking the backward locking. However, theirperformances degrade seriously when networks are deep. In this paper, wepropose decoupled parallel backpropagation algorithm for deep learningoptimization with convergence guarantee. Firstly, we decouple thebackpropagation algorithm using delayed gradients, and show that the backwardlocking is removed when we split the networks into multiple modules. Then, weutilize decoupled parallel backpropagation in two stochastic methods and provethat our method guarantees convergence to critical points for the non-convexproblem. Finally, we perform experiments for training deep convolutional neuralnetworks on benchmark datasets. The experimental results not only confirm ourtheoretical analysis, but also demonstrate that the proposed method can achievesignificant speedup without loss of accuracy.

Paper Abstract Writing through Editing Mechanism

  We present a paper abstract writing system based on an attentive neuralsequence-to-sequence model that can take a title as input and automaticallygenerate an abstract. We design a novel Writing-editing Network that can attendto both the title and the previously generated abstract drafts and theniteratively revise and polish the abstract. With two series of Turing tests,where the human judges are asked to distinguish the system-generated abstractsfrom human-written ones, our system passes Turing tests by junior domainexperts at a rate up to 30% and by non-expert at a rate up to 80%.

Naturally Phase Matched Lithium Niobate Nanocircuits for Integrated  Nonlinear Photonics

  High complexity, dense integrated nanophotonic circuits possessing strongnonlinearities are desirable for a breadth of applications in classical andquantum optics. In this work, we study natural phase matching via modalengineering in lithium niobate (LN) waveguides and microring resonators on chipfor second harmonic generation (SHG). By carefully engineering the geometrydispersion, we observe a $26\%~W^{-1}cm^{-2}$ normalized efficiency for SHG ina waveguide with submicron transverse mode confinement. With similarcross-sectional dimensions, we demonstrate phase matched SHG in a microringresonator with 10 times enhancement on the out-coupled second-harmonic power.Our platform is capable of harnessing the strongest optical nonlinear andelectro-optic effects in LN on chip with unrestricted planar circuit layouts.It offers opportunities for dense and scalable integration of efficientphotonic devices with low loss and high nonlinearity.

