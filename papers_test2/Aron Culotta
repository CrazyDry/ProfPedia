Detecting influenza outbreaks by analyzing Twitter messages

  We analyze over 500 million Twitter messages from an eight month period andfind that tracking a small number of flu-related keywords allows us to forecastfuture influenza rates with high accuracy, obtaining a 95% correlation withnational health statistics. We then analyze the robustness of this approach tospurious keyword matches, and we propose a document classification component tofilter these misleading messages. We find that this document classifier canreduce error rates by over half in simulated false alarm experiments, thoughmore research is needed to develop methods that are robust in cases ofextremely high noise.

Identifying leading indicators of product recalls from online reviews  using positive unlabeled learning and domain adaptation

  Consumer protection agencies are charged with safeguarding the public fromhazardous products, but the thousands of products under their jurisdiction makeit challenging to identify and respond to consumer complaints quickly. From theconsumer's perspective, online reviews can provide evidence of product defects,but manually sifting through hundreds of reviews is not always feasible. Inthis paper, we propose a system to mine Amazon.com reviews to identify productsthat may pose safety or health hazards. Since labeled data for this task arescarce, our approach combines positive unlabeled learning with domainadaptation to train a classifier from consumer complaints submitted to the U.S.Consumer Product Safety Commission. On a validation set of manually annotatedAmazon product reviews, we find that our approach results in an absolute F1score improvement of 8% over the best competing baseline. Furthermore, we applythe classifier to Amazon reviews of known recalled products; the classifieridentifies reviews reporting safety hazards prior to the recall date for 45% ofthe products. This suggests that the system may be able to provide an earlywarning system to alert consumers to hazardous products before an officialrecall is announced.

Controlling for Unobserved Confounds in Classification Using  Correlational Constraints

  As statistical classifiers become integrated into real-world applications, itis important to consider not only their accuracy but also their robustness tochanges in the data distribution. In this paper, we consider the case wherethere is an unobserved confounding variable $z$ that influences both thefeatures $\mathbf{x}$ and the class variable $y$. When the influence of $z$changes from training to testing data, we find that the classifier accuracy candegrade rapidly. In our approach, we assume that we can predict the value of$z$ at training time with some error. The prediction for $z$ is then fed toPearl's back-door adjustment to build our model. Because of the attenuationbias caused by measurement error in $z$, standard approaches to controlling for$z$ are ineffective. In response, we propose a method to properly control forthe influence of $z$ by first estimating its relationship with the classvariable $y$, then updating predictions for $z$ to match that estimatedrelationship. By adjusting the influence of $z$, we show that we can build amodel that exceeds competing baselines on accuracy as well as on robustnessover a range of confounding relationships.

When do Words Matter? Understanding the Impact of Lexical Choice on  Audience Perception using Individual Treatment Effect Estimation

  Studies across many disciplines have shown that lexical choice can affectaudience perception. For example, how users describe themselves in a socialmedia profile can affect their perceived socio-economic status. However, welack general methods for estimating the causal effect of lexical choice on theperception of a specific sentence. While randomized controlled trials mayprovide good estimates, they do not scale to the potentially millions ofcomparisons necessary to consider all lexical choices. Instead, in this paper,we first offer two classes of methods to estimate the effect on perception ofchanging one word to another in a given sentence. The first class of algorithmsbuilds upon quasi-experimental designs to estimate individual treatment effectsfrom observational data. The second class treats treatment effect estimation asa classification problem. We conduct experiments with three data sources (Yelp,Twitter, and Airbnb), finding that the algorithmic estimates align well withthose produced by randomized-control trials. Additionally, we find that it ispossible to transfer treatment effect classifiers across domains and stillmaintain high accuracy.

Inferring the Origin Locations of Tweets with Quantitative Confidence

  Social Internet content plays an increasingly critical role in many domains,including public health, disaster management, and politics. However, itsutility is limited by missing geographic information; for example, fewer than1.6% of Twitter messages (tweets) contain a geotag. We propose a scalable,content-based approach to estimate the location of tweets using a novel yetsimple variant of gaussian mixture models. Further, because real-worldapplications depend on quantified uncertainty for such estimates, we proposenovel metrics of accuracy, precision, and calibration, and we evaluate ourapproach accordingly. Experiments on 13 million global, comprehensivelymulti-lingual tweets show that our approach yields reliable, well-calibratedresults competitive with previous computationally intensive methods. We alsoshow that a relatively small number of training data are required for goodestimates (roughly 30,000 tweets) and models are quite time-invariant(effective on tweets many weeks newer than the training set). Finally, we showthat toponyms and languages with small geographic footprint provide the mostuseful location signals.

Mining the Demographics of Political Sentiment from Twitter Using  Learning from Label Proportions

  Opinion mining and demographic attribute inference have many applications insocial science. In this paper, we propose models to infer daily jointprobabilities of multiple latent attributes from Twitter data, such aspolitical sentiment and demographic attributes. Since it is costly andtime-consuming to annotate data for traditional supervised classification, weinstead propose scalable Learning from Label Proportions (LLP) models fordemographic and opinion inference using U.S. Census, national and statepolitical polls, and Cook partisan voting index as population level data. InLLP classification settings, the training data is divided into a set ofunlabeled bags, where only the label distribution in of each bag is known,removing the requirement of instance-level annotations. Our proposed LLP model,Weighted Label Regularization (WLR), provides a scalable generalization ofprior work on label regularization to support weights for samples inside bags,which is applicable in this setting where bags are arranged hierarchically(e.g., county-level bags are nested inside of state-level bags). We apply ourmodel to Twitter data collected in the year leading up to the 2016 U.S.presidential election, producing estimates of the relationships among politicalsentiment and demographics over time and place. We find that our approachclosely tracks traditional polling data stratified by demographic category,resulting in error reductions of 28-44% over baseline approaches. We alsoprovide descriptive evaluations showing how the model may be used to estimateinteractions among many variables and to identify linguistic temporalvariation, capabilities which are typically not feasible using traditionalpolling methods.

Co-training for Demographic Classification Using Deep Learning from  Label Proportions

  Deep learning algorithms have recently produced state-of-the-art accuracy inmany classification tasks, but this success is typically dependent on access tomany annotated training examples. For domains without such data, an attractivealternative is to train models with light, or distant supervision. In thispaper, we introduce a deep neural network for the Learning from LabelProportion (LLP) setting, in which the training data consist of bags ofunlabeled instances with associated label distributions for each bag. Weintroduce a new regularization layer, Batch Averager, that can be appended tothe last layer of any deep neural network to convert it from supervisedlearning to LLP. This layer can be implemented readily with existing deeplearning packages. To further support domains in which the data consist of twoconditionally independent feature views (e.g. image and text), we propose aco-training algorithm that iteratively generates pseudo bags and refits thedeep LLP model to improve classification accuracy. We demonstrate our models ondemographic attribute classification (gender and race/ethnicity), which hasmany applications in social media analysis, public health, and marketing. Weconduct experiments to predict demographics of Twitter users based on theirtweets and profile image, without requiring any user-level annotations fortraining. We find that the deep LLP approach outperforms baselines for bothtext and image features separately. Additionally, we find that co-trainingalgorithm improves image and text classification by 4% and 8% absolute F1,respectively. Finally, an ensemble of text and image classifiers furtherimproves the absolute F1 measure by 4% on average.

Deceptiveness of internet data for disease surveillance

  Quantifying how many people are or will be sick, and where, is a criticalingredient in reducing the burden of disease because it helps the public healthsystem plan and implement effective outbreak response. This process of diseasesurveillance is currently based on data gathering using clinical and laboratorymethods; this distributed human contact and resulting bureaucratic dataaggregation yield expensive procedures that lag real time by weeks or months.The promise of new surveillance approaches using internet data, such as webevent logs or social media messages, is to achieve the same goal but faster andcheaper. However, prior work in this area lacks a rigorous model of informationflow, making it difficult to assess the reliability of both specific approachesand the body of work as a whole.  We model disease surveillance as a Shannon communication. This new frameworklets any two disease surveillance approaches be compared using a unifiedvocabulary and conceptual model. Using it, we describe and compare thedeficiencies suffered by traditional and internet-based surveillance, introducea new risk metric called deceptiveness, and offer mitigations for some of thesedeficiencies. This framework also makes the rich tools of information theoryapplicable to disease surveillance. This better understanding will improve thedecision-making of public health practitioners by helping to leverageinternet-based surveillance in a way complementary to the strengths oftraditional surveillance.

Forecasting the presence and intensity of hostility on Instagram using  linguistic and social features

  Online antisocial behavior, such as cyberbullying, harassment, and trolling,is a widespread problem that threatens free discussion and has negativephysical and mental health consequences for victims and communities. Whileprior work has proposed automated methods to identify hostile comments inonline discussions, these methods work retrospectively on comments that havealready been posted, making it difficult to intervene before an interactionescalates. In this paper we instead consider the problem of forecasting futurehostilities in online discussions, which we decompose into two tasks: (1) givenan initial sequence of non-hostile comments in a discussion, predict whethersome future comment will contain hostility; and (2) given the first hostilecomment in a discussion, predict whether this will lead to an escalation ofhostility in subsequent comments. Thus, we aim to forecast both the presenceand intensity of hostile comments based on linguistic and social features fromearlier comments. To evaluate our approach, we introduce a corpus of over 30Kannotated Instagram comments from over 1,100 posts. Our approach is able topredict the appearance of a hostile comment on an Instagram post ten or morehours in the future with an AUC of .82 (task 1), and can furthermoredistinguish between high and low levels of future hostility with an AUC of .91(task 2).

