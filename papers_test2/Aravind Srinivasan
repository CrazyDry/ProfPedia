An Extension of the Lovasz Local Lemma, and its Applications to Integer  Programming

  The Lovasz Local Lemma due to Erdos and Lovasz is a powerful tool in provingthe existence of rare events. We present an extension of this lemma, whichworks well when the event to be shown to exist is a conjunction of individualevents, each of which asserts that a random variable does not deviate much fromits mean. As applications, we consider two classes of NP-hard integer programs:minimax and covering integer programs. A key technique, randomized rounding oflinear relaxations, was developed by Raghavan and Thompson to derive goodapproximation algorithms for such problems. We use our extension of the LocalLemma to prove that randomized rounding produces, with non-zero probability,much better feasible solutions than known before, if the constraint matrices ofthese integer programs are column-sparse (e.g., routing using short paths,problems on hypergraphs with small dimension/degree). This complements certainwell-known results from discrepancy theory. We also generalize the method ofpessimistic estimators due to Raghavan, to obtain constructive (algorithmic)versions of our results for covering integer programs.

A New Approximation Technique for Resource-Allocation Problems

  We develop a rounding method based on random walks in polytopes, which leadsto improved approximation algorithms and integrality gaps for severalassignment problems that arise in resource allocation and scheduling. Inparticular, it generalizes the work of Shmoys and Tardos on the generalizedassignment problem to the setting where some jobs can be dropped. Newconcentration bounds for random bipartite matching are developed as well.

Lift-and-Round to Improve Weighted Completion Time on Unrelated Machines

  We consider the problem of scheduling jobs on unrelated machines so as tominimize the sum of weighted completion times. Our main result is a$(3/2-c)$-approximation algorithm for some fixed $c>0$, improving upon thelong-standing bound of 3/2 (independently due to Skutella, Journal of the ACM,2001, and Sethuraman & Squillante, SODA, 1999). To do this, we first introducea new lift-and-project based SDP relaxation for the problem. This is necessaryas the previous convex programming relaxations have an integrality gap of$3/2$. Second, we give a new general bipartite-rounding procedure that producesan assignment with certain strong negative correlation properties.

Approximation algorithms for stochastic clustering

  We consider stochastic settings for clustering, and develop provably-good(approximation) algorithms for a number of these notions. These algorithmsallow one to obtain better approximation ratios compared to the usualdeterministic clustering setting. Additionally, they offer a number ofadvantages including providing fairer clustering and clustering which hasbetter long-term behavior for each user. In particular, they ensure that *everyuser* is guaranteed to get good service (on average). We also complement someof these with impossibility results.

Partial resampling to approximate covering integer programs

  We consider column-sparse covering integer programs, a generalization of setcover, which have attracted a long line of research developing (randomized)approximation algorithms. We develop a new rounding scheme based on the PartialResampling variant of the Lov\'{a}sz Local Lemma developed by Harris &Srinivasan (2013).  This achieves an approximation ratio of $1 + \frac{\ln(\Delta_1+1)}{a_{\text{min}}} + O\Big( \log(1 + \sqrt{ \frac{\log(\Delta_1+1)}{a_{\text{min}}}}) \Big)$, where $a_{\text{min}}$ is the minimumcovering constraint and $\Delta_1$ is the maximum $\ell_1$-norm of any columnof the covering matrix (whose entries are scaled to lie in $[0,1]$). When thereare additional constraints on the sizes of the variables, we show anapproximation ratio of $\ln \Delta_0 + O(\log \log \Delta_0)$ (where $\Delta_0$is the maximum number of non-zero entries in any column of the coveringmatrix). We also show nearly-matching inapproximability and integrality-gaplower bounds. These results improve asymptotically, in several different ways,over results shown by Srinivasan (2006) and Kolliopoulos & Young (2005).  We show also that the rounding process leads to negative correlation amongthe variables. This allows us to automatically handle multi-criteria programs,efficiently achieving approximation ratios which are essentially equivalent tothe single-criterion case and apply even when the number of criteria is large.

On k-Column Sparse Packing Programs

  We consider the class of packing integer programs (PIPs) that are columnsparse, i.e. there is a specified upper bound k on the number of constraintsthat each variable appears in. We give an (ek+o(k))-approximation algorithm fork-column sparse PIPs, improving on recent results of $k^2\cdot 2^k$ and$O(k^2)$. We also show that the integrality gap of our linear programmingrelaxation is at least 2k-1; it is known that k-column sparse PIPs are$\Omega(k/ \log k)$-hard to approximate. We also extend our result (at the lossof a small constant factor) to the more general case of maximizing a submodularobjective over k-column sparse packing constraints.

Fault-Tolerant Facility Location: a randomized dependent LP-rounding  algorithm

  We give a new randomized LP-rounding 1.725-approximation algorithm for themetric Fault-Tolerant Uncapacitated Facility Location problem. This improves onthe previously best known 2.076-approximation algorithm of Swamy & Shmoys. Tothe best of our knowledge, our work provides the first application of adependent-rounding technique in the domain of facility location. The analysisof our algorithm benefits from, and extends, methods developed forUncapacitated Facility Location; it also helps uncover new properties of thedependent-rounding approach. An important concept that we develop is a novel,hierarchical clustering scheme. Typically, LP-rounding approximation algorithmsfor facility location problems are based on partitioning facilities intodisjoint clusters and opening at least one facility in each cluster. We extendthis approach and construct a laminar family of clusters, which then guides therounding procedure. It allows to exploit properties of dependent rounding, andprovides a quite tight analysis resulting in the improved approximation ratio.

Network Clustering Approximation Algorithm Using One Pass Black Box  Sampling

  Finding a good clustering of vertices in a network, where vertices in thesame cluster are more tightly connected than those in different clusters, is auseful, important, and well-studied task. Many clustering algorithms scalewell, however they are not designed to operate upon internet-scale networkswith billions of nodes or more. We study one of the fastest and most memoryefficient algorithms possible - clustering based on the connected components ina random edge-induced subgraph. When defining the cost of a clustering to beits distance from such a random clustering, we show that this surprisinglysimple algorithm gives a solution that is within an expected factor of two orthree of optimal with either of two natural distance functions. In fact, thisapproximation guarantee works for any problem where there is a probabilitydistribution on clusterings. We then examine the behavior of this algorithm inthe context of social network trust inference.

On Random Sampling Auctions for Digital Goods

  In the context of auctions for digital goods, an interesting random samplingauction has been proposed by Goldberg, Hartline, and Wright [2001]. Thisauction has been analyzed by Feige, Flaxman, Hartline, and Kleinberg [2005],who have shown that it is 15-competitive in the worst case {which issubstantially better than the previously proven constant bounds but still farfrom the conjectured competitive ratio of 4. In this paper, we prove that theaforementioned random sampling auction is indeed 4-competitive for a largeclass of instances where the number of bids above (or equal to) the optimalsale price is at least 6. We also show that it is 4:68-competitive for thesmall class of remaining instances thus leaving a negligible gap between thelower and upper bound. We employ a mix of probabilistic techniques and dynamicprogramming to compute these bounds.

On Computing Maximal Independent Sets of Hypergraphs in Parallel

  Whether or not the problem of finding maximal independent sets (MIS) inhypergraphs is in (R)NC is one of the fundamental problems in the theory ofparallel computing. Unlike the well-understood case of MIS in graphs, for thehypergraph problem, our knowledge is quite limited despite considerable work.It is known that the problem is in \emph{RNC} when the edges of the hypergraphhave constant size. For general hypergraphs with $n$ vertices and $m$ edges,the fastest previously known algorithm works in time $O(\sqrt{n})$ with$\text{poly}(m,n)$ processors. In this paper we give an EREW PRAM algorithmthat works in time $n^{o(1)}$ with $\text{poly}(m,n)$ processors on generalhypergraphs satisfying $m \leq n^{\frac{\log^{(2)}n}{8(\log^{(3)}n)^2}}$, where$\log^{(2)}n = \log\log n$ and $\log^{(3)}n = \log\log\log n$. Our algorithm isbased on a sampling idea that reduces the dimension of the hypergraph andemploys the algorithm for constant dimension hypergraphs as a subroutine.

An Improved Approximation for $k$-median, and Positive Correlation in  Budgeted Optimization

  Dependent rounding is a useful technique for optimization problems with hardbudget constraints. This framework naturally leads to \emph{negativecorrelation} properties. However, what if an application naturally calls fordependent rounding on the one hand, and desires \emph{positive} correlation onthe other? More generally, we develop algorithms that guarantee the knownproperties of dependent rounding, but also have nearly best-possible behavior -near-independence, which generalizes positive correlation - on "small" subsetsof the variables. The recent breakthrough of Li & Svensson for the classical$k$-median problem has to handle positive correlation in certaindependent-rounding settings, and does so implicitly. We improve uponLi-Svensson's approximation ratio for $k$-median from $2.732 + \epsilon$ to$2.675 + \epsilon$ by developing an algorithm that improves upon variousaspects of their work. Our dependent-rounding approach helps us improve thedependence of the runtime on the parameter $\epsilon$ from Li-Svensson's$N^{O(1/\epsilon^2)}$ to $N^{O((1/\epsilon) \log(1/\epsilon))}$.

The Moser-Tardos Framework with Partial Resampling

  The resampling algorithm of Moser \& Tardos is a powerful approach to developconstructive versions of the Lov\'{a}sz Local Lemma (LLL). We generalize thisto partial resampling: when a bad event holds, we resample anappropriately-random subset of the variables that define this event, ratherthan the entire set as in Moser & Tardos. This is particularly useful when thebad events are determined by sums of random variables. This leads to severalimproved algorithmic applications in scheduling, graph transversals, packetrouting etc. For instance, we settle a conjecture of Szab\'{o} & Tardos (2006)on graph transversals asymptotically, and obtain improved approximation ratiosfor a packet routing problem of Leighton, Maggs, & Rao (1994).

Fairness in Resource Allocation and Slowed-down Dependent Rounding

  We consider an issue of much current concern: could fairness, an issue thatis already difficult to guarantee, worsen when algorithms run much of ourlives? We consider this in the context of resource-allocation problems, we showthat algorithms can guarantee certain types of fairness in a verifiable way.Our conceptual contribution is a simple approach to fairness in this context,which only requires that all users trust some public lottery. Our technicalcontributions are in ways to address the $k$-center and knapsack-centerproblems that arise in this context: we develop a novel dependent-roundingtechnique that, via the new ingredients of "slowing down" and additionalrandomization, guarantees stronger correlation properties than known before.

A Lottery Model for Center-type Problems With Outliers

  In this paper, we give tight approximation algorithms for the $k$-center andmatroid center problems with outliers. Unfairness arises naturally in thissetting: certain clients could always be considered as outliers. To addressthis issue, we introduce a lottery model in which each client $j$ is allowed tosubmit a parameter $p_j \in [0,1]$ and we look for a random solution thatcovers every client $j$ with probability at least $p_j$. Our techniques includea randomized rounding procedure to round a point inside a matroid intersectionpolytope to a basis plus at most one extra item such that all marginalprobabilities are preserved and such that a certain linear function of thevariables does not decrease in the process with probability one.

Algorithms to Approximate Column-Sparse Packing Problems

  Column-sparse packing problems arise in several contexts in bothdeterministic and stochastic discrete optimization. We present two unifyingideas, (non-uniform) attenuation and multiple-chance algorithms, to obtainimproved approximation algorithms for some well-known families of suchproblems. As three main examples, we attain the integrality gap, up tolower-order terms, for known LP relaxations for k-column sparse packing integerprograms (Bansal et al., Theory of Computing, 2012) and stochastic k-setpacking (Bansal et al., Algorithmica, 2012), and go "half the remainingdistance" to optimal for a major integrality-gap conjecture of Furedi, Kahn andSeymour on hypergraph matching (Combinatorica, 1993).

Approximation algorithms for stochastic and risk-averse optimization

  We present improved approximation algorithms in stochastic optimization. Weprove that the multi-stage stochastic versions of covering integer programs(such as set cover and vertex cover) admit essentially the same approximationalgorithms as their standard (non-stochastic) counterparts; this improves uponwork of Swamy \& Shmoys which shows an approximability that dependsmultiplicatively on the number of stages. We also present approximationalgorithms for facility location and some of its variants in the $2$-stagerecourse model, improving on previous approximation guarantees. We give a$2.2975$-approximation algorithm in the standard polynomial-scenario model andan algorithm with an expected per-scenario $2.4957$-approximation guarantee,which is applicable to the more general black-box distribution model.

New Constructive Aspects of the Lovasz Local Lemma

  The Lov\'{a}sz Local Lemma (LLL) states that the probability that none of aset of "bad" events happens is nonzero if the probability of each event issmall compared to the number of bad events it depends on. A series of resultshave provided algorithms to efficiently construct structures whose existence is(non-constructively) guaranteed by the full asymmetric LLL, culminating in therecent breakthrough of Moser & Tardos. We show that the output distribution ofthe Moser-Tardos procedure has sufficient randomness, leading to two classes ofalgorithmic applications. We first show that when an LLL application provides asmall amount of slack, the running time of the Moser-Tardos algorithm ispolynomial in the number of underlying independent variables (not events!), andcan thus be used to give efficient constructions in cases where the underlyingproof applies the LLL to super-polynomially many events (or where finding a badevent that holds is computationally hard). We demonstrate our method onapplications including: the first constant-factor approximation algorithm forthe Santa Claus problem, as well as efficient algorithms for acyclic edgecoloring, non-repetitive graph colorings, and Ramsey-type graphs. Second, weshow applications to cases where a few of the bad events can hold, leading tothe first such algorithmic applications of the LLL: MAX $k$-SAT is anillustrative example of this.

LP-rounding algorithms for facility-location problems

  We study LP-rounding approximation algorithms for metric uncapacitatedfacility-location problems. We first give a new analysis for the algorithm ofChudak and Shmoys, which differs from the analysis of Byrka and Aardal in thatnow we do not need any bound based on the solution to the dual LP program.Besides obtaining the optimal bifactor approximation as do Byrka and Aardal, wecan now also show that the algorithm with scaling parameter equaling 1.58 is,in fact, an 1.58-approximation algorithm. More importantly, we suggest anapproach based on additional randomization and analyses such as ours, whichcould achieve or approach the conjectured optimal 1.46...--approximation forthis basic problem.  Next, using essentially the same techniques, we obtain improved approximationalgorithms in the 2-stage stochastic variant of the problem, where we must opena subset of facilities having only stochastic information about the futuredemand from the clients. For this problem we obtain a 2.2975-approximationalgorithm in the standard setting, and a 2.4957-approximation in the morerestricted, per-scenario setting.  We then study robust fault-tolerant facility location, introduced by Chechikand Peleg: solutions here are designed to provide low connection cost in caseof failure of up to $k$ facilities. Chechik and Peleg gave a 6.5-approximationalgorithm for $k=1$ and a ($7.5k + 1.5$)-approximation algorithm for general$k$. We improve this to an LP-rounding $(k+5+4/k)$-approximation algorithm. Wealso observe that in case of oblivious failures the expected approximationratio can be reduced to $k + 1.5$, and that the integrality gap of the naturalLP-relaxation of the problem is at least $k + 1$.

'Beating the news' with EMBERS: Forecasting Civil Unrest using Open  Source Indicators

  We describe the design, implementation, and evaluation of EMBERS, anautomated, 24x7 continuous system for forecasting civil unrest across 10countries of Latin America using open source indicators such as tweets, newssources, blogs, economic indicators, and other data sources. Unlikeretrospective studies, EMBERS has been making forecasts into the future sinceNov 2012 which have been (and continue to be) evaluated by an independent T&Eteam (MITRE). Of note, EMBERS has successfully forecast the uptick and downtickof incidents during the June 2013 protests in Brazil. We outline the systemarchitecture of EMBERS, individual models that leverage specific data sources,and a fusion and suppression engine that supports trading off specificevaluation criteria. EMBERS also provides an audit trail interface that enablesthe investigation of why specific predictions were made along with the datautilized for forecasting. Through numerous evaluations, we demonstrate thesuperiority of EMBERS over baserate methods and its capability to forecastsignificant societal happenings.

Online Stochastic Matching: New Algorithms and Bounds

  Online matching has received significant attention over the last 15 years dueto its close connection to Internet advertising. As the seminal work of Karp,Vazirani, and Vazirani has an optimal (1 - 1/e) competitive ratio in thestandard adversarial online model, much effort has gone into developing usefulonline models that incorporate some stochasticity in the arrival process. Onesuch popular model is the "known I.I.D. model" where different customer-typesarrive online from a known distribution. We develop algorithms with improvedcompetitive ratios for some basic variants of this model with integral arrivalrates, including (a) the case of general weighted edges, where we improve thebest-known ratio of 0.667 due to Haeupler, Mirrokni and Zadimoghaddam to 0.705;and (b) the vertex-weighted case, where we improve the 0.7250 ratio of Jailletand Lu to 0.7299. We also consider an extension of stochastic rewards, avariant where each edge has an independent probability of being present. Forthe setting of stochastic rewards with non-integral arrival rates, we present asimple optimal non-adaptive algorithm with a ratio of 1 - 1/e. For the specialcase where each edge is unweighted and has a uniform constant probability ofbeing present, we improve upon 1 - 1/e by proposing a strengthened LPbenchmark.

A constructive algorithm for the LLL on permutations

  While there has been significant progress on algorithmic aspects of theLov\'{a}sz Local Lemma (LLL) in recent years, a noteworthy exception is whenthe LLL is used in the context of random permutations. The breakthroughalgorithm of Moser & Tardos only works in the setting of independent variables,and does not apply in this context. We resolve this by developing a randomizedpolynomial-time algorithm for such applications. A noteworthy application isfor Latin transversals: the best-known general result here (Bissacot et al.,improving on Erd\H{o}s and Spencer), states that any $n \times n$ matrix inwhich each entry appears at most $(27/256)n$ times, has a Latin transversal. Wepresent the first polynomial-time algorithm to construct such a transversal. Wealso develop RNC algorithms for Latin transversals, rainbow Hamiltonian cycles,strong chromatic number, and hypergraph packing.  In addition to efficiently finding a configuration which avoids bad-events,the algorithm of Moser & Tardos has many powerful extensions and properties.These include a well-characterized distribution on the output distribution,parallel algorithms, and a partial resampling variant. We show that ouralgorithm has nearly all of the same useful properties as the Moser-Tardosalgorithm, and present a comparison of this aspect with recent works on the LLLin general probability spaces.

Dependent rounding for knapsack/partition constraints and facility  location

  We develop a new dependent rounding algorithm targeting systems with amixture of knapsack and partition constraints. Such constraint systems arise ina number of facility location problems, and we study two in particular:multi-knapsack median and multi-knapsack center. Our rounding algorithms givesnew approximation and pseudo-approximation algorithms for these problems.  The new dependent rounding process has two main technical advantages overprevious ones. First, it gives substantial ``near-independence" propertiesamong the variables being rounded. These are critical for facility locationproblems with highly non-linear objective functions.  Second, the rounding process lends itself to a new type ofpseudo-approximation guarantee, which has an *additive* violation of theknapsack constraints. This is in contrast to previous algorithms whichtypically give $(1+\epsilon)$--multiplicative violations of these constraints.This additive violation is different from additive error; it is a more flexiblenotion which can be used as a technical tool to achieve new and more efficientmultiplicative pseudo-approximations and even true approximation algorithms.  One key technical tool we develop, which may be of independent interest, is anew tail bound analogous to Feige (2006) for sums of random variables withunbounded variances.

Allocation Problems in Ride-Sharing Platforms: Online Matching with  Offline Reusable Resources

  Bipartite matching markets pair agents on one side of a market with agents,items, or contracts on the opposing side. Prior work addresses online bipartitematching markets, where agents arrive over time and are dynamically matched toa known set of disposable resources. In this paper, we propose a new model,Online Matching with (offline) Reusable Resources under Known AdversarialDistributions (OM-RR-KAD), in which resources on the offline side are reusableinstead of disposable; that is, once matched, resources become available againat some point in the future. We show that our model is tractable by presentingan LP-based adaptive algorithm that achieves an online competitive ratio of 1/2- eps for any given eps greater than 0. We also show that no non-adaptivealgorithm can achieve a ratio of 1/2 + o(1) based on the same benchmark LP.Through a data-driven analysis on a massive openly-available dataset, we showour model is robust enough to capture the application of taxi dispatchingservices and ride-sharing systems. We also present heuristics that perform wellin practice.

Balancing Relevance and Diversity in Online Bipartite Matching via  Submodularity

  In bipartite matching problems, vertices on one side of a bipartite graph arepaired with those on the other. In its online variant, one side of the graph isavailable offline, while the vertices on the other side arrive online. When avertex arrives, an irrevocable and immediate decision should be made by thealgorithm; either match it to an available vertex or drop it. Examples of suchproblems include matching workers to firms, advertisers to keywords, organs topatients, and so on. Much of the literature focuses on maximizing the totalrelevance---modeled via total weight---of the matching. However, in manyreal-world problems, it is also important to consider contributions ofdiversity: hiring a diverse pool of candidates, displaying a relevant butdiverse set of ads, and so on. In this paper, we propose the Online SubmodularBipartite Matching (\osbm) problem, where the goal is to maximize a submodularfunction $f$ over the set of matched edges. This objective is general enough tocapture the notion of both diversity (\emph{e.g.,} a weighted coveragefunction) and relevance (\emph{e.g.,} the traditional linear function)---aswell as many other natural objective functions occurring in practice(\emph{e.g.,} limited total budget in advertising settings). We propose novelalgorithms that have provable guarantees and are essentially optimal whenrestricted to various special cases. We also run experiments on real-world andsynthetic datasets to validate our algorithms.

Algorithmic and enumerative aspects of the Moser-Tardos distribution

  Moser & Tardos have developed a powerful algorithmic approach (henceforth"MT") to the Lovasz Local Lemma (LLL); the basic operation done in MT and itsvariants is a search for "bad" events in a current configuration. In theinitial stage of MT, the variables are set independently. We examine thedistributions on these variables which arise during intermediate stages of MT.We show that these configurations have a more or less "random" form, buildingfurther on the "MT-distribution" concept of Haeupler et al. in understandingthe (intermediate and) output distribution of MT. This has a variety ofalgorithmic applications; the most important is that bad events can be foundrelatively quickly, improving upon MT across the complexity spectrum: it makessome polynomial-time algorithms sub-linear (e.g., for Latin transversals, whichare of basic combinatorial interest), gives lower-degree polynomial run-timesin some settings, transforms certain super-polynomial-time algorithms intopolynomial-time ones, and leads to Las Vegas algorithms for some coloringproblems for which only Monte Carlo algorithms were known.  We show that in certain conditions when the LLL condition is violated, avariant of the MT algorithm can still produce a distribution which avoids mostof the bad events. We show in some cases this MT variant can run faster thanthe original MT algorithm itself, and develop the first-known criterion for thecase of the asymmetric LLL. This can be used to find partial Latin transversals-- improving upon earlier bounds of Stein (1975) -- among other applications.We furthermore give applications in enumeration, showing that most applications(where we aim for all or most of the bad events to be avoided) have many moresolutions than known before by proving that the MT-distribution has "large"min-entropy and hence that its support-size is large.

Improved bounds and algorithms for graph cuts and network reliability

  Karger (SIAM Journal on Computing, 1999) developed the first fully-polynomialapproximation scheme to estimate the probability that a graph $G$ becomesdisconnected, given that its edges are removed independently with probability$p$. This algorithm runs in $n^{5+o(1)} \epsilon^{-3}$ time to obtain anestimate within relative error $\epsilon$.  We improve this run-time through algorithmic and graph-theoretic advances.First, there is a certain key sub-problem encountered by Karger, for which ageneric estimation procedure is employed, we show that this has a specialstructure for which a much more efficient algorithm can be used. Second, weshow better bounds on the number of edge cuts which are likely to fail. Here,Karger's analysis uses a variety of bounds for various graph parameters, weshow that these bounds cannot be simultaneously tight. We describe a new graphparameter, which simultaneously influences all the bounds used by Karger, andobtain much tighter estimates of the cut structure of $G$. These techniquesallow us to improve the runtime to $n^{3+o(1)} \epsilon^{-2}$, our results alsorigorously prove certain experimental observations of Karger & Tai (Proc.ACM-SIAM Symposium on Discrete Algorithms, 1997). Our rigorous proofs aremotivated by certain non-rigorous differential-equation approximations which,however, provably track the worst-case trajectories of the relevant parameters.  A key driver of Karger's approach (and other cut-related results) is a boundon the number of small cuts: we improve these estimates when the min-cut sizeis "small" and odd, augmenting, in part, a result of Bixby (Bulletin of theAMS, 1974).

Attenuate Locally, Win Globally: An Attenuation-based Framework for  Online Stochastic Matching with Timeouts

  Online matching problems have garnered significant attention in recent yearsdue to numerous applications in e-commerce, online advertisements,ride-sharing, etc. Many of them capture the uncertainty in the real world byincluding stochasticity in both the arrival process and the matching process.The Online Stochastic Matching with Timeouts problem introduced by Bansal, etal., (Algorithmica, 2012) models matching markets (e.g., E-Bay, Amazon). Buyersarrive from an independent and identically distributed (i.i.d.) knowndistribution on buyer profiles and can be shown a list of items one at a time.Each buyer has some probability of purchasing each item and a limit (timeout)on the number of items they can be shown.  Bansal et al., (Algorithmica, 2012) gave a 0.12-competitive algorithm whichwas improved by Adamczyk, et al., (ESA, 2015) to 0.24. We present an onlineattenuation framework that uses an algorithm for offline stochastic matching asa black box. On the upper bound side, we show that this framework, combinedwith a black-box adapted from Bansal et al., (Algorithmica, 2012), yields anonline algorithm which nearly doubles the ratio to 0.46. On the lower boundside, we show that no algorithm can achieve a ratio better than 0.632 using thestandard LP for this problem. This framework has a high potential for furtherimprovements since new algorithms for offline stochastic matching can directlyimprove the ratio for the online problem.  Our online framework also has the potential for a variety of extensions. Forexample, we introduce a natural generalization: Online Stochastic Matching withTwo-sided Timeouts in which both online and offline vertices have timeouts. Ourframework provides the first algorithm for this problem achieving a ratio of0.30. We once again use the algorithm of Adamczyk et al., (ESA, 2015) as ablack-box and plug-it into our framework.

