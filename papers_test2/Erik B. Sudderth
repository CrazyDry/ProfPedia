Bayesian Nonparametric Inference of Switching Linear Dynamical Systems

  Many complex dynamical phenomena can be effectively modeled by a system thatswitches among a set of conditionally linear dynamical modes. We consider twosuch models: the switching linear dynamical system (SLDS) and the switchingvector autoregressive (VAR) process. Our Bayesian nonparametric approachutilizes a hierarchical Dirichlet process prior to learn an unknown number ofpersistent, smooth dynamical modes. We additionally employ automatic relevancedetermination to infer a sparse set of dynamic dependencies allowing us tolearn SLDS with varying state dimension or switching VAR processes with varyingautoregressive order. We develop a sampling algorithm that combines a truncatedapproximation to the Dirichlet process with efficient joint sampling of themode and state sequences. The utility and flexibility of our model aredemonstrated on synthetic data, sequences of dancing honey bees, the IBOVESPAstock index, and a maneuvering target tracking application.

Joint Modeling of Multiple Related Time Series via the Beta Process

  We propose a Bayesian nonparametric approach to the problem of jointlymodeling multiple related time series. Our approach is based on the discoveryof a set of latent, shared dynamical behaviors. Using a beta process prior, thesize of the set and the sharing pattern are both inferred from data. We developefficient Markov chain Monte Carlo methods based on the Indian buffet processrepresentation of the predictive distribution of the beta process, withoutrelying on a truncated model. In particular, our approach uses the sum-productalgorithm to efficiently compute Metropolis-Hastings acceptance probabilities,and explores new dynamical behaviors via birth and death proposals. We examinethe benefits of our proposed feature-based model on several synthetic datasets,and also demonstrate promising results on unsupervised segmentation of visualmotion capture data.

Gibbs Sampling in Open-Universe Stochastic Languages

  Languages for open-universe probabilistic models (OUPMs) can representsituations with an unknown number of objects and iden- tity uncertainty. Whilesuch cases arise in a wide range of important real-world appli- cations,existing general purpose inference methods for OUPMs are far less efficientthan those available for more restricted lan- guages and model classes. Thispaper goes some way to remedying this deficit by in- troducing, and provingcorrect, a generaliza- tion of Gibbs sampling to partial worlds with possiblyvarying model structure. Our ap- proach draws on and extends previous genericOUPM inference methods, as well as aux- iliary variable samplers fornonparametric mixture models. It has been implemented for BLOG, a well-knownOUPM language. Combined with compile-time optimizations, the resultingalgorithm yields very substan- tial speedups over existing methods on sev- eraltest cases, and substantially improves the practicality of OUPM languagesgenerally.

Fast Learning of Clusters and Topics via Sparse Posteriors

  Mixture models and topic models generate each observation from a singlecluster, but standard variational posteriors for each observation assignpositive probability to all possible clusters. This requires dense storage andruntime costs that scale with the total number of clusters, even thoughtypically only a few clusters have significant posterior mass for any datapoint. We propose a constrained family of sparse variational distributions thatallow at most $L$ non-zero entries, where the tunable threshold $L$ trades offspeed for accuracy. Previous sparse approximations have used hard assignments($L=1$), but we find that moderate values of $L>1$ provide superiorperformance. Our approach easily integrates with stochastic or incrementaloptimization algorithms to scale to millions of examples. Experiments trainingmixture models of image patches and topic models for news articles show thatour approach produces better-quality models in far less time than baselinemethods.

Prediction-Constrained Training for Semi-Supervised Mixture and Topic  Models

  Supervisory signals have the potential to make low-dimensional datarepresentations, like those learned by mixture and topic models, moreinterpretable and useful. We propose a framework for training latent variablemodels that explicitly balances two goals: recovery of faithful generativeexplanations of high-dimensional data, and accurate prediction of associatedsemantic labels. Existing approaches fail to achieve these goals due to anincomplete treatment of a fundamental asymmetry: the intended application isalways predicting labels from data, not data from labels. Ourprediction-constrained objective for training generative models coherentlyintegrates loss-based supervisory signals while enabling effectivesemi-supervised learning from partially labeled data. We derive learningalgorithms for semi-supervised mixture and topic models using stochasticgradient descent with automatic differentiation. We demonstrate improvedprediction quality compared to several previous supervised topic models,achieving predictions competitive with high-dimensional logistic regression ontext sentiment analysis and electronic health records tasks whilesimultaneously learning interpretable topics.

Cascaded Scene Flow Prediction using Semantic Segmentation

  Given two consecutive frames from a pair of stereo cameras, 3D scene flowmethods simultaneously estimate the 3D geometry and motion of the observedscene. Many existing approaches use superpixels for regularization, but maypredict inconsistent shapes and motions inside rigidly moving objects. Weinstead assume that scenes consist of foreground objects rigidly moving infront of a static background, and use semantic cues to produce pixel-accuratescene flow estimates. Our cascaded classification framework accurately models3D scenes by iteratively refining semantic segmentation masks, stereocorrespondences, 3D rigid motion estimates, and optical flow fields. Weevaluate our method on the challenging KITTI autonomous driving benchmark, andshow that accounting for the motion of segmented vehicles leads tostate-of-the-art performance.

Bayesian Paragraph Vectors

  Word2vec (Mikolov et al., 2013) has proven to be successful in naturallanguage processing by capturing the semantic relationships between differentwords. Built on top of single-word embeddings, paragraph vectors (Le andMikolov, 2014) find fixed-length representations for pieces of text witharbitrary lengths, such as documents, paragraphs, and sentences. In this work,we propose a novel interpretation for neural-network-based paragraph vectors bydeveloping an unsupervised generative model whose maximum likelihood solutioncorresponds to traditional paragraph vectors. This probabilistic formulationallows us to go beyond point estimates of parameters and to perform Bayesianposterior inference. We find that the entropy of paragraph vectors decreaseswith the length of documents, and that information about posterior uncertaintyimproves performance in supervised learning tasks such as sentiment analysisand paraphrase detection.

Prediction-Constrained Topic Models for Antidepressant Recommendation

  Supervisory signals can help topic models discover low-dimensional datarepresentations that are more interpretable for clinical tasks. We propose aframework for training supervised latent Dirichlet allocation that balances twogoals: faithful generative explanations of high-dimensional data and accurateprediction of associated class labels. Existing approaches fail to balancethese goals by not properly handling a fundamental asymmetry: the intended taskis always predicting labels from data, not data from labels. Our newprediction-constrained objective trains models that predict labels from heldoutdata well while also producing good generative likelihoods and interpretabletopic-word parameters. In a case study on predicting depression medicationsfrom electronic health records, we demonstrate improved recommendationscompared to previous supervised topic models and high- dimensional logisticregression from words alone.

A Fusion Approach for Multi-Frame Optical Flow Estimation

  To date, top-performing optical flow estimation methods only take pairs ofconsecutive frames into account. While elegant and appealing, the idea of usingmore than two frames has not yet produced state-of-the-art results. We presenta simple, yet effective fusion approach for multi-frame optical flow thatbenefits from longer-term temporal cues. Our method first warps the opticalflow from previous frames to the current, thereby yielding multiple plausibleestimates. It then fuses the complementary information carried by theseestimates into a new optical flow field. At the time of writing, our methodranks first among published results in the MPI Sintel and KITTI 2015benchmarks. Our models will be available on https://github.com/NVlabs/PWC-Net.

Multi-layer Depth and Epipolar Feature Transformers for 3D Scene  Reconstruction

  We tackle the problem of automatically reconstructing a complete 3D model ofa scene from a single RGB image. This challenging task requires inferring theshape of both visible and occluded surfaces. Our approach utilizesviewer-centered, multi-layer representation of scene geometry adapted fromrecent methods for single object shape completion. To improve the accuracy ofview-centered representations for complex scenes, we introduce a novel"Epipolar Feature Transformer" that transfers convolutional network featuresfrom an input view to other virtual camera viewpoints, and thus better coversthe 3D scene geometry. Unlike existing approaches that first detect andlocalize objects in 3D, and then infer object shape using category-specificmodels, our approach is fully convolutional, end-to-end differentiable, andavoids the resolution and memory limitations of voxel representations. Wedemonstrate the advantages of multi-layer depth representations and epipolarfeature transformers on the reconstruction of a large database of indoorscenes.

A sticky HDP-HMM with application to speaker diarization

  We consider the problem of speaker diarization, the problem of segmenting anaudio recording of a meeting into temporal segments corresponding to individualspeakers. The problem is rendered particularly difficult by the fact that weare not allowed to assume knowledge of the number of people participating inthe meeting. To address this problem, we take a Bayesian nonparametric approachto speaker diarization that builds on the hierarchical Dirichlet process hiddenMarkov model (HDP-HMM) of Teh et al. [J. Amer. Statist. Assoc. 101 (2006)1566--1581]. Although the basic HDP-HMM tends to over-segment the audiodata---creating redundant states and rapidly switching among them---we describean augmented HDP-HMM that provides effective control over the switching rate.We also show that this augmentation makes it possible to treat emissiondistributions nonparametrically. To scale the resulting architecture torealistic diarization problems, we develop a sampling algorithm that employs atruncated approximation of the Dirichlet process to jointly resample the fullstate sequence, greatly improving mixing rates. Working with a benchmark NISTdata set, we show that our Bayesian nonparametric architecture yieldsstate-of-the-art speaker diarization results.

Joint modeling of multiple time series via the beta process with  application to motion capture segmentation

  We propose a Bayesian nonparametric approach to the problem of jointlymodeling multiple related time series. Our model discovers a latent set ofdynamical behaviors shared among the sequences, and segments each time seriesinto regions defined by a subset of these behaviors. Using a beta processprior, the size of the behavior set and the sharing pattern are both inferredfrom data. We develop Markov chain Monte Carlo (MCMC) methods based on theIndian buffet process representation of the predictive distribution of the betaprocess. Our MCMC inference algorithm efficiently adds and removes behaviorsvia novel split-merge moves as well as data-driven birth and death proposals,avoiding the need to consider a truncated model. We demonstrate promisingresults on unsupervised segmentation of human motion capture data.

