Working in Pairs: Understanding the Effects of Worker Interactions in  Crowdwork

  Crowdsourcing has gained popularity as a tool to harness human brain power tohelp solve problems that are difficult for computers. Previous work incrowdsourcing often assumes that workers complete crowdwork independently. Inthis paper, we relax the independent property of crowdwork and explore howintroducing direct, synchronous, and free-style interactions between workerswould affect crowdwork. In particular, motivated by the concept of peerinstruction in educational settings, we study the effects of peer communicationin crowdsourcing environments. In the crowdsourcing setting with peercommunication, pairs of workers are asked to complete the same task together byfirst generating their initial answers to the task independently and thenfreely discussing the tasks with each other and updating their answers afterthe discussion. We experimentally examine the effects of peer communication incrowdwork on various common types of tasks on crowdsourcing platforms,including image labeling, optical character recognition (OCR), audiotranscription, and nutrition analysis. Our experiment results show that thework quality is significantly improved in tasks with peer communicationcompared to tasks where workers complete the work independently. However,participating in tasks with peer communication has limited effects oninfluencing worker's independent performance in tasks of the same type in thefuture.

Adaptive Contract Design for Crowdsourcing Markets: Bandit Algorithms  for Repeated Principal-Agent Problems

  Crowdsourcing markets have emerged as a popular platform for matchingavailable workers with tasks to complete. The payment for a particular task istypically set by the task's requester, and may be adjusted based on the qualityof the completed work, for example, through the use of "bonus" payments. Inthis paper, we study the requester's problem of dynamically adjustingquality-contingent payments for tasks. We consider a multi-round version of thewell-known principal-agent model, whereby in each round a worker makes astrategic choice of the effort level which is not directly observable by therequester. In particular, our formulation significantly generalizes thebudget-free online task pricing problems studied in prior work.  We treat this problem as a multi-armed bandit problem, with each "arm"representing a potential contract. To cope with the large (and in fact,infinite) number of arms, we propose a new algorithm, AgnosticZooming, whichdiscretizes the contract space into a finite number of regions, effectivelytreating each region as a single arm. This discretization is adaptivelyrefined, so that more promising regions of the contract space are eventuallydiscretized more finely. We analyze this algorithm, showing that it achievesregret sublinear in the time horizon and substantially improves overnon-adaptive discretization (which is the only competing approach in theliterature).  Our results advance the state of art on several different topics: the theoryof crowdsourcing markets, principal-agent problems, multi-armed bandits, anddynamic pricing.

Incentivizing High Quality Crowdwork

  We study the causal effects of financial incentives on the quality ofcrowdwork. We focus on performance-based payments (PBPs), bonus paymentsawarded to workers for producing high quality work. We design and runrandomized behavioral experiments on the popular crowdsourcing platform AmazonMechanical Turk with the goal of understanding when, where, and why PBPs help,identifying properties of the payment, payment structure, and the task itselfthat make them most effective. We provide examples of tasks for which PBPs doimprove quality. For such tasks, the effectiveness of PBPs is not too sensitiveto the threshold for quality required to receive the bonus, while the magnitudeof the bonus must be large enough to make the reward salient. We also presentexamples of tasks for which PBPs do not improve quality. Our results suggestthat for PBPs to improve quality, the task must be effort-responsive: the taskmust allow workers to produce higher quality work by exerting more effort. Wealso give a simple method to determine if a task is effort-responsive a priori.Furthermore, our experiments suggest that all payments on Mechanical Turk are,to some degree, implicitly performance-based in that workers believe their workmay be rejected if their performance is sufficiently poor. Finally, we proposea new model of worker behavior that extends the standard principal-agent modelfrom economics to include a worker's subjective beliefs about his likelihood ofbeing paid, and show that the predictions of this model are in line with ourexperimental findings. This model may be useful as a foundation for theoreticalstudies of incentives in crowdsourcing markets.

