Simpler proof of the theorem by Pusey, Barrett, and Rudolph on the  reality of the quantum state

  The theorem of Pusey, Barrett, and Rudolph proves that different quantumstates describe different physical realities. Their proof is based on theconstruction of entanglement measurement bases of two, and more than two qbits.In this note, I show that a two-qubit entanglement base is sufficient for ageneral proof.

Asymptotics of Relativistic Spin Networks

  The stationary phase technique is used to calculate asymptotic formulae forSO(4) Relativistic Spin Networks. For the tetrahedral spin network this givesthe square of the Ponzano-Regge asymptotic formula for the SU(2) 6j symbol. Forthe 4-simplex (10j-symbol) the asymptotic formula is compared with numericalcalculations of the Spin Network evaluation. Finally we discuss the asymptoticsof the SO(3,1) 10j-symbol.

Remarks on variational problems for Fefferman's measure

  We investigate the Plateau and isoperimetric problems associated toFefferman's measure for strongly pseudoconvex real hypersurfaces in $\mathbbC^n$ (focusing on the case $n=2$), showing in particular that the isoperimetricproblem shares features of both the euclidean isoperimetric problem and thecorresponding problem in Blaschke's equiaffine geometry in which the keyinequalities are reversed.  The problems are invariant under constant-Jacobian biholomorphism, but wealso introduce a non-trivial modified isoperimetric quantity invariant undergeneral biholomorphism.

A Jansky VLA Survey of Magnetic Cataclysmic Variable Stars: I. The Data

  The Jansky Very Large Array was used to observe 121 magnetic cataclysmicvariables (MCVs). We report radio detections of 19 stars. Fourteen are newradio sources, increasing the number of MCVs that are radio sources by morethan twofold, from 8 to 22. Most detections are at 8.7 GHz (X-band) with alesser number at 5.4 and 21.1 GHz (C- and K-bands). Most flux density limitsare in the range of 47-470 uJy. With the exception of AE Aqr, the maximum fluxdetected is 818 uJy. Fourteen of the detections show approximately 100%circularly polarized emission, which is characteristic of electron-cyclotronmaser emission. The data suggest that MCVs might be divided into two classes ofradio emitters: those dominated by weakly polarized gyro-synchrotron emissionand those by highly polarized electron-cyclotron maser emission.

Using microsimulation feedback for trip adaptation for realistic traffic  in Dallas

  This paper presents a day-to-day re-routing relaxation approach for trafficsimulations. Starting from an initial planset for the routes, the route-basedmicrosimulation is executed. The result of the microsimulation is fed into are-router, which re-routes a certain percentage of all trips. This approachmakes the traffic patterns in the microsimulation much more reasonable.Further, it is shown that the method described in this paper can lead to strongoscillations in the solutions.

TRANSIMS traffic flow characteristics

  Knowledge of fundamental traffic flow characteristics of traffic simulationmodels is an essential requirement when using these models for the planning,design, and operation of transportation systems. In this paper we discuss thefollowing: a description of how features relevant to traffic flow are currentlyunder implementation in the TRANSIMS microsimulation, a proposition forstandardized traffic flow tests for traffic simulation models, and the resultsof these tests for two different versions of the TRANSIMS microsimulation.

Algorithms for Verifying Deep Neural Networks

  Deep neural networks are widely used for nonlinear function approximationwith applications ranging from computer vision to control. Although thesenetworks involve the composition of simple arithmetic operations, it can bevery challenging to verify whether a particular network satisfies certaininput-output properties. This article surveys methods that have emergedrecently for soundly verifying such properties. These methods borrow insightsfrom reachability analysis, optimization, and search. We discuss fundamentaldifferences and connections between existing algorithms. In addition, weprovide pedagogical implementations of existing methods and compare them on aset of benchmark problems.

On a Classification of Irreducible Almost-Commutative Geometries IV

  In this paper we will classify the finite spectral triples with KO-dimensionsix, following the classification found in [1,2,3,4], with up to four summandsin the matrix algebra. Again, heavy use is made of Kra jewski diagrams [5].Furthermore we will show that any real finite spectral triple in KO-dimension 6is automatically S 0 -real. This work has been inspired by the recent paper byAlain Connes [6] and John Barrett [7].  In the classification we find that the standard model of particle physics inits minimal version fits the axioms of noncommutative geometry in the case ofKO-dimension six. By minimal version it is meant that at least one neutrino hasto be massless and mass-terms mixing particles and antiparticles are prohibited

Almost-Commutative Geometry, massive Neutrinos and the Orientability  Axiom in KO-Dimension 6

  In recent publications Alain Connes [1] and John Barrett [2] proposed tochange the KO-dimension of the internal space of the standard model in itsnoncommutative representation [3] from zero to six. This apparently minormodification allowed to resolve the fermion doubling problem [4], and theintroduction of Majorana mass terms for the right-handed neutrino. The pricewhich had to be paid was that at least the orientability axiom ofnoncommutative geometry [5,6] may not be obeyed by the underlying geometry. Inthis publication we review three internal geometries, all three failing to meetthe orientability axiom of noncommutative geometry. They will serve as examplesto illustrate the nature of this lack of orientability. We will present anextension of the minimal standard model found in [7] by a right-handedneutrino, where only the sub-representation associated to this neutrino is notorientable.

The Spread of Voting Attitudes in Social Networks

  The Shapley-Shubik power index is a measure of each voters power in thepassage or failure of a vote. We extend this measure to graphs and consider adiscrete-time process in which voters may change their vote based on theoutcome of the previous vote. We use this model to study how voter influencecan spread through a network. We find conditions under which a vanishinglysmall portion of consenting voters can change the votes of the entirety of thenetwork. For a particular family of graphs, this process can be modeled usingcellular automata. In particular, we find a connection between this process andthe well-studied cellular automata, Rule 90. We use this connection to showthat such processes can exhibit arbitrarily-long periodicity.

The candidacy of shuffle and shear during compound twinning in hexagonal  close-packed structures

  This paper proposes a systematic generalized formulation for calculating bothatomic shuffling and shear candidates for a given compound twinning mode inhexagonal closed-packed metals. Although shuffles play an important role in themobility of twinning dislocations in non-Bravais metallic lattices, theiranalytical expressions have not been previously derived. The method isillustrated for both flat planes and corrugated planes which are exemplified by{11-22} and {10-12} twinning modes, respectively. The method distinguishesbetween shuffle displacements and net shuffles. While shuffle displacementscorrespond to movements between ideal atom positions in the parent and twinlattices, net shuffles comprise contributions from shear on overlying planeswhich can operate along opposite directions to those of shuffle displacements.Thus, net shuffles in the twinning direction can vanish in a limiting case, asis interestingly the case for those needed in the second plane by the b_4dislocation candidate in {11-22} twinning. It is found that while shuffledisplacement vectors can be irrational when K_1 is corrugated, net shufflevectors are always rational.

The whole is greater than the sum of the parts: on the possibility of  purely statistical interpretations of quantum theory

  The Pusey-Barrett-Rudolph theorem (PBR) claims to rule out the possibility ofa purely statistical interpretation of the quantum state under an assumption ofhow to represent independent operations in any hidden variable model. We showthat PBR's assumption of independence encodes an assumption of local causality,which is already known to conflict with the predictions of quantum theory viaBell-type inequalities. We devise a weaker formulation of independence within ageneral hidden variable model that is empirically indistinguishable from thePBR assumption in situations where certain hidden variables are inaccessible.Under this weaker principle we are able to construct an explicit hiddenvariable model that is purely statistical and also reproduces the quantumpredictions. Our results suggest that the assumption of a purely statisticalinterpretation is actually an innocent bystander in the PBR argument, ratherthan the driving force behind their contradiction.

RNA secondary structures having a compatible sequence of certain  nucleotide ratios

  Given a random RNA secondary structure, $S$, we study RNA sequences havingfixed ratios of nuclotides that are compatible with $S$. We perform thisanalysis for RNA secondary structures subject to various base pairing rules andminimum arc- and stack-length restrictions. Our main result reads as follows:in the simplex of the nucleotide ratios there exists a convex region in which,in the limit of long sequences, a random structure a.a.s.~has compatiblesequence with these ratios and outside of which a.a.s.~a random structure hasno such compatible sequence. We localize this region for RNA secondarystructures subject to various base pairing rules and minimum arc- andstack-length restrictions. In particular, for {\bf GC}-sequences having a ratioof {\bf G} nucleotides smaller than $1/3$, a random RNA secondary structurewithout any minimum arc- and stack-length restrictions has a.a.s.~no suchcompatible sequence. For sequences having a ratio of {\bf G} nucleotides largerthan $1/3$, a random RNA secondary structure has a.a.s. such compatiblesequences. We discuss our results in the context of various families of RNAstructures.

On the quantized dynamics of factorial languages

  We study local piecewise conjugacy of the quantized dynamics arising fromfactorial languages. We show that it induces a bijection between allowablewords of same length and thus it preserves entropy. In the case of soficfactorial languages we prove that local piecewise conjugacy translates tounlabeled graph isomorphism of the follower set graphs. Moreover it induces anunlabeled graph isomorphism between the Fischer covers of irreduciblesubshifts. We verify that local piecewise conjugacy does not preserve finitetype nor irreducibility; but it preserves soficity. Moreover it impliesidentification (up to a permutation) for factorial languages of type $1$ if,and only if, the follower set function is one-to-one on the symbol set.

IB2d Reloaded: a more powerful Python and MATLAB implementation of the  immersed boundary method

  The immersed boundary method (IB) is an elegant way to fully couple themotion of a fluid and deformations of an immersed elastic structure. In thatvein, the IB2d software allows for expedited explorations of fluid-structureinteraction for beginners and veterans to the field of computational fluiddynamics (CFD). While most open source CFD codes are written in low levelprogramming environments, IB2d was specifically written in high- levelprogramming environments to make its accessibility extend beyond scientistswith vast programming experience. Although introduced previously by Battista etal. 2015, many improvements and additions have been made to the software toallow for even more robust models of material properties for the elasticstructures, including a data analysis package for both the fluid and immersedstructure data, an improved time-stepping scheme for higher accuracy solutions,and functionality for modeling slight fluid density variations as given by theBoussinesq approximation.

Genetic robustness of let-7 miRNA sequence-structure pairs

  Genetic robustness, the preservation of evolved phenotypes against genotypicmutations, is one of the central concepts in evolution. In recent years a largebody of work has focused on the origins, mechanisms, and consequences ofrobustness in a wide range of biological systems. In particular, research onncRNAs studied the ability of sequences to maintain folded structures againstsingle-point mutations. In these studies, the structure is merely a reference.However, recent work revealed evidence that structure itself contributes to thegenetic robustness of ncRNAs. We follow this line of thought and considersequence-structure pairs as the unit of evolution and introduce the spectrum ofinverse folding rates (IFR-spectrum) as a measurement of genetic robustness.Our analysis of the miRNA let-7 family captures key features ofstructure-modulated evolution and facilitates the study of robustness againstmultiple-point mutations.

Accuracy of inference on the physics of binary evolution from  gravitational-wave observations

  The properties of the population of merging binary black holes encode some ofthe uncertain physics of the evolution of massive stars in binaries. The binaryblack hole merger rate and chirp mass distribution are being measured byground-based gravitational-wave detectors. We consider isolated binaryevolution and explore how accurately the physical model can be constrained withsuch observations by applying the Fisher information matrix to the mergingblack hole population simulated with the rapid binary population synthesis codeCOMPAS. We investigate variations in four COMPAS parameters: common envelopeefficiency, kick velocity dispersion, and mass loss rates during the luminousblue variable and Wolf--Rayet stellar evolutionary phases. We find that 1000observations would constrain these model parameters to a fractional accuracy ofa few percent. Given the empirically determined binary black hole merger rate,we can expect gravitational-wave observations alone to place strong constraintson the physics of stellar and binary evolution within a few years.

Elements of a Theory of Simulation

  Unlike computation or the numerical analysis of differential equations,simulation does not have a well established conceptual and mathematicalfoundation. Simulation is an arguable unique union of modeling and computation.However, simulation also qualifies as a separate species of systemrepresentation with its own motivations, characteristics, and implications.This work outlines how simulation can be rooted in mathematics and shows whichproperties some of the elements of such a mathematical framework has. Theproperties of simulation are described and analyzed in terms of properties ofdynamical systems. It is shown how and why a simulation produces emergentbehavior and why the analysis of the dynamics of the system being simulatedalways is an analysis of emergent phenomena. A notion of a universal simulatorand the definition of simulatability is proposed. This allows a description ofconditions under which simulations can distribute update functions over systemcomponents, thereby determining simulatability. The connection between thenotion of simulatability and the notion of computability is defined and theconcepts are distinguished. The basis of practical detection methods fordetermining effectively non-simulatable systems in practice is presented. Theconceptual framework is illustrated through examples from molecularself-assembly end engineering.

Sequence-structure relations of biopolymers

  Motivation: DNA data is transcribed into single-stranded RNA, which foldsinto specific molecular structures. In this paper we pose the question to whatextent sequence- and structure-information correlate. We view this correlationas structural semantics of sequence data that allows for a differentinterpretation than conventional sequence alignment. Structural semantics couldenable us to identify more general embedded "patterns" in DNA and RNAsequences. Results: We compute the partition function of sequences with respectto a fixed structure and connect this computation to the mutual information ofa sequence-structure pair for RNA secondary structures. We present a Boltzmannsampler and obtain the a priori probability of specific sequence patterns. Wepresent a detailed analysis for the three PDB-structures, 2JXV (hairpin), 2N3R(3-branch multi-loop) and 1EHZ (tRNA). We localize specific sequence patterns,contrast the energy spectrum of the Boltzmann sampled sequences versus thosesequences that refold into the same structure and derive a criterion toidentify native structures. We illustrate that there are multiple sequences inthe partition function of a fixed structure, each having nearly the same mutualinformation, that are nevertheless poorly aligned. This indicates thepossibility of the existence of relevant patterns embedded in the sequencesthat are not discoverable using alignments.

An efficient dual sampling algorithm with Hamming distance filtration

  Recently, a framework considering RNA sequences and their RNA secondarystructures as pairs, led to some information-theoretic perspectives on how thesemantics encoded in RNA sequences can be inferred. In this context, thepairing arises naturally from the energy model of RNA secondary structures.Fixing the sequence in the pairing produces the RNA energy landscape, whosepartition function was discovered by McCaskill. Dually, fixing the structureinduces the energy landscape of sequences. The latter has been considered fordesigning more efficient inverse folding algorithms. We present here theHamming distance filtered, dual partition function, together with a Boltzmannsampler using novel dynamic programming routines for the loop-based energymodel. The time complexity of the algorithm is $O(h^2n)$, where $h,n$ areHamming distance and sequence length, respectively, reducing the timecomplexity of samplers, reported in the literature by $O(n^2)$. We then presenttwo applications, the first being in the context of the evolution of naturalsequence-structure pairs of microRNAs and the second constructing neutralpaths. The former studies the inverse fold rate (IFR) of sequence-structurepairs, filtered by Hamming distance, observing that such pairs evolve towardshigher levels of robustness, i.e.,~increasing IFR. The latter is an algorithmthat constructs neutral paths: given two sequences in a neutral network, weemploy the sampler in order to construct short paths connecting them,consisting of sequences all contained in the neutral network.

Conclusive Exclusion of Quantum States

  In the task of quantum state exclusion we consider a quantum system, preparedin a state chosen from a known set. The aim is to perform a measurement on thesystem which can conclusively rule that a subset of the possible preparationprocedures can not have taken place. We ask what conditions the set of statesmust obey in order for this to be possible and how well we can complete thetask when it is not. The task of quantum state discrimination forms a subclassof this set of problems. Within this paper we formulate the general problem asa Semidefinite Program (SDP), enabling us to derive sufficient and necessaryconditions for a measurement to be optimal. Furthermore, we obtain a necessarycondition on the set of states for exclusion to be achievable with certaintyand give a construction for a lower bound on the probability of error. Thistask of conclusively excluding states has gained importance in the context ofthe foundations of quantum mechanics due to a result of Pusey, Barrett andRudolph (PBR). Motivated by this, we use our SDP to derive a bound on how wella class of hidden variable models can perform at a particular task, proving ananalogue of Tsirelson's bound for the PBR experiment and the optimality of ameasurement given by PBR in the process. We also introduce variations ofconclusive exclusion, including unambiguous state exclusion, and stateexclusion with worst case error.

Review of small-angle coronagraphic techniques in the wake of  ground-based second-generation adaptive optics systems

  Small-angle coronagraphy is technically and scientifically appealing becauseit enables the use of smaller telescopes, allows covering wider wavelengthranges, and potentially increases the yield and completeness of circumstellarenvironment - exoplanets and disks - detection and characterization campaigns.However, opening up this new parameter space is challenging. Here we willreview the four posts of high contrast imaging and their intricate interactionsat very small angles (within the first 4 resolution elements from the star).The four posts are: choice of coronagraph, optimized wavefront control,observing strategy, and post-processing methods. After detailing each of thefour foundations, we will present the lessons learned from the 10+ years ofoperations of zeroth and first-generation adaptive optics systems. We will thententatively show how informative the current integration of second-generationadaptive optics system is, and which lessons can already be drawn from thisfresh experience. Then, we will review the current state of the art, bypresenting world record contrasts obtained in the framework of technologicaldemonstrations for space-based exoplanet imaging and characterization missionconcepts. Finally, we will conclude by emphasizing the importance of thecross-breeding between techniques developed for both ground-based andspace-based projects, which is relevant for future high contrast imaginginstruments and facilities in space or on the ground.

