Algorithms for Efficient Mining of Statistically Significant Attribute  Association Information

  Knowledge of the association information between the attributes in a data setprovides insight into the underlying structure of the data and explains therelationships (independence, synergy, redundancy) between the attributes andclass (if present). Complex models learnt computationally from the data aremore interpretable to a human analyst when such interdependencies are known. Inthis paper, we focus on mining two types of association information among theattributes - correlation information and interaction information for bothsupervised (class attribute present) and unsupervised analysis (class attributeabsent). Identifying the statistically significant attribute associations is acomputationally challenging task - the number of possible associationsincreases exponentially and many associations contain redundant informationwhen a number of correlated attributes are present. In this paper, we exploreefficient data mining methods to discover non-redundant attribute sets thatcontain significant association information indicating the presence ofinformative patterns in the data.

Integrate Multi-omic Data Using Affinity Network Fusion (ANF) for Cancer  Patient Clustering

  Clustering cancer patients into subgroups and identifying cancer subtypes isan important task in cancer genomics. Clustering based on comprehensivemulti-omic molecular profiling can often achieve better results than thoseusing a single data type, since each omic data type (representing one view ofpatients) may contain complementary information. However, it is challenging tointegrate heterogeneous omic data types directly. Based on one popular method-- Similarity Network Fusion (SNF), we presented Affinity Network Fusion (ANF)in this paper, an "upgrade" of SNF with several advantages. Similar to SNF, ANFtreats each omic data type as one view of patients and learns a fused affinity(transition) matrix for clustering. We applied ANF to a carefully processedharmonized cancer dataset downloaded from GDC data portals consisting of 2193patients, and generated promising results on clustering patients into correctdisease types. Our experimental results also demonstrated the power of featureselection and transformation combined with using ANF in patient clustering.Moreover, eigengap analysis suggests that the learned affinity matrices of fourcancer types using our proposed framework may have successfully capturedpatient group structure and can be used for discovering unknown cancersubtypes.

Affinity Network Fusion and Semi-supervised Learning for Cancer Patient  Clustering

  Defining subtypes of complex diseases such as cancer and stratifying patientgroups with the same disease but different subtypes for targeted treatments isimportant for personalized and precision medicine. Approaches that incorporatemulti-omic data are more advantageous to those using only one data type forpatient clustering and disease subtype discovery. However, it is challenging tointegrate multi-omic data as they are heterogeneous and noisy. In this paper,we present Affinity Network Fusion (ANF) to integrate multi-omic data forpatient clustering. ANF first constructs patient affinity networks for eachomic data type, and then calculates a fused network for spectral clustering. Weapplied ANF to a processed harmonized cancer dataset downloaded from GDC dataportal consisting of 2193 patients, and generated promising results onclustering patients into correct disease types. Moreover, we developed asemi-supervised model combining ANF and neural network for few-shot learning.In several cases, the model can achieve greater than 90% acccuracy on test setwith training less than 1% of the data. This demonstrates the power of ANF inlearning a good representation of patients, and shows the great potential ofsemi-supervised learning in cancer patient clustering.

Multi-view Factorization AutoEncoder with Network Constraints for  Multi-omic Integrative Analysis

  Multi-omic data provides multiple views of the same patients. Integrativeanalysis of multi-omic data is crucial to elucidate the molecular underpinningof disease etiology. However, multi-omic data has the "big p, small N" problem(the number of features is large, but the number of samples is small), it ischallenging to train a complicated machine learning model from the multi-omicdata alone and make it generalize well. Here we propose a framework termedMulti-view Factorization AutoEncoder with network constraints to integratemulti-omic data with domain knowledge (biological interactions networks). Ourframework employs deep representation learning to learn feature embeddings andpatient embeddings simultaneously, enabling us to integrate feature interactionnetwork and patient view similarity network constraints into the trainingobjective. The whole framework is end-to-end differentiable. We applied ourapproach to the TCGA Pan-cancer dataset and achieved satisfactory results topredict disease progression-free interval (PFI) and patient overall survival(OS) events. Code will be made publicly available.

AffinityNet: semi-supervised few-shot learning for disease type  prediction

  While deep learning has achieved great success in computer vision and manyother fields, currently it does not work very well on patient genomic data withthe "big p, small N" problem (i.e., a relatively small number of samples withhigh-dimensional features). In order to make deep learning work with a smallamount of training data, we have to design new models that facilitate few-shotlearning. Here we present the Affinity Network Model (AffinityNet), a dataefficient deep learning model that can learn from a limited number of trainingexamples and generalize well. The backbone of the AffinityNet model consists ofstacked k-Nearest-Neighbor (kNN) attention pooling layers. The kNN attentionpooling layer is a generalization of the Graph Attention Model (GAM), and canbe applied to not only graphs but also any set of objects regardless of whethera graph is given or not. As a new deep learning module, kNN attention poolinglayers can be plugged into any neural network model just like convolutionallayers. As a simple special case of kNN attention pooling layer, featureattention layer can directly select important features that are useful forclassification tasks. Experiments on both synthetic data and cancer genomicdata from TCGA projects show that our AffinityNet model has bettergeneralization power than conventional neural network models with littletraining data. The code is freely available athttps://github.com/BeautyOfWeb/AffinityNet .

