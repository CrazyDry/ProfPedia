Occlusion-Aware Object Localization, Segmentation and Pose Estimation

  We present a learning approach for localization and segmentation of objectsin an image in a manner that is robust to partial occlusion. Our algorithmproduces a bounding box around the full extent of the object and labels pixelsin the interior that belong to the object. Like existing segmentation awaredetection approaches, we learn an appearance model of the object and considerregions that do not fit this model as potential occlusions. However, inaddition to the established use of pairwise potentials for encouraging localconsistency, we use higher order potentials which capture information at thelevel of im- age segments. We also propose an efficient loss function thattargets both localization and segmentation performance. Our algorithm achieves13.52% segmentation error and 0.81 area under the false-positive per image vs.recall curve on average over the challenging CMU Kitchen Occlusion Dataset.This is a 42.44% decrease in segmentation error and a 16.13% increase inlocalization performance compared to the state-of-the-art. Finally, we showthat the visibility labelling produced by our algorithm can make full 3D poseestimation from a single image robust to occlusion.

Grasping for a Purpose: Using Task Goals for Efficient Manipulation  Planning

  In this paper we propose an approach for efficient grasp selection formanipulation tasks of unknown objects. Even for simple tasks such aspick-and-place, a unique solution is rare to occur. Rather, multiple candidategrasps must be considered and (potentially) tested till a successful,kinematically feasible path is found. To make this process efficient, thegrasps should be ordered such that those more likely to succeed are testedfirst. We propose to use grasp manipulability as a metric to prioritize grasps.We present results of simulation experiments which demonstrate the usefulnessof our metric. Additionally, we present experiments with our physical robotperforming simple manipulation tasks with a small set of different householdobjects.

From the Lab to the Desert: Fast Prototyping and Learning of Robot  Locomotion

  We present a methodology for fast prototyping of morphologies and controllersfor robot locomotion. Going beyond simulation-based approaches, we argue thatthe form and function of a robot, as well as their interplay with real-worldenvironmental conditions are critical. Hence, fast design and learning cyclesare necessary to adapt robot shape and behavior to their environment. To thisend, we present a combination of laminate robot manufacturing andsample-efficient reinforcement learning. We leverage this methodology toconduct an extensive robot learning experiment. Inspired by locomotion in seaturtles, we design a low-cost crawling robot with variable, interchangeablefins. Learning is performed using both bio-inspired and original fin designs inan artificial indoor environment as well as a natural environment in theArizona desert. The findings of this study show that static policies developedin the laboratory do not translate to effective locomotion strategies innatural environments. In contrast to that, sample-efficient reinforcementlearning can help to rapidly accommodate changes in the environment or therobot.

Deep Predictive Models for Collision Risk Assessment in Autonomous  Driving

  In this paper, we investigate a predictive approach for collision riskassessment in autonomous and assisted driving. A deep predictive model istrained to anticipate imminent accidents from traditional video streams. Inparticular, the model learns to identify cues in RGB images that are predictiveof hazardous upcoming situations. In contrast to previous work, our approachincorporates (a) temporal information during decision making, (b) multi-modalinformation about the environment, as well as the proprioceptive state andsteering actions of the controlled vehicle, and (c) information about theuncertainty inherent to the task. To this end, we discuss Deep PredictiveModels and present an implementation using a Bayesian Convolutional LSTM.Experiments in a simple simulation environment show that the approach can learnto predict impending accidents with reasonable accuracy, especially whenmultiple cameras are used as input sources.

Information Maximizing Exploration with a Latent Dynamics Model

  All reinforcement learning algorithms must handle the trade-off betweenexploration and exploitation. Many state-of-the-art deep reinforcement learningmethods use noise in the action selection, such as Gaussian noise in policygradient methods or $\epsilon$-greedy in Q-learning. While these methods areappealing due to their simplicity, they do not explore the state space in amethodical manner. We present an approach that uses a model to derive rewardbonuses as a means of intrinsic motivation to improve model-free reinforcementlearning. A key insight of our approach is that this dynamics model can belearned in the latent feature space of a value function, representing thedynamics of the agent and the environment. This method is both theoreticallygrounded and computationally advantageous, permitting the efficient use ofBayesian information-theoretic methods in high-dimensional state spaces. Weevaluate our method on several continuous control tasks, focusing on improvingexploration.

