Accuracy Bounds for Belief Propagation

  The belief propagation (BP) algorithm is widely applied to performapproximate inference on arbitrary graphical models, in part due to itsexcellent empirical properties and performance. However, little is knowntheoretically about when this algorithm will perform well. Using recentanalysis of convergence and stability properties in BP and new results onapproximations in binary systems, we derive a bound on the error in BP'sestimates for pairwise Markov random fields over discrete valued randomvariables. Our bound is relatively simple to compute, and compares favorablywith a previous method of bounding the accuracy of BP.

Join-graph based cost-shifting schemes

  We develop several algorithms taking advantage of two common approaches forbounding MPE queries in graphical models: minibucket elimination andmessage-passing updates for linear programming relaxations. Both methods arequite similar, and offer useful perspectives for the other; our hybridapproaches attempt to balance the advantages of each. We demonstrate the powerof our hybrid algorithms through extensive empirical evaluation. Most notably,a Branch and Bound search guided by the heuristic function calculated by one ofour new algorithms has recently won first place in the PASCAL2 inferencechallenge.

Tightening MRF Relaxations with Planar Subproblems

  We describe a new technique for computing lower-bounds on the minimum energyconfiguration of a planar Markov Random Field (MRF). Our method successivelyadds large numbers of constraints and enforces consistency over binaryprojections of the original problem state space. These constraints arerepresented in terms of subproblems in a dual-decomposition framework that isoptimized using subgradient techniques. The complete set of constraints weconsider enforces cycle consistency over the original graph. In practice wefind that the method converges quickly on most problems with the addition of afew subproblems and outperforms existing methods for some interesting classesof hard potentials.

Fast Planar Correlation Clustering for Image Segmentation

  We describe a new optimization scheme for finding high-quality correlationclusterings in planar graphs that uses weighted perfect matching as asubroutine. Our method provides lower-bounds on the energy of the optimalcorrelation clustering that are typically fast to compute and tight inpractice. We demonstrate our algorithm on the problem of image segmentationwhere this approach outperforms existing global optimization techniques inminimizing the objective and is competitive with the state of the art inproducing high-quality segmentations.

Belief Propagation for Structured Decision Making

  Variational inference algorithms such as belief propagation have hadtremendous impact on our ability to learn and use graphical models, and givemany insights for developing or understanding exact and approximate inference.However, variational approaches have not been widely adoped for decision makingin graphical models, often formulated through influence diagrams and includingboth centralized and decentralized (or multi-agent) decisions. In this work, wepresent a general variational framework for solving structured cooperativedecision-making problems, use it to propose several belief propagation-likealgorithms, and analyze them both theoretically and empirically.

Planar Cycle Covering Graphs

  We describe a new variational lower-bound on the minimum energy configurationof a planar binary Markov Random Field (MRF). Our method is based on addingauxiliary nodes to every face of a planar embedding of the graph in order tocapture the effect of unary potentials. A ground state of the resultingapproximation can be computed efficiently by reduction to minimum-weightperfect matching. We show that optimization of variational parameters achievesthe same lower-bound as dual-decomposition into the set of all cycles of theoriginal graph. We demonstrate that our variational optimization convergesquickly and provides high-quality solutions to hard combinatorial problems10-100x faster than competing algorithms that optimize the same bound.

Variational Algorithms for Marginal MAP

  Marginal MAP problems are notoriously difficult tasks for graphical models.We derive a general variational framework for solving marginal MAP problems, inwhich we apply analogues of the Bethe, tree-reweighted, and mean fieldapproximations. We then derive a "mixed" message passing algorithm and aconvergent alternative using CCCP to solve the BP-type approximations.Theoretically, we give conditions under which the decoded solution is a globalor local optimum, and obtain novel upper bounds on solutions. Experimentally wedemonstrate that our algorithms outperform related approaches. We also showthat EM and variational EM comprise a special case of our framework.

Negative Tree Reweighted Belief Propagation

  We introduce a new class of lower bounds on the log partition function of aMarkov random field which makes use of a reversed Jensen's inequality. Inparticular, our method approximates the intractable distribution using a linearcombination of spanning trees with negative weights. This technique is alower-bound counterpart to the tree-reweighted belief propagation algorithm,which uses a convex combination of spanning trees with positive weights toprovide corresponding upper bounds. We develop algorithms to optimize andtighten the lower bounds over the non-convex set of valid parameter values. Ouralgorithm generalizes mean field approaches (including naive and structuredmean field approximations), which it includes as a limiting case.

Adaptive Inference on General Graphical Models

  Many algorithms and applications involve repeatedly solving variations of thesame inference problem; for example we may want to introduce new evidence tothe model or perform updates to conditional dependencies. The goal of adaptiveinference is to take advantage of what is preserved in the model and performinference more rapidly than from scratch. In this paper, we describe techniquesfor adaptive inference on general graphs that support marginal computation andupdates to the conditional probabilities and dependencies in logarithmic time.We give experimental results for an implementation of our algorithm, anddemonstrate its potential performance benefit in the study of proteinstructure.

Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick  Breaking Representation

  Nonparametric Bayesian approaches to clustering, information retrieval,language modeling and object recognition have recently shown great promise as anew paradigm for unsupervised data analysis. Most contributions have focused onthe Dirichlet process mixture models or extensions thereof for which efficientGibbs samplers exist. In this paper we explore Gibbs samplers for infinitecomplexity mixture models in the stick breaking representation. The advantageof this representation is improved modeling flexibility. For instance, one candesign the prior distribution over cluster sizes or couple multiple infinitemixture models (e.g. over time) at the level of their parameters (i.e. thedependent Dirichlet process model). However, Gibbs samplers for infinitemixture models (as recently introduced in the statistics literature) seem tomix poorly over cluster labels. Among others issues, this can have the adverseeffect that labels for the same cluster in coupled mixture models are mixed up.We introduce additional moves in these samplers to improve mixing over clusterlabels and to bring clusters into correspondence. An application to modeling ofstorm trajectories is used to illustrate these ideas.

A Cluster-Cumulant Expansion at the Fixed Points of Belief Propagation

  We introduce a new cluster-cumulant expansion (CCE) based on the fixed pointsof iterative belief propagation (IBP). This expansion is similar in spirit tothe loop-series (LS) recently introduced in [1]. However, in contrast to thelatter, the CCE enjoys the following important qualities: 1) it is defined forarbitrary state spaces 2) it is easily extended to fixed points of generalizedbelief propagation (GBP), 3) disconnected groups of variables will notcontribute to the CCE and 4) the accuracy of the expansion empirically improvesupon that of the LS. The CCE is based on the same M\"obius transform as theKikuchi approximation, but unlike GBP does not require storing the beliefs ofthe GBP-clusters nor does it suffer from convergence issues during beliefupdating.

A Low Density Lattice Decoder via Non-Parametric Belief Propagation

  The recent work of Sommer, Feder and Shalvi presented a new family of codescalled low density lattice codes (LDLC) that can be decoded efficiently andapproach the capacity of the AWGN channel. A linear time iterative decodingscheme which is based on a message-passing formulation on a factor graph isgiven.  In the current work we report our theoretical findings regarding the relationbetween the LDLC decoder and belief propagation. We show that the LDLC decoderis an instance of non-parametric belief propagation and further connect it tothe Gaussian belief propagation algorithm. Our new results enable borrowingknowledge from the non-parametric and Gaussian belief propagation domains intothe LDLC domain. Specifically, we give more general convergence conditions forconvergence of the LDLC decoder (under the same assumptions of the originalLDLC convergence analysis). We discuss how to extend the LDLC decoder fromLatin square to full rank, non-square matrices. We propose an efficientconstruction of sparse generator matrix and its matching decoder. We reportpreliminary experimental results which show our decoder has comparable symbolto error rate compared to the original LDLC decoder.%

