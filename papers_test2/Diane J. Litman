Classifying Cue Phrases in Text and Speech Using Machine Learning

  Cue phrases may be used in a discourse sense to explicitly signal discoursestructure, but also in a sentential sense to convey semantic rather thanstructural information. This paper explores the use of machine learning forclassifying cue phrases as discourse or sentential. Two machine learningprograms (Cgrendel and C4.5) are used to induce classification rules from setsof pre-classified cue phrases and their features. Machine learning is shown tobe an effective technique for not only automating the generation ofclassification rules, but also for improving upon previous results.

Intention-based Segmentation: Human Reliability and Correlation with  Linguistic Cues

  Certain spans of utterances in a discourse, referred to here as segments, arewidely assumed to form coherent units. Further, the segmental structure ofdiscourse has been claimed to constrain and be constrained by many phenomena.However, there is weak consensus on the nature of segments and the criteria forrecognizing or generating them. We present quantitative results of a two partstudy using a corpus of spontaneous, narrative monologues. The first partevaluates the statistical reliability of human segmentation of our corpus,where speaker intention is the segmentation criterion. We then use thesubjects' segmentations to evaluate the correlation of discourse segmentationwith three linguistic cues (referential noun phrases, cue words, and pauses),using information retrieval metrics.

Cue Phrase Classification Using Machine Learning

  Cue phrases may be used in a discourse sense to explicitly signal discoursestructure, but also in a sentential sense to convey semantic rather thanstructural information. Correctly classifying cue phrases as discourse orsentential is critical in natural language processing systems that exploitdiscourse structure, e.g., for performing tasks such as anaphora resolution andplan recognition. This paper explores the use of machine learning forclassifying cue phrases as discourse or sentential. Two machine learningprograms (Cgrendel and C4.5) are used to induce classification models from setsof pre-classified cue phrases and their features in text and speech. Machinelearning is shown to be an effective technique for not only automating thegeneration of classification models, but also for improving upon previousresults. When compared to manually derived classification models already in theliterature, the learned models often perform with higher accuracy and containnew linguistic insights into the data. In addition, the ability toautomatically construct classification models makes it easier to comparativelyanalyze the utility of alternative feature representations of the data.Finally, the ease of retraining makes the learning approach more scalable andflexible than manual methods.

Empirically Evaluating an Adaptable Spoken Dialogue System

  Recent technological advances have made it possible to build real-time,interactive spoken dialogue systems for a wide variety of applications.However, when users do not respect the limitations of such systems, performancetypically degrades. Although users differ with respect to their knowledge ofsystem limitations, and although different dialogue strategies make systemlimitations more apparent to users, most current systems do not try to improveperformance by adapting dialogue behavior to individual users. This paperpresents an empirical evaluation of TOOT, an adaptable spoken dialogue systemfor retrieving train schedules on the web. We conduct an experiment in which 20users carry out 4 tasks with both adaptable and non-adaptable versions of TOOT,resulting in a corpus of 80 dialogues. The values for a wide range ofevaluation measures are then extracted from this corpus. Our results show thatadaptable TOOT generally outperforms non-adaptable TOOT, and that the utilityof adaptation depends on TOOT's initial dialogue strategies.

Combining Multiple Knowledge Sources for Discourse Segmentation

  We predict discourse segment boundaries from linguistic features ofutterances, using a corpus of spoken narratives as data. We present two methodsfor developing segmentation algorithms from training data: hand tuning andmachine learning. When multiple types of features are used, results approachhuman performance on an independent test set (both methods), and usingcross-validation (machine learning).

PARADISE: A Framework for Evaluating Spoken Dialogue Agents

  This paper presents PARADISE (PARAdigm for DIalogue System Evaluation), ageneral framework for evaluating spoken dialogue agents. The frameworkdecouples task requirements from an agent's dialogue behaviors, supportscomparisons among dialogue strategies, enables the calculation of performanceover subdialogues and whole dialogues, specifies the relative contribution ofvarious factors to performance, and makes it possible to compare agentsperforming different tasks by normalizing for task complexity.

