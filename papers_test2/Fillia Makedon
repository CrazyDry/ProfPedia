Improving the Accuracy of the CogniLearn System for Cognitive Behavior  Assessment

  HTKS is a game-like cognitive assessment method, designed for childrenbetween four and eight years of age. During the HTKS assessment, a childresponds to a sequence of requests, such as "touch your head" or "touch yourtoes". The cognitive challenge stems from the fact that the children areinstructed to interpret these requests not literally, but by touching adifferent body part than the one stated. In prior work, we have developed theCogniLearn system, that captures data from subjects performing the HTKS game,and analyzes the motion of the subjects. In this paper we propose some specificimprovements that make the motion analysis module more accurate. As a result ofthese improvements, the accuracy in recognizing cases where subjects touchtheir toes has gone from 76.46% in our previous work to 97.19% in this paper.

Towards Deep Learning based Hand Keypoints Detection for Rapid  Sequential Movements from RGB Images

  Hand keypoints detection and pose estimation has numerous applications incomputer vision, but it is still an unsolved problem in many aspects. Anapplication of hand keypoints detection is in performing cognitive assessmentsof a subject by observing the performance of that subject in physical tasksinvolving rapid finger motion. As a part of this work, we introduce a novelhand key-points benchmark dataset that consists of hand gestures recordedspecifically for cognitive behavior monitoring. We explore the state of the artmethods in hand keypoint detection and we provide quantitative evaluations forthe performance of these methods on our dataset. In future, these results andour dataset can serve as a useful benchmark for hand keypoint recognition forrapid finger movements.

Using Humanoid Robot to Instruct and Evaluate Performance of a Physical  Task

  In this paper, we present a tool to assess users ability to change tasks. Todo this, we use a variation of the Box and Blocks Test. In this version, ahumanoid robot instructs a user to perform a task involving the movement ofcertain colored blocks. The robot changes randomly change the color of blocksthat the user is supposed to move. Canny Edge Detection and HoughTransformation are used to assess user perform the robot's built-in camera.This will allow the robot to inform the user and keep a log of their progress.We present this method for monitoring user progress by describing how the movedblocks are detected. We also present the results of a pilot study where usersused this system to perform the task. Preliminary results show that users donot perform differently when the task is changed in this scenario.

