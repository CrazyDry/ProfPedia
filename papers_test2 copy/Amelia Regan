Thompson Sampling in Dynamic Systems for Contextual Bandit Problems

  We consider the multiarm bandit problems in the timevarying dynamic systemfor rich structural features. For the nonlinear dynamic model, we propose theapproximate inference for the posterior distributions based on LaplaceApproximation. For the context bandit problems, Thompson Sampling is adoptedbased on the underlying posterior distributions of the parameters. Morespecifically, we introduce the discount decays on the previous samples impactand analyze the different decay rates with the underlying sample dynamics.Consequently, the exploration and exploitation is adaptively tradeoff accordingto the dynamics in the system.

Sorting with GPUs: A Survey

  Sorting is a fundamental operation in computer science and is a bottleneck inmany important fields. Sorting is critical to database applications, onlinesearch and indexing,biomedical computing, and many other applications. Theexplosive growth in computational power and availability of GPU coprocessorshas allowed sort operations on GPUs to be done much faster than anyequivalently priced CPU. Current trends in GPU computing shows that thisexplosive growth in GPU capabilities is likely to continue for some time. Assuch, there is a need to develop algorithms to effectively harness the power ofGPUs for crucial applications such as sorting.

Online Classification Using a Voted RDA Method

  We propose a voted dual averaging method for online classification problemswith explicit regularization. This method employs the update rule of theregularized dual averaging (RDA) method, but only on the subsequence oftraining examples where a classification error is made. We derive a bound onthe number of mistakes made by this method on the training set, as well as itsgeneralization error rate. We also introduce the concept of relative strengthof regularization, and show how it affects the mistake bound and generalizationperformance. We experimented with the method using $\ell_1$ regularization on alarge-scale natural language processing task, and obtained state-of-the-artclassification performance with fairly sparse models.

A Spatial-Temporal Decomposition Based Deep Neural Network for Time  Series Forecasting

  Spatial time series forecasting problems arise in a broad range ofapplications, such as environmental and transportation problems. These problemsare challenging because of the existence of specific spatial, short-term andlong-term patterns, and the curse of dimensionality. In this paper, we proposea deep neural network framework for large-scale spatial time series forecastingproblems. We explicitly designed the neural network architecture for capturingvarious types of patterns. In preprocessing, a time series decomposition methodis applied to separately feed short-term, long-term and spatial patterns intodifferent components of a neural network. A fuzzy clustering method findscluster of neighboring time series based on similarity of time seriesresiduals; as they can be meaningful short-term patterns for spatial timeseries. In neural network architecture, each kernel of a multi-kernelconvolution layer is applied to a cluster of time series to extract short-termfeatures in neighboring areas. The output of convolution layer is concatenatedby trends and followed by convolution-LSTM layer to capture long-term patternsin larger regional areas. To make a robust prediction when faced with missingdata, an unsupervised pretrained denoising autoencoder reconstructs the outputof the model in a fine-tuning step. The experimental results illustrate themodel outperforms baseline and state of the art models in a traffic flowprediction dataset.

