Towards an Achievable Performance for the Loop Nests

  Numerous code optimization techniques, including loop nest optimizations,have been developed over the last four decades. Loop optimization techniquestransform loop nests to improve the performance of the code on a targetarchitecture, including exposing parallelism. Finding and evaluating anoptimal, semantic-preserving sequence of transformations is a complex problem.The sequence is guided using heuristics and/or analytical models and there isno way of knowing how close it gets to optimal performance or if there is anyheadroom for improvement. This paper makes two contributions. First, it uses acomparative analysis of loop optimizations/transformations across multiplecompilers to determine how much headroom may exist for each compiler. Andsecond, it presents an approach to characterize the loop nests based on theirhardware performance counter values and a Machine Learning approach thatpredicts which compiler will generate the fastest code for a loop nest. Theprediction is made for both auto-vectorized, serial compilation and forauto-parallelization. The results show that the headroom for state-of-the-artcompilers ranges from 1.10x to 1.42x for the serial code and from 1.30x to1.71x for the auto-parallelized code. These results are based on the MachineLearning predictions.

