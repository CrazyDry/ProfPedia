Fairness as a Program Property

  We explore the following question: Is a decision-making program fair, forsome useful definition of fairness? First, we describe how several algorithmicfairness questions can be phrased as program verification problems. Second, wediscuss an automated verification technique for proving or disproving fairnessof decision-making programs with respect to a probabilistic model of thepopulation.

Quantifying Program Bias

  With the range and sensitivity of algorithmic decisions expanding at abreak-neck speed, it is imperative that we aggressively investigate whetherprograms are biased. We propose a novel probabilistic program analysistechnique and apply it to quantifying bias in decision-making programs.Specifically, we (i) present a sound and complete automated verificationtechnique for proving quantitative properties of probabilistic programs; (ii)show that certain notions of bias, recently proposed in the fairnessliterature, can be phrased as quantitative correctness properties; and (iii)present FairSquare, the first verification tool for quantifying program bias,and evaluate it on a range of decision-making programs.

Spatial Interpolants

  We propose Splinter, a new technique for proving properties ofheap-manipulating programs that marries (1) a new separation logic-basedanalysis for heap reasoning with (2) an interpolation-based technique forrefining heap-shape invariants with data invariants. Splinter is propertydirected, precise, and produces counterexample traces when a property does nothold. Using the novel notion of spatial interpolants modulo theories, Splintercan infer complex invariants over general recursive predicates, e.g., of theform all elements in a linked list are even or a binary tree is sorted.Furthermore, we treat interpolation as a black box, which gives us the freedomto encode data manipulation in any suitable theory for a given program (e.g.,bit vectors, arrays, or linear arithmetic), so that our technique immediatelybenefits from any future advances in SMT solving and interpolation.

Constraint-Based Synthesis of Coupling Proofs

  Proof by coupling is a classical technique for proving properties about pairsof randomized algorithms by carefully relating (or coupling) two probabilisticexecutions. In this paper, we show how to automatically construct such proofsfor probabilistic programs. First, we present f-coupled postconditions, anabstraction describing two correlated program executions. Second, we show howproperties of f-coupled postconditions can imply various probabilisticproperties of the original programs. Third, we demonstrate how to reduce theproof-search problem to a purely logical synthesis problem of the form $\existsf\ldotp \forall X\ldotp \phi$, making probabilistic reasoning unnecessary. Wedevelop a prototype implementation to automatically build coupling proofs forprobabilistic properties, including uniformity and independence of programexpressions.

Synthesizing Coupling Proofs of Differential Privacy

  Differential privacy has emerged as a promising probabilistic formulation ofprivacy, generating intense interest within academia and industry. We present apush-button, automated technique for verifying $\varepsilon$-differentialprivacy of sophisticated randomized algorithms. We make several conceptual,algorithmic, and practical contributions: (i) Inspired by the recent advanceson approximate couplings and randomness alignment, we present a new prooftechnique called coupling strategies, which casts differential privacy proofsas a winning strategy in a game where we have finite privacy resources toexpend. (ii) To discover a winning strategy, we present a constraint-basedformulation of the problem as a set of Horn modulo couplings (HMC) constraints,a novel combination of first-order Horn clauses and probabilistic constraints.(iii) We present a technique for solving HMC constraints by transformingprobabilistic constraints into logical constraints with uninterpretedfunctions. (iv) Finally, we implement our technique in the FairSquare verifierand provide the first automated privacy proofs for a number of challengingalgorithms from the differential privacy literature, including Report NoisyMax, the Exponential Mechanism, and the Sparse Vector Mechanism.

Neural-Augmented Static Analysis of Android Communication

  We address the problem of discovering communication links betweenapplications in the popular Android mobile operating system, an importantproblem for security and privacy in Android. Any scalable static analysis inthis complex setting is bound to produce an excessive amount offalse-positives, rendering it impractical. To improve precision, we propose toaugment static analysis with a trained neural-network model that estimates theprobability that a communication link truly exists. We describe aneural-network architecture that encodes abstractions of communicating objectsin two applications and estimates the probability with which a link indeedexists. At the heart of our architecture are type-directed encoders (TDE), ageneral framework for elegantly constructing encoders of a compound data typeby recursively composing encoders for its constituent types. We evaluate ourapproach on a large corpus of Android applications, and demonstrate that itachieves very high accuracy. Further, we conduct thorough interpretabilitystudies to understand the internals of the learned neural networks.

Trace Abstraction Modulo Probability

  We propose trace abstraction modulo probability, a proof technique forverifying high-probability accuracy guarantees of probabilistic programs. Ourproofs overapproximate the set of program traces using failure automata,finite-state automata that upper bound the probability of failing to satisfy atarget specification. We automate proof construction by reducing probabilisticreasoning to logical reasoning: we use program synthesis methods to selectaxioms for sampling instructions, and then apply Craig interpolation to provethat traces fail the target specification with only a small probability. Ourmethod handles programs with unknown inputs, parameterized distributions,infinite state spaces, and parameterized specifications. We evaluate ourtechnique on a range of randomized algorithms drawn from the differentialprivacy literature and beyond. To our knowledge, our approach is the first toautomatically establish accuracy properties of these algorithms.

Scaling-Up In-Memory Datalog Processing: Observations and Techniques

  Recursive query processing has experienced a recent resurgence, as a resultof its use in many modern application domains, including data integration,graph analytics, security, program analysis, networking and decision making.Due to the large volumes of data being processed, several research efforts,across multiple communities, have explored how to scale up recursive queries,typically expressed in Datalog. Our experience with these tools indicated thattheir performance does not translate across domains (e.g., a tool design forlarge-scale graph analytics does not exhibit the same performance onprogram-analysis tasks, and vice versa). As a result, we designed andimplemented a general-purpose Datalog engine, called RecStep, on top of aparallel single-node relational system. In this paper, we outline the differenttechniques we use in RecStep, and the contribution of each technique to overallperformance. We also present results from a detailed set of experimentscomparing RecStep with a number of other Datalog systems using both graphanalytics and program-analysis tasks, summarizing pros and cons of existingtechniques based on the analysis of our observations. We show that RecStepgenerally outperforms the state-of-the-art parallel Datalog engines on complexand large-scale Datalog program evaluation, by a 4-6X margin. An additionalinsight from our work is that we show that it is possible to build ahigh-performance Datalog system on top of a relational engine, an idea that hasbeen dismissed in past work in this area.

