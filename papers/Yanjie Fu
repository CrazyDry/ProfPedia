Provably Good Early Detection of Diseases using Non-Sparse  Covariance-Regularized Linear Discriminant Analysis

  To improve the performance of Linear Discriminant Analysis (LDA) for earlydetection of diseases using Electronic Health Records (EHR) data, we propose\TheName{} -- a novel framework for \emph{\underline{E}HR based\underline{E}arly \underline{D}etection of \underline{D}iseases} on top of\emph{Covariance-Regularized} LDA models. Specifically, \TheName\ employs a\emph{non-sparse} inverse covariance matrix (or namely precision matrix)estimator derived from graphical lasso and incorporates the estimator into LDAclassifiers to improve classification accuracy. Theoretical analysis on\TheName\ shows that it can bound the expected error rate of LDAclassification, under certain assumptions. Finally, we conducted extensiveexperiments using a large-scale real-world EHR dataset -- CHSN. We compared oursolution with other regularized LDA and downstream classifiers. The resultshows \TheName\ outperforms all baselines and backups our theoretical analysis.

CSWA: Aggregation-Free Spatial-Temporal Community Sensing

  In this paper, we present a novel community sensing paradigm -- {C}ommunity{S}ensing {W}ithout {A}ggregation}. CSWA is designed to obtain the environmentinformation (e.g., air pollution or temperature) in each subarea of the targetarea, without aggregating sensor and location data collected by communitymembers. CSWA operates on top of a secured peer-to-peer network over thecommunity members and proposes a novel \emph{Decentralized Spatial-TemporalCompressive Sensing} framework based on \emph{Parallelized Stochastic GradientDescent}. Through learning the \emph{low-rank structure} via distributedoptimization, CSWA approximates the value of the sensor data in each subarea(both covered and uncovered) for each sensing cycle using the sensor datalocally stored in each member's mobile device. Simulation experiments based onreal-world datasets demonstrate that CSWA exhibits low approximation error(i.e., less than $0.2 ^\circ$C in city-wide temperature sensing task and $10$units of PM2.5 index in urban air pollution sensing) and performs comparably to(sometimes better than) state-of-the-art algorithms based on the dataaggregation and centralized computation.

Heterogeneous Metric Learning with Content-based Regularization for  Software Artifact Retrieval

  The problem of software artifact retrieval has the goal to effectively locatesoftware artifacts, such as a piece of source code, in a large code repository.This problem has been traditionally addressed through the textual query. Inother words, information retrieval techniques will be exploited based on thetextual similarity between queries and textual representation of softwareartifacts, which is generated by collecting words from comments, identifiers,and descriptions of programs. However, in addition to these semanticinformation, there are rich information embedded in source codes themselves.These source codes, if analyzed properly, can be a rich source for enhancingthe efforts of software artifact retrieval. To this end, in this paper, wedevelop a feature extraction method on source codes. Specifically, this methodcan capture both the inherent information in the source codes and the semanticinformation hidden in the comments, descriptions, and identifiers of the sourcecodes. Moreover, we design a heterogeneous metric learning approach, whichallows to integrate code features and text features into the same latentsemantic space. This, in turn, can help to measure the artifact similarity byexploiting the joint power of both code and text features. Finally, extensiveexperiments on real-world data show that the proposed method can help toimprove the performances of software artifact retrieval with a significantmargin.

REMIX: Automated Exploration for Interactive Outlier Detection

  Outlier detection is the identification of points in a dataset that do notconform to the norm. Outlier detection is highly sensitive to the choice of thedetection algorithm and the feature subspace used by the algorithm. Extractingdomain-relevant insights from outliers needs systematic exploration of thesechoices since diverse outlier sets could lead to complementary insights. Thischallenge is especially acute in an interactive setting, where the choices mustbe explored in a time-constrained manner. In this work, we present REMIX, thefirst system to address the problem of outlier detection in an interactivesetting. REMIX uses a novel mixed integer programming (MIP) formulation forautomatically selecting and executing a diverse set of outlier detectors withina time limit. This formulation incorporates multiple aspects such as (i) anupper limit on the total execution time of detectors (ii) diversity in thespace of algorithms and features, and (iii) meta-learning for evaluating thecost and utility of detectors. REMIX provides two distinct ways for the analystto consume its results: (i) a partitioning of the detectors explored by REMIXinto perspectives through low-rank non-negative matrix factorization; eachperspective can be easily visualized as an intuitive heatmap of experimentsversus outliers, and (ii) an ensembled set of outliers which combines outlierscores from all detectors. We demonstrate the benefits of REMIX throughextensive empirical validation on real-world data.

LATTE: Application Oriented Social Network Embedding

  In recent years, many research works propose to embed the network structureddata into a low-dimensional feature space, where each node is represented as afeature vector. However, due to the detachment of embedding process withexternal tasks, the learned embedding results by most existing embedding modelscan be ineffective for application tasks with specific objectives, e.g.,community detection or information diffusion. In this paper, we propose studythe application oriented heterogeneous social network embedding problem.Significantly different from the existing works, besides the network structurepreservation, the problem should also incorporate the objectives of externalapplications in the objective function. To resolve the problem, in this paper,we propose a novel network embedding framework, namely the "appLicAtionorienTed neTwork Embedding" (Latte) model. In Latte, the heterogeneous networkstructure can be applied to compute the node "diffusive proximity" scores,which capture both local and global network structures. Based on these computedscores, Latte learns the network representation feature vectors by extendingthe autoencoder model model to the heterogeneous network scenario, which canalso effectively unite the objectives of network embedding and externalapplication tasks. Extensive experiments have been done on real-worldheterogeneous social network datasets, and the experimental results havedemonstrated the outstanding performance of Latte in learning therepresentation vectors for specific application tasks.

Fake News Detection with Deep Diffusive Network Model

  In recent years, due to the booming development of online social networks,fake news for various commercial and political purposes has been appearing inlarge numbers and widespread in the online world. With deceptive words, onlinesocial network users can get infected by these online fake news easily, whichhas brought about tremendous effects on the offline society already. Animportant goal in improving the trustworthiness of information in online socialnetworks is to identify the fake news timely. This paper aims at investigatingthe principles, methodologies and algorithms for detecting fake news articles,creators and subjects from online social networks and evaluating thecorresponding performance. This paper addresses the challenges introduced bythe unknown characteristics of fake news and diverse connections among newsarticles, creators and subjects. Based on a detailed data analysis, this paperintroduces a novel automatic fake news credibility inference model, namelyFakeDetector. Based on a set of explicit and latent features extracted from thetextual information, FakeDetector builds a deep diffusive network model tolearn the representations of news articles, creators and subjectssimultaneously. Extensive experiments have been done on a real-world fake newsdataset to compare FakeDetector with several state-of-the-art models, and theexperimental results have demonstrated the effectiveness of the proposed model.

Explainable Social Contextual Image Recommendation with Hierarchical  Attention

  Image based social networks are among the most popular social networkingservices in recent years. With tremendous images uploaded everyday,understanding users' preferences to the user-generated images and recommendingthem to users have become an urgent need. However, this is a challenging task.On one hand, we have to overcome the extremely data sparsity issue in imagerecommendation. On the other hand, we have to model the complex aspects thatinfluence users' preferences to these highly subjective content from theheterogeneous data. In this paper, we develop an explainable social contextualimage recommendation model to simultaneously explain and predict users'preferences to images. Specifically, in addition to user interest modeling inthe standard recommendation, we identify three key aspects that affect eachuser's preference on the social platform, where each aspect summarizes acontextual representation from the complex relationships between users andimages. We design a hierarchical attention model in recommendation processgiven the three contextual aspects. Particularly, the bottom layered attentionnetworks learn to select informative elements of each aspect from heterogeneousdata, and the top layered attention network learns to score the aspectimportance of the three identified aspects for each user. In this way, we couldovercome the data sparsity issue by leveraging the social contextual aspectsfrom heterogeneous data, and explain the underlying reasons for each user'sbehavior with the learned hierarchial attention scores. Extensive experimentalresults on real-world datasets clearly show the superiority of our proposedmodel.

SocialGCN: An Efficient Graph Convolutional Network based Model for  Social Recommendation

  Collaborative Filtering (CF) is one of the most successful approaches forrecommender systems. With the emergence of online social networks, socialrecommendation has become a popular research direction. Most of these socialrecommendation models utilized each user's local neighbors' preferences toalleviate the data sparsity issue in CF. However, they only considered thelocal neighbors of each user and neglected the process that users' preferencesare influenced as information diffuses in the social network. Recently, GraphConvolutional Networks~(GCN) have shown promising results by modeling theinformation diffusion process in graphs that leverage both graph structure andnode feature information. To this end, in this paper, we propose an effectivegraph convolutional neural network based model for social recommendation. Basedon a classical CF model, the key idea of our proposed model is that we borrowthe strengths of GCNs to capture how users' preferences are influenced by thesocial diffusion process in social networks. The diffusion of users'preferences is built on a layer-wise diffusion manner, with the initial userembedding as a function of the current user's features and a free base userlatent vector that is not contained in the user feature. Similarly, each item'slatent vector is also a combination of the item's free latent vector, as wellas its feature representation. Furthermore, we show that our proposed model isflexible when user and item features are not available. Finally, extensiveexperimental results on two real-world datasets clearly show the effectivenessof our proposed model.

BL-MNE: Emerging Heterogeneous Social Network Embedding through Broad  Learning with Aligned Autoencoder

  Network embedding aims at projecting the network data into a low-dimensionalfeature space, where the nodes are represented as a unique feature vector andnetwork structure can be effectively preserved. In recent years, more and moreonline application service sites can be represented as massive and complexnetworks, which are extremely challenging for traditional machine learningalgorithms to deal with. Effective embedding of the complex network data intolow-dimension feature representation can both save data storage space andenable traditional machine learning algorithms applicable to handle the networkdata. Network embedding performance will degrade greatly if the networks are ofa sparse structure, like the emerging networks with few connections. In thispaper, we propose to learn the embedding representation for a target emergingnetwork based on the broad learning setting, where the emerging network isaligned with other external mature networks at the same time. To solve theproblem, a new embedding framework, namely "Deep alIgned autoencoder basedeMbEdding" (DIME), is introduced in this paper. DIME handles the diverse linkand attribute in a unified analytic based on broad learning, and introduces themultiple aligned attributed heterogeneous social network concept to model thenetwork structure. A set of meta paths are introduced in the paper, whichdefine various kinds of connections among users via the heterogeneous link andattribute information. The closeness among users in the networks are defined asthe meta proximity scores, which will be fed into DIME to learn the embeddingvectors of users in the emerging network. Extensive experiments have been doneon real-world aligned social networks, which have demonstrated theeffectiveness of DIME in learning the emerging network embedding vectors.

Insight-HXMT observations of the first binary neutron star merger  GW170817

  Finding the electromagnetic (EM) counterpart of binary compact star merger,especially the binary neutron star (BNS) merger, is critically important forgravitational wave (GW) astronomy, cosmology and fundamental physics. On Aug.17, 2017, Advanced LIGO and \textit{Fermi}/GBM independently triggered thefirst BNS merger, GW170817, and its high energy EM counterpart, GRB 170817A,respectively, resulting in a global observation campaign covering gamma-ray,X-ray, UV, optical, IR, radio as well as neutrinos. The High Energy X-raytelescope (HE) onboard \textit{Insight}-HXMT (Hard X-ray Modulation Telescope)is the unique high-energy gamma-ray telescope that monitored the entire GWlocalization area and especially the optical counterpart (SSS17a/AT2017gfo)with very large collection area ($\sim$1000 cm$^2$) and microsecond timeresolution in 0.2-5 MeV. In addition, \textit{Insight}-HXMT quickly implementeda Target of Opportunity (ToO) observation to scan the GW localization area forpotential X-ray emission from the GW source. Although it did not detect anysignificant high energy (0.2-5 MeV) radiation from GW170817, its observationhelped to confirm the unexpected weak and soft nature of GRB 170817A.Meanwhile, \textit{Insight}-HXMT/HE provides one of the most stringentconstraints (~10$^{-7}$ to 10$^{-6}$ erg/cm$^2$/s) for both GRB170817A and anyother possible precursor or extended emissions in 0.2-5 MeV, which help us tobetter understand the properties of EM radiation from this BNS merger.Therefore the observation of \textit{Insight}-HXMT constitutes an importantchapter in the full context of multi-wavelength and multi-messenger observationof this historical GW event.

