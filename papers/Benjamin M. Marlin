Learning Time Series Detection Models from Temporally Imprecise Labels

  In this paper, we consider a new low-quality label learning problem: learning
time series detection models from temporally imprecise labels. In this problem,
the data consist of a set of input time series, and supervision is provided by
a sequence of noisy time stamps corresponding to the occurrence of positive
class events. Such temporally imprecise labels commonly occur in areas like
mobile health research where human annotators are tasked with labeling the
occurrence of very short duration events. We propose a general learning
framework for this problem that can accommodate different base classifiers and
noise models. We present results on real mobile health data showing that the
proposed framework significantly outperforms a number of alternatives including
assuming that the label time stamps are noise-free, transforming the problem
into the multiple instance learning framework, and learning on labels that were
manually re-aligned.


Modeling Irregularly Sampled Clinical Time Series

  While the volume of electronic health records (EHR) data continues to grow,
it remains rare for hospital systems to capture dense physiological data
streams, even in the data-rich intensive care unit setting. Instead, typical
EHR records consist of sparse and irregularly observed multivariate time
series, which are well understood to present particularly challenging problems
for machine learning methods. In this paper, we present a new deep learning
architecture for addressing this problem based on the use of a semi-parametric
interpolation network followed by the application of a prediction network. The
interpolation network allows for information to be shared across multiple
dimensions during the interpolation stage, while any standard deep learning
model can be used for the prediction network. We investigate the performance of
this architecture on the problems of mortality and length of stay prediction.


Integrating Propositional and Relational Label Side Information for
  Hierarchical Zero-Shot Image Classification

  Zero-shot learning (ZSL) is one of the most extreme forms of learning from
scarce labeled data. It enables predicting that images belong to classes for
which no labeled training instances are available. In this paper, we present a
new ZSL framework that leverages both label attribute side information and a
semantic label hierarchy. We present two methods, lifted zero-shot prediction
and a custom conditional random field (CRF) model, that integrate both forms of
side information. We propose benchmark tasks for this framework that focus on
making predictions across a range of semantic levels. We show that lifted
zero-shot prediction can dramatically outperform baseline methods when making
predictions within specified semantic levels, and that the probability
distribution provided by the CRF model can be leveraged to yield further
performance improvements when making unconstrained predictions over the
hierarchy.


Learning Tree-Structured Detection Cascades for Heterogeneous Networks
  of Embedded Devices

  In this paper, we present a new approach to learning cascaded classifiers for
use in computing environments that involve networks of heterogeneous and
resource-constrained, low-power embedded compute and sensing nodes. We present
a generalization of the classical linear detection cascade to the case of
tree-structured cascades where different branches of the tree execute on
different physical compute nodes in the network. Different nodes have access to
different features, as well as access to potentially different computation and
energy resources. We concentrate on the problem of jointly learning the
parameters for all of the classifiers in the cascade given a fixed cascade
architecture and a known set of costs required to carry out the computation at
each node.To accomplish the objective of joint learning of all detectors, we
propose a novel approach to combining classifier outputs during training that
better matches the hard cascade setting in which the learned system will be
deployed. This work is motivated by research in the area of mobile health where
energy efficient real time detectors integrating information from multiple
wireless on-body sensors and a smart phone are needed for real-time monitoring
and delivering just- in-time adaptive interventions. We apply our framework to
two activity recognition datasets as well as the problem of cigarette smoking
detection from a combination of wrist-worn actigraphy data and respiration
chest band data.


