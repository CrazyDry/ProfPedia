Head Reconstruction from Internet Photos

  3D face reconstruction from Internet photos has recently produced exciting
results. A person's face, e.g., Tom Hanks, can be modeled and animated in 3D
from a completely uncalibrated photo collection. Most methods, however, focus
solely on face area and mask out the rest of the head. This paper proposes that
head modeling from the Internet is a problem we can solve. We target
reconstruction of the rough shape of the head. Our method is to gradually
"grow" the head mesh starting from the frontal face and extending to the rest
of views using photometric stereo constraints. We call our method
boundary-value growing algorithm. Results on photos of celebrities downloaded
from the Internet are presented.


Y-Net: Joint Segmentation and Classification for Diagnosis of Breast
  Biopsy Images

  In this paper, we introduce a conceptually simple network for generating
discriminative tissue-level segmentation masks for the purpose of breast cancer
diagnosis. Our method efficiently segments different types of tissues in breast
biopsy images while simultaneously predicting a discriminative map for
identifying important areas in an image. Our network, Y-Net, extends and
generalizes U-Net by adding a parallel branch for discriminative map generation
and by supporting convolutional block modularity, which allows the user to
adjust network efficiency without altering the network topology. Y-Net delivers
state-of-the-art segmentation accuracy while learning 6.6x fewer parameters
than its closest competitors. The addition of descriptive power from Y-Net's
discriminative segmentation masks improve diagnostic classification accuracy by
7% over state-of-the-art methods for diagnostic classification. Source code is
available at: https://sacmehta.github.io/YNet.


3D Face Hallucination from a Single Depth Frame

  We present an algorithm that takes a single frame of a person's face from a
depth camera, e.g., Kinect, and produces a high-resolution 3D mesh of the input
face. We leverage a dataset of 3D face meshes of 1204 distinct individuals
ranging from age 3 to 40, captured in a neutral expression. We divide the input
depth frame into semantically significant regions (eyes, nose, mouth, cheeks)
and search the database for the best matching shape per region. We further
combine the input depth frame with the matched database shapes into a single
mesh that results in a high-resolution shape of the input person. Our system is
fully automatic and uses only depth data for matching, making it invariant to
imaging conditions. We evaluate our results using ground truth shapes, as well
as compare to state-of-the-art shape estimation methods. We demonstrate the
robustness of our local matching approach with high-quality reconstruction of
faces that fall outside of the dataset span, e.g., faces older than 40 years
old, facial expressions, and different ethnicities.


Video to Fully Automatic 3D Hair Model

  Imagine taking a selfie video with your mobile phone and getting as output a
3D model of your head (face and 3D hair strands) that can be later used in VR,
AR, and any other domain. State of the art hair reconstruction methods allow
either a single photo (thus compromising 3D quality) or multiple views, but
they require manual user interaction (manual hair segmentation and capture of
fixed camera views that span full 360 degree). In this paper, we describe a
system that can completely automatically create a reconstruction from any video
(even a selfie video), and we don't require specific views, since taking your
-90 degree, 90 degree, and full back views is not feasible in a selfie capture.
  In the core of our system, in addition to the automatization components, hair
strands are estimated and deformed in 3D (rather than 2D as in state of the
art) thus enabling superior results. We provide qualitative, quantitative, and
Mechanical Turk human studies that support the proposed system, and show
results on a diverse variety of videos (8 different celebrity videos, 9 selfie
mobile videos, spanning age, gender, hair length, type, and styling).


The SINS/zC-SINF survey of z~2 galaxy kinematics: evidence for
  gravitational quenching

  As part of the SINS/zC-SINF surveys of high-z galaxy kinematics, we derive
the radial distributions of H-alpha surface brightness, stellar mass surface
density, and dynamical mass at ~2 kpc resolution in 19 z~2 star-forming disks
with deep SINFONI AO spectroscopy at the ESO VLT. From these data we infer the
radial distribution of the Toomre Q-parameter for these main-sequence star
forming galaxies (SFGs), covering almost two decades of stellar mass (10^9.6 to
10^11.5 solar masses). In more than half of our SFGs, the H-alpha distributions
cannot be fit by a centrally peaked distribution, such as an exponential, but
are better described by a ring, or the combination of a ring and an
exponential. At the same time the kinematic data indicate the presence of a
mass distribution more centrally concentrated than a single exponential
distribution for 5 of the 19 galaxies. The resulting Q-distributions are
centrally peaked for all, and significantly exceed unity there for three
quarters of the SFGs. The occurrence of H-alpha rings and of large nuclear
Q-values is strongly correlated, and is more common for the more massive SFGs.
While our sample is small and there remain substantial uncertainties and
caveats, our observations are consistent with a scenario in which cloud
fragmentation and global star formation are secularly suppressed in gas rich
high-z disks from the inside out, as the central stellar mass density of the
disks grows.


Training the Next Generation of Astronomers

  While both society and astronomy have evolved greatly over the past fifty
years, the academic institutions and incentives that shape our field have
remained largely stagnant. As a result, the astronomical community is faced
with several major challenges, including: (1) the training that we provide does
not align with the skills that future astronomers will need, (2) the
postdoctoral phase is becoming increasingly demanding and demoralizing, and (3)
our jobs are increasingly unfriendly to families with children. Solving these
problems will require conscious engineering of our profession. Fortunately,
this Decadal Review offers the opportunity to revise outmoded practices to be
more effective and equitable. The highest priority of the Subcommittee on the
State of the Profession should be to recommend specific, funded activities that
will ensure the field meets the challenges we describe.


