An Extensible Benchmarking Infrastructure for Motion Planning Algorithms

  Sampling-based planning algorithms are the most common probabilisticallycomplete algorithms and are widely used on many robot platforms. Within thisclass of algorithms, many variants have been proposed over the last 20 years,yet there is still no characterization of which algorithms are well-suited forwhich classes of problems. This has motivated us to develop a benchmarkinginfrastructure for motion planning algorithms. It consists of three maincomponents. First, we have created an extensive benchmarking software frameworkthat is included with the Open Motion Planning Library (OMPL), a C++ librarythat contains implementations of many sampling-based algorithms. Second, wehave defined extensible formats for storing benchmark results. The formats arefairly straightforward so that other planning libraries could easily producecompatible output. Finally, we have created an interactive, versatilevisualization tool for compact presentation of collected benchmark data. Thetool and underlying database facilitate the analysis of performance acrossbenchmark problems and planners.

Using Local Experiences for Global Motion Planning

  Sampling-based planners are effective in many real-world applications such asrobotics manipulation, navigation, and even protein modeling. However, it isoften challenging to generate a collision-free path in environments where keyareas are hard to sample. In the absence of any prior information,sampling-based planners are forced to explore uniformly or heuristically, whichcan lead to degraded performance. One way to improve performance is to useprior knowledge of environments to adapt the sampling strategy to the problemat hand. In this work, we decompose the workspace into local primitives,memorizing local experiences by these primitives in the form of local samplers,and store them in a database. We synthesize an efficient global sampler byretrieving local experiences relevant to the given situation. Our methodtransfers knowledge effectively between diverse environments that share localprimitives and speeds up the performance dramatically. Our results show, interms of solution time, an improvement of multiple orders of magnitude in twotraditionally challenging high-dimensional problems compared tostate-of-the-art approaches.

Bounded Policy Synthesis for POMDPs with Safe-Reachability Objectives

  Planning robust executions under uncertainty is a fundamental challenge forbuilding autonomous robots. Partially Observable Markov Decision Processes(POMDPs) provide a standard framework for modeling uncertainty in manyapplications. In this work, we study POMDPs with safe-reachability objectives,which require that with a probability above some threshold, a goal state iseventually reached while keeping the probability of visiting unsafe statesbelow some threshold. This POMDP formulation is different from the traditionalPOMDP models with optimality objectives and we show that in some cases, POMDPswith safe-reachability objectives can provide a better guarantee of both safetyand reachability than the existing POMDP models through an example. A keyalgorithmic problem for POMDPs is policy synthesis, which requires reasoningover a vast space of beliefs (probability distributions). To address thischallenge, we introduce the notion of a goal-constrained belief space, whichonly contains beliefs reachable from the initial belief under desiredexecutions that can achieve the given safe-reachability objective. Our methodcompactly represents this space over a bounded horizon using symbolicconstraints, and employs an incremental Satisfiability Modulo Theories (SMT)solver to efficiently search for a valid policy over it. We evaluate our methodusing a case study involving a partially observable robotic domain withuncertain obstacles. The results show that our method can synthesize policiesover large belief spaces with a small number of SMT solver calls by focusing onthe goal-constrained belief space.

