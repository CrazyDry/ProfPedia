Improving the Accuracy of the CogniLearn System for Cognitive Behavior
  Assessment

  HTKS is a game-like cognitive assessment method, designed for children
between four and eight years of age. During the HTKS assessment, a child
responds to a sequence of requests, such as "touch your head" or "touch your
toes". The cognitive challenge stems from the fact that the children are
instructed to interpret these requests not literally, but by touching a
different body part than the one stated. In prior work, we have developed the
CogniLearn system, that captures data from subjects performing the HTKS game,
and analyzes the motion of the subjects. In this paper we propose some specific
improvements that make the motion analysis module more accurate. As a result of
these improvements, the accuracy in recognizing cases where subjects touch
their toes has gone from 76.46% in our previous work to 97.19% in this paper.


Towards Deep Learning based Hand Keypoints Detection for Rapid
  Sequential Movements from RGB Images

  Hand keypoints detection and pose estimation has numerous applications in
computer vision, but it is still an unsolved problem in many aspects. An
application of hand keypoints detection is in performing cognitive assessments
of a subject by observing the performance of that subject in physical tasks
involving rapid finger motion. As a part of this work, we introduce a novel
hand key-points benchmark dataset that consists of hand gestures recorded
specifically for cognitive behavior monitoring. We explore the state of the art
methods in hand keypoint detection and we provide quantitative evaluations for
the performance of these methods on our dataset. In future, these results and
our dataset can serve as a useful benchmark for hand keypoint recognition for
rapid finger movements.


Using Humanoid Robot to Instruct and Evaluate Performance of a Physical
  Task

  In this paper, we present a tool to assess users ability to change tasks. To
do this, we use a variation of the Box and Blocks Test. In this version, a
humanoid robot instructs a user to perform a task involving the movement of
certain colored blocks. The robot changes randomly change the color of blocks
that the user is supposed to move. Canny Edge Detection and Hough
Transformation are used to assess user perform the robot's built-in camera.
This will allow the robot to inform the user and keep a log of their progress.
We present this method for monitoring user progress by describing how the moved
blocks are detected. We also present the results of a pilot study where users
used this system to perform the task. Preliminary results show that users do
not perform differently when the task is changed in this scenario.


