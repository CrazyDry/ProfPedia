The Lovelace 2.0 Test of Artificial Creativity and Intelligence

  Observing that the creation of certain types of artistic artifacts
necessitate intelligence, we present the Lovelace 2.0 Test of creativity as an
alternative to the Turing Test as a means of determining whether an agent is
intelligent. The Lovelace 2.0 Test builds off prior tests of creativity and
additionally provides a means of directly comparing the relative intelligence
of different agents.


Computational Narrative Intelligence: A Human-Centered Goal for
  Artificial Intelligence

  Narrative intelligence is the ability to craft, tell, understand, and respond
affectively to stories. We argue that instilling artificial intelligences with
computational narrative intelligence affords a number of applications
beneficial to humans. We lay out some of the machine learning challenges
necessary to solve to achieve computational narrative intelligence. Finally, we
argue that computational narrative is a practical step towards machine
enculturation, the teaching of sociocultural values to machines.


A Python Engine for Teaching Artificial Intelligence in Games

  Computer games play an important role in our society and motivate people to
learn computer science. Since artificial intelligence is integral to most
games, they can also be used to teach artificial intelligence. We introduce the
Game AI Game Engine (GAIGE), a Python game engine specifically designed to
teach about how AI is used in computer games. A progression of seven
assignments builds toward a complete, working Multi-User Battle Arena (MOBA)
game. We describe the engine, the assignments, and our experiences using it in
a class on Game Artificial Intelligence.


Human-Centered Artificial Intelligence and Machine Learning

  Humans are increasingly coming into contact with artificial intelligence and
machine learning systems. Human-centered artificial intelligence is a
perspective on AI and ML that algorithms must be designed with awareness that
they are part of a larger system consisting of humans. We lay forth an argument
that human-centered artificial intelligence can be broken down into two
aspects: (1) AI systems that understand humans from a sociocultural
perspective, and (2) AI systems that help humans understand them. We further
argue that issues of social responsibility such as fairness, accountability,
interpretability, and transparency.


Creative Invention Benchmark

  In this paper we present the Creative Invention Benchmark (CrIB), a
2000-problem benchmark for evaluating a particular facet of computational
creativity. Specifically, we address combinational p-creativity, the creativity
at play when someone combines existing knowledge to achieve a solution novel to
that individual. We present generation strategies for the five problem
categories of the benchmark and a set of initial baselines.


Enter the Matrix: Safely Interruptible Autonomous Systems via
  Virtualization

  Autonomous systems that operate around humans will likely always rely on kill
switches that stop their execution and allow them to be remote-controlled for
the safety of humans or to prevent damage to the system. It is theoretically
possible for an autonomous system with sufficient sensor and effector
capability that learn online using reinforcement learning to discover that the
kill switch deprives it of long-term reward and thus learn to disable the
switch or otherwise prevent a human operator from using the switch. This is
referred to as the big red button problem. We present a technique that prevents
a reinforcement learning agent from learning to disable the kill switch. We
introduce an interruption process in which the agent's sensors and effectors
are redirected to a virtual simulation where it continues to believe it is
receiving reward. We illustrate our technique in a simple grid world
environment.


Guiding Reinforcement Learning Exploration Using Natural Language

  In this work we present a technique to use natural language to help
reinforcement learning generalize to unseen environments. This technique uses
neural machine translation, specifically the use of encoder-decoder networks,
to learn associations between natural language behavior descriptions and
state-action information. We then use this learned model to guide agent
exploration using a modified version of policy shaping to make it more
effective at learning in unseen environments. We evaluate this technique using
the popular arcade game, Frogger, under ideal and non-ideal conditions. This
evaluation shows that our modified policy shaping algorithm improves over a
Q-learning agent as well as a baseline version of policy shaping.


Evaluating Singleplayer and Multiplayer in Human Computation Games

  Human computation games (HCGs) can provide novel solutions to intractable
computational problems, help enable scientific breakthroughs, and provide
datasets for artificial intelligence. However, our knowledge about how to
design and deploy HCGs that appeal to players and solve problems effectively is
incomplete. We present an investigatory HCG based on Super Mario Bros. We used
this game in a human subjects study to investigate how different social
conditions---singleplayer and multiplayer---and scoring
mechanics---collaborative and competitive---affect players' subjective
experiences, accuracy at the task, and the completion rate. In doing so, we
demonstrate a novel design approach for HCGs, and discuss the benefits and
tradeoffs of these mechanics in HCG design.


Event Representations for Automated Story Generation with Deep Neural
  Nets

  Automated story generation is the problem of automatically selecting a
sequence of events, actions, or words that can be told as a story. We seek to
develop a system that can generate stories by learning everything it needs to
know from textual story corpora. To date, recurrent neural networks that learn
language models at character, word, or sentence levels have had little success
generating coherent stories. We explore the question of event representations
that provide a mid-level of abstraction between words and sentences in order to
retain the semantic information of the original data while minimizing event
sparsity. We present a technique for preprocessing textual story data into
event sequences. We then present a technique for automated story generation
whereby we decompose the problem into the generation of successive events
(event2event) and the generation of natural language sentences from events
(event2sentence). We give empirical results comparing different event
representations and their effects on event successor generation and the
translation of events to natural language.


Rationalization: A Neural Machine Translation Approach to Generating
  Natural Language Explanations

  We introduce AI rationalization, an approach for generating explanations of
autonomous system behavior as if a human had performed the behavior. We
describe a rationalization technique that uses neural machine translation to
translate internal state-action representations of an autonomous agent into
natural language. We evaluate our technique in the Frogger game environment,
training an autonomous game playing agent to rationalize its action choices
using natural language. A natural language training corpus is collected from
human players thinking out loud as they play the game. We motivate the use of
rationalization as an approach to explanation generation and show the results
of two experiments evaluating the effectiveness of rationalization. Results of
these evaluations show that neural machine translation is able to accurately
generate rationalizations that describe agent behavior, and that
rationalizations are more satisfying to humans than other alternative methods
of explanation.


A Framework for Exploring and Evaluating Mechanics in Human Computation
  Games

  Human computation games (HCGs) are a crowdsourcing approach to solving
computationally-intractable tasks using games. In this paper, we describe the
need for generalizable HCG design knowledge that accommodates the needs of both
players and tasks. We propose a formal representation of the mechanics in HCGs,
providing a structural breakdown to visualize, compare, and explore the space
of HCG mechanics. We present a methodology based on small-scale design
experiments using fixed tasks while varying game elements to observe effects on
both the player experience and the human computation task completion. Finally
we discuss applications of our framework using comparisons of prior HCGs and
recent design experiments. Ultimately, we wish to enable easier exploration and
development of HCGs, helping these games provide meaningful player experiences
while solving difficult problems.


Explore, Exploit or Listen: Combining Human Feedback and Policy Model to
  Speed up Deep Reinforcement Learning in 3D Worlds

  We describe a method to use discrete human feedback to enhance the
performance of deep learning agents in virtual three-dimensional environments
by extending deep-reinforcement learning to model the confidence and
consistency of human feedback. This enables deep reinforcement learning
algorithms to determine the most appropriate time to listen to the human
feedback, exploit the current policy model, or explore the agent's environment.
Managing the trade-off between these three strategies allows DRL agents to be
robust to inconsistent or intermittent human feedback. Through experimentation
using a synthetic oracle, we show that our technique improves the training
speed and overall performance of deep reinforcement learning in navigating
three-dimensional environments using Minecraft. We further show that our
technique is robust to highly innacurate human feedback and can also operate
when no human feedback is given.


Combinets: Creativity via Recombination of Neural Networks

  One of the defining characteristics of human creativity is the ability to
make conceptual leaps, creating something surprising from typical knowledge. In
comparison, deep neural networks often struggle to handle cases outside of
their training data, which is especially problematic for problems with limited
training data. Approaches exist to transfer knowledge from problems with
sufficient data to those with insufficient data, but they tend to require
additional training or a domain-specific method of transfer. We present a new
approach, conceptual expansion, that serves as a general representation for
reusing existing trained models to derive new models without backpropagation.
We evaluate our approach on few-shot variations of two tasks: image
classification and image generation, and outperform standard transfer learning
approaches.


Controllable Neural Story Plot Generation via Reinforcement Learning

  Language-modeling--based approaches to story plot generation attempt to
construct a plot by sampling from a language model (LM) to predict the next
character, word, or sentence to add to the story. LM techniques lack the
ability to receive guidance from the user to achieve a specific goal, resulting
in stories that don't have a clear sense of progression and lack coherence. We
present a reward-shaping technique that analyzes a story corpus and produces
intermediate rewards that are backpropagated into a pre-trained LM in order to
guide the model towards a given goal. Automated evaluations show our technique
can create a model that generates story plots which consistently achieve a
specified goal. Human-subject studies show that the generated stories have more
plausible event ordering than baseline plot generation techniques.


Playing Text-Adventure Games with Graph-Based Deep Reinforcement
  Learning

  Text-based adventure games provide a platform on which to explore
reinforcement learning in the context of a combinatorial action space, such as
natural language. We present a deep reinforcement learning architecture that
represents the game state as a knowledge graph which is learned during
exploration. This graph is used to prune the action space, enabling more
efficient exploration. The question of which action to take can be reduced to a
question-answering task, a form of transfer learning that pre-trains certain
parts of our architecture. In experiments using the TextWorld framework, we
show that our proposed technique can learn a control policy faster than
baseline alternatives. We have also open-sourced our code at
https://github.com/rajammanabrolu/KG-DQN.


