Deeply Supervised Semantic Model for Click-Through Rate Prediction in
  Sponsored Search

  In sponsored search it is critical to match ads that are relevant to a query
and to accurately predict their likelihood of being clicked. Commercial search
engines typically use machine learning models for both query-ad relevance
matching and click-through-rate (CTR) prediction. However, matching models are
based on the similarity between a query and an ad, ignoring the fact that a
retrieved ad may not attract clicks, while click models rely on click history,
being of limited use for new queries and ads. We propose a deeply supervised
architecture that jointly learns the semantic embeddings of a query and an ad
as well as their corresponding CTR.We also propose a novel cohort negative
sampling technique for learning implicit negative signals. We trained the
proposed architecture using one billion query-ad pairs from a major commercial
web search engine. This architecture improves the best-performing baseline deep
neural architectures by 2\% of AUC for CTR prediction and by statistically
significant 0.5\% of NDCG for query-ad matching.


Improving confidence while predicting trends in temporal disease
  networks

  For highly sensitive real-world predictive analytic applications such as
healthcare and medicine, having good prediction accuracy alone is often not
enough. These kinds of applications require a decision making process which
uses uncertainty estimation as input whenever possible. Quality of uncertainty
estimation is a subject of over or under confident prediction, which is often
not addressed in many models. In this paper we show several extensions to the
Gaussian Conditional Random Fields model, which aim to provide higher quality
uncertainty estimation. These extensions are applied to the temporal disease
graph built from the State Inpatient Database (SID) of California, acquired
from the HCUP. Our experiments demonstrate benefits of using graph information
in modeling temporal disease properties as well as improvements in uncertainty
estimation provided by given extensions of the Gaussian Conditional Random
Fields method.


Searching for Synergism Among Combinations of Drugs of Abuse and the Use
  of Isobolographic Analysis

  It is well known that individuals who abuse drugs usually use more than one
substance. Toxic consequences of single and multiple drug use are well
documented in the Treatment Episodes Data Set that lists combinations that
result in hospital admissions. Using this list as a guide, we focused our
attention on combinations that result in the most hospital admissions and
searched the PubMed database to determine the number of publications dealing
with these toxic combinations. Of special interest were those publications that
looked for or used the term synergism in their titles or abstracts, a search
that produced an extensive list of published articles. However, a further
intersection of these with the term isobole revealed a surprisingly small
number of literature reports. Because the method of isoboles is the most common
quantitative method for distinguishing between drug synergism and simple
additivity, the small number of investigations that actually employed this
quantitation suggests that the term synergism is not properly documented in
describing the toxicity among these abused substances. The possible reasons for
this lack of quantitation may be related to a misunderstanding of the modeling
equations. The theory and modeling are discussed here.


Semi-supervised learning for structured regression on partially observed
  attributed graphs

  Conditional probabilistic graphical models provide a powerful framework for
structured regression in spatio-temporal datasets with complex correlation
patterns. However, in real-life applications a large fraction of observations
is often missing, which can severely limit the representational power of these
models. In this paper we propose a Marginalized Gaussian Conditional Random
Fields (m-GCRF) structured regression model for dealing with missing labels in
partially observed temporal attributed graphs. This method is aimed at learning
with both labeled and unlabeled parts and effectively predicting future values
in a graph. The method is even capable of learning from nodes for which the
response variable is never observed in history, which poses problems for many
state-of-the-art models that can handle missing data. The proposed model is
characterized for various missingness mechanisms on 500 synthetic graphs. The
benefits of the new method are also demonstrated on a challenging application
for predicting precipitation based on partial observations of climate variables
in a temporal graph that spans the entire continental US. We also show that the
method can be useful for optimizing the costs of data collection in climate
applications via active reduction of the number of weather stations to
consider. In experiments on these real-world and synthetic datasets we show
that the proposed model is consistently more accurate than alternative
semi-supervised structured models, as well as models that either use imputation
to deal with missing values or simply ignore them altogether.


Modeling Customer Engagement from Partial Observations

  It is of high interest for a company to identify customers expected to bring
the largest profit in the upcoming period. Knowing as much as possible about
each customer is crucial for such predictions. However, their demographic data,
preferences, and other information that might be useful for building loyalty
programs is often missing. Additionally, modeling relations among different
customers as a network can be beneficial for predictions at an individual
level, as similar customers tend to have similar purchasing patterns. We
address this problem by proposing a robust framework for structured regression
on deficient data in evolving networks with a supervised representation
learning based on neural features embedding. The new method is compared to
several unstructured and structured alternatives for predicting customer
behavior (e.g. purchasing frequency and customer ticket) on user networks
generated from customer databases of two companies from different industries.
The obtained results show $4\%$ to $130\%$ improvement in accuracy over
alternatives when all customer information is known. Additionally, the
robustness of our method is demonstrated when up to $80\%$ of demographic
information was missing where it was up to several folds more accurate as
compared to alternatives that are either ignoring cases with missing values or
learn their feature representation in an unsupervised manner.


Deep Attention Model for Triage of Emergency Department Patients

  Optimization of patient throughput and wait time in emergency departments
(ED) is an important task for hospital systems. For that reason, Emergency
Severity Index (ESI) system for patient triage was introduced to help guide
manual estimation of acuity levels, which is used by nurses to rank the
patients and organize hospital resources. However, despite improvements that it
brought to managing medical resources, such triage system greatly depends on
nurse's subjective judgment and is thus prone to human errors. Here, we propose
a novel deep model based on the word attention mechanism designed for
predicting a number of resources an ED patient would need. Our approach
incorporates routinely available continuous and nominal (structured) data with
medical text (unstructured) data, including patient's chief complaint, past
medical history, medication list, and nurse assessment collected for 338,500 ED
visits over three years in a large urban hospital. Using both structured and
unstructured data, the proposed approach achieves the AUC of $\sim 88\%$ for
the task of identifying resource intensive patients (binary classification),
and the accuracy of $\sim 44\%$ for predicting exact category of number of
resources (multi-class classification task), giving an estimated lift over
nurses' performance by 16\% in accuracy. Furthermore, the attention mechanism
of the proposed model provides interpretability by assigning attention scores
for nurses' notes which is crucial for decision making and implementation of
such approaches in the real systems working on human health.


