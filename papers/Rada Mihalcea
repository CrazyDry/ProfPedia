Authorship Attribution Using Word Network Features

  In this paper, we explore a set of novel features for authorship attribution
of documents. These features are derived from a word network representation of
natural language text. As has been noted in previous studies, natural language
tends to show complex network structure at word level, with low degrees of
separation and scale-free (power law) degree distribution. There has also been
work on authorship attribution that incorporates ideas from complex networks.
The goal of our paper is to explore properties of these complex networks that
are suitable as features for machine-learning-based authorship attribution of
documents. We performed experiments on three different datasets, and obtained
promising results.


Stateology: State-Level Interactive Charting of Language, Feelings, and
  Values

  People's personality and motivations are manifest in their everyday language
usage. With the emergence of social media, ample examples of such usage are
procurable. In this paper, we aim to analyze the vocabulary used by close to
200,000 Blogger users in the U.S. with the purpose of geographically portraying
various demographic, linguistic, and psychological dimensions at the state
level. We give a description of a web-based tool for viewing maps that depict
various characteristics of the social media users as derived from this large
blog dataset of over two billion words.


Factors Influencing the Surprising Instability of Word Embeddings

  Despite the recent popularity of word embedding methods, there is only a
small body of work exploring the limitations of these representations. In this
paper, we consider one aspect of embedding spaces, namely their stability. We
show that even relatively high frequency words (100-200 occurrences) are often
unstable. We provide empirical evidence for how various factors contribute to
the stability of word embeddings, and we analyze the effects of stability on
downstream tasks.


Speaker Naming in Movies

  We propose a new model for speaker naming in movies that leverages visual,
textual, and acoustic modalities in an unified optimization framework. To
evaluate the performance of our model, we introduce a new dataset consisting of
six episodes of the Big Bang Theory TV show and eighteen full movies covering
different genres. Our experiments show that our multimodal model significantly
outperforms several competitive baselines on the average weighted F-score
metric. To demonstrate the effectiveness of our framework, we design an
end-to-end memory network model that leverages our speaker naming model and
achieves state-of-the-art results on the subtitles task of the MovieQA 2017
Challenge.


Predicting the Industry of Users on Social Media

  Automatic profiling of social media users is an important task for supporting
a multitude of downstream applications. While a number of studies have used
social media content to extract and study collective social attributes, there
is a lack of substantial research that addresses the detection of a user's
industry. We frame this task as classification using both feature engineering
and ensemble learning. Our industry-detection system uses both posted content
and profile information to detect a user's industry with 64.3% accuracy,
significantly outperforming the majority baseline in a taxonomy of fourteen
industry classes. Our qualitative analysis suggests that a person's industry
not only affects the words used and their perceived meanings, but also the
number and type of emotions being expressed.


Automatic Detection of Fake News

  The proliferation of misleading information in everyday access media outlets
such as social media feeds, news blogs, and online newspapers have made it
challenging to identify trustworthy news sources, thus increasing the need for
computational tools able to provide insights into the reliability of online
content. In this paper, we focus on the automatic identification of fake
content in online news. Our contribution is twofold. First, we introduce two
novel datasets for the task of fake news detection, covering seven different
news domains. We describe the collection, annotation, and validation process in
detail and present several exploratory analysis on the identification of
linguistic differences in fake and legitimate news content. Second, we conduct
a set of learning experiments to build accurate fake news detectors. In
addition, we provide comparative analyses of the automatic and manual
identification of fake news.


Direct Network Transfer: Transfer Learning of Sentence Embeddings for
  Semantic Similarity

  Sentence encoders, which produce sentence embeddings using neural networks,
are typically evaluated by how well they transfer to downstream tasks. This
includes semantic similarity, an important task in natural language
understanding. Although there has been much work dedicated to building sentence
encoders, the accompanying transfer learning techniques have received
relatively little attention. In this paper, we propose a transfer learning
setting specialized for semantic similarity, which we refer to as direct
network transfer. Through experiments on several standard text similarity
datasets, we show that applying direct network transfer to existing encoders
can lead to state-of-the-art performance. Additionally, we compare several
approaches to transfer sentence encoders to semantic similarity tasks, showing
that the choice of transfer learning setting greatly affects the performance in
many cases, and differs by encoder and dataset.


CASCADE: Contextual Sarcasm Detection in Online Discussion Forums

  The literature in automated sarcasm detection has mainly focused on lexical,
syntactic and semantic-level analysis of text. However, a sarcastic sentence
can be expressed with contextual presumptions, background and commonsense
knowledge. In this paper, we propose CASCADE (a ContextuAl SarCasm DEtector)
that adopts a hybrid approach of both content and context-driven modeling for
sarcasm detection in online social media discussions. For the latter, CASCADE
aims at extracting contextual information from the discourse of a discussion
thread. Also, since the sarcastic nature and form of expression can vary from
person to person, CASCADE utilizes user embeddings that encode stylometric and
personality features of the users. When used along with content-based feature
extractors such as Convolutional Neural Networks (CNNs), we see a significant
boost in the classification performance on a large Reddit corpus.


Multi-Label Transfer Learning for Multi-Relational Semantic Similarity

  Multi-relational semantic similarity datasets define the semantic relations
between two short texts in multiple ways, e.g., similarity, relatedness, and so
on. Yet, all the systems to date designed to capture such relations target one
relation at a time. We propose a multi-label transfer learning approach based
on LSTM to make predictions for several relations simultaneously and aggregate
the losses to update the parameters. This multi-label regression approach
jointly learns the information provided by the multiple relations, rather than
treating them as separate tasks. Not only does this approach outperform the
single-task approach and the traditional multi-task learning approach, but it
also achieves state-of-the-art performance on all but one relation of the Human
Activity Phrase dataset.


DialogueRNN: An Attentive RNN for Emotion Detection in Conversations

  Emotion detection in conversations is a necessary step for a number of
applications, including opinion mining over chat history, social media threads,
debates, argumentation mining, understanding consumer feedback in live
conversations, etc. Currently, systems do not treat the parties in the
conversation individually by adapting to the speaker of each utterance. In this
paper, we describe a new method based on recurrent neural networks that keeps
track of the individual party states throughout the conversation and uses this
information for emotion classification. Our model outperforms the state of the
art by a significant margin on two different datasets.


A Comparative Analysis of Content-based Geolocation in Blogs and Tweets

  The geolocation of online information is an essential component in any
geospatial application. While most of the previous work on geolocation has
focused on Twitter, in this paper we quantify and compare the performance of
text-based geolocation methods on social media data drawn from both Blogger and
Twitter. We introduce a novel set of location specific features that are both
highly informative and easily interpretable, and show that we can achieve error
rate reductions of up to 12.5% with respect to the best previously proposed
geolocation features. We also show that despite posting longer text, Blogger
users are significantly harder to geolocate than Twitter users. Additionally,
we investigate the effect of training and testing on different media
(cross-media predictions), or combining multiple social media sources
(multi-media predictions). Finally, we explore the geolocability of social
media in relation to three user dimensions: state, gender, and industry.


MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion
  Annotations

  Emotion recognition algorithms rely on data annotated with high quality
labels. However, emotion expression and perception are inherently subjective.
There is generally not a single annotation that can be unambiguously declared
"correct". As a result, annotations are colored by the manner in which they
were collected. In this paper, we conduct crowdsourcing experiments to
investigate this impact on both the annotations themselves and on the
performance of these algorithms. We focus on one critical question: the effect
of context. We present a new emotion dataset, Multimodal Stressed Emotion
(MuSE), and annotate the dataset using two conditions: randomized, in which
annotators are presented with clips in random order, and contextualized, in
which annotators are presented with clips in order. We find that contextual
labeling schemes result in annotations that are more similar to a speaker's own
self-reported labels and that labels generated from randomized schemes are most
easily predictable by automated systems.


MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in
  Conversations

  Emotion recognition in conversations is a challenging Artificial Intelligence
(AI) task. Recently, it has gained popularity due to its potential applications
in many interesting AI tasks such as empathetic dialogue generation, user
behavior understanding, and so on. To the best of our knowledge, there is no
multimodal multi-party conversational dataset available, which contains more
than two speakers in a dialogue. In this work, we propose the Multimodal
EmotionLines Dataset (MELD), which we created by enhancing and extending the
previously introduced EmotionLines dataset. MELD contains 13,708 utterances
from 1433 dialogues of Friends TV series. MELD is superior to other
conversational emotion recognition datasets SEMAINE and IEMOCAP as it consists
of multiparty conversations and number of utterances in MELD is almost twice as
these two datasets. Every utterance in MELD is associated with an emotion and a
sentiment label. Utterances in MELD are multimodal encompassing audio and
visual modalities along with the text. We have also addressed several
shortcomings in EmotionLines and proposed a strong multimodal baseline. The
baseline results show that both contextual and multimodal information play
important role in emotion recognition in conversations.


