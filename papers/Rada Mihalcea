Authorship Attribution Using Word Network Features

  In this paper, we explore a set of novel features for authorship attributionof documents. These features are derived from a word network representation ofnatural language text. As has been noted in previous studies, natural languagetends to show complex network structure at word level, with low degrees ofseparation and scale-free (power law) degree distribution. There has also beenwork on authorship attribution that incorporates ideas from complex networks.The goal of our paper is to explore properties of these complex networks thatare suitable as features for machine-learning-based authorship attribution ofdocuments. We performed experiments on three different datasets, and obtainedpromising results.

Stateology: State-Level Interactive Charting of Language, Feelings, and  Values

  People's personality and motivations are manifest in their everyday languageusage. With the emergence of social media, ample examples of such usage areprocurable. In this paper, we aim to analyze the vocabulary used by close to200,000 Blogger users in the U.S. with the purpose of geographically portrayingvarious demographic, linguistic, and psychological dimensions at the statelevel. We give a description of a web-based tool for viewing maps that depictvarious characteristics of the social media users as derived from this largeblog dataset of over two billion words.

Factors Influencing the Surprising Instability of Word Embeddings

  Despite the recent popularity of word embedding methods, there is only asmall body of work exploring the limitations of these representations. In thispaper, we consider one aspect of embedding spaces, namely their stability. Weshow that even relatively high frequency words (100-200 occurrences) are oftenunstable. We provide empirical evidence for how various factors contribute tothe stability of word embeddings, and we analyze the effects of stability ondownstream tasks.

Speaker Naming in Movies

  We propose a new model for speaker naming in movies that leverages visual,textual, and acoustic modalities in an unified optimization framework. Toevaluate the performance of our model, we introduce a new dataset consisting ofsix episodes of the Big Bang Theory TV show and eighteen full movies coveringdifferent genres. Our experiments show that our multimodal model significantlyoutperforms several competitive baselines on the average weighted F-scoremetric. To demonstrate the effectiveness of our framework, we design anend-to-end memory network model that leverages our speaker naming model andachieves state-of-the-art results on the subtitles task of the MovieQA 2017Challenge.

Predicting the Industry of Users on Social Media

  Automatic profiling of social media users is an important task for supportinga multitude of downstream applications. While a number of studies have usedsocial media content to extract and study collective social attributes, thereis a lack of substantial research that addresses the detection of a user'sindustry. We frame this task as classification using both feature engineeringand ensemble learning. Our industry-detection system uses both posted contentand profile information to detect a user's industry with 64.3% accuracy,significantly outperforming the majority baseline in a taxonomy of fourteenindustry classes. Our qualitative analysis suggests that a person's industrynot only affects the words used and their perceived meanings, but also thenumber and type of emotions being expressed.

Automatic Detection of Fake News

  The proliferation of misleading information in everyday access media outletssuch as social media feeds, news blogs, and online newspapers have made itchallenging to identify trustworthy news sources, thus increasing the need forcomputational tools able to provide insights into the reliability of onlinecontent. In this paper, we focus on the automatic identification of fakecontent in online news. Our contribution is twofold. First, we introduce twonovel datasets for the task of fake news detection, covering seven differentnews domains. We describe the collection, annotation, and validation process indetail and present several exploratory analysis on the identification oflinguistic differences in fake and legitimate news content. Second, we conducta set of learning experiments to build accurate fake news detectors. Inaddition, we provide comparative analyses of the automatic and manualidentification of fake news.

Direct Network Transfer: Transfer Learning of Sentence Embeddings for  Semantic Similarity

  Sentence encoders, which produce sentence embeddings using neural networks,are typically evaluated by how well they transfer to downstream tasks. Thisincludes semantic similarity, an important task in natural languageunderstanding. Although there has been much work dedicated to building sentenceencoders, the accompanying transfer learning techniques have receivedrelatively little attention. In this paper, we propose a transfer learningsetting specialized for semantic similarity, which we refer to as directnetwork transfer. Through experiments on several standard text similaritydatasets, we show that applying direct network transfer to existing encoderscan lead to state-of-the-art performance. Additionally, we compare severalapproaches to transfer sentence encoders to semantic similarity tasks, showingthat the choice of transfer learning setting greatly affects the performance inmany cases, and differs by encoder and dataset.

CASCADE: Contextual Sarcasm Detection in Online Discussion Forums

  The literature in automated sarcasm detection has mainly focused on lexical,syntactic and semantic-level analysis of text. However, a sarcastic sentencecan be expressed with contextual presumptions, background and commonsenseknowledge. In this paper, we propose CASCADE (a ContextuAl SarCasm DEtector)that adopts a hybrid approach of both content and context-driven modeling forsarcasm detection in online social media discussions. For the latter, CASCADEaims at extracting contextual information from the discourse of a discussionthread. Also, since the sarcastic nature and form of expression can vary fromperson to person, CASCADE utilizes user embeddings that encode stylometric andpersonality features of the users. When used along with content-based featureextractors such as Convolutional Neural Networks (CNNs), we see a significantboost in the classification performance on a large Reddit corpus.

Multi-Label Transfer Learning for Multi-Relational Semantic Similarity

  Multi-relational semantic similarity datasets define the semantic relationsbetween two short texts in multiple ways, e.g., similarity, relatedness, and soon. Yet, all the systems to date designed to capture such relations target onerelation at a time. We propose a multi-label transfer learning approach basedon LSTM to make predictions for several relations simultaneously and aggregatethe losses to update the parameters. This multi-label regression approachjointly learns the information provided by the multiple relations, rather thantreating them as separate tasks. Not only does this approach outperform thesingle-task approach and the traditional multi-task learning approach, but italso achieves state-of-the-art performance on all but one relation of the HumanActivity Phrase dataset.

DialogueRNN: An Attentive RNN for Emotion Detection in Conversations

  Emotion detection in conversations is a necessary step for a number ofapplications, including opinion mining over chat history, social media threads,debates, argumentation mining, understanding consumer feedback in liveconversations, etc. Currently, systems do not treat the parties in theconversation individually by adapting to the speaker of each utterance. In thispaper, we describe a new method based on recurrent neural networks that keepstrack of the individual party states throughout the conversation and uses thisinformation for emotion classification. Our model outperforms the state of theart by a significant margin on two different datasets.

A Comparative Analysis of Content-based Geolocation in Blogs and Tweets

  The geolocation of online information is an essential component in anygeospatial application. While most of the previous work on geolocation hasfocused on Twitter, in this paper we quantify and compare the performance oftext-based geolocation methods on social media data drawn from both Blogger andTwitter. We introduce a novel set of location specific features that are bothhighly informative and easily interpretable, and show that we can achieve errorrate reductions of up to 12.5% with respect to the best previously proposedgeolocation features. We also show that despite posting longer text, Bloggerusers are significantly harder to geolocate than Twitter users. Additionally,we investigate the effect of training and testing on different media(cross-media predictions), or combining multiple social media sources(multi-media predictions). Finally, we explore the geolocability of socialmedia in relation to three user dimensions: state, gender, and industry.

MuSE-ing on the Impact of Utterance Ordering On Crowdsourced Emotion  Annotations

  Emotion recognition algorithms rely on data annotated with high qualitylabels. However, emotion expression and perception are inherently subjective.There is generally not a single annotation that can be unambiguously declared"correct". As a result, annotations are colored by the manner in which theywere collected. In this paper, we conduct crowdsourcing experiments toinvestigate this impact on both the annotations themselves and on theperformance of these algorithms. We focus on one critical question: the effectof context. We present a new emotion dataset, Multimodal Stressed Emotion(MuSE), and annotate the dataset using two conditions: randomized, in whichannotators are presented with clips in random order, and contextualized, inwhich annotators are presented with clips in order. We find that contextuallabeling schemes result in annotations that are more similar to a speaker's ownself-reported labels and that labels generated from randomized schemes are mosteasily predictable by automated systems.

MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in  Conversations

  Emotion recognition in conversations is a challenging Artificial Intelligence(AI) task. Recently, it has gained popularity due to its potential applicationsin many interesting AI tasks such as empathetic dialogue generation, userbehavior understanding, and so on. To the best of our knowledge, there is nomultimodal multi-party conversational dataset available, which contains morethan two speakers in a dialogue. In this work, we propose the MultimodalEmotionLines Dataset (MELD), which we created by enhancing and extending thepreviously introduced EmotionLines dataset. MELD contains 13,708 utterancesfrom 1433 dialogues of Friends TV series. MELD is superior to otherconversational emotion recognition datasets SEMAINE and IEMOCAP as it consistsof multiparty conversations and number of utterances in MELD is almost twice asthese two datasets. Every utterance in MELD is associated with an emotion and asentiment label. Utterances in MELD are multimodal encompassing audio andvisual modalities along with the text. We have also addressed severalshortcomings in EmotionLines and proposed a strong multimodal baseline. Thebaseline results show that both contextual and multimodal information playimportant role in emotion recognition in conversations.

