Simpler proof of the theorem by Pusey, Barrett, and Rudolph on the
  reality of the quantum state

  The theorem of Pusey, Barrett, and Rudolph proves that different quantum
states describe different physical realities. Their proof is based on the
construction of entanglement measurement bases of two, and more than two qbits.
In this note, I show that a two-qubit entanglement base is sufficient for a
general proof.


Asymptotics of Relativistic Spin Networks

  The stationary phase technique is used to calculate asymptotic formulae for
SO(4) Relativistic Spin Networks. For the tetrahedral spin network this gives
the square of the Ponzano-Regge asymptotic formula for the SU(2) 6j symbol. For
the 4-simplex (10j-symbol) the asymptotic formula is compared with numerical
calculations of the Spin Network evaluation. Finally we discuss the asymptotics
of the SO(3,1) 10j-symbol.


Remarks on variational problems for Fefferman's measure

  We investigate the Plateau and isoperimetric problems associated to
Fefferman's measure for strongly pseudoconvex real hypersurfaces in $\mathbb
C^n$ (focusing on the case $n=2$), showing in particular that the isoperimetric
problem shares features of both the euclidean isoperimetric problem and the
corresponding problem in Blaschke's equiaffine geometry in which the key
inequalities are reversed.
  The problems are invariant under constant-Jacobian biholomorphism, but we
also introduce a non-trivial modified isoperimetric quantity invariant under
general biholomorphism.


A Jansky VLA Survey of Magnetic Cataclysmic Variable Stars: I. The Data

  The Jansky Very Large Array was used to observe 121 magnetic cataclysmic
variables (MCVs). We report radio detections of 19 stars. Fourteen are new
radio sources, increasing the number of MCVs that are radio sources by more
than twofold, from 8 to 22. Most detections are at 8.7 GHz (X-band) with a
lesser number at 5.4 and 21.1 GHz (C- and K-bands). Most flux density limits
are in the range of 47-470 uJy. With the exception of AE Aqr, the maximum flux
detected is 818 uJy. Fourteen of the detections show approximately 100%
circularly polarized emission, which is characteristic of electron-cyclotron
maser emission. The data suggest that MCVs might be divided into two classes of
radio emitters: those dominated by weakly polarized gyro-synchrotron emission
and those by highly polarized electron-cyclotron maser emission.


Using microsimulation feedback for trip adaptation for realistic traffic
  in Dallas

  This paper presents a day-to-day re-routing relaxation approach for traffic
simulations. Starting from an initial planset for the routes, the route-based
microsimulation is executed. The result of the microsimulation is fed into a
re-router, which re-routes a certain percentage of all trips. This approach
makes the traffic patterns in the microsimulation much more reasonable.
Further, it is shown that the method described in this paper can lead to strong
oscillations in the solutions.


TRANSIMS traffic flow characteristics

  Knowledge of fundamental traffic flow characteristics of traffic simulation
models is an essential requirement when using these models for the planning,
design, and operation of transportation systems. In this paper we discuss the
following: a description of how features relevant to traffic flow are currently
under implementation in the TRANSIMS microsimulation, a proposition for
standardized traffic flow tests for traffic simulation models, and the results
of these tests for two different versions of the TRANSIMS microsimulation.


Algorithms for Verifying Deep Neural Networks

  Deep neural networks are widely used for nonlinear function approximation
with applications ranging from computer vision to control. Although these
networks involve the composition of simple arithmetic operations, it can be
very challenging to verify whether a particular network satisfies certain
input-output properties. This article surveys methods that have emerged
recently for soundly verifying such properties. These methods borrow insights
from reachability analysis, optimization, and search. We discuss fundamental
differences and connections between existing algorithms. In addition, we
provide pedagogical implementations of existing methods and compare them on a
set of benchmark problems.


On a Classification of Irreducible Almost-Commutative Geometries IV

  In this paper we will classify the finite spectral triples with KO-dimension
six, following the classification found in [1,2,3,4], with up to four summands
in the matrix algebra. Again, heavy use is made of Kra jewski diagrams [5].
Furthermore we will show that any real finite spectral triple in KO-dimension 6
is automatically S 0 -real. This work has been inspired by the recent paper by
Alain Connes [6] and John Barrett [7].
  In the classification we find that the standard model of particle physics in
its minimal version fits the axioms of noncommutative geometry in the case of
KO-dimension six. By minimal version it is meant that at least one neutrino has
to be massless and mass-terms mixing particles and antiparticles are prohibited


Almost-Commutative Geometry, massive Neutrinos and the Orientability
  Axiom in KO-Dimension 6

  In recent publications Alain Connes [1] and John Barrett [2] proposed to
change the KO-dimension of the internal space of the standard model in its
noncommutative representation [3] from zero to six. This apparently minor
modification allowed to resolve the fermion doubling problem [4], and the
introduction of Majorana mass terms for the right-handed neutrino. The price
which had to be paid was that at least the orientability axiom of
noncommutative geometry [5,6] may not be obeyed by the underlying geometry. In
this publication we review three internal geometries, all three failing to meet
the orientability axiom of noncommutative geometry. They will serve as examples
to illustrate the nature of this lack of orientability. We will present an
extension of the minimal standard model found in [7] by a right-handed
neutrino, where only the sub-representation associated to this neutrino is not
orientable.


The Spread of Voting Attitudes in Social Networks

  The Shapley-Shubik power index is a measure of each voters power in the
passage or failure of a vote. We extend this measure to graphs and consider a
discrete-time process in which voters may change their vote based on the
outcome of the previous vote. We use this model to study how voter influence
can spread through a network. We find conditions under which a vanishingly
small portion of consenting voters can change the votes of the entirety of the
network. For a particular family of graphs, this process can be modeled using
cellular automata. In particular, we find a connection between this process and
the well-studied cellular automata, Rule 90. We use this connection to show
that such processes can exhibit arbitrarily-long periodicity.


RNA secondary structures having a compatible sequence of certain
  nucleotide ratios

  Given a random RNA secondary structure, $S$, we study RNA sequences having
fixed ratios of nuclotides that are compatible with $S$. We perform this
analysis for RNA secondary structures subject to various base pairing rules and
minimum arc- and stack-length restrictions. Our main result reads as follows:
in the simplex of the nucleotide ratios there exists a convex region in which,
in the limit of long sequences, a random structure a.a.s.~has compatible
sequence with these ratios and outside of which a.a.s.~a random structure has
no such compatible sequence. We localize this region for RNA secondary
structures subject to various base pairing rules and minimum arc- and
stack-length restrictions. In particular, for {\bf GC}-sequences having a ratio
of {\bf G} nucleotides smaller than $1/3$, a random RNA secondary structure
without any minimum arc- and stack-length restrictions has a.a.s.~no such
compatible sequence. For sequences having a ratio of {\bf G} nucleotides larger
than $1/3$, a random RNA secondary structure has a.a.s. such compatible
sequences. We discuss our results in the context of various families of RNA
structures.


The candidacy of shuffle and shear during compound twinning in hexagonal
  close-packed structures

  This paper proposes a systematic generalized formulation for calculating both
atomic shuffling and shear candidates for a given compound twinning mode in
hexagonal closed-packed metals. Although shuffles play an important role in the
mobility of twinning dislocations in non-Bravais metallic lattices, their
analytical expressions have not been previously derived. The method is
illustrated for both flat planes and corrugated planes which are exemplified by
{11-22} and {10-12} twinning modes, respectively. The method distinguishes
between shuffle displacements and net shuffles. While shuffle displacements
correspond to movements between ideal atom positions in the parent and twin
lattices, net shuffles comprise contributions from shear on overlying planes
which can operate along opposite directions to those of shuffle displacements.
Thus, net shuffles in the twinning direction can vanish in a limiting case, as
is interestingly the case for those needed in the second plane by the b_4
dislocation candidate in {11-22} twinning. It is found that while shuffle
displacement vectors can be irrational when K_1 is corrugated, net shuffle
vectors are always rational.


The whole is greater than the sum of the parts: on the possibility of
  purely statistical interpretations of quantum theory

  The Pusey-Barrett-Rudolph theorem (PBR) claims to rule out the possibility of
a purely statistical interpretation of the quantum state under an assumption of
how to represent independent operations in any hidden variable model. We show
that PBR's assumption of independence encodes an assumption of local causality,
which is already known to conflict with the predictions of quantum theory via
Bell-type inequalities. We devise a weaker formulation of independence within a
general hidden variable model that is empirically indistinguishable from the
PBR assumption in situations where certain hidden variables are inaccessible.
Under this weaker principle we are able to construct an explicit hidden
variable model that is purely statistical and also reproduces the quantum
predictions. Our results suggest that the assumption of a purely statistical
interpretation is actually an innocent bystander in the PBR argument, rather
than the driving force behind their contradiction.


On the quantized dynamics of factorial languages

  We study local piecewise conjugacy of the quantized dynamics arising from
factorial languages. We show that it induces a bijection between allowable
words of same length and thus it preserves entropy. In the case of sofic
factorial languages we prove that local piecewise conjugacy translates to
unlabeled graph isomorphism of the follower set graphs. Moreover it induces an
unlabeled graph isomorphism between the Fischer covers of irreducible
subshifts. We verify that local piecewise conjugacy does not preserve finite
type nor irreducibility; but it preserves soficity. Moreover it implies
identification (up to a permutation) for factorial languages of type $1$ if,
and only if, the follower set function is one-to-one on the symbol set.


IB2d Reloaded: a more powerful Python and MATLAB implementation of the
  immersed boundary method

  The immersed boundary method (IB) is an elegant way to fully couple the
motion of a fluid and deformations of an immersed elastic structure. In that
vein, the IB2d software allows for expedited explorations of fluid-structure
interaction for beginners and veterans to the field of computational fluid
dynamics (CFD). While most open source CFD codes are written in low level
programming environments, IB2d was specifically written in high- level
programming environments to make its accessibility extend beyond scientists
with vast programming experience. Although introduced previously by Battista et
al. 2015, many improvements and additions have been made to the software to
allow for even more robust models of material properties for the elastic
structures, including a data analysis package for both the fluid and immersed
structure data, an improved time-stepping scheme for higher accuracy solutions,
and functionality for modeling slight fluid density variations as given by the
Boussinesq approximation.


Genetic robustness of let-7 miRNA sequence-structure pairs

  Genetic robustness, the preservation of evolved phenotypes against genotypic
mutations, is one of the central concepts in evolution. In recent years a large
body of work has focused on the origins, mechanisms, and consequences of
robustness in a wide range of biological systems. In particular, research on
ncRNAs studied the ability of sequences to maintain folded structures against
single-point mutations. In these studies, the structure is merely a reference.
However, recent work revealed evidence that structure itself contributes to the
genetic robustness of ncRNAs. We follow this line of thought and consider
sequence-structure pairs as the unit of evolution and introduce the spectrum of
inverse folding rates (IFR-spectrum) as a measurement of genetic robustness.
Our analysis of the miRNA let-7 family captures key features of
structure-modulated evolution and facilitates the study of robustness against
multiple-point mutations.


Accuracy of inference on the physics of binary evolution from
  gravitational-wave observations

  The properties of the population of merging binary black holes encode some of
the uncertain physics of the evolution of massive stars in binaries. The binary
black hole merger rate and chirp mass distribution are being measured by
ground-based gravitational-wave detectors. We consider isolated binary
evolution and explore how accurately the physical model can be constrained with
such observations by applying the Fisher information matrix to the merging
black hole population simulated with the rapid binary population synthesis code
COMPAS. We investigate variations in four COMPAS parameters: common envelope
efficiency, kick velocity dispersion, and mass loss rates during the luminous
blue variable and Wolf--Rayet stellar evolutionary phases. We find that 1000
observations would constrain these model parameters to a fractional accuracy of
a few percent. Given the empirically determined binary black hole merger rate,
we can expect gravitational-wave observations alone to place strong constraints
on the physics of stellar and binary evolution within a few years.


Elements of a Theory of Simulation

  Unlike computation or the numerical analysis of differential equations,
simulation does not have a well established conceptual and mathematical
foundation. Simulation is an arguable unique union of modeling and computation.
However, simulation also qualifies as a separate species of system
representation with its own motivations, characteristics, and implications.
This work outlines how simulation can be rooted in mathematics and shows which
properties some of the elements of such a mathematical framework has. The
properties of simulation are described and analyzed in terms of properties of
dynamical systems. It is shown how and why a simulation produces emergent
behavior and why the analysis of the dynamics of the system being simulated
always is an analysis of emergent phenomena. A notion of a universal simulator
and the definition of simulatability is proposed. This allows a description of
conditions under which simulations can distribute update functions over system
components, thereby determining simulatability. The connection between the
notion of simulatability and the notion of computability is defined and the
concepts are distinguished. The basis of practical detection methods for
determining effectively non-simulatable systems in practice is presented. The
conceptual framework is illustrated through examples from molecular
self-assembly end engineering.


Sequence-structure relations of biopolymers

  Motivation: DNA data is transcribed into single-stranded RNA, which folds
into specific molecular structures. In this paper we pose the question to what
extent sequence- and structure-information correlate. We view this correlation
as structural semantics of sequence data that allows for a different
interpretation than conventional sequence alignment. Structural semantics could
enable us to identify more general embedded "patterns" in DNA and RNA
sequences. Results: We compute the partition function of sequences with respect
to a fixed structure and connect this computation to the mutual information of
a sequence-structure pair for RNA secondary structures. We present a Boltzmann
sampler and obtain the a priori probability of specific sequence patterns. We
present a detailed analysis for the three PDB-structures, 2JXV (hairpin), 2N3R
(3-branch multi-loop) and 1EHZ (tRNA). We localize specific sequence patterns,
contrast the energy spectrum of the Boltzmann sampled sequences versus those
sequences that refold into the same structure and derive a criterion to
identify native structures. We illustrate that there are multiple sequences in
the partition function of a fixed structure, each having nearly the same mutual
information, that are nevertheless poorly aligned. This indicates the
possibility of the existence of relevant patterns embedded in the sequences
that are not discoverable using alignments.


An efficient dual sampling algorithm with Hamming distance filtration

  Recently, a framework considering RNA sequences and their RNA secondary
structures as pairs, led to some information-theoretic perspectives on how the
semantics encoded in RNA sequences can be inferred. In this context, the
pairing arises naturally from the energy model of RNA secondary structures.
Fixing the sequence in the pairing produces the RNA energy landscape, whose
partition function was discovered by McCaskill. Dually, fixing the structure
induces the energy landscape of sequences. The latter has been considered for
designing more efficient inverse folding algorithms. We present here the
Hamming distance filtered, dual partition function, together with a Boltzmann
sampler using novel dynamic programming routines for the loop-based energy
model. The time complexity of the algorithm is $O(h^2n)$, where $h,n$ are
Hamming distance and sequence length, respectively, reducing the time
complexity of samplers, reported in the literature by $O(n^2)$. We then present
two applications, the first being in the context of the evolution of natural
sequence-structure pairs of microRNAs and the second constructing neutral
paths. The former studies the inverse fold rate (IFR) of sequence-structure
pairs, filtered by Hamming distance, observing that such pairs evolve towards
higher levels of robustness, i.e.,~increasing IFR. The latter is an algorithm
that constructs neutral paths: given two sequences in a neutral network, we
employ the sampler in order to construct short paths connecting them,
consisting of sequences all contained in the neutral network.


Conclusive Exclusion of Quantum States

  In the task of quantum state exclusion we consider a quantum system, prepared
in a state chosen from a known set. The aim is to perform a measurement on the
system which can conclusively rule that a subset of the possible preparation
procedures can not have taken place. We ask what conditions the set of states
must obey in order for this to be possible and how well we can complete the
task when it is not. The task of quantum state discrimination forms a subclass
of this set of problems. Within this paper we formulate the general problem as
a Semidefinite Program (SDP), enabling us to derive sufficient and necessary
conditions for a measurement to be optimal. Furthermore, we obtain a necessary
condition on the set of states for exclusion to be achievable with certainty
and give a construction for a lower bound on the probability of error. This
task of conclusively excluding states has gained importance in the context of
the foundations of quantum mechanics due to a result of Pusey, Barrett and
Rudolph (PBR). Motivated by this, we use our SDP to derive a bound on how well
a class of hidden variable models can perform at a particular task, proving an
analogue of Tsirelson's bound for the PBR experiment and the optimality of a
measurement given by PBR in the process. We also introduce variations of
conclusive exclusion, including unambiguous state exclusion, and state
exclusion with worst case error.


Review of small-angle coronagraphic techniques in the wake of
  ground-based second-generation adaptive optics systems

  Small-angle coronagraphy is technically and scientifically appealing because
it enables the use of smaller telescopes, allows covering wider wavelength
ranges, and potentially increases the yield and completeness of circumstellar
environment - exoplanets and disks - detection and characterization campaigns.
However, opening up this new parameter space is challenging. Here we will
review the four posts of high contrast imaging and their intricate interactions
at very small angles (within the first 4 resolution elements from the star).
The four posts are: choice of coronagraph, optimized wavefront control,
observing strategy, and post-processing methods. After detailing each of the
four foundations, we will present the lessons learned from the 10+ years of
operations of zeroth and first-generation adaptive optics systems. We will then
tentatively show how informative the current integration of second-generation
adaptive optics system is, and which lessons can already be drawn from this
fresh experience. Then, we will review the current state of the art, by
presenting world record contrasts obtained in the framework of technological
demonstrations for space-based exoplanet imaging and characterization mission
concepts. Finally, we will conclude by emphasizing the importance of the
cross-breeding between techniques developed for both ground-based and
space-based projects, which is relevant for future high contrast imaging
instruments and facilities in space or on the ground.


