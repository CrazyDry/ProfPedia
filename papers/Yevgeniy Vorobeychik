Simulation-Based Game Theoretic Analysis of Keyword Auctions with  Low-Dimensional Bidding Strategies

  We perform a simulation-based analysis of keyword auctions modeled asone-shot games of incomplete information to study a series of mechanism designquestions. Our first question addresses the degree to which incentivecompatibility fails in generalized second-price (GSP) auctions. Our resultssuggest that sincere bidding in GSP auctions is a strikingly poor strategy anda poor predictor of equilibrium outcomes. We next show that the rank-by-revenuemechanism is welfare optimal, corroborating past results. Finally, we analyzeprofit as a function of auction mechanism under a series of alternativesettings. Our conclusions coincide with those of Lahaie and Pennock [2007] whenvalues and quality scores are strongly positively correlated: in such a case,rank-by-bid rules are clearly superior. We diverge, however, in showing thatauctions that put little weight on quality scores almost universally dominatethe pure rank-by-revenue scheme.

Constrained Automated Mechanism Design for Infinite Games of Incomplete  Information

  We present a functional framework for automated mechanism design based on atwo-stage game model of strategic interaction between the designer and themechanism participants, and apply it to several classes of two-player infinitegames of incomplete information. At the core of our framework is a black-boxoptimization algorithm which guides the selection process of candidatemechanisms. Our approach yields optimal or nearly optimal mechanisms in severalapplication domains using various objective functions. By comparing our resultswith known optimal mechanisms, and in some cases improving on the best knownmechanisms, we provide evidence that ours is a promising approach to parametricdesign of indirect mechanisms.

Adversarial Regression for Detecting Attacks in Cyber-Physical Systems

  Attacks in cyber-physical systems (CPS) which manipulate sensor readings cancause enormous physical damage if undetected. Detection of attacks on sensorsis crucial to mitigate this issue. We study supervised regression as a means todetect anomalous sensor readings, where each sensor's measurement is predictedas a function of other sensors. We show that several common learning approachesin this context are still vulnerable to \emph{stealthy attacks}, whichcarefully modify readings of compromised sensors to cause desired damage whileremaining undetected. Next, we model the interaction between the CPS defenderand attacker as a Stackelberg game in which the defender chooses detectionthresholds, while the attacker deploys a stealthy attack in response. Wepresent a heuristic algorithm for finding an approximately optimal thresholdfor the defender in this game, and show that it increases system resilience toattacks without significantly increasing the false alarm rate.

Optical Neural Networks

  We develop a novel optical neural network (ONN) framework which introduces adegree of scalar invariance to image classification estima- tion. Taking a hintfrom the human eye, which has higher resolution near the center of the retina,images are broken out into multiple levels of varying zoom based on a focalpoint. Each level is passed through an identical convolutional neural network(CNN) in a Siamese fashion, and the results are recombined to produce a highaccuracy estimate of the object class. ONNs act as a wrapper around existingCNNs, and can thus be applied to many existing algorithms to produce notableaccuracy improvements without having to change the underlying architecture.

Noncooperatively Optimized Tolerance: Decentralized Strategic  Optimization in Complex Systems

  We introduce noncooperatively optimized tolerance (NOT), a generalization ofhighly optimized tolerance (HOT) that involves strategic (game theoretic)interactions between parties in a complex system. We illustrate our model inthe forest fire (percolation) framework. As the number of players increases,our model retains features of HOT, such as robustness, high yield combined withhigh density, and self-dissimilar landscapes, but also develops features ofself-organized criticality (SOC) when the number of players is large enough.For example, the forest landscape becomes increasingly homogeneous andprotection from adverse events (lightning strikes) becomes less closelycorrelated with the spatial distribution of these events. While HOT is aspecial case of our model, the resemblance to SOC is only partial; for example,the distribution of cascades, while becoming increasingly heavy-tailed as thenumber of players increases, also deviates more significantly from a power lawin this regime. Surprisingly, the system retains considerable robustness evenas it becomes fractured, due in part to emergent cooperation betweenneighboring players. At the same time, increasing homogeneity promotesresilience against changes in the lightning distribution, giving rise tointermediate regimes where the system is robust to a particular distribution ofadverse events, yet not very fragile to changes.

Influence and Dynamic Behavior in Random Boolean Networks

  We present a rigorous mathematical framework for analyzing dynamics of abroad class of Boolean network models. We use this framework to provide thefirst formal proof of many of the standard critical transition results inBoolean network analysis, and offer analogous characterizations for novelclasses of random Boolean networks. We precisely connect the short-run dynamicbehavior of a Boolean network to the average influence of the transferfunctions. We show that some of the assumptions traditionally made in the morecommon mean-field analysis of Boolean networks do not hold in general.  For example, we offer some evidence that imbalance, or expected internalinhomogeneity, of transfer functions is a crucial feature that tends to drivequiescent behavior far more strongly than previously observed.

Computing Optimal Security Strategies for Interdependent Assets

  We introduce a novel framework for computing optimal randomized securitypolicies in networked domains which extends previous approaches in severalways. First, we extend previous linear programming techniques for Stackelbergsecurity games to incorporate benefits and costs of arbitrary securityconfigurations on individual assets. Second, we offer a principled model offailure cascades that allows us to capture both the direct and indirect valueof assets, and extend this model to capture uncertainty about the structure ofthe interdependency network. Third, we extend the linear programmingformulation to account for exogenous (random) failures in addition to targetedattacks. The goal of our work is two-fold. First, we aim to develop techniquesfor computing optimal security strategies in realistic settings involvinginterdependent security. To this end, we evaluate the value of our technicalcontributions in comparison with previous approaches, and show that ourapproach yields much better defense policies and scales to realistic graphs.Second, our computational framework enables us to attain theoretical insightsabout security on networks. As an example, we study how allowing security to beendogenous impacts the relative resilience of different network topologies.

Characterizing short-term stability for Boolean networks over any  distribution of transfer functions

  We present a characterization of short-term stability of random Booleannetworks under \emph{arbitrary} distributions of transfer functions. Given anydistribution of transfer functions for a random Boolean network, we present aformula that decides whether short-term chaos (damage spreading) will happen.We provide a formal proof for this formula, and empirically show that itspredictions are accurate. Previous work only works for special cases ofbalanced families. It has been observed that these characterizations fail forunbalanced families, yet such families are widespread in real biologicalnetworks.

Mechanism Design for Team Formation

  Team formation is a core problem in AI. Remarkably, little prior work hasaddressed the problem of mechanism design for team formation, accounting forthe need to elicit agents' preferences over potential teammates. Coalitionformation in the related hedonic games has received much attention, but onlyfrom the perspective of coalition stability, with little emphasis on themechanism design objectives of true preference elicitation, social welfare, andequity. We present the first formal mechanism design framework for teamformation, building on recent combinatorial matching market design literature.We exhibit four mechanisms for this problem, two novel, two simple extensionsof known mechanisms from other domains. Two of these (one new, one known) havedesirable theoretical properties. However, we use extensive experiments to showour second novel mechanism, despite having no theoretical guarantees,empirically achieves good incentive compatibility, welfare, and fairness.

A General Retraining Framework for Scalable Adversarial Classification

  Traditional classification algorithms assume that training and test data comefrom similar distributions. This assumption is violated in adversarialsettings, where malicious actors modify instances to evade detection. A numberof custom methods have been developed for both adversarial evasion attacks androbust learning. We propose the first systematic and general-purpose retrainingframework which can: a) boost robustness of an \emph{arbitrary} learningalgorithm, in the face of b) a broader class of adversarial models than anyprior methods. We show that, under natural conditions, the retraining frameworkminimizes an upper bound on optimal adversarial risk, and show how to extendthis result to account for approximations of evasion attacks. Extensiveexperimental evaluation demonstrates that our retraining methods are nearlyindistinguishable from state-of-the-art algorithms for optimizing adversarialrisk, but are more general and far more scalable. The experiments also confirmthat without retraining, our adversarial framework dramatically reduces theeffectiveness of learning. In contrast, retraining significantly boostsrobustness to evasion attacks without significantly compromising overallaccuracy.

Vulnerability of Fixed-Time Control of Signalized Intersections to  Cyber-Tampering

  Recent experimental studies have shown that traffic management systems arevulnerable to cyber-attacks on sensor data. This paper studies thevulnerability of fixed-time control of signalized intersections when sensorsmeasuring traffic flow information are compromised and perturbed by anadversary. The problems are formulated by considering three maliciousobjectives: 1) worst-case network accumulation, which aims to destabilize theoverall network as much as possible; 2) worst-case lane accumulation, whichaims to cause worst-case accumulation on some target lanes; and 3) risk-aversetarget accumulation, which aims to reach a target accumulation by making theminimum perturbation to sensor data. The problems are solved using bilevelprogramming optimization methods. Finally, a case study of a real network isused to illustrate the results.

Robust High-Dimensional Linear Regression

  The effectiveness of supervised learning techniques has made them ubiquitousin research and practice. In high-dimensional settings, supervised learningcommonly relies on dimensionality reduction to improve performance and identifythe most important factors in predicting outcomes. However, the economicimportance of learning has made it a natural target for adversarialmanipulation of training data, which we term poisoning attacks. Priorapproaches to dealing with robust supervised learning rely on strongassumptions about the nature of the feature matrix, such as featureindependence and sub-Gaussian noise with low variance. We propose an integratedmethod for robust regression that relaxes these assumptions, assuming only thatthe feature matrix can be well approximated by a low-rank matrix. Ourtechniques integrate improved robust low-rank matrix approximation and robustprinciple component regression, and yield strong performance guarantees.Moreover, we experimentally show that our methods significantly outperformstate of the art both in running time and prediction error.

Data Poisoning Attacks on Factorization-Based Collaborative Filtering

  Recommendation and collaborative filtering systems are important in moderninformation and e-commerce applications. As these systems are becomingincreasingly popular in the industry, their outputs could affect businessdecision making, introducing incentives for an adversarial party to compromisethe availability or integrity of such systems. We introduce a data poisoningattack on collaborative filtering systems. We demonstrate how a powerfulattacker with full knowledge of the learner can generate malicious data so asto maximize his/her malicious objectives, while at the same time mimickingnormal user behavior to avoid being detected. While the complete knowledgeassumption seems extreme, it enables a robust assessment of the vulnerabilityof collaborative filtering schemes to highly motivated attacks. We presentefficient solutions for two popular factorization-based collaborative filteringalgorithms: the \emph{alternative minimization} formulation and the\emph{nuclear norm minimization} method. Finally, we test the effectiveness ofour proposed algorithms on real-world data and discuss potential defensivestrategies.

Empirically Grounded Agent-Based Models of Innovation Diffusion: A  Critical Review

  Innovation diffusion has been studied extensively in a variety ofdisciplines, including sociology, economics, marketing, ecology, and computerscience. Traditional literature on innovation diffusion has been dominated bymodels of aggregate behavior and trends. However, the agent-based modeling(ABM) paradigm is gaining popularity as it captures agent heterogeneity andenables fine-grained modeling of interactions mediated by social and geographicnetworks. While most ABM work on innovation diffusion is theoretical,empirically grounded models are increasingly important, particularly in guidingpolicy decisions. We present a critical review of empirically groundedagent-based models of innovation diffusion, developing a categorization of thisresearch based on types of agent models as well as applications. By connectingthe modeling methodologies in the fields of information and innovationdiffusion, we suggest that the maximum likelihood estimation framework widelyused in the former is a promising paradigm for calibration of agent-basedmodels for innovation diffusion. Although many advances have been made tostandardize ABM methodology, we identify four major issues in model calibrationand validation, and suggest potential solutions.

Controlling Elections through Social Influence

  Election control considers the problem of an adversary who attempts to tamperwith a voting process, in order to either ensure that their favored candidatewins (constructive control) or another candidate loses (destructive control).As online social networks have become significant sources of information forpotential voters, a new tool in an attacker's arsenal is to effect control byharnessing social influence, for example, by spreading fake news and otherforms of misinformation through online social media.  We consider the computational problem of election control via socialinfluence, studying the conditions under which finding good adversarialstrategies is computationally feasible. We consider two objectives for theadversary in both the constructive and destructive control settings:probability and margin of victory (POV and MOV, respectively). We presentseveral strong negative results, showing, for example, that the problem ofmaximizing POV is inapproximable for any constant factor. On the other hand, wepresent approximation algorithms which provide somewhat weaker approximationguarantees, such as bicriteria approximations for the POV objective andconstant-factor approximations for MOV. Finally, we present mixed integerprogramming formulations for these problems. Experimental results show that ourapproximation algorithms often find near-optimal control strategies, indicatingthat election control through social influence is a salient threat to electionintegrity.

Adversarial Classification on Social Networks

  The spread of unwanted or malicious content through social media has become amajor challenge. Traditional examples of this include social network spam, butan important new concern is the propagation of fake news through social media.A common approach for mitigating this problem is by using standard statisticalclassification to distinguish malicious (e.g., fake news) instances from benign(e.g., actual news stories). However, such an approach ignores the fact thatmalicious instances propagate through the network, which is consequential bothin quantifying consequences (e.g., fake news diffusing through the network),and capturing detection redundancy (bad content can be detected at differentnodes). An additional concern is evasion attacks, whereby the generators ofmalicious instances modify the nature of these to escape detection. We modelthis problem as a Stackelberg game between the defender who is choosingparameters of the detection model, and an attacker, who is choosing both thenode at which to initiate malicious spread, and the nature of maliciousentities. We develop a novel bi-level programming approach for this problem, aswell as a novel solution approach based on implicit function gradients, andexperimentally demonstrate the advantage of our approach over alternativeswhich ignore network structure.

Adversarial Task Assignment

  The problem of assigning tasks to workers is of long-standing fundamentalimportance. Examples of this include the classical problem of assigningcomputing tasks to nodes in a distributed computing environment, assigning jobsto robots, and crowdsourcing. Extensive research into this problem generallyaddresses important issues such as uncertainty and incentives. However, theproblem of adversarial tampering with the task assignment process has notreceived as much attention.  We are concerned with a particular adversarial setting where an attacker maytarget a set of workers in order to prevent the tasks assigned to these workersfrom being completed. When all tasks are homogeneous, we provide an efficientalgorithm for computing the optimal assignment. When tasks are heterogeneous,we show that the adversarial assignment problem is NP-Hard, and present analgorithm for solving it approximately. Our theoretical results are accompaniedby extensive experiments showing the effectiveness of our algorithms.

Community Detection by Information Flow Simulation

  Community detection remains an important problem in data mining, owing to thelack of scalable algorithms that exploit all aspects of available data - namelythe directionality of flow of information and the dynamics thereof. Mostexisting methods use measures of connectedness in the graphical structure. Inthis paper, we present a fast, scalable algorithm to detect communities indirected, weighted graph representations of social networks by simulating flowof information through them. By design, our algorithm naturally handlesundirected or unweighted networks as well. Our algorithm runs in$\mathcal{O}(|E|)$ time, which is better than most existing work and uses$\mathcal{O}(|E|)$ space and hence scales easily to very large datasets.Finally, we show that our algorithm outperforms the state-of-the-art MarkovClustering Algorithm (MCL) in both accuracy and scalability on ground truthdata (in a number of cases, we can find communities in graphs too large forMCL).

Adversarial Regression with Multiple Learners

  Despite the considerable success enjoyed by machine learning techniques inpractice, numerous studies demonstrated that many approaches are vulnerable toattacks. An important class of such attacks involves adversaries changingfeatures at test time to cause incorrect predictions. Previous investigationsof this problem pit a single learner against an adversary. However, in manysituations an adversary's decision is aimed at a collection of learners, ratherthan specifically targeted at each independently. We study the problem ofadversarial linear regression with multiple learners. We approximate theresulting game by exhibiting an upper bound on learner loss functions, and showthat the resulting game has a unique symmetric equilibrium. We present analgorithm for computing this equilibrium, and show through extensiveexperiments that equilibrium models are significantly more robust thanconventional regularized linear regression.

Adversarial Coordination on Social Networks

  Decentralized coordination is one of the fundamental challenges for societiesand organizations. While extensively explored from a variety of perspectives,one issue which has received limited attention is human coordination in thepresence of adversarial agents. We study this problem by situating humansubjects as nodes on a network, and endowing each with a role, either regular(with the goal of achieving consensus among all regular players), oradversarial (aiming to prevent consensus among regular players). We show thatadversarial nodes are, indeed, quite successful in preventing consensus.However, we demonstrate that having the ability to communicate among networkneighbors can considerably improve coordination success, as well as resilienceto adversarial nodes. Our analysis of communication suggests that adversarialnodes attempt to exploit this capability for their ends, but do so in asomewhat limited way, perhaps to prevent regular nodes from recognizing theirintent. In addition, we show that the presence of trusted nodes generally haslimited value, but does help when many adversarial nodes are present andplayers can communicate. Finally, we use experimental data to develop acomputational model of human behavior, and explore a number of additionalparametric variations, such as features of network topologies, using theresulting data-driven agent-based model.

Synergistic Security for the Industrial Internet of Things: Integrating  Redundancy, Diversity, and Hardening

  As the Industrial Internet of Things (IIot) becomes more prevalent incritical application domains, ensuring security and resilience in the face ofcyber-attacks is becoming an issue of paramount importance. Cyber-attacksagainst critical infrastructures, for example, against smart water-distributionand transportation systems, pose serious threats to public health and safety.Owing to the severity of these threats, a variety of security techniques areavailable. However, no single technique can address the whole spectrum ofcyber-attacks that may be launched by a determined and resourceful attacker. Inlight of this, we consider a multi-pronged approach for designing secure andresilient IIoT systems, which integrates redundancy, diversity, and hardeningtechniques. We introduce a framework for quantifying cyber-security risks andoptimizing IIoT design by determining security investments in redundancy,diversity, and hardening. To demonstrate the applicability of our framework, wepresent two case studies in water distribution and transportation a case studyin water-distribution systems. Our numerical evaluation shows that integratingredundancy, diversity, and hardening can lead to reduced security risk at thesame cost.

Defending Elections Against Malicious Spread of Misinformation

  The integrity of democratic elections depends on voters' access to accurateinformation. However, modern media environments, which are dominated by socialmedia, provide malicious actors with unprecedented ability to manipulateelections via misinformation, such as fake news. We study a zero-sum gamebetween an attacker, who attempts to subvert an election by propagating a fakenew story or other misinformation over a set of advertising channels, and adefender who attempts to limit the attacker's impact. Computing an equilibriumin this game is challenging as even the pure strategy sets of players areexponential. Nevertheless, we give provable polynomial-time approximationalgorithms for computing the defender's minimax optimal strategy across a rangeof settings, encompassing different population structures as well as models ofthe information available to each player. Experimental results confirm that ouralgorithms provide near-optimal defender strategies and showcase variations inthe difficulty of defending elections depending on the resources and knowledgeavailable to the defender.

Attacking Similarity-Based Link Prediction in Social Networks

  Link prediction is one of the fundamental problems in computational socialscience. A particularly common means to predict existence of unobserved linksis via structural similarity metrics, such as the number of common neighbors;node pairs with higher similarity are thus deemed more likely to be linked.However, a number of applications of link prediction, such as predicting linksin gang or terrorist networks, are adversarial, with another party incentivizedto minimize its effectiveness by manipulating observed information about thenetwork. We offer a comprehensive algorithmic investigation of the problem ofattacking similarity-based link prediction through link deletion, focusing ontwo broad classes of such approaches, one which uses only local informationabout target links, and another which uses global network information. While weshow several variations of the general problem to be NP-Hard for both local andglobal metrics, we exhibit a number of well-motivated special cases which aretractable. Additionally, we provide principled and empirically effectivealgorithms for the intractable cases, in some cases proving worst-caseapproximation guarantees.

Plan Interdiction Games

  We propose a framework for cyber risk assessment and mitigation which modelsattackers as formal planners and defenders as interdicting such plans. Weillustrate the value of plan interdiction problems by first modeling networkcyber risk through the use of formal planning, and subsequently formalizing animportant question of prioritizing vulnerabilities for patching in the planinterdiction framework. In particular, we show that selectively patchingrelatively few vulnerabilities allows a network administrator to significantlyreduce exposure to cyber risk. More broadly, we have developed a number ofscalable approaches for plan interdiction problems, making especiallysignificant advances when attack plans involve uncertainty about systemdynamics. However, important open problems remain, including how to effectivelycapture information asymmetry between the attacker and defender, how to bestmodel dynamics in the attacker-defender interaction, and how to developscalable algorithms for solving associated plan interdiction games.

Regularized Ensembles and Transferability in Adversarial Learning

  Despite the considerable success of convolutional neural networks in a broadarray of domains, recent research has shown these to be vulnerable to smalladversarial perturbations, commonly known as adversarial examples. Moreover,such examples have shown to be remarkably portable, or transferable, from onemodel to another, enabling highly successful black-box attacks. We explore thisissue of transferability and robustness from two dimensions: first, consideringthe impact of conventional $l_p$ regularization as well as replacing the toplayer with a linear support vector machine (SVM), and second, the value ofcombining regularized models into an ensemble. We show that models trained withdifferent regularizers present barriers to transferability, as does partialinformation about the models comprising the ensemble.

Distributionally Robust Removal of Malicious Nodes from Networks

  An important problem in networked systems is detection and removal ofsuspected malicious nodes. A crucial consideration in such settings is theuncertainty endemic in detection, coupled with considerations of networkconnectivity, which impose indirect costs from mistakely removing benign nodesas well as failing to remove malicious nodes. A recent approach proposed toaddress this problem directly tackles these considerations, but has asignificant limitation: it assumes that the decision maker has accurateknowledge of the joint maliciousness probability of the nodes on the network.This is clearly not the case in practice, where such a distribution is at bestan estimate from limited evidence. To address this problem, we propose adistributionally robust framework for optimal node removal. While the problemis NP-Hard, we propose a principled algorithmic technique for solving itapproximately based on duality combined with Semidefinite Programmingrelaxation. A combination of both theoretical and empirical analysis, thelatter using both synthetic and real data, provide strong evidence that ouralgorithmic approach is highly effective and, in particular, is significantlymore robust than the state of the art.

Simple Physical Adversarial Examples against End-to-End Autonomous  Driving Models

  Recent advances in machine learning, especially techniques such as deepneural networks, are promoting a range of high-stakes applications, includingautonomous driving, which often relies on deep learning for perception. Whiledeep learning for perception has been shown to be vulnerable to a host ofsubtle adversarial manipulations of images, end-to-end demonstrations ofsuccessful attacks, which manipulate the physical environment and result inphysical consequences, are scarce. Moreover, attacks typically involvecarefully constructed adversarial examples at the level of pixels. Wedemonstrate the first end-to-end attacks on autonomous driving in simulation,using simple physically realizable attacks: the painting of black lines on theroad. These attacks target deep neural network models for end-to-end autonomousdriving control. A systematic investigation shows that such attacks aresurprisingly easy to engineer, and we describe scenarios (e.g., right turns) inwhich they are highly effective, and others that are less vulnerable (e.g.,driving straight). Further, we use network deconvolution to demonstrate thatthe attacks succeed by inducing activation patterns similar to entirelydifferent scenarios used in training.

Multidefender Security Games

  Stackelberg security game models and associated computational tools have seendeployment in a number of high-consequence security settings, such as LAXcanine patrols and Federal Air Marshal Service. These models focus on isolatedsystems with only one defender, despite being part of a more complex systemwith multiple players. Furthermore, many real systems such as transportationnetworks and the power grid exhibit interdependencies between targets and,consequently, between decision makers jointly charged with protecting them. Tounderstand such multidefender strategic interactions present in security, weinvestigate game theoretic models of security games with multiple defenders.Unlike most prior analysis, we focus on the situations in which each defendermust protect multiple targets, so that even a single defender's best responsedecision is, in general, highly non-trivial. We start with an analyticalinvestigation of multidefender security games with independent targets,offering an equilibrium and price-of-anarchy analysis of three models withincreasing generality. In all models, we find that defenders have the incentiveto over-protect targets, at times significantly. Additionally, in the simplermodels, we find that the price of anarchy is unbounded, linearly increasingboth in the number of defenders and the number of targets per defender.Considering interdependencies among targets, we develop a novel mixed-integerlinear programming formulation to compute a defender's best response, and makeuse of this formulation in approximating Nash equilibria of the game. We applythis approach towards computational strategic analysis of several models ofnetworks representing interdependencies, including real-world power networks.Our analysis shows how network structure and the probability of failure spreaddetermine the propensity of defenders to over- or under-invest in security.

Predicting Human Cooperation

  The Prisoner's Dilemma has been a subject of extensive research due to itsimportance in understanding the ever-present tension between individualself-interest and social benefit. A strictly dominant strategy in a Prisoner'sDilemma (defection), when played by both players, is mutually harmful.Repetition of the Prisoner's Dilemma can give rise to cooperation as anequilibrium, but defection is as well, and this ambiguity is difficult toresolve. The numerous behavioral experiments investigating the Prisoner'sDilemma highlight that players often cooperate, but the level of cooperationvaries significantly with the specifics of the experimental predicament. Wepresent the first computational model of human behavior in repeated Prisoner'sDilemma games that unifies the diversity of experimental observations in asystematic and quantitatively reliable manner. Our model relies on data weintegrated from many experiments, comprising 168,386 individual decisions. Thecomputational model is composed of two pieces: the first predicts thefirst-period action using solely the structural game parameters, while thesecond predicts dynamic actions using both game parameters and history of play.Our model is extremely successful not merely at fitting the data, but inpredicting behavior at multiple scales in experimental designs not used forcalibration, using only information about the game structure. We demonstratethe power of our approach through a simulation analysis revealing how to bestpromote human cooperation.

Scheduling Resource-Bounded Monitoring Devices for Event Detection and  Isolation in Networks

  In networked systems, monitoring devices such as sensors are typicallydeployed to monitor various target locations. Targets are the points in thephysical space at which events of some interest, such as random faults orattacks, can occur. Most often, these devices have limited energy supplies, andthey can operate for a limited duration. As a result, energy-efficientmonitoring of various target locations through a set of monitoring devices withlimited energy supplies is a crucial problem in networked systems. In thispaper, we study optimal scheduling of monitoring devices to maximize networkcoverage for detecting and isolating events on targets for a given networklifetime. The monitoring devices considered could remain active only for afraction of the overall network lifetime. We formulate the problem ofscheduling of monitoring devices as a graph labeling problem, which unlikeother existing solutions, allows us to directly utilize the underlying networkstructure to explore the trade-off between coverage and network lifetime. Inthis direction, first we propose a greedy heuristic to solve the graph labelingproblem, and then provide a game-theoretic solution to achieve near optimalgraph labeling. Moreover, the proposed setup can be used to simultaneouslysolve the scheduling and placement of monitoring devices, which yields improvedperformance as compared to separately solving the placement and schedulingproblems. Finally, we illustrate our results on various networks, includingreal-world water distribution networks.

How Robust is Robust ML? Evaluating Models of Classifier Evasion in PDF  Malware Detection

  Machine learning (ML) techniques are increasingly common in securityapplications, such as malware and intrusion detection. However, ML models areoften susceptible to evasion attacks, in which an adversary makes changes tothe input (such as malware) in order to avoid being detected. A conventionalapproach to evaluate ML robustness to such attacks, as well as to design robustML, is by considering simplified feature-space models of attacks, where theattacker changes ML features directly to effect evasion, while minimizing orconstraining the magnitude of this change. We investigate the effectiveness ofthis approach to designing robust ML in the face of attacks that can berealized in actual malware (realizable attacks). We demonstrate that in thecontext of structure-based PDF malware detection, such techniques appear tohave limited effectiveness, but they are effective with content-baseddetectors. In either case, we show that augmenting the feature space modelswith conserved features (those that cannot be unilaterally modified withoutcompromising malicious functionality) significantly improves performance.Finally, we show that feature space models enable generalized robustness whenfaced with a variety of realizable attacks, as compared to classifiers whichare tuned to be robust to a specific realizable attack.

Adversarial Task Allocation

  The problem of allocating tasks to workers is of long standing fundamentalimportance. Examples of this include the classical problem of assigningcomputing tasks to nodes in a distributed computing environment, as well as themore recent problem of crowdsourcing where a broad array of tasks are slated tobe completed by human workers. Extensive research into this problem generallyaddresses important issues such as uncertainty and, in crowdsourcing,incentives. However, the problem of adversarial tampering with the taskallocation process has not received as much attention. We are concerned with aparticular adversarial setting in task allocation where an attacker may targeta specific worker in order to prevent the tasks assigned to this worker frombeing completed. We consider two attack models: one in which the adversaryobserves only the allocation policy (which may be randomized), and the secondin which the attacker observes the actual allocation decision. For the casewhen all tasks are homogeneous, we provide polynomial-time algorithms for bothsettings. When tasks are heterogeneous, however, we show the adversarialallocation problem to be NP-Hard, and present algorithms for solving it whenthe defender is restricted to assign only a single worker per task. Ourexperiments show, surprisingly, that the difference between the two attackmodels is minimal: deterministic allocation can achieve nearly as much utilityas randomized.

Get Your Workload in Order: Game Theoretic Prioritization of Database  Auditing

  For enhancing the privacy protections of databases, where the increasingamount of detailed personal data is stored and processed, multiple mechanismshave been developed, such as audit logging and alert triggers, which notifyadministrators about suspicious activities; however, the two main limitationsin common are: 1) the volume of such alerts is often substantially greater thanthe capabilities of resource-constrained organizations, and 2) strategicattackers may disguise their actions or carefully choosing which records theytouch, making incompetent the statistical detection models. For solving them,we introduce a novel approach to database auditing that explicitly accounts foradversarial behavior by 1) prioritizing the order in which types of alerts areinvestigated and 2) providing an upper bound on how much resource to allocatefor each type. We model the interaction between a database auditor andpotential attackers as a Stackelberg game in which the auditor chooses anauditing policy and attackers choose which records to target. A correspondingapproach combining linear programming, column generation, and heuristic searchis proposed to derive an auditing policy. For testing the policy-searchingperformance, a publicly available credit card application dataset are adopted,on which it shows that our methods produce high-quality mixed strategies asdatabase audit policies, and our general approach significantly outperformsnon-game-theoretic baselines.

Detection and Mitigation of Attacks on Transportation Networks as a  Multi-Stage Security Game

  In recent years, state-of-the-art traffic-control devices have evolved fromstandalone hardware to networked smart devices. Smart traffic control enablesoperators to decrease traffic congestion and environmental impact by acquiringreal-time traffic data and changing traffic signals from fixed to adaptiveschedules. However, these capabilities have inadvertently exposed trafficcontrol to a wide range of cyber-attacks, which adversaries can easily mountthrough wireless networks or even through the Internet. Indeed, recent studieshave found that a large number of traffic signals that are deployed in practicesuffer from exploitable vulnerabilities, which adversaries may use to takecontrol of the devices. Thanks to hardware-based failsafes, adversaries cannotcause traffic accidents directly by setting compromised signals to dangerousconfigurations. Nonetheless, an adversary could cause disastrous trafficcongestion by changing the schedule of compromised traffic signals, therebyeffectively crippling the transportation network. To provide theoreticalfoundations for the protection of transportation networks from these attacks,we introduce a game-theoretic model of launching, detecting, and mitigatingattacks that tamper with traffic-signal schedules. We show that finding optimalstrategies is a computationally challenging problem, and we propose efficientheuristic algorithms for finding near optimal strategies. We also introduce aGaussian-process based anomaly detector, which can alert operators to ongoingattacks. Finally, we evaluate our algorithms and the proposed detector usingnumerical experiments based on the SUMO traffic simulator.

Attack Tolerance of Link Prediction Algorithms: How to Hide Your  Relations in a Social Network

  Link prediction is one of the fundamental research problems in networkanalysis. Intuitively, it involves identifying the edges that are most likelyto be added to a given network, or the edges that appear to be missing from thenetwork when in fact they are present. Various algorithms have been proposed tosolve this problem over the past decades. For all their benefits, suchalgorithms raise serious privacy concerns, as they could be used to expose aconnection between two individuals who wish to keep their relationship private.With this in mind, we investigate the ability of such individuals to evade linkprediction algorithms. More precisely, we study their ability to strategicallyalter their connections so as to increase the probability that some of theirconnections remain unidentified by link prediction algorithms. We formalizethis question as an optimization problem, and prove that finding an optimalsolution is NP-complete. Despite this hardness, we show that the situation isnot bleak in practice. In particular, we propose two heuristics that can easilybe applied by members of the general public on existing social media. Wedemonstrate the effectiveness of those heuristics on a wide variety of networksand against a plethora of link prediction algorithms.

Removing Malicious Nodes from Networks

  A fundamental challenge in networked systems is detection and removal ofsuspected malicious nodes. In reality, detection is always imperfect, and thedecision about which potentially malicious nodes to remove must trade off falsepositives (erroneously removing benign nodes) and false negatives (mistakenlyfailing to remove malicious nodes). However, in network settings thisconventional tradeoff must now account for node connectivity. In particular,malicious nodes may exert malicious influence, so that mistakenly leaving someof these in the network may cause damage to spread. On the other hand, removingbenign nodes causes direct harm to these, and indirect harm to their benignneighbors who would wish to communicate with them.  We formalize the problem of removing potentially malicious nodes from anetwork under uncertainty through an objective that takes connectivity intoaccount. We show that optimally solving the resulting problem is NP-Hard. Wethen propose a tractable solution approach based on a convex relaxation of theobjective. Finally, we experimentally demonstrate that our approachsignificantly outperforms both a simple baseline that ignores networkstructure, as well as a state-of-the-art approach for a related problem, onboth synthetic and real-world datasets.

An Online Decision-Theoretic Pipeline for Responder Dispatch

  The problem of dispatching emergency responders to service traffic accidents,fire, distress calls and crimes plagues urban areas across the globe. Whilesuch problems have been extensively looked at, most approaches are offline.Such methodologies fail to capture the dynamically changing environments underwhich critical emergency response occurs, and therefore, fail to be implementedin practice. Any holistic approach towards creating a pipeline for effectiveemergency response must also look at other challenges that it subsumes -predicting when and where incidents happen and understanding the changingenvironmental dynamics. We describe a system that collectively deals with allthese problems in an online manner, meaning that the models get updated withstreaming data sources. We highlight why such an approach is crucial to theeffectiveness of emergency response, and present an algorithmic framework thatcan compute promising actions for a given decision-theoretic model forresponder dispatch. We argue that carefully crafted heuristic measures canbalance the trade-off between computational time and the quality of solutionsachieved and highlight why such an approach is more scalable and tractable thantraditional approaches. We also present an online mechanism for incidentprediction, as well as an approach based on recurrent neural networks forlearning and predicting environmental features that affect responder dispatch.We compare our methodology with prior state-of-the-art and existing dispatchstrategies in the field, which show that our approach results in a reduction inresponse time with a drastic reduction in computational time.

Optimal Thresholds for Anomaly-Based Intrusion Detection in Dynamical  Environments

  In cyber-physical systems, malicious and resourceful attackers couldpenetrate the system through cyber means and cause significant physical damage.Consequently, detection of such attacks becomes integral towards making thesesystems resilient to attacks. To achieve this objective, intrusion detectionsystems (IDS) that are able to detect malicious behavior can be deployed.However, practical IDS are imperfect and sometimes they may produce falsealarms for a normal system behavior. Since alarms need to be investigated forany potential damage, a large number of false alarms may increase theoperational costs significantly. Thus, IDS need to be configured properly, asoversensitive IDS could detect attacks early but at the cost of a higher numberof false alarms. Similarly, IDS with low sensitivity could reduce the falsealarms while increasing the time to detect the attacks. The configuration ofIDS to strike the right balance between time to detecting attacks and the rateof false positives is a challenging task, especially in dynamic environments,in which the damage incurred by a successful attack is time-varying.  In this paper, we study the problem of finding optimal detection thresholdsfor anomaly-based detectors implemented in dynamical systems in the face ofstrategic attacks. We formulate the problem as an attacker-defender securitygame, and determine thresholds for the detector to achieve an optimal trade-offbetween the detection delay and the false positive rates. In this direction,first, we provide an algorithm that computes optimal fixed threshold thatremains fixed throughout. Second, we allow detector's threshold to change withtime to further minimize the defender's loss and provide an algorithm tocompute time-varying thresholds, which we call adaptive thresholds. Finally, wenumerically evaluate our results using a water distribution network as acase-study.

