On Multiplicative Multitask Feature Learning

  We investigate a general framework of multiplicative multitask featurelearning which decomposes each task's model parameters into a multiplication oftwo components. One of the components is used across all tasks and the othercomponent is task-specific. Several previous methods have been proposed asspecial cases of our framework. We study the theoretical properties of thisframework when different regularization conditions are applied to the twodecomposed components. We prove that this framework is mathematicallyequivalent to the widely used multitask feature learning methods that are basedon a joint regularization of all model parameters, but with a more general formof regularizers. Further, an analytical formula is derived for the across-taskcomponent as related to the task-specific component for all these regularizers,leading to a better understanding of the shrinkage effect. Study of thisframework motivates new multitask learning algorithms. We propose two newlearning formulations by varying the parameters in the proposed framework.Empirical studies have revealed the relative advantages of the two newformulations by comparing with the state of the art, which provides instructiveinsights into the feature learning problem with multiple tasks.

A Survey on Multi-View Clustering

  With advances in information acquisition technologies, multi-view data becomeubiquitous. Multi-view learning has thus become more and more popular inmachine learning and data mining fields. Multi-view unsupervised orsemi-supervised learning, such as co-training, co-regularization has gainedconsiderable attention. Although recently, multi-view clustering (MVC) methodshave been developed rapidly, there has not been a survey to summarize andanalyze the current progress. Therefore, this paper reviews the commonstrategies for combining multiple views of data and based on this summary wepropose a novel taxonomy of the MVC approaches. We further discuss therelationships between MVC and multi-view representation, ensemble clustering,multi-task clustering, multi-view supervised and semi-supervised learning.Several representative real-world applications are elaborated. To promotefuture development of MVC, we envision several open problems that may requirefurther investigation and thorough examination.

Communication-Optimal Distributed Dynamic Graph Clustering

  We consider the problem of clustering graph nodes over large-scale dynamicgraphs, such as citation networks, images and web networks, when graph updatessuch as node/edge insertions/deletions are observed distributively. We proposecommunication-efficient algorithms for two well-established communicationmodels namely the message passing and the blackboard models. Given a graph with$n$ nodes that is observed at $s$ remote sites over time $[1,t]$, the twoproposed algorithms have communication costs $\tilde{O}(ns)$ and$\tilde{O}(n+s)$ ($\tilde{O}$ hides a polylogarithmic factor), almost matchingtheir lower bounds, $\Omega(ns)$ and $\Omega(n+s)$, respectively, in themessage passing and the blackboard models. More importantly, we prove that ateach time point in $[1,t]$ our algorithms generate clustering quality nearly asgood as that of centralizing all updates up to that time and then applying astandard centralized clustering algorithm. We conducted extensive experimentson both synthetic and real-life datasets which confirmed the communicationefficiency of our approach over baseline algorithms while achieving comparableclustering results.

Quantum spin Hall insulators and quantum valley Hall insulators of  BiX/SbX (X = H, F, Cl, and Br) monolayers with a record bulk band gap

  Large bulk band gap is critical for application of the quantum spin Hall(QSH) insulator or two dimensional (2D) topological insulator (TI) inspintronic device operating at room temperature (RT). Based on thefirst-principles calculations, here we predict a group of 2D topologicalinsulators BiX/SbX (X = H, F, Cl, and Br) monolayers with extraordinarily largebulk gaps from 0.32 to a record value of 1.08 eV. These giant-gaps are entirelydue to the result of strong spin-orbit interaction related to px and pyorbitals of Bi/Sb atoms around the two valley K and K' of honeycomb lattice,which is different significantly from the one consisted of pz orbital just likein graphene/silicene. The topological characteristic of BiX/SbX monolayers isconfirmed by the calculated nontrivial Z2 index and an explicit construction ofthe low energy effective Hamiltonian in these systems. We show that thehoneycomb structures of BiX monolayers remain stable even at a temperature of600 K. These features make the giant-gap TIs BiX/SbX monolayers an idealplatform to realize many exotic phenomena and fabricate new quantum devicesoperating at RT. Furthermore, biased BiX/SbX monolayers become a quantum valleyHall insulator, showing valley-selective circular dichroism.

Low-Energy Effective Hamiltonian for Giant-Gap Quantum Spin Hall  Insulators in Honeycomb X-Hydride/Halide (X=N-Bi) Monolayers

  Using the tight-binding method in combination with first-principlescalculations, we systematically derive a low-energy effective Hilbert subspaceand Hamiltonian with spin-orbit coupling for two-dimensional hydrogenated andhalogenated group-V monolayers. These materials are proposed to be giant-gapquantum spin Hall insulators with record huge bulk band gaps opened by thespin-orbit coupling at the Dirac points, e.g., from 0.74 to 1.08 eV inBi\textit{X} (\textit{X} = H, F, Cl, and Br) monolayers. We find that thelow-energy Hilbert subspace mainly consists of $p_{x}$ and $p_{y}$ orbitalsfrom the group-V elements, and the giant first-order effective intrinsicspin-orbit coupling is from the on-site spin-orbit interaction. These featuresare quite distinct from those of group-IV monolayers such as graphene andsilicene. There, the relevant orbital is $p_z$ and the effective intrinsicspin-orbit coupling is from the next-nearest-neighbor spin-orbit interactionprocesses. These systems represent the first real 2D honeycomb latticematerials in which the low-energy physics is associated with $p_{x}$ and$p_{y}$ orbitals. A spinful lattice Hamiltonian with an on-site spin-orbitcoupling term is also derived, which could facilitate further investigations ofthese intriguing topological materials.

Hybrid-DCA: A Double Asynchronous Approach for Stochastic Dual  Coordinate Ascent

  In prior works, stochastic dual coordinate ascent (SDCA) has beenparallelized in a multi-core environment where the cores communicate throughshared memory, or in a multi-processor distributed memory environment where theprocessors communicate through message passing. In this paper, we propose ahybrid SDCA framework for multi-core clusters, the most common high performancecomputing environment that consists of multiple nodes each having multiplecores and its own shared memory. We distribute data across nodes where eachnode solves a local problem in an asynchronous parallel fashion on its cores,and then the local updates are aggregated via an asynchronous across-nodeupdate scheme. The proposed double asynchronous method converges to a globalsolution for $L$-Lipschitz continuous loss functions, and at a linearconvergence rate if a smooth convex loss function is used. Extensive empiricalcomparison has shown that our algorithm scales better than the best knownshared-memory methods and runs faster than previous distributed-memory methods.Big datasets, such as one of 280 GB from the LIBSVM repository, cannot beaccommodated on a single node and hence cannot be solved by a parallelalgorithm. For such a dataset, our hybrid algorithm takes 30 seconds to achievea duality gap of $10^{-6}$ on 16 nodes each using 8 cores, which issignificantly faster than the best known distributed algorithms, such asCoCoA+, that take more than 300 seconds on 16 nodes.

Longitudinal LASSO: Jointly Learning Features and Temporal Contingency  for Outcome Prediction

  Longitudinal analysis is important in many disciplines, such as the study ofbehavioral transitions in social science. Only very recently, feature selectionhas drawn adequate attention in the context of longitudinal modeling. Standardtechniques, such as generalized estimating equations, have been modified toselect features by imposing sparsity-inducing regularizers. However, they donot explicitly model how a dependent variable relies on features measured atproximal time points. Recent graphical Granger modeling can select features inlagged time points but ignores the temporal correlations within an individual'srepeated measurements. We propose an approach to automatically andsimultaneously determine both the relevant features and the relevant temporalpoints that impact the current outcome of the dependent variable. Meanwhile,the proposed model takes into account the non-{\em i.i.d} nature of the data byestimating the within-individual correlations. This approach decomposes modelparameters into a summation of two components and imposes separate block-wiseLASSO penalties to each component when building a linear model in terms of thepast $\tau$ measurements of features. One component is used to select featureswhereas the other is used to select temporal contingent points. An acceleratedgradient descent algorithm is developed to efficiently solve the relatedoptimization problem with detailed convergence analysis and asymptoticanalysis. Computational results on both synthetic and real world problemsdemonstrate the superior performance of the proposed approach over existingtechniques.

End-to-end Structure-Aware Convolutional Networks for Knowledge Base  Completion

  Knowledge graph embedding has been an active research topic for knowledgebase completion, with progressive improvement from the initial TransE, TransH,DistMult et al to the current state-of-the-art ConvE. ConvE uses 2D convolutionover embeddings and multiple layers of nonlinear features to model knowledgegraphs. The model can be efficiently trained and scalable to large knowledgegraphs. However, there is no structure enforcement in the embedding space ofConvE. The recent graph convolutional network (GCN) provides another way oflearning graph node embedding by successfully utilizing graph connectivitystructure. In this work, we propose a novel end-to-end Structure-AwareConvolutional Network (SACN) that takes the benefit of GCN and ConvE together.SACN consists of an encoder of a weighted graph convolutional network (WGCN),and a decoder of a convolutional network called Conv-TransE. WGCN utilizesknowledge graph node structure, node attributes and edge relation types. It haslearnable weights that adapt the amount of information from neighbors used inlocal aggregation, leading to more accurate embeddings of graph nodes. Nodeattributes in the graph are represented as additional nodes in the WGCN. Thedecoder Conv-TransE enables the state-of-the-art ConvE to be translationalbetween entities and relations while keeps the same link prediction performanceas ConvE. We demonstrate the effectiveness of the proposed SACN on standardFB15k-237 and WN18RR datasets, and it gives about 10% relative improvement overthe state-of-the-art ConvE in terms of HITS@1, HITS@3 and HITS@10.

Classification of Neurological Gait Disorders Using Multi-task Feature  Learning

  As our population ages, neurological impairments and degeneration of themusculoskeletal system yield gait abnormalities, which can significantly reducequality of life. Gait rehabilitative therapy has been widely adopted to helppatients maximize community participation and living independence. To furtherimprove the precision and efficiency of rehabilitative therapy, more objectivemethods need to be developed based on sensory data. In this paper, analgorithmic framework is proposed to provide classification of gait disorderscaused by two common neurological diseases, stroke and Parkinson's Disease(PD), from ground contact force (GCF) data. An advanced machine learningmethod, multi-task feature learning (MTFL), is used to jointly trainclassification models of a subject's gait in three classes, post-stroke, PD andhealthy gait. Gait parameters related to mobility, balance, strength and rhythmare used as features for the classification. Out of all the features used, theMTFL models capture the more important ones per disease, which will helpprovide better objective assessment and therapy progress tracking. To evaluatethe proposed methodology we use data from a human participant study, whichincludes five PD patients, three post-stroke patients, and three healthysubjects. Despite the diversity of abnormalities, the evaluation shows that theproposed approach can successfully distinguish post-stroke and PD gait fromhealthy gait, as well as post-stroke from PD gait, with Area Under the Curve(AUC) score of at least 0.96. Moreover, the methodology helps select importantgait features to better understand the key characteristics that distinguishabnormal gaits and design personalized treatment.

VIGAN: Missing View Imputation with Generative Adversarial Networks

  In an era when big data are becoming the norm, there is less concern with thequantity but more with the quality and completeness of the data. In manydisciplines, data are collected from heterogeneous sources, resulting inmulti-view or multi-modal datasets. The missing data problem has beenchallenging to address in multi-view data analysis. Especially, when certainsamples miss an entire view of data, it creates the missing view problem.Classic multiple imputations or matrix completion methods are hardly effectivehere when no information can be based on in the specific view to impute datafor such samples. The commonly-used simple method of removing samples with amissing view can dramatically reduce sample size, thus diminishing thestatistical power of a subsequent analysis. In this paper, we propose a novelapproach for view imputation via generative adversarial networks (GANs), whichwe name by VIGAN. This approach first treats each view as a separate domain andidentifies domain-to-domain mappings via a GAN using randomly-sampled data fromeach view, and then employs a multi-modal denoising autoencoder (DAE) toreconstruct the missing view from the GAN outputs based on paired data acrossthe views. Then, by optimizing the GAN and DAE jointly, our model enables theknowledge integration for domain mappings and view correspondences toeffectively recover the missing view. Empirical results on benchmark datasetsvalidate the VIGAN approach by comparing against the state of the art. Theevaluation of VIGAN in a genetic study of substance use disorders furtherproves the effectiveness and usability of this approach in life science.

Edge Attention-based Multi-Relational Graph Convolutional Networks

  Graph convolutional network (GCN) is generalization of convolutional neuralnetwork (CNN) to work with arbitrarily structured graphs. A binary adjacencymatrix is commonly used in training a GCN. Recently, the attention mechanismallows the network to learn a dynamic and adaptive aggregation of theneighborhood. We propose a new GCN model on the graphs where edges arecharacterized in multiple views or precisely in terms of multiplerelationships. For instance, in chemical graph theory, compound structures areoften represented by the hydrogen-depleted molecular graph where nodescorrespond to atoms and edges correspond to chemical bonds. Multiple attributescan be important to characterize chemical bonds, such as atom pair (the typesof atoms that a bond connects), aromaticity, and whether a bond is in a ring.The different attributes lead to different graph representations for the samemolecule. There is growing interests in both chemistry and machine learningfields to directly learn molecular properties of compounds from the moleculargraph, instead of from fingerprints predefined by chemists. The proposed GCNmodel, which we call edge attention-based multi-relational GCN (EAGCN), jointlylearns attention weights and node features in graph convolution. For each bondattribute, a real-valued attention matrix is used to replace the binaryadjacency matrix. By designing a dictionary for the edge attention, and formingthe attention matrix of each molecule by looking up the dictionary, the EAGCNexploits correspondence between bonds in different molecules. The prediction ofcompound properties is based on the aggregated node features, which isindependent of the varying molecule (graph) size. We demonstrate the efficacyof the EAGCN on multiple chemical datasets: Tox21, HIV, Freesolv, andLipophilicity, and interpret the resultant attention weights.

