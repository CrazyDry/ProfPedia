The Melbourne Shuffle: Improving Oblivious Storage in the Cloud

  We present a simple, efficient, and secure data-oblivious randomized shufflealgorithm. This is the first secure data-oblivious shuffle that is not based onsorting. Our method can be used to improve previous oblivious storage solutionsfor network-based outsourcing of data.

Steady state analysis of balanced-allocation routing

  We compare the long-term, steady-state performance of a variant of thestandard Dynamic Alternative Routing (DAR) technique commonly used in telephoneand ATM networks, to the performance of a path-selection algorithm based on the"balanced-allocation" principle; we refer to this new algorithm as the BalancedDynamic Alternative Routing (BDAR) algorithm. While DAR checks alternativeroutes sequentially until available bandwidth is found, the BDAR algorithmcompares and chooses the best among a small number of alternatives.  We show that, at the expense of a minor increase in routing overhead, theBDAR algorithm gives a substantial improvement in network performance, in termsboth of network congestion and of bandwidth requirement.

ABRA: Approximating Betweenness Centrality in Static and Dynamic Graphs  with Rademacher Averages

  We present ABRA, a suite of algorithms that compute and maintainprobabilistically-guaranteed, high-quality, approximations of the betweennesscentrality of all nodes (or edges) on both static and fully dynamic graphs. Ouralgorithms rely on random sampling and their analysis leverages on Rademacheraverages and pseudodimension, fundamental concepts from statistical learningtheory. To our knowledge, this is the first application of these concepts tothe field of graph analysis. The results of our experimental evaluation showthat our approach is much faster than exact methods, and vastly outperforms, inboth speed and number of samples, current state-of-the-art algorithms with thesame quality guarantees.

Bandits and Experts in Metric Spaces

  In a multi-armed bandit problem, an online algorithm chooses from a set ofstrategies in a sequence of trials so as to maximize the total payoff of thechosen strategies. While the performance of bandit algorithms with a smallfinite strategy set is quite well understood, bandit problems with largestrategy sets are still a topic of very active investigation, motivated bypractical applications such as online auctions and web advertisement. The goalof such research is to identify broad and natural classes of strategy sets andpayoff functions which enable the design of efficient solutions.  In this work we study a very general setting for the multi-armed banditproblem in which the strategies form a metric space, and the payoff functionsatisfies a Lipschitz condition with respect to the metric. We refer to thisproblem as the "Lipschitz MAB problem". We present a solution for themulti-armed bandit problem in this setting. That is, for every metric space wedefine an isometry invariant which bounds from below the performance ofLipschitz MAB algorithms for this metric space, and we present an algorithmwhich comes arbitrarily close to meeting this bound. Furthermore, our techniquegives even better results for benign payoff functions. We also address thefull-feedback ("best expert") version of the problem, where after every roundthe payoffs from all arms are revealed.

Multi-Armed Bandits in Metric Spaces

  In a multi-armed bandit problem, an online algorithm chooses from a set ofstrategies in a sequence of trials so as to maximize the total payoff of thechosen strategies. While the performance of bandit algorithms with a smallfinite strategy set is quite well understood, bandit problems with largestrategy sets are still a topic of very active investigation, motivated bypractical applications such as online auctions and web advertisement. The goalof such research is to identify broad and natural classes of strategy sets andpayoff functions which enable the design of efficient solutions. In this workwe study a very general setting for the multi-armed bandit problem in which thestrategies form a metric space, and the payoff function satisfies a Lipschitzcondition with respect to the metric. We refer to this problem as the"Lipschitz MAB problem". We present a complete solution for the multi-armedproblem in this setting. That is, for every metric space (L,X) we define anisometry invariant which bounds from below the performance of Lipschitz MABalgorithms for X, and we present an algorithm which comes arbitrarily close tomeeting this bound. Furthermore, our technique gives even better results forbenign payoff functions.

MADMX: A Novel Strategy for Maximal Dense Motif Extraction

  We develop, analyze and experiment with a new tool, called MADMX, whichextracts frequent motifs, possibly including don't care characters, frombiological sequences. We introduce density, a simple and flexible measure forbounding the number of don't cares in a motif, defined as the ratio of solid(i.e., different from don't care) characters to the total length of the motif.By extracting only maximal dense motifs, MADMX reduces the output size andimproves performance, while enhancing the quality of the discoveries. Theefficiency of our approach relies on a newly defined combining operation,dubbed fusion, which allows for the construction of maximal dense motifs in abottom-up fashion, while avoiding the generation of nonmaximal ones. We provideexperimental evidence of the efficiency and the quality of the motifs returnedby MADMX

An Efficient Rigorous Approach for Identifying Statistically Significant  Frequent Itemsets

  As advances in technology allow for the collection, storage, and analysis ofvast amounts of data, the task of screening and assessing the significance ofdiscovered patterns is becoming a major challenge in data mining applications.In this work, we address significance in the context of frequent itemsetmining. Specifically, we develop a novel methodology to identify a meaningfulsupport threshold s* for a dataset, such that the number of itemsets withsupport at least s* represents a substantial deviation from what would beexpected in a random dataset with the same number of transactions and the sameindividual item frequencies. These itemsets can then be flagged asstatistically significant with a small false discovery rate. We presentextensive experimental results to substantiate the effectiveness of ourmethodology.

Space-Round Tradeoffs for MapReduce Computations

  This work explores fundamental modeling and algorithmic issues arising in thewell-established MapReduce framework. First, we formally specify acomputational model for MapReduce which captures the functional flavor of theparadigm by allowing for a flexible use of parallelism. Indeed, the modeldiverges from a traditional processor-centric view by featuring parameterswhich embody only global and local memory constraints, thus favoring a moredata-centric view. Second, we apply the model to the fundamental computationtask of matrix multiplication presenting upper and lower bounds for both denseand sparse matrix multiplication, which highlight interesting tradeoffs betweenspace and round complexity. Finally, building on the matrix multiplicationresults, we derive further space-round tradeoffs on matrix inversion andmatching.

A Clustering Approach to Solving Large Stochastic Matching Problems

  In this work we focus on efficient heuristics for solving a class ofstochastic planning problems that arise in a variety of business, investment,and industrial applications. The problem is best described in terms of futurebuy and sell contracts. By buying less reliable, but less expensive, buy(supply) contracts, a company or a trader can cover a position of more reliableand more expensive sell contracts. The goal is to maximize the expected netgain (profit) by constructing a dose to optimum portfolio out of the availablebuy and sell contracts. This stochastic planning problem can be formulated as atwo-stage stochastic linear programming problem with recourse. However, thisformalization leads to solutions that are exponential in the number of possiblefailure combinations. Thus, this approach is not feasible for large scaleproblems. In this work we investigate heuristic approximation techniquesalleviating the efficiency problem. We primarily focus on the clusteringapproach and devise heuristics for finding clusterings leading to goodapproximations. We illustrate the quality and feasibility of the approachthrough experimental data.

A Practical Parallel Algorithm for Diameter Approximation of Massive  Weighted Graphs

  We present a space and time efficient practical parallel algorithm forapproximating the diameter of massive weighted undirected graphs on distributedplatforms supporting a MapReduce-like abstraction. The core of the algorithm isa weighted graph decomposition strategy generating disjoint clusters of boundedweighted radius. Theoretically, our algorithm uses linear space and yields apolylogarithmic approximation guarantee; moreover, for important practicalclasses of graphs, it runs in a number of rounds asymptotically smaller thanthose required by the natural approximation provided by the state-of-the-art$\Delta$-stepping SSSP algorithm, which is its only practical linear-spacecompetitor in the aforementioned computational scenario. We complement ourtheoretical findings with an extensive experimental analysis on large benchmarkgraphs, which demonstrates that our algorithm attains substantial improvementson a number of key performance indicators with respect to the aforementionedcompetitor, while featuring a similar approximation ratio (a small constantless than 1.4, as opposed to the polylogarithmic theoretical bound).

Optimizing Static and Adaptive Probing Schedules for Rapid Event  Detection

  We formulate and study a fundamental search and detection problem, ScheduleOptimization, motivated by a variety of real-world applications, ranging frommonitoring content changes on the web, social networks, and user activities todetecting failure on large systems with many individual machines.  We consider a large system consists of many nodes, where each node has itsown rate of generating new events, or items. A monitoring application can probea small number of nodes at each step, and our goal is to compute a probingschedule that minimizes the expected number of undiscovered items at thesystem, or equivalently, minimizes the expected time to discover a new item inthe system.  We study the Schedule Optimization problem both for deterministic andrandomized memoryless algorithms. We provide lower bounds on the cost of anoptimal schedule and construct close to optimal schedules with rigorousmathematical guarantees. Finally, we present an adaptive algorithm that startswith no prior information on the system and converges to the optimal memorylessalgorithms by adapting to observed data.

TRIÈST: Counting Local and Global Triangles in Fully-dynamic Streams  with Fixed Memory Size

  We present TRI\`EST, a suite of one-pass streaming algorithms to computeunbiased, low-variance, high-quality approximations of the global and local(i.e., incident to each vertex) number of triangles in a fully-dynamic graphrepresented as an adversarial stream of edge insertions and deletions. Ouralgorithms use reservoir sampling and its variants to exploit theuser-specified memory space at all times. This is in contrast with previousapproaches which use hard-to-choose parameters (e.g., a fixed samplingprobability) and offer no guarantees on the amount of memory they will use. Weshow a full analysis of the variance of the estimations and novel concentrationbounds for these quantities. Our experimental results on very large graphs showthat TRI\`EST outperforms state-of-the-art approaches in accuracy and exhibitsa small update time.

Controlling False Discoveries During Interactive Data Exploration

  Recent tools for interactive data exploration significantly increase thechance that users make false discoveries. The crux is that these toolsimplicitly allow the user to test a large body of different hypotheses withjust a few clicks thus incurring in the issue commonly known in statistics asthe multiple hypothesis testing error. In this paper, we propose solutions tointegrate multiple hypothesis testing control into interactive data explorationtools. A key insight is that existing methods for controlling the falsediscovery rate (such as FDR) are not directly applicable for interactive dataexploration. We therefore discuss a set of new control procedures that arebetter suited and integrated them in our system called Aware. By means ofextensive experiments using both real-world and synthetic data sets wedemonstrate how Aware can help experts and novice users alike to efficientlycontrol false discoveries.

Practical and Provably Secure Onion Routing

  In an onion routing protocol, messages travel through several intermediariesbefore arriving at their destinations, they are wrapped in layers of encryption(hence they are called "onions"). The goal is to make it hard to establish whosent the message. It is a practical and widespread tool for creating anonymouschannels.  For the standard adversary models --- network, passive, and active --- wepresent practical and provably secure onion routing protocols. Akin to Tor, inour protocols each party independently chooses the routing paths for hisonions. For security parameter $\lambda$, our differentially private solutionfor the active adversary takes $O(\log^2\lambda)$ rounds and requires everyparticipant to transmit $O(\log^{4} \lambda)$ onions in every round.

Unknown Examples & Machine Learning Model Generalization

  Over the past decades, researchers and ML practitioners have come up withbetter and better ways to build, understand and improve the quality of MLmodels, but mostly under the key assumption that the training data isdistributed identically to the testing data. In many real-world applications,however, some potential training examples are unknown to the modeler, due tosample selection bias or, more generally, covariate shift, i.e., a distributionshift between the training and deployment stage. The resulting discrepancybetween training and testing distributions leads to poor generalizationperformance of the ML model and hence biased predictions. We provide novelalgorithms that estimate the number and properties of these unknown trainingexamples---unknown unknowns. This information can then be used to correct thetraining set, prior to seeing any test data. The key idea is to combinespecies-estimation techniques with data-driven methods for estimating thefeature values for the unknown unknowns. Experiments on a variety of ML modelsand datasets indicate that taking the unknown examples into account can yield amore robust ML model that generalizes better.

VizRec: A framework for secure data exploration via visual  representation

  Visual representations of data (visualizations) are tools of great importanceand widespread use in data analytics as they provide users visual insight topatterns in the observed data in a simple and effective way. However, sincevisualizations tools are applied to sample data, there is a a risk ofvisualizing random fluctuations in the sample rather than a true pattern in thedata. This problem is even more significant when visualization is used toidentify interesting patterns among many possible possibilities, or to identifyan interesting deviation in a pair of observations among many possible pairs,as commonly done in visual recommendation systems.  We present VizRec, a framework for improving the performance of visualrecommendation systems by quantifying the statistical significance ofrecommended visualizations. The proposed methodology allows to control theprobability of misleading visual recommendations using both classicalstatistical testing procedures and a novel application of the VapnikChervonenkis (VC) dimension method which is a fundamental concept instatistical learning theory.

Uniform Convergence Bounds for Codec Selection

  We frame the problem of selecting an optimal audio encoding scheme as asupervised learning task. Through uniform convergence theory, we guaranteeapproximately optimal codec selection while controlling for selection bias. Wepresent rigorous statistical guarantees for the codec selection problem thathold for arbitrary distributions over audio sequences and for arbitrary qualitymetrics. Our techniques can thus balance sound quality and compression ratio,and use audio samples from the distribution to select a codec that performswell on that particular type of data. The applications of our technique areimmense, as it can be used to optimize for quality and bandwidth usage ofstreaming and other digital media, while significantly outperforming approachesthat apply a fixed codec to all data sources.

On the Complexity of Anonymous Communication Through Public Networks

  Anonymous channels allow users to connect to websites or communicate with oneanother privately. Assume that either Alice or Allison is communicating with (apossibly corrupt) Bob. To protect the sender, we seek a protocol that provablyguarantees that these two scenarios are indistinguishable to an adversary thatcan monitor the traffic on all channels of the network and control the internaloperations in a constant fraction of the nodes.  Onion routing is the method of choice for achieving anonymous communication,used for example by Tor. In an onion routing protocol, messages travel throughseveral intermediaries before arriving at their destinations; they are wrappedin layers of encryption (hence they are called ``onions''). In this paper, wegive the first rigorous characterization of the complexity of onion routingprotocols for anonymous communication through public networks. We show that inorder to provide anonymity, an onion routing scheme requires each participantto transmit, on average, a superlogarithmic number of onions. We match thesenegative results with a protocol in which every participant creates apolylogarithmic number of onions and participates in a polylogarithmic numberof transmissions.

Mining Top-K Frequent Itemsets Through Progressive Sampling

  We study the use of sampling for efficiently mining the top-K frequentitemsets of cardinality at most w. To this purpose, we define an approximationto the top-K frequent itemsets to be a family of itemsets which includes(resp., excludes) all very frequent (resp., very infrequent) itemsets, togetherwith an estimate of these itemsets' frequencies with a bounded error. Our firstresult is an upper bound on the sample size which guarantees that the top-Kfrequent itemsets mined from a random sample of that size approximate theactual top-K frequent itemsets, with probability larger than a specified value.We show that the upper bound is asymptotically tight when w is constant. Ourmain algorithmic contribution is a progressive sampling approach, combined withsuitable stopping conditions, which on appropriate inputs is able to extractapproximate top-K frequent itemsets from samples whose sizes are smaller thanthe general upper bound. In order to test the stopping conditions, thisapproach maintains the frequency of all itemsets encountered, which ispractical only for small w. However, we show how this problem can be mitigatedby using a variation of Bloom filters. A number of experiments conducted onboth synthetic and real bench- mark datasets show that using samplessubstantially smaller than the original dataset (i.e., of size defined by theupper bound or reached through the progressive sampling approach) enable toapproximate the actual top-K frequent itemsets with accuracy much higher thanwhat analytically proved.

Infectious Random Walks

  We study the dynamics of information (or virus) dissemination by $m$ mobileagents performing independent random walks on an $n$-node grid. We formulateour results in terms of two scenarios: broadcasting and gossiping. In thebroadcasting scenario, the mobile agents are initially placed uniformly atrandom among the grid nodes. At time 0, one agent is informed of a rumor andstarts a random walk. When an informed agent meets an uninformed agent, thelatter becomes informed and starts a new random walk. We study the broadcastingtime of the system, that is, the time it takes for all agents to know therumor. In the gossiping scenario, each agent is given a distinct rumor at time0 and all agents start random walks. When two agents meet, they share allrumors they are aware of. We study the gossiping time of the system, that is,the time it takes for all agents to know all rumors. We prove that both thebroadcasting and the gossiping times are $\tilde\Theta(n/\sqrt{m})$ w.h.p.,thus achieving a tight characterization up to logarithmic factors. Previousresults for the grid provided bounds which were weaker and only concernedaverage times. In the context of virus infection, a corollary of our results isthat static and dynamically moving agents are infected at about the same speed.

Fast Distributed PageRank Computation

  Over the last decade, PageRank has gained importance in a wide range ofapplications and domains, ever since it first proved to be effective indetermining node importance in large graphs (and was a pioneering idea behindGoogle's search engine). In distributed computing alone, PageRank vector, ormore generally random walk based quantities have been used for severaldifferent applications ranging from determining important nodes, loadbalancing, search, and identifying connectivity structures. Surprisingly,however, there has been little work towards designing provably efficientfully-distributed algorithms for computing PageRank. The difficulty is thattraditional matrix-vector multiplication style iterative methods may not alwaysadapt well to the distributed setting owing to communication bandwidthrestrictions and convergence rates.  In this paper, we present fast random walk-based distributed algorithms forcomputing PageRanks in general graphs and prove strong bounds on the roundcomplexity. We first present a distributed algorithm that takes $O\big(\logn/\eps \big)$ rounds with high probability on any graph (directed orundirected), where $n$ is the network size and $\eps$ is the reset probabilityused in the PageRank computation (typically $\eps$ is a fixed constant). Wethen present a faster algorithm that takes $O\big(\sqrt{\log n}/\eps \big)$rounds in undirected graphs. Both of the above algorithms are scalable, as eachnode sends only small ($\polylog n$) number of bits over each edge per round.To the best of our knowledge, these are the first fully distributed algorithmsfor computing PageRank vector with provably efficient running time.

Accurate Computation of Survival Statistics in Genome-wide Studies

  A key challenge in genomics is to identify genetic variants that distinguishpatients with different survival time following diagnosis or treatment. Whilethe log-rank test is widely used for this purpose, nearly all implementationsof the log-rank test rely on an asymptotic approximation that is notappropriate in many genomics applications. This is because: the two populationsdetermined by a genetic variant may have very different sizes; and theevaluation of many possible variants demands highly accurate computation ofvery small p-values. We demonstrate this problem for cancer genomics data wherethe standard log-rank test leads to many false positive associations betweensomatic mutations and survival time. We develop and analyze a novel algorithm,Exact Log-rank Test (ExaLT), that accurately computes the p-value of thelog-rank statistic under an exact distribution that is appropriate for any sizepopulations. We demonstrate the advantages of ExaLT on data from publishedcancer genomics studies, finding significant differences from the reportedp-values. We analyze somatic mutations in six cancer types from The CancerGenome Atlas (TCGA), finding mutations with known association to survival aswell as several novel associations. In contrast, standard implementations ofthe log-rank test report dozens-hundreds of likely false positive associationsas more significant than these known associations.

Space and Time Efficient Parallel Graph Decomposition, Clustering, and  Diameter Approximation

  We develop a novel parallel decomposition strategy for unweighted, undirectedgraphs, based on growing disjoint connected clusters from batches of centersprogressively selected from yet uncovered nodes. With respect to similarprevious decompositions, our strategy exercises a tighter control on both thenumber of clusters and their maximum radius.  We present two important applications of our parallel graph decomposition:(1) $k$-center clustering approximation; and (2) diameter approximation. Inboth cases, we obtain algorithms which feature a polylogarithmic approximationfactor and are amenable to a distributed implementation that is geared formassive (long-diameter) graphs. The total space needed for the computation islinear in the problem size, and the parallel depth is substantially sublinearin the diameter for graphs with low doubling dimension. To the best of ourknowledge, ours are the first parallel approximations for these problems whichachieve sub-diameter parallel time, for a relevant class of graphs, using onlylinear space. Besides the theoretical guarantees, our algorithms allow for avery simple implementation on clustered architectures: we report on extensiveexperiments which demonstrate their effectiveness and efficiency on largegraphs as compared to alternative known approaches.

Wiggins: Detecting Valuable Information in Dynamic Networks Using  Limited Resources

  Detecting new information and events in a dynamic network by probingindividual nodes has many practical applications: discovering new webpages,analyzing influence properties in network, and detecting failure propagation inelectronic circuits or infections in public drinkable water systems. Inpractice, it is infeasible for anyone but the owner of the network (ifexistent) to monitor all nodes at all times. In this work we study theconstrained setting when the observer can only probe a small set of nodes ateach time step to check whether new pieces of information (items) have reachedthose nodes.  We formally define the problem through an infinite time generating processthat places new items in subsets of nodes according to an unknown probabilitydistribution. Items have an exponentially decaying novelty, modeling theirdecreasing value. The observer uses a probing schedule (i.e., a probabilitydistribution over the set of nodes) to choose, at each time step, a small setof nodes to check for new items. The goal is to compute a schedule thatminimizes the average novelty of undetected items. We present an algorithm,WIGGINS, to compute the optimal schedule through convex optimization, and thenshow how it can be adapted when the parameters of the problem must be learnedor change over time. We also present a scalable variant of WIGGINS for theMapReduce framework. The results of our experimental evaluation on real socialnetworks demonstrate the practicality of our approach.

MapReduce and Streaming Algorithms for Diversity Maximization in Metric  Spaces of Bounded Doubling Dimension

  Given a dataset of points in a metric space and an integer $k$, a diversitymaximization problem requires determining a subset of $k$ points maximizingsome diversity objective measure, e.g., the minimum or the average distancebetween two points in the subset. Diversity maximization is computationallyhard, hence only approximate solutions can be hoped for. Although itsapplications are mainly in massive data analysis, most of the past research ondiversity maximization focused on the sequential setting. In this work wepresent space and pass/round-efficient diversity maximization algorithms forthe Streaming and MapReduce models and analyze their approximation guaranteesfor the relevant class of metric spaces of bounded doubling dimension. Likeother approaches in the literature, our algorithms rely on the determination ofhigh-quality core-sets, i.e., (much) smaller subsets of the input which containgood approximations to the optimal solution for the whole input. For a varietyof diversity objective functions, our algorithms attain an$(\alpha+\epsilon)$-approximation ratio, for any constant $\epsilon>0$, where$\alpha$ is the best approximation ratio achieved by a polynomial-time,linear-space sequential algorithm for the same diversity objective. Thisimproves substantially over the approximation ratios attainable in Streamingand MapReduce by state-of-the-art algorithms for general metric spaces. Weprovide extensive experimental evidence of the effectiveness of our algorithmson both real world and synthetic datasets, scaling up to over a billion points.

Scalable Betweenness Centrality Maximization via Sampling

  Betweenness centrality is a fundamental centrality measure in social networkanalysis. Given a large-scale network, how can we find the most central nodes?This question is of key importance to numerous important applications that relyon betweenness centrality, including community detection and understandinggraph vulnerability. Despite the large amount of work on designing scalableapproximation algorithms for betweenness centrality, estimating it onlarge-scale networks remains a computational challenge.  In this paper, we study the Betweenness Centrality Maximization problem:given a graph $G=(V,E)$ and a positive integer $k$, find a set $S^* \subseteqV$ that maximizes betweenness centrality subject to the cardinality constraint$|S^*| \leq k$. We present an efficient randomized algorithm that provides a$(1-1/e-\epsilon)$-approximation with high probability, where $\epsilon>0$. Ourresults improve the current state-of-the-art result byYoshida~\cite{yoshida2014almost}. Furthermore, we provide theoretical evidencefor the validity of a crucial assumption in the literature of betweennesscentrality estimation, namely that in real-world networks $O(|V|^2)$ shortestpaths pass through the top-$k$ central nodes, where $k$ is a constant. On theexperimental side, we perform an extensive experimental analysis of our methodon real-world networks, demonstrate its accuracy and scalability, and studydifferent properties of central nodes. Finally, we provide three graph miningapplications of our method.

Tiered Sampling: An Efficient Method for Approximate Counting Sparse  Motifs in Massive Graph Streams

  We introduce Tiered Sampling, a novel technique for approximate countingsparse motifs in massive graphs whose edges are observed in a stream. Ourtechnique requires only a single pass on the data and uses a memory of fixedsize $M$, which can be magnitudes smaller than the number of edges.  Our methods addresses the challenging task of counting sparse motifs -sub-graph patterns that have low probability to appear in a sample of $M$ edgesin the graph, which is the maximum amount of data available to the algorithmsin each step. To obtain an unbiased and low variance estimate of the count wepartition the available memory to tiers (layers) of reservoir samples. Whilethe base layer is a standard reservoir sample of edges, other layers arereservoir samples of sub-structures of the desired motif. By storing morefrequent sub-structures of the motif, we increase the probability of detectingan occurrence of the sparse motif we are counting, thus decreasing the varianceand error of the estimate.  We demonstrate the advantage of our method in the specific applications ofcounting sparse 4 and 5-cliques in massive graphs. We present a completeanalytical analysis and extensive experimental results using both synthetic andreal-world data. Our results demonstrate the advantage of our method inobtaining high-quality approximations for the number of 4 and 5-cliques forlarge graphs using a very limited amount of memory, significantly outperformingthe single edge sample approach for counting sparse motifs in large scalegraphs.

Tight Bounds on Information Dissemination in Sparse Mobile Networks

  Motivated by the growing interest in mobile systems, we study the dynamics ofinformation dissemination between agents moving independently on a plane.Formally, we consider $k$ mobile agents performing independent random walks onan $n$-node grid. At time $0$, each agent is located at a random node of thegrid and one agent has a rumor. The spread of the rumor is governed by adynamic communication graph process ${G_t(r) | t \geq 0}$, where two agents areconnected by an edge in $G_t(r)$ iff their distance at time $t$ is within theirtransmission radius $r$. Modeling the physical reality that the speed of radiotransmission is much faster than the motion of the agents, we assume that therumor can travel throughout a connected component of $G_t$ before the graph isaltered by the motion. We study the broadcast time $T_B$ of the system, whichis the time it takes for all agents to know the rumor. We focus on the sparsecase (below the percolation point $r_c \approx \sqrt{n/k}$) where, with highprobability, no connected component in $G_t$ has more than a logarithmic numberof agents and the broadcast time is dominated by the time it takes for manyindependent random walks to meet each other. Quite surprisingly, we show thatfor a system below the percolation point the broadcast time does not depend onthe relation between the mobility speed and the transmission radius. In fact,we prove that $T_B = \tilde{O}(n / \sqrt{k})$ for any $0 \leq r < r_c$, evenwhen the transmission range is significantly larger than the mobility range inone step, giving a tight characterization up to logarithmic factors. Our resultcomplements a recent result of Peres et al. (SODA 2011) who showed that abovethe percolation point the broadcast time is polylogarithmic in $k$.

The VC-Dimension of Queries and Selectivity Estimation Through Sampling

  We develop a novel method, based on the statistical concept of theVapnik-Chervonenkis dimension, to evaluate the selectivity (output cardinality)of SQL queries - a crucial step in optimizing the execution of large scaledatabase and data-mining operations. The major theoretical contribution of thiswork, which is of independent interest, is an explicit bound to theVC-dimension of a range space defined by all possible outcomes of a collection(class) of queries. We prove that the VC-dimension is a function of the maximumnumber of Boolean operations in the selection predicate and of the maximumnumber of select and join operations in any individual query in the collection,but it is neither a function of the number of queries in the collection nor ofthe size (number of tuples) of the database. We leverage on this result anddevelop a method that, given a class of queries, builds a concise random sampleof a database, such that with high probability the execution of any query inthe class on the sample provides an accurate estimate for the selectivity ofthe query on the original large database. The error probability holdssimultaneously for the selectivity estimates of all queries in the collection,thus the same sample can be used to evaluate the selectivity of multiplequeries, and the sample needs to be refreshed only following major changes inthe database. The sample representation computed by our method is typicallysufficiently small to be stored in main memory. We present extensiveexperimental results, validating our theoretical analysis and demonstrating theadvantage of our technique when compared to complex selectivity estimationtechniques used in PostgreSQL and the Microsoft SQL Server.

Distributed Agreement in Dynamic Peer-to-Peer Networks

  Motivated by the need for robust and fast distributed computation in highlydynamic Peer-to-Peer (P2P) networks, we study algorithms for the fundamentaldistributed agreement problem. P2P networks are highly dynamic networks thatexperience heavy node {\em churn}. Our goal is to design fast algorithms(running in a small number of rounds) that guarantee, despite high node churnrate, that almost all nodes reach a stable agreement. Our main contributionsare randomized distributed algorithms that guarantee {\em stablealmost-everywhere agreement} with high probability even under high adversarialchurn in a polylogarithmic number of rounds:  1. An $O(\log^2 n)$-round ($n$ is the stable network size) randomizedalgorithm that achieves almost-everywhere agreement with high probability underup to {\em linear} churn {\em per round} (i.e., $\epsilon n$, for some smallconstant $\epsilon > 0$), assuming that the churn is controlled by an obliviousadversary (that has complete knowledge and control of what nodes join and leaveand at what time and has unlimited computational power, but is oblivious to therandom choices made by the algorithm). Our algorithm requires onlypolylogarithmic in $n$ bits to be processed and sent (per round) by each node.  2. An $O(\log m\log^3 n)$-round randomized algorithm that achievesalmost-everywhere agreement with high probability under up to $\epsilon\sqrt{n}$ churn per round (for some small $\epsilon > 0$), where $m$ is thesize of the input value domain, that works even under an adaptive adversary(that also knows the past random choices made by the algorithm). This algorithmrequires up to polynomial in $n$ bits (and up to $O(\log m)$ bits) to beprocessed and sent (per round) by each node.

Efficient Discovery of Association Rules and Frequent Itemsets through  Sampling with Tight Performance Guarantees

  The tasks of extracting (top-$K$) Frequent Itemsets (FI's) and AssociationRules (AR's) are fundamental primitives in data mining and databaseapplications. Exact algorithms for these problems exist and are widely used,but their running time is hindered by the need of scanning the entire dataset,possibly multiple times. High quality approximations of FI's and AR's aresufficient for most practical uses, and a number of recent works explored theapplication of sampling for fast discovery of approximate solutions to theproblems. However, these works do not provide satisfactory performanceguarantees on the quality of the approximation, due to the difficulty ofbounding the probability of under- or over-sampling any one of an unknownnumber of frequent itemsets. In this work we circumvent this issue by applyingthe statistical concept of \emph{Vapnik-Chervonenkis (VC) dimension} to developa novel technique for providing tight bounds on the sample size that guaranteesapproximation within user-specified parameters. Our technique applies both toabsolute and to relative approximations of (top-$K$) FI's and AR's. Theresulting sample size is linearly dependent on the VC-dimension of a rangespace associated with the dataset to be mined. The main theoreticalcontribution of this work is a proof that the VC-dimension of this range spaceis upper bounded by an easy-to-compute characteristic quantity of the datasetwhich we call \emph{d-index}, and is the maximum integer $d$ such that thedataset contains at least $d$ transactions of length at least $d$ such that noone of them is a superset of or equal to another. We show that this bound isstrict for a large class of datasets.

Storage and Search in Dynamic Peer-to-Peer Networks

  We study robust and efficient distributed algorithms for searching, storing,and maintaining data in dynamic Peer-to-Peer (P2P) networks. P2P networks arehighly dynamic networks that experience heavy node churn (i.e., nodes join andleave the network continuously over time). Our goal is to guarantee, despitehigh node churn rate, that a large number of nodes in the network can store,retrieve, and maintain a large number of data items. Our main contributions arefast randomized distributed algorithms that guarantee the above with highprobability (whp) even under high adversarial churn:  1. A randomized distributed search algorithm that (whp) guarantees thatsearches from as many as $n - o(n)$ nodes ($n$ is the stable network size)succeed in ${O}(\log n)$-rounds despite ${O}(n/\log^{1+\delta} n)$ churn, forany small constant $\delta > 0$, per round. We assume that the churn iscontrolled by an oblivious adversary (that has complete knowledge and controlof what nodes join and leave and at what time, but is oblivious to the randomchoices made by the algorithm).  2. A storage and maintenance algorithm that guarantees (whp) data items canbe efficiently stored (with only $\Theta(\log{n})$ copies of each data item)and maintained in a dynamic P2P network with churn rate up to${O}(n/\log^{1+\delta} n)$ per round. Our search algorithm together with ourstorage and maintenance algorithm guarantees that as many as $n - o(n)$ nodescan efficiently store, maintain, and search even under ${O}(n/\log^{1+\delta}n)$ churn per round. Our algorithms require only polylogarithmic in $n$ bits tobe processed and sent (per round) by each node.  To the best of our knowledge, our algorithms are the first-known,fully-distributed storage and search algorithms that provably work under highlydynamic settings (i.e., high churn rates per step).

Balanced Allocation: Patience is not a Virtue

  Load balancing is a well-studied problem, with balls-in-bins being theprimary framework. The greedy algorithm $\mathsf{Greedy}[d]$ of Azar et al.places each ball by probing $d > 1$ random bins and placing the ball in theleast loaded of them. With high probability, the maximum load under$\mathsf{Greedy}[d]$ is exponentially lower than the result when balls areplaced uniformly randomly. V\"ocking showed that a slightly asymmetric variant,$\mathsf{Left}[d]$, provides a further significant improvement. However, thisimprovement comes at an additional computational cost of imposing structure onthe bins.  Here, we present a fully decentralized and easy-to-implement algorithm called$\mathsf{FirstDiff}[d]$ that combines the simplicity of $\mathsf{Greedy}[d]$and the improved balance of $\mathsf{Left}[d]$. The key idea in$\mathsf{FirstDiff}[d]$ is to probe until a different bin size from the firstobservation is located, then place the ball. Although the number of probescould be quite large for some of the balls, we show that$\mathsf{FirstDiff}[d]$ requires only at most $d$ probes on average per ball(in both the standard and the heavily-loaded settings). Thus the number ofprobes is no greater than either that of $\mathsf{Greedy}[d]$ or$\mathsf{Left}[d]$. More importantly, we show that $\mathsf{FirstDiff}[d]$closely matches the improved maximum load ensured by $\mathsf{Left}[d]$ in boththe standard and heavily-loaded settings. We further provide a tight lowerbound on the maximum load up to $O(\log \log \log n)$ terms. We additionallygive experimental data that $\mathsf{FirstDiff}[d]$ is indeed as good as$\mathsf{Left}[d]$, if not better, in practice.

Machine Learning in High Energy Physics Community White Paper

  Machine learning is an important research area in particle physics, beginningwith applications to high-level physics analysis in the 1990s and 2000s,followed by an explosion of applications in particle and event identificationand reconstruction in the 2010s. In this document we discuss promising futureresearch and development areas in machine learning in particle physics with aroadmap for their implementation, software and hardware resource requirements,collaborative initiatives with the data science community, academia andindustry, and training the particle physics community in data science. The mainobjective of the document is to connect and motivate these areas of researchand development with the physics drivers of the High-Luminosity Large HadronCollider and future neutrino experiments and identify the resource needs fortheir implementation. Additionally we identify areas where collaboration withexternal communities will be of great benefit.

