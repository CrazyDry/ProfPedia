Solving Multistage Influence Diagrams using Branch-and-Bound Search

  A branch-and-bound approach to solving influ- ence diagrams has beenpreviously proposed in the literature, but appears to have never beenimplemented and evaluated - apparently due to the difficulties of computingeffective bounds for the branch-and-bound search. In this paper, we describehow to efficiently compute effective bounds, and we develop a practicalimplementa- tion of depth-first branch-and-bound search for influence diagramevaluation that outperforms existing methods for solving influence diagramswith multiple stages.

Most Relevant Explanation: Properties, Algorithms, and Evaluations

  Most Relevant Explanation (MRE) is a method for finding multivariateexplanations for given evidence in Bayesian networks [12]. This paper studiesthe theoretical properties of MRE and develops an algorithm for findingmultiple top MRE solutions. Our study shows that MRE relies on an implicit softrelevance measure in automatically identifying the most relevant targetvariables and pruning less relevant variables from an explanation. The softmeasure also enables MRE to capture the intuitive phenomenon of explaining awayencoded in Bayesian networks. Furthermore, our study shows that the solutionspace of MRE has a special lattice structure which yields interesting dominancerelations among the solutions. A K-MRE algorithm based on these dominancerelations is developed for generating a set of top solutions that are morerepresentative. Our empirical results show that MRE methods are promisingapproaches for explanation in Bayesian networks.

Importance Sampling in Bayesian Networks: An Influence-Based  Approximation Strategy for Importance Functions

  One of the main problems of importance sampling in Bayesian networks isrepresentation of the importance function, which should ideally be as close aspossible to the posterior joint distribution. Typically, we represent animportance function as a factorization, i.e., product of conditionalprobability tables (CPTs). Given diagnostic evidence, we do not have explicitforms for the CPTs in the networks. We first derive the exact form for the CPTsof the optimal importance function. Since the calculation is hard, we usuallyonly use their approximations. We review several popular strategies and pointout their limitations. Based on an analysis of the influence of evidence, wepropose a method for approximating the exact form of importance function byexplicitly modeling the most important additional dependence relationsintroduced by evidence. Our experimental results show that the newapproximation strategy offers an immediate improvement in the quality of theimportance function.

Annealed MAP

  Maximum a Posteriori assignment (MAP) is the problem of finding the mostprobable instantiation of a set of variables given the partial evidence on theother variables in a Bayesian network. MAP has been shown to be a NP-hardproblem [22], even for constrained networks, such as polytrees [18]. Hence,previous approaches often fail to yield any results for MAP problems in largecomplex Bayesian networks. To address this problem, we propose AnnealedMAPalgorithm, a simulated annealing-based MAP algorithm. The AnnealedMAP algorithmsimulates a non-homogeneous Markov chain whose invariant function is aprobability density that concentrates itself on the modes of the targetdensity. We tested this algorithm on several real Bayesian networks. Theresults show that, while maintaining good quality of the MAP solutions, theAnnealedMAP algorithm is also able to solve many problems that are beyond thereach of previous approaches.

An Improved Admissible Heuristic for Learning Optimal Bayesian Networks

  Recently two search algorithms, A* and breadth-first branch and bound(BFBnB), were developed based on a simple admissible heuristic for learningBayesian network structures that optimize a scoring function. The heuristicrepresents a relaxation of the learning problem such that each variable choosesoptimal parents independently. As a result, the heuristic may contain manydirected cycles and result in a loose bound. This paper introduces an improvedadmissible heuristic that tries to avoid directed cycles within small groups ofvariables. A sparse representation is also introduced to store only the uniqueoptimal parent choices. Empirical results show that the new techniquessignificantly improved the efficiency and scalability of A* and BFBnB on mostof datasets tested in this paper.

An Importance Sampling Algorithm Based on Evidence Pre-propagation

  Precision achieved by stochastic sampling algorithms for Bayesian networkstypically deteriorates in face of extremely unlikely evidence. To address thisproblem, we propose the Evidence Pre-propagation Importance Sampling algorithm(EPIS-BN), an importance sampling algorithm that computes an approximateimportance function by the heuristic methods: loopy belief Propagation ande-cutoff. We tested the performance of e-cutoff on three large real Bayesiannetworks: ANDES, CPCS, and PATHFINDER. We observed that on each of thesenetworks the EPIS-BN algorithm gives us a considerable improvement over thecurrent state of the art algorithm, the AIS-BN algorithm. In addition, itavoids the costly learning stage of the AIS-BN algorithm.

Most Relevant Explanation in Bayesian Networks

  A major inference task in Bayesian networks is explaining why some variablesare observed in their particular states using a set of target variables.Existing methods for solving this problem often generate explanations that areeither too simple (underspecified) or too complex (overspecified). In thispaper, we introduce a method called Most Relevant Explanation (MRE) which findsa partial instantiation of the target variables that maximizes the generalizedBayes factor (GBF) as the best explanation for the given evidence. Our studyshows that GBF has several theoretical properties that enable MRE toautomatically identify the most relevant target variables in forming itsexplanation. In particular, conditional Bayes factor (CBF), defined as the GBFof a new explanation conditioned on an existing explanation, provides a softmeasure on the degree of relevance of the variables in the new explanation inexplaining the evidence given the existing explanation. As a result, MRE isable to automatically prune less relevant variables from its explanation. Wealso show that CBF is able to capture well the explaining-away phenomenon thatis often represented in Bayesian networks. Moreover, we define two dominancerelations between the candidate solutions and use the relations to generalizeMRE to find a set of top explanations that is both diverse and representative.Case studies on several benchmark diagnostic Bayesian networks show that MRE isoften able to find explanatory hypotheses that are not only precise but alsoconcise.

Improving the Scalability of Optimal Bayesian Network Learning with  External-Memory Frontier Breadth-First Branch and Bound Search

  Previous work has shown that the problem of learning the optimal structure ofa Bayesian network can be formulated as a shortest path finding problem in agraph and solved using A* search. In this paper, we improve the scalability ofthis approach by developing a memory-efficient heuristic search algorithm forlearning the structure of a Bayesian network. Instead of using A*, we propose afrontier breadth-first branch and bound search that leverages the layeredstructure of the search graph of this problem so that no more than two layersof the graph, plus solution reconstruction information, need to be stored inmemory at a time. To further improve scalability, the algorithm stores most ofthe graph in external memory, such as hard disk, when it does not fit in RAM.Experimental results show that the resulting algorithm solves significantlylarger problems than the current state of the art.

Solving Limited-Memory Influence Diagrams Using Branch-and-Bound Search

  A limited-memory influence diagram (LIMID) generalizes a traditionalinfluence diagram by relaxing the assumptions of regularity and no-forgetting,allowing a wider range of decision problems to be modeled. Algorithms forsolving traditional influence diagrams are not easily generalized to solveLIMIDs, however, and only recently have exact algorithms for solving LIMIDsbeen developed. In this paper, we introduce an exact algorithm for solvingLIMIDs that is based on branch-and-bound search. Our approach is related to theapproach of solving an influence diagram by converting it to an equivalentdecision tree, with the difference that the LIMID is converted to a muchsmaller decision graph that can be searched more efficiently.

Evaluating Anytime Algorithms for Learning Optimal Bayesian Networks

  Exact algorithms for learning Bayesian networks guarantee to find provablyoptimal networks. However, they may fail in difficult learning tasks due tolimited time or memory. In this research we adapt several anytime heuristicsearch-based algorithms to learn Bayesian networks. These algorithms findhigh-quality solutions quickly, and continually improve the incumbent solutionor prove its optimality before resources are exhausted. Empirical results showthat the anytime window A* algorithm usually finds higher-quality, oftenoptimal, networks more quickly than other approaches. The results also showthat, surprisingly, while generating networks with few parents per variable arestructurally simpler, they are harder to learn than complex generating networkswith more parents per variable.

