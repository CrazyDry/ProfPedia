Solving Multistage Influence Diagrams using Branch-and-Bound Search

  A branch-and-bound approach to solving influ- ence diagrams has been
previously proposed in the literature, but appears to have never been
implemented and evaluated - apparently due to the difficulties of computing
effective bounds for the branch-and-bound search. In this paper, we describe
how to efficiently compute effective bounds, and we develop a practical
implementa- tion of depth-first branch-and-bound search for influence diagram
evaluation that outperforms existing methods for solving influence diagrams
with multiple stages.


Most Relevant Explanation: Properties, Algorithms, and Evaluations

  Most Relevant Explanation (MRE) is a method for finding multivariate
explanations for given evidence in Bayesian networks [12]. This paper studies
the theoretical properties of MRE and develops an algorithm for finding
multiple top MRE solutions. Our study shows that MRE relies on an implicit soft
relevance measure in automatically identifying the most relevant target
variables and pruning less relevant variables from an explanation. The soft
measure also enables MRE to capture the intuitive phenomenon of explaining away
encoded in Bayesian networks. Furthermore, our study shows that the solution
space of MRE has a special lattice structure which yields interesting dominance
relations among the solutions. A K-MRE algorithm based on these dominance
relations is developed for generating a set of top solutions that are more
representative. Our empirical results show that MRE methods are promising
approaches for explanation in Bayesian networks.


An Improved Admissible Heuristic for Learning Optimal Bayesian Networks

  Recently two search algorithms, A* and breadth-first branch and bound
(BFBnB), were developed based on a simple admissible heuristic for learning
Bayesian network structures that optimize a scoring function. The heuristic
represents a relaxation of the learning problem such that each variable chooses
optimal parents independently. As a result, the heuristic may contain many
directed cycles and result in a loose bound. This paper introduces an improved
admissible heuristic that tries to avoid directed cycles within small groups of
variables. A sparse representation is also introduced to store only the unique
optimal parent choices. Empirical results show that the new techniques
significantly improved the efficiency and scalability of A* and BFBnB on most
of datasets tested in this paper.


An Importance Sampling Algorithm Based on Evidence Pre-propagation

  Precision achieved by stochastic sampling algorithms for Bayesian networks
typically deteriorates in face of extremely unlikely evidence. To address this
problem, we propose the Evidence Pre-propagation Importance Sampling algorithm
(EPIS-BN), an importance sampling algorithm that computes an approximate
importance function by the heuristic methods: loopy belief Propagation and
e-cutoff. We tested the performance of e-cutoff on three large real Bayesian
networks: ANDES, CPCS, and PATHFINDER. We observed that on each of these
networks the EPIS-BN algorithm gives us a considerable improvement over the
current state of the art algorithm, the AIS-BN algorithm. In addition, it
avoids the costly learning stage of the AIS-BN algorithm.


Importance Sampling in Bayesian Networks: An Influence-Based
  Approximation Strategy for Importance Functions

  One of the main problems of importance sampling in Bayesian networks is
representation of the importance function, which should ideally be as close as
possible to the posterior joint distribution. Typically, we represent an
importance function as a factorization, i.e., product of conditional
probability tables (CPTs). Given diagnostic evidence, we do not have explicit
forms for the CPTs in the networks. We first derive the exact form for the CPTs
of the optimal importance function. Since the calculation is hard, we usually
only use their approximations. We review several popular strategies and point
out their limitations. Based on an analysis of the influence of evidence, we
propose a method for approximating the exact form of importance function by
explicitly modeling the most important additional dependence relations
introduced by evidence. Our experimental results show that the new
approximation strategy offers an immediate improvement in the quality of the
importance function.


Annealed MAP

  Maximum a Posteriori assignment (MAP) is the problem of finding the most
probable instantiation of a set of variables given the partial evidence on the
other variables in a Bayesian network. MAP has been shown to be a NP-hard
problem [22], even for constrained networks, such as polytrees [18]. Hence,
previous approaches often fail to yield any results for MAP problems in large
complex Bayesian networks. To address this problem, we propose AnnealedMAP
algorithm, a simulated annealing-based MAP algorithm. The AnnealedMAP algorithm
simulates a non-homogeneous Markov chain whose invariant function is a
probability density that concentrates itself on the modes of the target
density. We tested this algorithm on several real Bayesian networks. The
results show that, while maintaining good quality of the MAP solutions, the
AnnealedMAP algorithm is also able to solve many problems that are beyond the
reach of previous approaches.


Most Relevant Explanation in Bayesian Networks

  A major inference task in Bayesian networks is explaining why some variables
are observed in their particular states using a set of target variables.
Existing methods for solving this problem often generate explanations that are
either too simple (underspecified) or too complex (overspecified). In this
paper, we introduce a method called Most Relevant Explanation (MRE) which finds
a partial instantiation of the target variables that maximizes the generalized
Bayes factor (GBF) as the best explanation for the given evidence. Our study
shows that GBF has several theoretical properties that enable MRE to
automatically identify the most relevant target variables in forming its
explanation. In particular, conditional Bayes factor (CBF), defined as the GBF
of a new explanation conditioned on an existing explanation, provides a soft
measure on the degree of relevance of the variables in the new explanation in
explaining the evidence given the existing explanation. As a result, MRE is
able to automatically prune less relevant variables from its explanation. We
also show that CBF is able to capture well the explaining-away phenomenon that
is often represented in Bayesian networks. Moreover, we define two dominance
relations between the candidate solutions and use the relations to generalize
MRE to find a set of top explanations that is both diverse and representative.
Case studies on several benchmark diagnostic Bayesian networks show that MRE is
often able to find explanatory hypotheses that are not only precise but also
concise.


Improving the Scalability of Optimal Bayesian Network Learning with
  External-Memory Frontier Breadth-First Branch and Bound Search

  Previous work has shown that the problem of learning the optimal structure of
a Bayesian network can be formulated as a shortest path finding problem in a
graph and solved using A* search. In this paper, we improve the scalability of
this approach by developing a memory-efficient heuristic search algorithm for
learning the structure of a Bayesian network. Instead of using A*, we propose a
frontier breadth-first branch and bound search that leverages the layered
structure of the search graph of this problem so that no more than two layers
of the graph, plus solution reconstruction information, need to be stored in
memory at a time. To further improve scalability, the algorithm stores most of
the graph in external memory, such as hard disk, when it does not fit in RAM.
Experimental results show that the resulting algorithm solves significantly
larger problems than the current state of the art.


Solving Limited-Memory Influence Diagrams Using Branch-and-Bound Search

  A limited-memory influence diagram (LIMID) generalizes a traditional
influence diagram by relaxing the assumptions of regularity and no-forgetting,
allowing a wider range of decision problems to be modeled. Algorithms for
solving traditional influence diagrams are not easily generalized to solve
LIMIDs, however, and only recently have exact algorithms for solving LIMIDs
been developed. In this paper, we introduce an exact algorithm for solving
LIMIDs that is based on branch-and-bound search. Our approach is related to the
approach of solving an influence diagram by converting it to an equivalent
decision tree, with the difference that the LIMID is converted to a much
smaller decision graph that can be searched more efficiently.


Evaluating Anytime Algorithms for Learning Optimal Bayesian Networks

  Exact algorithms for learning Bayesian networks guarantee to find provably
optimal networks. However, they may fail in difficult learning tasks due to
limited time or memory. In this research we adapt several anytime heuristic
search-based algorithms to learn Bayesian networks. These algorithms find
high-quality solutions quickly, and continually improve the incumbent solution
or prove its optimality before resources are exhausted. Empirical results show
that the anytime window A* algorithm usually finds higher-quality, often
optimal, networks more quickly than other approaches. The results also show
that, surprisingly, while generating networks with few parents per variable are
structurally simpler, they are harder to learn than complex generating networks
with more parents per variable.


