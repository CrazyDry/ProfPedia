A Proof of the Front-Door Adjustment Formula

  We provide a proof of the the Front-Door adjustment formula using the
do-calculus.


Comment on: Decomposition of structural learning about directed acyclic
  graphs [1]

  We propose an alternative proof concerning necessary and sufficient
conditions to split the problem of searching for d-separators and building the
skeleton of a DAG into small problems for every node of a separation tree T.
The proof is simpler than the original [1]. The same proof structure has been
used in [2] for learning the structure of multivariate regression chain graphs
(MVR CGs).


On the Properties of MVR Chain Graphs

  Depending on the interpretation of the type of edges, a chain graph can
represent different relations between variables and thereby independence
models. Three interpretations, known by the acronyms LWF, MVR, and AMP, are
prevalent. Multivariate regression chain graphs (MVR CGs) were introduced by
Cox and Wermuth in 1993. We review Markov properties for MVR chain graphs and
propose an alternative global and local Markov property for them. Except for
pairwise Markov properties, we show that for MVR chain graphs all Markov
properties in the literature are equivalent for semi-graphoids. We derive a new
factorization formula for MVR chain graphs which is more explicit than and
different from the proposed factorizations for MVR chain graphs in the
literature. Finally, we provide a summary table comparing different features of
LWF, AMP, and MVR chain graphs.


A New Result on the Complexity of Heuristic Estimates for the A*
  Algorithm

  Relaxed models are abstract problem descriptions generated by ignoring
constraints that are present in base-level problems. They play an important
role in planning and search algorithms, as it has been shown that the length of
an optimal solution to a relaxed model yields a monotone heuristic for an A?
search of a base-level problem. Optimal solutions to a relaxed model may be
computed algorithmically or by search in a further relaxed model, leading to a
search that explores a hierarchy of relaxed models. In this paper, we review
the traditional definition of problem relaxation and show that searching in the
abstraction hierarchy created by problem relaxation will not reduce the
computational effort required to find optimal solutions to the base- level
problem, unless the relaxed problem found in the hierarchy can be transformed
by some optimization (e.g., subproblem factoring). Specifically, we prove that
any A* search of the base-level using a heuristic h2 will largely dominate an
A* search of the base-level using a heuristic h1, if h1 must be computed by an
A* search of the relaxed model using h2.


Structural Learning of Multivariate Regression Chain Graphs via
  Decomposition

  We extend the decomposition approach for learning Bayesian networks (BN)
proposed by (Xie et al., 2006) to learning multivariate regression chain graphs
(MVR CGs), which include BNs as a special case. The same advantages of this
decomposition approach hold in the more general setting: reduces complexity and
increased power of computational independence tests. Moreover, latent (hidden)
variables can be represented in MVR CGs by using bidirected edges, and our
algorithm correctly recovers any independence structure that is faithful to a
MVR CG, thus greatly extending the range of applications of decomposition-based
model selection techniques. While our new algorithm has the same complexity as
the one in (Xie et al., 2006) for BNs, it requires larger components for
general MVR CGs, to insure that sufficient data is present to estimate
parameters.


Pearl's Calculus of Intervention Is Complete

  This paper is concerned with graphical criteria that can be used to solve the
problem of identifying casual effects from nonexperimental data in a causal
Bayesian network structure, i.e., a directed acyclic graph that represents
causal relationships. We first review Pearl's work on this topic [Pearl, 1995],
in which several useful graphical criteria are presented. Then we present a
complete algorithm [Huang and Valtorta, 2006b] for the identifiability problem.
By exploiting the completeness of this algorithm, we prove that the three basic
do-calculus rules that Pearl presents are complete, in the sense that, if a
causal effect is identifiable, there exists a sequence of applications of the
rules of the do-calculus that transforms the causal effect formula into a
formula that only includes observational quantities.


An Algorithm for the Construction of Bayesian Network Structures from
  Data

  Previous algorithms for the construction of Bayesian belief network
structures from data have been either highly dependent on conditional
independence (CI) tests, or have required an ordering on the nodes to be
supplied by the user. We present an algorithm that integrates these two
approaches - CI tests are used to generate an ordering on the nodes from the
database which is then used to recover the underlying Bayesian network
structure using a non CI based method. Results of preliminary evaluation of the
algorithm on two networks (ALARM and LED) are presented. We also discuss some
algorithm performance issues and open problems.


On the Detection of Conflicts in Diagnostic Bayesian Networks Using
  Abstraction

  An important issue in the use of expert systems is the so-called brittleness
problem. Expert systems model only a limited part of the world. While the
explicit management of uncertainty in expert systems itigates the brittleness
problem, it is still possible for a system to be used, unwittingly, in ways
that the system is not prepared to address. Such a situation may be detected by
the method of straw models, first presented by Jensen et al. [1990] and later
generalized and justified by Laskey [1991]. We describe an algorithm, which we
have implemented, that takes as input an annotated diagnostic Bayesian network
(the base model) and constructs, without assistance, a bipartite network to be
used as a straw model. We show that in some cases this straw model is better
that the independent straw model of Jensen et al., the only other straw model
for which a construction algorithm has been designed and implemented.


A Hybrid Algorithm to Compute Marginal and Joint Beliefs in Bayesian
  Networks and Its Complexity

  There exist two general forms of exact algorithms for updating probabilities
in Bayesian Networks. The first approach involves using a structure, usually a
clique tree, and performing local message based calculation to extract the
belief in each variable. The second general class of algorithm involves the use
of non-serial dynamic programming techniques to extract the belief in some
desired group of variables. In this paper we present a hybrid algorithm based
on the latter approach yet possessing the ability to retrieve the belief in all
single variables. The technique is advantageous in that it saves a NP-hard
computation step over using one algorithm of each type. Furthermore, this
technique re-enforces a conjecture of Jensen and Jensen [JJ94] in that it still
requires a single NP-hard step to set up the structure on which inference is
performed, as we show by confirming Li and D'Ambrosio's [LD94] conjectured
NP-hardness of OFP.


Parameter identifiability of discrete Bayesian networks with hidden
  variables

  Identifiability of parameters is an essential property for a statistical
model to be useful in most settings. However, establishing parameter
identifiability for Bayesian networks with hidden variables remains
challenging. In the context of finite state spaces, we give algebraic arguments
establishing identifiability of some special models on small DAGs. We also
establish that, for fixed state spaces, generic identifiability of parameters
depends only on the Markov equivalence class of the DAG. To illustrate the use
of these results, we investigate identifiability for all binary Bayesian
networks with up to five variables, one of which is hidden and parental to all
observable ones. Surprisingly, some of these models have parameterizations that
are generically 4-to-one, and not 2-to-one as label swapping of the hidden
states would suggest. This leads to interesting difficulties in interpreting
causal effects.


On a hypergraph probabilistic graphical model

  We propose a directed acyclic hypergraph framework for a probabilistic
graphical model that we call Bayesian hypergraphs. The space of directed
acyclic hypergraphs is much larger than the space of chain graphs. Hence
Bayesian hypergraphs can model much finer factorizations than Bayesian networks
or LWF chain graphs and provide simpler and more computationally efficient
procedures for factorizations and interventions. Bayesian hypergraphs also
allow a modeler to represent causal patterns of interaction such as Noisy-OR
graphically (without additional annotations). We introduce global, local and
pairwise Markov properties of Bayesian hypergraphs and prove under which
conditions they are equivalent. We define a projection operator, called shadow,
that maps Bayesian hypergraphs to chain graphs, and show that the Markov
properties of a Bayesian hypergraph are equivalent to those of its
corresponding chain graph. We extend the causal interpretation of LWF chain
graphs to Bayesian hypergraphs and provide corresponding formulas and a
graphical criterion for intervention.


Transfer Learning for Performance Modeling of Configurable Systems: A
  Causal Analysis

  Modern systems (e.g., deep neural networks, big data analytics, and
compilers) are highly configurable, which means they expose different
performance behavior under different configurations. The fundamental challenge
is that one cannot simply measure all configurations due to the sheer size of
the configuration space. Transfer learning has been used to reduce the
measurement efforts by transferring knowledge about performance behavior of
systems across environments. Previously, research has shown that statistical
models are indeed transferable across environments. In this work, we
investigate identifiability and transportability of causal effects and
statistical relations in highly-configurable systems. Our causal analysis
agrees with previous exploratory analysis \cite{Jamshidi17} and confirms that
the causal effects of configuration options can be carried over across
environments with high confidence. We expect that the ability to carry over
causal relations will enable effective performance analysis of
highly-configurable systems.


