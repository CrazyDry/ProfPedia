A Proof of the Front-Door Adjustment Formula

  We provide a proof of the the Front-Door adjustment formula using thedo-calculus.

Comment on: Decomposition of structural learning about directed acyclic  graphs [1]

  We propose an alternative proof concerning necessary and sufficientconditions to split the problem of searching for d-separators and building theskeleton of a DAG into small problems for every node of a separation tree T.The proof is simpler than the original [1]. The same proof structure has beenused in [2] for learning the structure of multivariate regression chain graphs(MVR CGs).

On the Properties of MVR Chain Graphs

  Depending on the interpretation of the type of edges, a chain graph canrepresent different relations between variables and thereby independencemodels. Three interpretations, known by the acronyms LWF, MVR, and AMP, areprevalent. Multivariate regression chain graphs (MVR CGs) were introduced byCox and Wermuth in 1993. We review Markov properties for MVR chain graphs andpropose an alternative global and local Markov property for them. Except forpairwise Markov properties, we show that for MVR chain graphs all Markovproperties in the literature are equivalent for semi-graphoids. We derive a newfactorization formula for MVR chain graphs which is more explicit than anddifferent from the proposed factorizations for MVR chain graphs in theliterature. Finally, we provide a summary table comparing different features ofLWF, AMP, and MVR chain graphs.

A New Result on the Complexity of Heuristic Estimates for the A*  Algorithm

  Relaxed models are abstract problem descriptions generated by ignoringconstraints that are present in base-level problems. They play an importantrole in planning and search algorithms, as it has been shown that the length ofan optimal solution to a relaxed model yields a monotone heuristic for an A?search of a base-level problem. Optimal solutions to a relaxed model may becomputed algorithmically or by search in a further relaxed model, leading to asearch that explores a hierarchy of relaxed models. In this paper, we reviewthe traditional definition of problem relaxation and show that searching in theabstraction hierarchy created by problem relaxation will not reduce thecomputational effort required to find optimal solutions to the base- levelproblem, unless the relaxed problem found in the hierarchy can be transformedby some optimization (e.g., subproblem factoring). Specifically, we prove thatany A* search of the base-level using a heuristic h2 will largely dominate anA* search of the base-level using a heuristic h1, if h1 must be computed by anA* search of the relaxed model using h2.

Structural Learning of Multivariate Regression Chain Graphs via  Decomposition

  We extend the decomposition approach for learning Bayesian networks (BN)proposed by (Xie et al., 2006) to learning multivariate regression chain graphs(MVR CGs), which include BNs as a special case. The same advantages of thisdecomposition approach hold in the more general setting: reduces complexity andincreased power of computational independence tests. Moreover, latent (hidden)variables can be represented in MVR CGs by using bidirected edges, and ouralgorithm correctly recovers any independence structure that is faithful to aMVR CG, thus greatly extending the range of applications of decomposition-basedmodel selection techniques. While our new algorithm has the same complexity asthe one in (Xie et al., 2006) for BNs, it requires larger components forgeneral MVR CGs, to insure that sufficient data is present to estimateparameters.

Pearl's Calculus of Intervention Is Complete

  This paper is concerned with graphical criteria that can be used to solve theproblem of identifying casual effects from nonexperimental data in a causalBayesian network structure, i.e., a directed acyclic graph that representscausal relationships. We first review Pearl's work on this topic [Pearl, 1995],in which several useful graphical criteria are presented. Then we present acomplete algorithm [Huang and Valtorta, 2006b] for the identifiability problem.By exploiting the completeness of this algorithm, we prove that the three basicdo-calculus rules that Pearl presents are complete, in the sense that, if acausal effect is identifiable, there exists a sequence of applications of therules of the do-calculus that transforms the causal effect formula into aformula that only includes observational quantities.

An Algorithm for the Construction of Bayesian Network Structures from  Data

  Previous algorithms for the construction of Bayesian belief networkstructures from data have been either highly dependent on conditionalindependence (CI) tests, or have required an ordering on the nodes to besupplied by the user. We present an algorithm that integrates these twoapproaches - CI tests are used to generate an ordering on the nodes from thedatabase which is then used to recover the underlying Bayesian networkstructure using a non CI based method. Results of preliminary evaluation of thealgorithm on two networks (ALARM and LED) are presented. We also discuss somealgorithm performance issues and open problems.

A Hybrid Algorithm to Compute Marginal and Joint Beliefs in Bayesian  Networks and Its Complexity

  There exist two general forms of exact algorithms for updating probabilitiesin Bayesian Networks. The first approach involves using a structure, usually aclique tree, and performing local message based calculation to extract thebelief in each variable. The second general class of algorithm involves the useof non-serial dynamic programming techniques to extract the belief in somedesired group of variables. In this paper we present a hybrid algorithm basedon the latter approach yet possessing the ability to retrieve the belief in allsingle variables. The technique is advantageous in that it saves a NP-hardcomputation step over using one algorithm of each type. Furthermore, thistechnique re-enforces a conjecture of Jensen and Jensen [JJ94] in that it stillrequires a single NP-hard step to set up the structure on which inference isperformed, as we show by confirming Li and D'Ambrosio's [LD94] conjecturedNP-hardness of OFP.

On the Detection of Conflicts in Diagnostic Bayesian Networks Using  Abstraction

  An important issue in the use of expert systems is the so-called brittlenessproblem. Expert systems model only a limited part of the world. While theexplicit management of uncertainty in expert systems itigates the brittlenessproblem, it is still possible for a system to be used, unwittingly, in waysthat the system is not prepared to address. Such a situation may be detected bythe method of straw models, first presented by Jensen et al. [1990] and latergeneralized and justified by Laskey [1991]. We describe an algorithm, which wehave implemented, that takes as input an annotated diagnostic Bayesian network(the base model) and constructs, without assistance, a bipartite network to beused as a straw model. We show that in some cases this straw model is betterthat the independent straw model of Jensen et al., the only other straw modelfor which a construction algorithm has been designed and implemented.

Parameter identifiability of discrete Bayesian networks with hidden  variables

  Identifiability of parameters is an essential property for a statisticalmodel to be useful in most settings. However, establishing parameteridentifiability for Bayesian networks with hidden variables remainschallenging. In the context of finite state spaces, we give algebraic argumentsestablishing identifiability of some special models on small DAGs. We alsoestablish that, for fixed state spaces, generic identifiability of parametersdepends only on the Markov equivalence class of the DAG. To illustrate the useof these results, we investigate identifiability for all binary Bayesiannetworks with up to five variables, one of which is hidden and parental to allobservable ones. Surprisingly, some of these models have parameterizations thatare generically 4-to-one, and not 2-to-one as label swapping of the hiddenstates would suggest. This leads to interesting difficulties in interpretingcausal effects.

On a hypergraph probabilistic graphical model

  We propose a directed acyclic hypergraph framework for a probabilisticgraphical model that we call Bayesian hypergraphs. The space of directedacyclic hypergraphs is much larger than the space of chain graphs. HenceBayesian hypergraphs can model much finer factorizations than Bayesian networksor LWF chain graphs and provide simpler and more computationally efficientprocedures for factorizations and interventions. Bayesian hypergraphs alsoallow a modeler to represent causal patterns of interaction such as Noisy-ORgraphically (without additional annotations). We introduce global, local andpairwise Markov properties of Bayesian hypergraphs and prove under whichconditions they are equivalent. We define a projection operator, called shadow,that maps Bayesian hypergraphs to chain graphs, and show that the Markovproperties of a Bayesian hypergraph are equivalent to those of itscorresponding chain graph. We extend the causal interpretation of LWF chaingraphs to Bayesian hypergraphs and provide corresponding formulas and agraphical criterion for intervention.

Transfer Learning for Performance Modeling of Configurable Systems: A  Causal Analysis

  Modern systems (e.g., deep neural networks, big data analytics, andcompilers) are highly configurable, which means they expose differentperformance behavior under different configurations. The fundamental challengeis that one cannot simply measure all configurations due to the sheer size ofthe configuration space. Transfer learning has been used to reduce themeasurement efforts by transferring knowledge about performance behavior ofsystems across environments. Previously, research has shown that statisticalmodels are indeed transferable across environments. In this work, weinvestigate identifiability and transportability of causal effects andstatistical relations in highly-configurable systems. Our causal analysisagrees with previous exploratory analysis \cite{Jamshidi17} and confirms thatthe causal effects of configuration options can be carried over acrossenvironments with high confidence. We expect that the ability to carry overcausal relations will enable effective performance analysis ofhighly-configurable systems.

