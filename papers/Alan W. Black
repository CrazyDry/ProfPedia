Anomalous Fermion Production in Gravitational Collapse

  The Dirac equation is solved in the Einstein-Yang-Mills background found by
Bartnik and McKinnon. We find a normalizable zero-energy fermion mode in the
$s$-wave sector. As shown recently, their solution corresponds to a
gravitational sphaleron which mediates transitions between topologically
distinct vacua. Since the Bartnik-McKinnon solution is unstable, it will either
collapse to form a black hole or radiate away its energy. In either case, as
the Chern-Simons number of the configuration changes, there will be an
accompanying anomalous change in fermion number.


Fermion Quasi-normal modes of the Kerr Black-Hole

  In this paper we study the fermion quasi-normal modes of a 4-dimensional
rotating black-hole using the WKB(J) (to third and sixth order) and the AIM
semi-analytic methods in the massless Dirac fermion sector. These semi-analytic
approximations are computed in a pedagogical manner with comparisons made to
the numerical values of the quasi-normal mode frequencies presented in the
literature. It was found that The WKB(J) method and AIM show good agreement
with direct numerical solutions for low values of the overtone number $n$ and
angular quantum number l.


Data Augmentation for Neural Online Chat Response Selection

  Data augmentation seeks to manipulate the available data for training to
improve the generalization ability of models. We investigate two data
augmentation proxies, permutation and flipping, for neural dialog response
selection task on various models over multiple datasets, including both Chinese
and English languages. Different from standard data augmentation techniques,
our method combines the original and synthesized data for prediction. Empirical
results show that our approach can gain 1 to 3 recall-at-1 points over baseline
models in both full-scale and small-scale settings.


Style Transfer Through Multilingual and Feedback-Based Back-Translation

  Style transfer is the task of transferring an attribute of a sentence (e.g.,
formality) while maintaining its semantic content. The key challenge in style
transfer is to strike a balance between the competing goals, one to preserve
meaning and the other to improve the style transfer accuracy. Prior research
has identified that the task of meaning preservation is generally harder to
attain and evaluate. This paper proposes two extensions of the state-of-the-art
style transfer models aiming at improving the meaning preservation in style
transfer. Our evaluation shows that these extensions help to ground meaning
better while improving the transfer accuracy.


Black is to Criminal as Caucasian is to Police:Detecting and Removing
  Multiclass Bias in Word Embeddings

  Online texts -- across genres, registers, domains, and styles -- are riddled
with human stereotypes, expressed in overt or subtle ways. Word embeddings,
trained on these texts, perpetuate and amplify these stereotypes, and propagate
biases to machine learning models that use word embeddings as features. In this
work, we propose a method to debias word embeddings in multiclass settings such
as race and religion, extending the work of (Bolukbasi et al., 2016) from the
binary setting, such as binary gender. Next, we propose a novel methodology for
the evaluation of multiclass debiasing. We demonstrate that our multiclass
debiasing is robust and maintains the efficacy in standard NLP tasks.


A Deep Learning Approach to Data-driven Parameterizations for
  Statistical Parametric Speech Synthesis

  Nearly all Statistical Parametric Speech Synthesizers today use Mel Cepstral
coefficients as the vocal tract parameterization of the speech signal. Mel
Cepstral coefficients were never intended to work in a parametric speech
synthesis framework, but as yet, there has been little success in creating a
better parameterization that is more suited to synthesis. In this paper, we use
deep learning algorithms to investigate a data-driven parameterization
technique that is designed for the specific requirements of synthesis. We
create an invertible, low-dimensional, noise-robust encoding of the Mel Log
Spectrum by training a tapered Stacked Denoising Autoencoder (SDA). This SDA is
then unwrapped and used as the initialization for a Multi-Layer Perceptron
(MLP). The MLP is fine-tuned by training it to reconstruct the input at the
output layer. This MLP is then split down the middle to form encoding and
decoding networks. These networks produce a parameterization of the Mel Log
Spectrum that is intended to better fulfill the requirements of synthesis.
Results are reported for experiments conducted using this resulting
parameterization with the ClusterGen speech synthesizer.


Character-based Neural Machine Translation

  We introduce a neural machine translation model that views the input and
output sentences as sequences of characters rather than words. Since word-level
information provides a crucial source of bias, our input model composes
representations of character sequences into representations of words (as
determined by whitespace boundaries), and then these are translated using a
joint attention/translation model. In the target language, the translation is
modeled as a sequence of word vectors, but each word is generated one character
at a time, conditional on the previous character generations in each word. As
the representation and generation of words is performed at the character level,
our model is capable of interpreting and generating unseen word forms. A
secondary benefit of this approach is that it alleviates much of the challenges
associated with preprocessing/tokenization of the source and target languages.
We show that our model can achieve translation results that are on par with
conventional word-based models.


Recurrent Neural Network Postfilters for Statistical Parametric Speech
  Synthesis

  In the last two years, there have been numerous papers that have looked into
using Deep Neural Networks to replace the acoustic model in traditional
statistical parametric speech synthesis. However, far less attention has been
paid to approaches like DNN-based postfiltering where DNNs work in conjunction
with traditional acoustic models. In this paper, we investigate the use of
Recurrent Neural Networks as a potential postfilter for synthesis. We explore
the possibility of replacing existing postfilters, as well as highlight the
ease with which arbitrary new features can be added as input to the postfilter.
We also tried a novel approach of jointly training the Classification And
Regression Tree and the postfilter, rather than the traditional approach of
training them independently.


Finding Function in Form: Compositional Character Models for Open
  Vocabulary Word Representation

  We introduce a model for constructing vector representations of words by
composing characters using bidirectional LSTMs. Relative to traditional word
representation models that have independent vectors for each word type, our
model requires only a single vector per character type and a fixed set of
parameters for the compositional model. Despite the compactness of this model
and, more importantly, the arbitrary nature of the form-function relationship
in language, our "composed" word representations yield state-of-the-art results
in language modeling and part-of-speech tagging. Benefits over traditional
baselines are particularly pronounced in morphologically rich languages (e.g.,
Turkish).


Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic
  Representation Learning

  We introduce polyglot language models, recurrent neural network models
trained to predict symbol sequences in many different languages using shared
representations of symbols and conditioning on typological information about
the language to be predicted. We apply these to the problem of modeling phone
sequences---a domain in which universal symbol inventories and
cross-linguistically shared feature representations are a natural fit.
Intrinsic evaluation on held-out perplexity, qualitative analysis of the
learned representations, and extrinsic evaluation in two downstream
applications that make use of phonetic features show (i) that polyglot models
better generalize to held-out data than comparable monolingual models and (ii)
that polyglot phonetic feature representations are of higher quality than those
learned monolingually.


Learning Conversational Systems that Interleave Task and Non-Task
  Content

  Task-oriented dialog systems have been applied in various tasks, such as
automated personal assistants, customer service providers and tutors. These
systems work well when users have clear and explicit intentions that are
well-aligned to the systems' capabilities. However, they fail if users
intentions are not explicit. To address this shortcoming, we propose a
framework to interleave non-task content (i.e. everyday social conversation)
into task conversations. When the task content fails, the system can still keep
the user engaged with the non-task content. We trained a policy using
reinforcement learning algorithms to promote long-turn conversation coherence
and consistency, so that the system can have smooth transitions between task
and non-task content. To test the effectiveness of the proposed framework, we
developed a movie promotion dialog system. Experiments with human users
indicate that a system that interleaves social and task content achieves a
better task success rate and is also rated as more engaging compared to a pure
task-oriented system.


Linguistic Markers of Influence in Informal Interactions

  There has been a long standing interest in understanding `Social Influence'
both in Social Sciences and in Computational Linguistics. In this paper, we
present a novel approach to study and measure interpersonal influence in daily
interactions. Motivated by the basic principles of influence, we attempt to
identify indicative linguistic features of the posts in an online knitting
community. We present the scheme used to operationalize and label the posts
with indicator features. Experiments with the identified features show an
improvement in the classification accuracy of influence by 3.15%. Our results
illustrate the important correlation between the characteristics of the
language and its potential to influence others.


Style Transfer Through Back-Translation

  Style transfer is the task of rephrasing the text to contain specific
stylistic properties without changing the intent or affect within the context.
This paper introduces a new method for automatic style transfer. We first learn
a latent representation of the input sentence which is grounded in a language
translation model in order to better preserve the meaning of the sentence while
reducing stylistic properties. Then adversarial generation techniques are used
to make the output match the desired style. We evaluate this technique on three
different style transformations: sentiment, gender and political slant.
Compared to two state-of-the-art style transfer modeling techniques we show
improvements both in automatic evaluation of style transfer and in manual
evaluation of meaning preservation and fluency.


Generating Mandarin and Cantonese F0 Contours with Decision Trees and
  BLSTMs

  This paper models the fundamental frequency contours on both Mandarin and
Cantonese speech with decision trees and DNNs (deep neural networks). Different
kinds of f0 representations and model architectures are tested for decision
trees and DNNs. A new model called Additive-BLSTM (additive bidirectional long
short term memory) that predicts a base f0 contour and a residual f0 contour
with two BLSTMs is proposed. With respect to objective measures of RMSE and
correlation, applying tone-dependent trees together with sample normalization
and delta feature regularization within decision tree framework performs best.
While the new Additive-BLSTM model with delta feature regularization performs
even better. Subjective listening tests on both Mandarin and Cantonese
comparing Random Forest model (multiple decision trees) and the Additive-BLSTM
model were also held and confirmed the advantage of the new model according to
the listeners' preference.


Domain Robust Feature Extraction for Rapid Low Resource ASR Development

  Developing a practical speech recognizer for a low resource language is
challenging, not only because of the (potentially unknown) properties of the
language, but also because test data may not be from the same domain as the
available training data. In this paper, we focus on the latter challenge, i.e.
domain mismatch, for systems trained using a sequence-based criterion. We
demonstrate the effectiveness of using a pre-trained English recognizer, which
is robust to such mismatched conditions, as a domain normalizing feature
extractor on a low resource language. In our example, we use Turkish
Conversational Speech and Broadcast News data. This enables rapid development
of speech recognizers for new languages which can easily adapt to any domain.
Testing in various cross-domain scenarios, we achieve relative improvements of
around 25% in phoneme error rate, with improvements being around 50% for some
domains.


A Dataset for Document Grounded Conversations

  This paper introduces a document grounded dataset for text conversations. We
define "Document Grounded Conversations" as conversations that are about the
contents of a specified document. In this dataset the specified documents were
Wikipedia articles about popular movies. The dataset contains 4112
conversations with an average of 21.43 turns per conversation. This positions
this dataset to not only provide a relevant chat history while generating
responses but also provide a source of information that the models could use.
We describe two neural architectures that provide benchmark performance on the
task of generating the next response. We also evaluate our models for
engagement and fluency, and find that the information from the document helps
in generating more engaging and fluent responses.


Multimodal Polynomial Fusion for Detecting Driver Distraction

  Distracted driving is deadly, claiming 3,477 lives in the U.S. in 2015 alone.
Although there has been a considerable amount of research on modeling the
distracted behavior of drivers under various conditions, accurate automatic
detection using multiple modalities and especially the contribution of using
the speech modality to improve accuracy has received little attention. This
paper introduces a new multimodal dataset for distracted driving behavior and
discusses automatic distraction detection using features from three modalities:
facial expression, speech and car signals. Detailed multimodal feature analysis
shows that adding more modalities monotonically increases the predictive
accuracy of the model. Finally, a simple and effective multimodal fusion
technique using a polynomial fusion layer shows superior distraction detection
results compared to the baseline SVM and neural network models.


The Second Conversational Intelligence Challenge (ConvAI2)

  We describe the setting and results of the ConvAI2 NeurIPS competition that
aims to further the state-of-the-art in open-domain chatbots. Some key
takeaways from the competition are: (i) pretrained Transformer variants are
currently the best performing models on this task, (ii) but to improve
performance on multi-turn conversations with humans, future systems must go
beyond single word metrics like perplexity to measure the performance across
sequences of utterances (conversations) -- in terms of repetition, consistency
and balance of dialogue acts (e.g. how many questions asked vs. answered).


Phoneme Level Language Models for Sequence Based Low Resource ASR

  Building multilingual and crosslingual models help bring different languages
together in a language universal space. It allows models to share parameters
and transfer knowledge across languages, enabling faster and better adaptation
to a new language. These approaches are particularly useful for low resource
languages. In this paper, we propose a phoneme-level language model that can be
used multilingually and for crosslingual adaptation to a target language. We
show that our model performs almost as well as the monolingual models by using
six times fewer parameters, and is capable of better adaptation to languages
not seen during training in a low resource scenario. We show that these
phoneme-level language models can be used to decode sequence based
Connectionist Temporal Classification (CTC) acoustic model outputs to obtain
comparable word error rates with Weighted Finite State Transducer (WFST) based
decoding in Babel languages. We also show that these phoneme-level language
models outperform WFST decoding in various low-resource conditions like
adapting to a new language and domain mismatch between training and testing
data.


The ARIEL-CMU Systems for LoReHLT18

  This paper describes the ARIEL-CMU submissions to the Low Resource Human
Language Technologies (LoReHLT) 2018 evaluations for the tasks Machine
Translation (MT), Entity Discovery and Linking (EDL), and detection of
Situation Frames in Text and Speech (SF Text and Speech).


A Survey of Code-switched Speech and Language Processing

  Code-switching, the alternation of languages within a conversation or
utterance, is a common communicative phenomenon that occurs in multilingual
communities across the world. This survey reviews computational approaches for
code-switched Speech and Natural Language Processing. We motivate why
processing code-switched text and speech is essential for building intelligent
agents and systems that interact with users in multilingual communities. As
code-switching data and resources are scarce, we list what is available in
various code-switched language pairs with the language processing tasks they
can be used for. We review code-switching research in various Speech and NLP
applications, including language processing tools and end-to-end systems. We
conclude with future directions and open problems in the field.


A concise overview of the Maunakea Spectroscopic Explorer

  This short document is intended as a companion and introduction to the
Detailed Science Case (DSC) for the Maunakea Spectroscopic Explorer. It
provides a concise summary of the essential characteristics of MSE from the
perspective of the international astronomical community. MSE is a wide field
telescope (1.5 square degree field of view) with an aperture of 11.25m. It is
dedicated to multi-object spectroscopy at several different spectral
resolutions in the range R ~ 2500 - 40000 over a broad wavelength range (0.36 -
1.8{\mu}m). MSE will enable transformational science in areas as diverse as
exoplanetary host characterization; stellar monitoring campaigns; tomographic
mapping of the interstellar and intergalactic media; the in-situ chemical
tagging of the distant Galaxy; connecting galaxies to the large scale structure
of the Universe; measuring the mass functions of cold dark matter sub-halos in
galaxy and cluster-scale hosts; reverberation mapping of supermassive black
holes in quasars. MSE is the largest ground based optical and near infrared
telescope in its class, and it will occupy a unique and critical role in the
emerging network of astronomical facilities active in the 2020s. MSE is an
essential follow-up facility to current and next generations of
multi-wavelength imaging surveys, including LSST, Gaia, Euclid, eROSITA, SKA,
and WFIRST, and is an ideal feeder facility for E-ELT, TMT and GMT.


Detection of Galactic Center source G2 at 3.8 $μ$m during periapse
  passage

  We report new observations of the Galactic Center source G2 from the W. M.
Keck Observatory. G2 is a dusty red object associated with gas that shows tidal
interactions as it nears closest approach with the Galaxy's central black hole.
Our observations, conducted as G2 passed through periapse, were designed to
test the proposal that G2 is a 3 earth mass gas cloud. Such a cloud should be
tidally disrupted during periapse passage. The data were obtained using the
Keck II laser guide star adaptive optics system (LGSAO) and the facility
near-infrared camera (NIRC2) through the K' [2.1 $\mu$m] and L' [3.8 $\mu$m]
broadband filters. Several results emerge from these observations: 1) G2 has
survived its closest approach to the black hole as a compact, unresolved source
at L'; 2) G2's L' brightness measurements are consistent with those over the
last decade; 3) G2's motion continues to be consistent with a Keplerian model.
These results rule out G2 as a pure gas cloud and imply that G2 has a central
star. This star has a luminosity of $\sim$30 $L_{\odot} $ and is surrounded by
a large ($\sim$2.6 AU) optically thick dust shell. The differences between the
L' and Br-$\gamma$ observations can be understood with a model in which L' and
Br-$\gamma$ emission arises primarily from internal and external heating,
respectively. We suggest that G2 is a binary star merger product and will
ultimately appear similar to the B-stars that are tightly clustered around the
black hole (the so-called S-star cluster).


Dark-ages Reionization and Galaxy Formation Simulation - X. The small
  contribution of quasars to reionization

  Motivated by recent measurements of the number density of faint AGN at high
redshift, we investigate the contribution of quasars to reionization by
tracking the growth of central supermassive black holes in an update of the
Meraxes semi-analytic model. The model is calibrated against the observed
stellar mass function at $z\sim0.6-7$, the black hole mass function at
$z\lesssim0.5$, the global ionizing emissivity at $z\sim2-5$ and the Thomson
scattering optical depth. The model reproduces a Magorrian relation in
agreement with observations at $z<0.5$ and predicts a decreasing black hole
mass towards higher redshifts at fixed total stellar mass. With the
implementation of an opening angle of 80 deg for quasar radiation,
corresponding to an observable fraction of ${\sim}23.4$ per cent due to
obscuration by dust, the model is able to reproduce the observed quasar
luminosity function at $z\sim0.6-6$. The stellar light from galaxies hosting
faint AGN contributes a significant or dominant fraction of the UV flux. At
high redshift, the model is consistent with the bright end quasar luminosity
function and suggests that the recent faint $z\sim4$ AGN sample compiled by
Giallongo et al. (2015) includes a significant fraction of stellar light.
Direct application of this luminosity function to the calculation of AGN
ionizing emissivity consequently overestimates the number of ionizing photons
produced by quasars by a factor of 3 at $z\sim6$. We conclude that quasars are
unlikely to make a significant contribution to reionization.


Characterizing X-ray and Radio emission in the Black Hole X-Ray Binary
  V404 Cygni during Quiescence

  We present results from multi-wavelength simultaneous X-ray and radio
observations of the black hole X-ray binary V404 Cyg in quiescence. Our
coverage with NuSTAR provides the very first opportunity to study the X-ray
spectrum of V404 Cyg at energies above 10 keV. The unabsorbed broad-band
(0.3--30 keV) quiescent luminosity of the source is 8.9$\times$10$^{32}$ erg
s$^{-1}$ for a distance of 2.4 kpc. The source shows clear variability on short
time scales (an hour to a couple of hours) in radio, soft X-ray and hard X-ray
bands in the form of multiple flares. The broad-band X-ray spectra obtained
from XMM-Newton and NuSTAR can be characterized with a power-law model having
photon index $\Gamma$=2.12$\pm$0.07 (90\% confidence errors); however,
residuals at high energies indicate spectral curvature significant at a
3$\sigma$ confidence level with e-folding energy of the cutoff to be
20$^{+20}_{-7}$ keV. Such curvature can be explained using synchrotron emission
from the base of a jet outflow. Radio observations using the VLA reveal that
the spectral index evolves on very fast time-scales (as short as 10 min.),
switching between optically thick and thin synchrotron emission, possibly due
to instabilities in the compact jet or stochastic instabilities in accretion
rate. We explore different scenarios to explain this very fast variability.


Sequence-based Multi-lingual Low Resource Speech Recognition

  Techniques for multi-lingual and cross-lingual speech recognition can help in
low resource scenarios, to bootstrap systems and enable analysis of new
languages and domains. End-to-end approaches, in particular sequence-based
techniques, are attractive because of their simplicity and elegance. While it
is possible to integrate traditional multi-lingual bottleneck feature
extractors as front-ends, we show that end-to-end multi-lingual training of
sequence models is effective on context independent models trained using
Connectionist Temporal Classification (CTC) loss. We show that our model
improves performance on Babel languages by over 6% absolute in terms of
word/phoneme error rate when compared to mono-lingual systems built in the same
setting for these languages. We also show that the trained model can be adapted
cross-lingually to an unseen language using just 25% of the target data. We
show that training on multiple languages is important for very low resource
cross-lingual target scenarios, but not for multi-lingual testing scenarios.
Here, it appears beneficial to include large well prepared datasets.


Connection between the Accretion Disk and Jet in the Radio Galaxy 3C 111

  We present the results of extensive multi-frequency monitoring of the radio
galaxy 3C 111 between 2004 and 2010 at X-ray (2.4--10 keV), optical (R band),
and radio (14.5, 37, and 230 GHz) wave bands, as well as multi-epoch imaging
with the Very Long Baseline Array (VLBA) at 43 GHz. Over the six years of
observation, significant dips in the X-ray light curve are followed by
ejections of bright superluminal knots in the VLBA images. This shows a clear
connection between the radiative state near the black hole, where the X-rays
are produced, and events in the jet. The X-ray continuum flux and Fe line
intensity are strongly correlated, with a time lag shorter than 90 days and
consistent with zero. This implies that the Fe line is generated within 90
light-days of the source of the X-ray continuum. The power spectral density
function of X-ray variations contains a break, with steeper slope at shorter
timescales. The break timescale of 13 (+12,-6) days is commensurate with
scaling according to the mass of the central black hole based on observations
of Seyfert galaxies and black hole X-ray binaries (BHXRBs). The data are
consistent with the standard paradigm, in which the X-rays are predominantly
produced by inverse Compton scattering of thermal optical/UV seed photons from
the accretion disk by a distribution of hot electrons --- the corona ---
situated near the disk. Most of the optical emission is generated in the
accretion disk due to reprocessing of the X-ray emission. The relationships
that we have uncovered between the accretion disk and the jet in 3C 111, as
well as in the FR I radio galaxy 3C 120 in a previous paper, support the
paradigm that active galactic nuclei and Galactic BHXRBs are fundamentally
similar, with characteristic time and size scales proportional to the mass of
the central black hole


Disk-Jet Connection in the Radio Galaxy 3C 120

  We present the results of extensive multi-frequency monitoring of the radio
galaxy 3C 120 between 2002 and 2007 at X-ray, optical, and radio wave bands, as
well as imaging with the Very Long Baseline Array (VLBA). Over the 5 yr of
observation, significant dips in the X-ray light curve are followed by
ejections of bright superluminal knots in the VLBA images. Consistent with
this, the X-ray flux and 37 GHz flux are anti-correlated with X-ray leading the
radio variations. This implies that, in this radio galaxy, the radiative state
of accretion disk plus corona system, where the X-rays are produced, has a
direct effect on the events in the jet, where the radio emission originates.
The X-ray power spectral density of 3C 120 shows a break, with steeper slope at
shorter timescale and the break timescale is commensurate with the mass of the
central black hole based on observations of Seyfert galaxies and black hole
X-ray binaries. These findings provide support for the paradigm that black hole
X-ray binaries and active galactic nuclei are fundamentally similar systems,
with characteristic time and size scales linearly proportional to the mass of
the central black hole. The X-ray and optical variations are strongly
correlated in 3C 120, which implies that the optical emission in this object
arises from the same general region as the X-rays, i.e., in the accretion
disk-corona system. We numerically model multi-wavelength light curves of 3C
120 from such a system with the optical-UV emission produced in the disk and
the X-rays generated by scattering of thermal photons by hot electrons in the
corona. From the comparison of the temporal properties of the model light
curves to that of the observed variability, we constrain the physical size of
the corona and the distances of the emitting regions from the central BH.


The 1.4 mm core of Centaurus A: First VLBI results with the South Pole
  Telescope

  Centaurus A (Cen A) is a bright radio source associated with the nearby
galaxy NGC 5128 where high-resolution radio observations can probe the jet at
scales of less than a light-day. The South Pole Telescope (SPT) and the Atacama
Pathfinder Experiment (APEX) performed a single-baseline very-long-baseline
interferometry (VLBI) observation of Cen A in January 2015 as part of VLBI
receiver deployment for the SPT. We measure the correlated flux density of Cen
A at a wavelength of 1.4 mm on a $\sim$7000 km (5 G$\lambda$) baseline.
Ascribing this correlated flux density to the core, and with the use of a
contemporaneous short-baseline flux density from a Submillimeter Array
observation, we infer a core brightness temperature of $1.4 \times 10^{11}$ K.
This is close to the equipartition brightness temperature, where the magnetic
and relativistic particle energy densities are equal. Under the assumption of a
circular Gaussian core component, we derive an upper limit to the core size
$\phi = 34.0 \pm 1.8~\mu\textrm{as}$, corresponding to 120 Schwarzschild radii
for a black hole mass of $5.5 \times 10^7 M_{\odot}$.


The Fast, Luminous Ultraviolet Transient AT2018cow: Extreme Supernova,
  or Disruption of a Star by an Intermediate-Mass Black Hole?

  Wide-field optical surveys have begun to uncover large samples of fast
(t_rise < 5d), luminous (M_peak < -18), blue transients. While commonly
attributed to the breakout of a supernova shock into a dense wind, the great
distances to the transients of this class found so far have hampered detailed
investigation of their properties. We present photometry and spectroscopy from
a comprehensive worldwide campaign to observe AT2018cow (ATLAS18qqn), the first
fast-luminous optical transient to be found in real time at low redshift. Our
first spectra (<2 days after discovery) are entirely featureless. A very broad
absorption feature suggestive of near-relativistic velocities develops between
3-8 days, then disappears. Broad emission features of H and He develop after
>10 days. The spectrum remains extremely hot throughout its evolution, and the
photospheric radius contracts with time (receding below R<10^14 cm after 1
month). This behaviour does not match that of any known supernova, although a
relativistic jet within a fallback supernova could explain some of the observed
features. Alternatively, the transient could originate from the disruption of a
star by an intermediate-mass black hole, although this would require
long-lasting emission of highly super-Eddington thermal radiation. In either
case, AT2018cow suggests that the population of fast luminous transients
represents a new class of astrophysical event. Intensive follow-up of this
event in its late phases, and of any future events found at comparable
distance, will be essential to better constrain their origins.


Catching Element Formation In The Act

  Gamma-ray astronomy explores the most energetic photons in nature to address
some of the most pressing puzzles in contemporary astrophysics. It encompasses
a wide range of objects and phenomena: stars, supernovae, novae, neutron stars,
stellar-mass black holes, nucleosynthesis, the interstellar medium, cosmic rays
and relativistic-particle acceleration, and the evolution of galaxies. MeV
gamma-rays provide a unique probe of nuclear processes in astronomy, directly
measuring radioactive decay, nuclear de-excitation, and positron annihilation.
The substantial information carried by gamma-ray photons allows us to see
deeper into these objects, the bulk of the power is often emitted at gamma-ray
energies, and radioactivity provides a natural physical clock that adds unique
information. New science will be driven by time-domain population studies at
gamma-ray energies. This science is enabled by next-generation gamma-ray
instruments with one to two orders of magnitude better sensitivity, larger sky
coverage, and faster cadence than all previous gamma-ray instruments. This
transformative capability permits: (a) the accurate identification of the
gamma-ray emitting objects and correlations with observations taken at other
wavelengths and with other messengers; (b) construction of new gamma-ray maps
of the Milky Way and other nearby galaxies where extended regions are
distinguished from point sources; and (c) considerable serendipitous science of
scarce events -- nearby neutron star mergers, for example. Advances in
technology push the performance of new gamma-ray instruments to address a wide
set of astrophysical questions.


