A Risk Comparison of Ordinary Least Squares vs Ridge Regression

  We compare the risk of ridge regression to a simple variant of ordinary least
squares, in which one simply projects the data onto a finite dimensional
subspace (as specified by a Principal Component Analysis) and then performs an
ordinary (un-regularized) least squares regression in this subspace. This note
shows that the risk of this ordinary least squares method is within a constant
factor (namely 4) of the risk of ridge regression.


The Remarkable Benefit of User-Level Aggregation for Lexical-based
  Population-Level Predictions

  Nowcasting based on social media text promises to provide unobtrusive and
near real-time predictions of community-level outcomes. These outcomes are
typically regarding people, but the data is often aggregated without regard to
users in the Twitter populations of each community. This paper describes a
simple yet effective method for building community-level models using Twitter
language aggregated by user. Results on four different U.S. county-level tasks,
spanning demographic, health, and psychological outcomes show large and
consistent improvements in prediction accuracies (e.g. from Pearson r=.73 to
.82 for median income prediction or r=.37 to .47 for life satisfaction
prediction) over the standard approach of aggregating all tweets. We make our
aggregated and anonymized community-level data, derived from 37 billion tweets
-- over 1 billion of which were mapped to counties, available for research.


Probability aggregation in time-series: Dynamic hierarchical modeling of
  sparse expert beliefs

  Most subjective probability aggregation procedures use a single probability
judgment from each expert, even though it is common for experts studying real
problems to update their probability estimates over time. This paper advances
into unexplored areas of probability aggregation by considering a dynamic
context in which experts can update their beliefs at random intervals. The
updates occur very infrequently, resulting in a sparse data set that cannot be
modeled by standard time-series procedures. In response to the lack of
appropriate methodology, this paper presents a hierarchical model that takes
into account the expert's level of self-reported expertise and produces
aggregate probabilities that are sharp and well calibrated both in- and
out-of-sample. The model is demonstrated on a real-world data set that includes
over 2300 experts making multiple probability forecasts over two years on
different subsets of 166 international political events.


Spectral dimensionality reduction for HMMs

  Hidden Markov Models (HMMs) can be accurately approximated using
co-occurrence frequencies of pairs and triples of observations by using a fast
spectral method in contrast to the usual slow methods like EM or Gibbs
sampling. We provide a new spectral method which significantly reduces the
number of model parameters that need to be estimated, and generates a sample
complexity that does not depend on the size of the observation vocabulary. We
present an elementary proof giving bounds on the relative accuracy of
probability estimates from our model. (Correlaries show our bounds can be
weakened to provide either L1 bounds or KL bounds which provide easier direct
comparisons to previous work.) Our theorem uses conditions that are checkable
from the data, instead of putting conditions on the unobservable Markov
transition matrix.


Probabilistic Models for Unified Collaborative and Content-Based
  Recommendation in Sparse-Data Environments

  Recommender systems leverage product and community information to target
products to consumers. Researchers have developed collaborative recommenders,
content-based recommenders, and (largely ad-hoc) hybrid systems. We propose a
unified probabilistic framework for merging collaborative and content-based
recommendations. We extend Hofmann's [1999] aspect model to incorporate
three-way co-occurrence data among users, items, and item content. The relative
influence of collaboration data versus content data is not imposed as an
exogenous parameter, but rather emerges naturally from the given data sources.
Global probabilistic models coupled with standard Expectation Maximization (EM)
learning algorithms tend to drastically overfit in sparse-data situations, as
is typical in recommendation applications. We show that secondary content
information can often be used to overcome sparsity. Experiments on data from
the ResearchIndex library of Computer Science publications show that
appropriate mixture models incorporating secondary data produce significantly
better quality recommenders than k-nearest neighbors (k-NN). Global
probabilistic models also allow more general inferences than local methods like
k-NN.


Partial Information Framework: Model-Based Aggregation of Estimates from
  Diverse Information Sources

  Prediction polling is an increasingly popular form of crowdsourcing in which
multiple participants estimate the probability or magnitude of some future
event. These estimates are then aggregated into a single forecast.
Historically, randomness in scientific estimation has been generally assumed to
arise from unmeasured factors which are viewed as measurement noise. However,
when combining subjective estimates, heterogeneity stemming from differences in
the participants' information is often more important than measurement noise.
This paper formalizes information diversity as an alternative source of such
heterogeneity and introduces a novel modeling framework that is particularly
well-suited for prediction polls. A practical specification of this framework
is proposed and applied to the task of aggregating probability and point
estimates from two real-world prediction polls. In both cases our model
outperforms standard measurement-error-based aggregators, hence providing
evidence in favor of information diversity being the more important source of
heterogeneity.


Modeling Probability Forecasts via Information Diversity

  Randomness in scientific estimation is generally assumed to arise from
unmeasured or uncontrolled factors. However, when combining subjective
probability estimates, heterogeneity stemming from people's cognitive or
information diversity is often more important than measurement noise. This
paper presents a novel framework that models the heterogeneity arising from
experts that use partially overlapping information sources, and applies that
model to the task of aggregating the probabilities given by a group of experts
who forecast whether an event will occur or not. Our model describes the
distribution of information across experts in terms of easily interpretable
parameters and shows how the optimal amount of extremizing of the average
probability forecast (shifting it closer to its nearest extreme) varies as a
function of the experts' information overlap. Our model thus gives a more
principled understanding of the historically ad hoc practice of extremizing
average forecasts.


A Risk Ratio Comparison of $l_0$ and $l_1$ Penalized Regression

  There has been an explosion of interest in using $l_1$-regularization in
place of $l_0$-regularization for feature selection. We present theoretical
results showing that while $l_1$-penalized linear regression never outperforms
$l_0$-regularization by more than a constant factor, in some cases using an
$l_1$ penalty is infinitely worse than using an $l_0$ penalty. We also show
that the "optimal" $l_1$ solutions are often inferior to $l_0$ solutions found
using stepwise regression.
  We also compare algorithms for solving these two problems and show that
although solutions can be found efficiently for the $l_1$ problem, the
"optimal" $l_1$ solutions are often inferior to $l_0$ solutions found using
greedy classic stepwise regression. Furthermore, we show that solutions
obtained by solving the convex $l_1$ problem can be improved by selecting the
best of the $l_1$ models (for different regularization penalties) by using an
$l_0$ criterion. In other words, an approximate solution to the right problem
can be better than the exact solution to the wrong problem.


Latent Human Traits in the Language of Social Media: An Open-Vocabulary
  Approach

  Over the past century, personality theory and research has successfully
identified core sets of characteristics that consistently describe and explain
fundamental differences in the way people think, feel and behave. Such
characteristics were derived through theory, dictionary analyses, and survey
research using explicit self-reports. The availability of social media data
spanning millions of users now makes it possible to automatically derive
characteristics from language use -- at large scale. Taking advantage of
linguistic information available through Facebook, we study the process of
inferring a new set of potential human traits based on unprompted language use.
We subject these new traits to a comprehensive set of evaluations and compare
them with a popular five factor model of personality. We find that our
language-based trait construct is often more generalizable in that it often
predicts non-questionnaire-based outcomes better than questionnaire-based
traits (e.g. entities someone likes, income and intelligence quotient), while
the factors remain nearly as stable as traditional factors. Our approach
suggests a value in new constructs of personality derived from everyday human
language use.


Tree-Structured Boosting: Connections Between Gradient Boosted Stumps
  and Full Decision Trees

  Additive models, such as produced by gradient boosting, and full interaction
models, such as classification and regression trees (CART), are widely used
algorithms that have been investigated largely in isolation. We show that these
models exist along a spectrum, revealing never-before-known connections between
these two approaches. This paper introduces a novel technique called
tree-structured boosting for creating a single decision tree, and shows that
this method can produce models equivalent to CART or gradient boosted stumps at
the extremes by varying a single parameter. Although tree-structured boosting
is designed primarily to provide both the model interpretability and predictive
performance needed for high-stake applications like medicine, it also can
produce decision trees represented by hybrid models between CART and boosted
stumps that can outperform either of these approaches.


Learning Neural Emotion Analysis from 100 Observations: The Surprising
  Effectiveness of Pre-Trained Word Representations

  Deep Learning has drastically reshaped virtually all areas of NLP. Yet on the
downside, it is commonly thought to be dependent on vast amounts of training
data. As such, these techniques appear ill-suited for areas where annotated
data is limited, like emotion analysis, with its many nuanced and
hard-to-acquire annotation formats, or other low-data scenarios encountered in
under-resourced languages. In contrast to this popular notion, we provide
empirical evidence from three typologically diverse languages that today's
favorite neural architectures can be trained on a few hundred observations
only. Our results suggest that high-quality, pre-trained word embeddings are
crucial for achieving high performance despite such strong data limitations.


Studying Cultural Differences in Emoji Usage across the East and the
  West

  Global acceptance of Emojis suggests a cross-cultural, normative use of
Emojis. Meanwhile, nuances in Emoji use across cultures may also exist due to
linguistic differences in expressing emotions and diversity in conceptualizing
topics. Indeed, literature in cross-cultural psychology has found both
normative and culture-specific ways in which emotions are expressed. In this
paper, using social media, we compare the Emoji usage based on frequency,
context, and topic associations across countries in the East (China and Japan)
and the West (United States, United Kingdom, and Canada). Across the East and
the West, our study examines a) similarities and differences on the usage of
different categories of Emojis such as People, Food \& Drink, Travel \& Places
etc., b) potential mapping of Emoji use differences with previously identified
cultural differences in users' expression about diverse concepts such as death,
money emotions and family, and c) relative correspondence of validated
psycho-linguistic categories with Ekman's emotions. The analysis of Emoji use
in the East and the West reveals recognizable normative and culture specific
patterns. This research reveals the ways in which Emojis can be used for
cross-cultural communication.


What Twitter Profile and Posted Images Reveal About Depression and
  Anxiety

  Previous work has found strong links between the choice of social media
images and users' emotions, demographics and personality traits. In this study,
we examine which attributes of profile and posted images are associated with
depression and anxiety of Twitter users. We used a sample of 28,749 Facebook
users to build a language prediction model of survey-reported depression and
anxiety, and validated it on Twitter on a sample of 887 users who had taken
anxiety and depression surveys. We then applied it to a different set of 4,132
Twitter users to impute language-based depression and anxiety labels, and
extracted interpretable features of posted and profile pictures to uncover the
associations with users' depression and anxiety, controlling for demographics.
For depression, we find that profile pictures suppress positive emotions rather
than display more negative emotions, likely because of social media
self-presentation biases. They also tend to show the single face of the user
(rather than show her in groups of friends), marking increased focus on the
self, emblematic for depression. Posted images are dominated by grayscale and
low aesthetic cohesion across a variety of image features. Profile images of
anxious users are similarly marked by grayscale and low aesthetic cohesion, but
less so than those of depressed users. Finally, we show that image features can
be used to predict depression and anxiety, and that multitask learning that
includes a joint modeling of demographics improves prediction performance.
Overall, we find that the image attributes that mark depression and anxiety
offer a rich lens into these conditions largely congruent with the
psychological literature, and that images on Twitter allow inferences about the
mental health status of users.


