Stacked Approximated Regression Machine: A Simple Deep Learning Approach

  With the agreement of my coauthors, I Zhangyang Wang would like to withdraw
the manuscript "Stacked Approximated Regression Machine: A Simple Deep Learning
Approach". Some experimental procedures were not included in the manuscript,
which makes a part of important claims not meaningful. In the relevant
research, I was solely responsible for carrying out the experiments; the other
coauthors joined in the discussions leading to the main algorithm.
  Please see the updated text for more details.


Decentralized Recommender Systems

  This paper proposes a decentralized recommender system by formulating the
popular collaborative filleting (CF) model into a decentralized matrix
completion form over a set of users. In such a way, data storages and
computations are fully distributed. Each user could exchange limited
information with its local neighborhood, and thus it avoids the centralized
fusion. Advantages of the proposed system include a protection on user privacy,
as well as better scalability and robustness. We compare our proposed algorithm
with several state-of-the-art algorithms on the FlickerUserFavor dataset, and
demonstrate that the decentralized algorithm can gain a competitive performance
to others.


Designing A Composite Dictionary Adaptively From Joint Examples

  We study the complementary behaviors of external and internal examples in
image restoration, and are motivated to formulate a composite dictionary design
framework. The composite dictionary consists of the global part learned from
external examples, and the sample-specific part learned from internal examples.
The dictionary atoms in both parts are further adaptively weighted to emphasize
their model statistics. Experiments demonstrate that the joint utilization of
external and internal examples leads to substantial improvements, with
successful applications in image denoising and super resolution.


Self-Tuned Deep Super Resolution

  Deep learning has been successfully applied to image super resolution (SR).
In this paper, we propose a deep joint super resolution (DJSR) model to exploit
both external and self similarities for SR. A Stacked Denoising Convolutional
Auto Encoder (SDCAE) is first pre-trained on external examples with proper data
augmentations. It is then fine-tuned with multi-scale self examples from each
input, where the reliability of self examples is explicitly taken into account.
We also enhance the model performance by sub-model training and selection. The
DJSR model is extensively evaluated and compared with state-of-the-arts, and
show noticeable performance improvements both quantitatively and perceptually
on a wide range of images.


Learning Super-Resolution Jointly from External and Internal Examples

  Single image super-resolution (SR) aims to estimate a high-resolution (HR)
image from a lowresolution (LR) input. Image priors are commonly learned to
regularize the otherwise seriously ill-posed SR problem, either using external
LR-HR pairs or internal similar patterns. We propose joint SR to adaptively
combine the advantages of both external and internal SR methods. We define two
loss functions using sparse coding based external examples, and epitomic
matching based on internal examples, as well as a corresponding adaptive weight
to automatically balance their contributions according to their reconstruction
errors. Extensive SR results demonstrate the effectiveness of the proposed
method over the existing state-of-the-art methods, and is also verified by our
subjective evaluation study.


Learning A Task-Specific Deep Architecture For Clustering

  While sparse coding-based clustering methods have shown to be successful,
their bottlenecks in both efficiency and scalability limit the practical usage.
In recent years, deep learning has been proved to be a highly effective,
efficient and scalable feature learning tool. In this paper, we propose to
emulate the sparse coding-based clustering pipeline in the context of deep
learning, leading to a carefully crafted deep model benefiting from both. A
feed-forward network structure, named TAGnet, is constructed based on a
graph-regularized sparse coding algorithm. It is then trained with
task-specific loss functions from end to end. We discover that connecting deep
learning to sparse coding benefits not only the model performance, but also its
initialization and interpretation. Moreover, by introducing auxiliary
clustering tasks to the intermediate feature hierarchy, we formulate DTAGnet
and obtain a further performance boost. Extensive experiments demonstrate that
the proposed model gains remarkable margins over several state-of-the-art
methods.


Real-World Font Recognition Using Deep Network and Domain Adaptation

  We address a challenging fine-grain classification problem: recognizing a
font style from an image of text. In this task, it is very easy to generate
lots of rendered font examples but very hard to obtain real-world labeled
images. This real-to-synthetic domain gap caused poor generalization to new
real data in previous methods (Chen et al. (2014)). In this paper, we refer to
Convolutional Neural Networks, and use an adaptation technique based on a
Stacked Convolutional Auto-Encoder that exploits unlabeled real-world images
combined with synthetic data. The proposed method achieves an accuracy of
higher than 80% (top-5) on a real-world dataset.


$\mathbf{D^3}$: Deep Dual-Domain Based Fast Restoration of
  JPEG-Compressed Images

  In this paper, we design a Deep Dual-Domain ($\mathbf{D^3}$) based fast
restoration model to remove artifacts of JPEG compressed images. It leverages
the large learning capacity of deep networks, as well as the problem-specific
expertise that was hardly incorporated in the past design of deep
architectures. For the latter, we take into consideration both the prior
knowledge of the JPEG compression scheme, and the successful practice of the
sparsity-based dual-domain approach. We further design the One-Step Sparse
Inference (1-SI) module, as an efficient and light-weighted feed-forward
approximation of sparse coding. Extensive experiments verify the superiority of
the proposed $D^3$ model over several state-of-the-art methods. Specifically,
our best model is capable of outperforming the latest deep model for around 1
dB in PSNR, and is 30 times faster.


Studying Very Low Resolution Recognition Using Deep Networks

  Visual recognition research often assumes a sufficient resolution of the
region of interest (ROI). That is usually violated in practice, inspiring us to
explore the Very Low Resolution Recognition (VLRR) problem. Typically, the ROI
in a VLRR problem can be smaller than $16 \times 16$ pixels, and is challenging
to be recognized even by human experts. We attempt to solve the VLRR problem
using deep learning methods. Taking advantage of techniques primarily in super
resolution, domain adaptation and robust regression, we formulate a dedicated
deep learning method and demonstrate how these techniques are incorporated step
by step. Any extra complexity, when introduced, is fully justified by both
analysis and simulation results. The resulting \textit{Robust Partially Coupled
Networks} achieves feature enhancement and recognition simultaneously. It
allows for both the flexibility to combat the LR-HR domain mismatch, and the
robustness to outliers. Finally, the effectiveness of the proposed models is
evaluated on three different VLRR tasks, including face identification, digit
recognition and font recognition, all of which obtain very impressive
performances.


Brain-Inspired Deep Networks for Image Aesthetics Assessment

  Image aesthetics assessment has been challenging due to its subjective
nature. Inspired by the scientific advances in the human visual perception and
neuroaesthetics, we design Brain-Inspired Deep Networks (BDN) for this task.
BDN first learns attributes through the parallel supervised pathways, on a
variety of selected feature dimensions. A high-level synthesis network is
trained to associate and transform those attributes into the overall aesthetics
rating. We then extend BDN to predicting the distribution of human ratings,
since aesthetics ratings are often subjective. Another highlight is our
first-of-its-kind study of label-preserving transformations in the context of
aesthetics assessment, which leads to an effective data augmentation approach.
Experimental results on the AVA dataset show that our biological inspired and
task-specific BDN model gains significantly performance improvement, compared
to other state-of-the-art models with the same or higher parameter capacity.


Learning Deep $\ell_0$ Encoders

  Despite its nonconvex nature, $\ell_0$ sparse approximation is desirable in
many theoretical and application cases. We study the $\ell_0$ sparse
approximation problem with the tool of deep learning, by proposing Deep
$\ell_0$ Encoders. Two typical forms, the $\ell_0$ regularized problem and the
$M$-sparse problem, are investigated. Based on solid iterative algorithms, we
model them as feed-forward neural networks, through introducing novel neurons
and pooling functions. Enforcing such structural priors acts as an effective
network regularization. The deep encoders also enjoy faster inference, larger
learning capacity, and better scalability compared to conventional sparse
coding solutions. Furthermore, under task-driven losses, the models can be
conveniently optimized from end to end. Numerical results demonstrate the
impressive performances of the proposed encoders.


Learning A Deep $\ell_\infty$ Encoder for Hashing

  We investigate the $\ell_\infty$-constrained representation which
demonstrates robustness to quantization errors, utilizing the tool of deep
learning. Based on the Alternating Direction Method of Multipliers (ADMM), we
formulate the original convex minimization problem as a feed-forward neural
network, named \textit{Deep $\ell_\infty$ Encoder}, by introducing the novel
Bounded Linear Unit (BLU) neuron and modeling the Lagrange multipliers as
network biases. Such a structural prior acts as an effective network
regularization, and facilitates the model initialization. We then investigate
the effective use of the proposed model in the application of hashing, by
coupling the proposed encoders under a supervised pairwise loss, to develop a
\textit{Deep Siamese $\ell_\infty$ Network}, which can be optimized from end to
end. Extensive experiments demonstrate the impressive performances of the
proposed model. We also provide an in-depth analysis of its behaviors against
the competitors.


Deep Double Sparsity Encoder: Learning to Sparsify Not Only Features But
  Also Parameters

  This paper emphasizes the significance to jointly exploit the problem
structure and the parameter structure, in the context of deep modeling. As a
specific and interesting example, we describe the deep double sparsity encoder
(DDSE), which is inspired by the double sparsity model for dictionary learning.
DDSE simultaneously sparsities the output features and the learned model
parameters, under one unified framework. In addition to its intuitive model
interpretation, DDSE also possesses compact model size and low complexity.
Extensive simulations compare DDSE with several carefully-designed baselines,
and verify the consistently superior performance of DDSE. We further apply DDSE
to the novel application domain of brain encoding, with promising preliminary
results achieved.


Predicting Depression Severity by Multi-Modal Feature Engineering and
  Fusion

  We present our preliminary work to determine if patient's vocal acoustic,
linguistic, and facial patterns could predict clinical ratings of depression
severity, namely Patient Health Questionnaire depression scale (PHQ-8). We
proposed a multi modal fusion model that combines three different modalities:
audio, video , and text features. By training over AVEC 2017 data set, our
proposed model outperforms each single modality prediction model, and surpasses
the data set baseline with ice margin.


Decomposition-Based Domain Adaptation for Real-World Font Recognition

  We present a domain adaption framework to address a domain mismatch between
synthetic training and real-world testing data. We demonstrate our method on a
challenging fine-grain classification problem: recognizing a font style from an
image of text. In this task, it is very easy to generate lots of rendered font
examples but very hard to obtain real-world labeled images. This
real-to-synthetic domain gap caused poor generalization to new real data in
previous font recognition methods (Chen et al. (2014)). In this paper, we
introduce a Convolutional Neural Network decomposition approach, leveraging a
large training corpus of synthetic data to obtain effective features for
classification. This is done using an adaptation technique based on a Stacked
Convolutional Auto-Encoder that exploits a large collection of unlabeled
real-world text images combined with synthetic data preprocessed in a specific
way. The proposed DeepFont method achieves an accuracy of higher than 80%
(top-5) on a new large labeled real-world dataset we collected.


DeepFont: Identify Your Font from An Image

  As font is one of the core design concepts, automatic font identification and
similar font suggestion from an image or photo has been on the wish list of
many designers. We study the Visual Font Recognition (VFR) problem, and advance
the state-of-the-art remarkably by developing the DeepFont system. First of
all, we build up the first available large-scale VFR dataset, named AdobeVFR,
consisting of both labeled synthetic data and partially labeled real-world
data. Next, to combat the domain mismatch between available training and
testing data, we introduce a Convolutional Neural Network (CNN) decomposition
approach, using a domain adaptation technique based on a Stacked Convolutional
Auto-Encoder (SCAE) that exploits a large corpus of unlabeled real-world text
images combined with synthetic data preprocessed in a specific way. Moreover,
we study a novel learning-based model compression approach, in order to reduce
the DeepFont model size without sacrificing its performance. The DeepFont
system achieves an accuracy of higher than 80% (top-5) on our collected
dataset, and also produces a good font similarity measure for font selection
and suggestion. We also achieve around 6 times compression of the model without
any visible loss of recognition accuracy.


Deep $k$-Means: Re-Training and Parameter Sharing with Harder Cluster
  Assignments for Compressing Deep Convolutions

  The current trend of pushing CNNs deeper with convolutions has created a
pressing demand to achieve higher compression gains on CNNs where convolutions
dominate the computation and parameter amount (e.g., GoogLeNet, ResNet and Wide
ResNet). Further, the high energy consumption of convolutions limits its
deployment on mobile devices. To this end, we proposed a simple yet effective
scheme for compressing convolutions though applying k-means clustering on the
weights, compression is achieved through weight-sharing, by only recording $K$
cluster centers and weight assignment indexes. We then introduced a novel
spectrally relaxed $k$-means regularization, which tends to make hard
assignments of convolutional layer weights to $K$ learned cluster centers
during re-training. We additionally propose an improved set of metrics to
estimate energy consumption of CNN hardware implementations, whose estimation
results are verified to be consistent with previously proposed energy
estimation tool extrapolated from actual hardware measurements. We finally
evaluated Deep $k$-Means across several CNN models in terms of both compression
ratio and energy consumption reduction, observing promising results without
incurring accuracy loss. The code is available at
https://github.com/Sandbox3aster/Deep-K-Means


Towards Privacy-Preserving Visual Recognition via Adversarial Training:
  A Pilot Study

  This paper aims to improve privacy-preserving visual recognition, an
increasingly demanded feature in smart camera applications, by formulating a
unique adversarial training framework. The proposed framework explicitly learns
a degradation transform for the original video inputs, in order to optimize the
trade-off between target task performance and the associated privacy budgets on
the degraded video. A notable challenge is that the privacy budget, often
defined and measured in task-driven contexts, cannot be reliably indicated
using any single model performance, because a strong protection of privacy has
to sustain against any possible model that tries to hack privacy information.
Such an uncommon situation has motivated us to propose two strategies, i.e.,
budget model restarting and ensemble, to enhance the generalization of the
learned degradation on protecting privacy against unseen hacker models. Novel
training strategies, evaluation protocols, and result visualization methods
have been designed accordingly. Two experiments on privacy-preserving action
recognition, with privacy budgets defined in various ways, manifest the
compelling effectiveness of the proposed framework in simultaneously
maintaining high target task (action recognition) performance while suppressing
the privacy breach risk.


Adversarially Trained Model Compression: When Robustness Meets
  Efficiency

  The robustness of deep models to adversarial attacks has gained significant
attention in recent years, so has the model compactness and efficiency: yet the
two have been mostly studied separately, with few relationships drawn between
each other. This paper is concerned with: how can we combine the best of both
worlds, obtaining a robust and compact network? The answer is not as
straightforward as it may seem, since the two goals of model robustness and
compactness may contradict from time to time. We formally study this new
question, by proposing a novel Adversarially Trained Model Compression (ATMC)
framework. A unified constrained optimization formulation is designed, with an
efficient algorithm developed. An extensive group of experiments are then
carefully designed and presented, demonstrating that ATMC obtains remarkably
more favorable trade-off among model size, accuracy and robustness, over
currently available alternatives in various settings.


UnitBox: An Advanced Object Detection Network

  In present object detection systems, the deep convolutional neural networks
(CNNs) are utilized to predict bounding boxes of object candidates, and have
gained performance advantages over the traditional region proposal methods.
However, existing deep CNN methods assume the object bounds to be four
independent variables, which could be regressed by the $\ell_2$ loss
separately. Such an oversimplified assumption is contrary to the well-received
observation, that those variables are correlated, resulting to less accurate
localization. To address the issue, we firstly introduce a novel Intersection
over Union ($IoU$) loss function for bounding box prediction, which regresses
the four bounds of a predicted box as a whole unit. By taking the advantages of
$IoU$ loss and deep fully convolutional networks, the UnitBox is introduced,
which performs accurate and efficient localization, shows robust to objects of
varied shapes and scales, and converges fast. We apply UnitBox on face
detection task and achieve the best performance among all published methods on
the FDDB benchmark.


Task-driven Visual Saliency and Attention-based Visual Question
  Answering

  Visual question answering (VQA) has witnessed great progress since May, 2015
as a classic problem unifying visual and textual data into a system. Many
enlightening VQA works explore deep into the image and question encodings and
fusing methods, of which attention is the most effective and infusive
mechanism. Current attention based methods focus on adequate fusion of visual
and textual features, but lack the attention to where people focus to ask
questions about the image. Traditional attention based methods attach a single
value to the feature at each spatial location, which losses many useful
information. To remedy these problems, we propose a general method to perform
saliency-like pre-selection on overlapped region features by the interrelation
of bidirectional LSTM (BiLSTM), and use a novel element-wise multiplication
based attention method to capture more competent correlation information
between visual and textual features. We conduct experiments on the large-scale
COCO-VQA dataset and analyze the effectiveness of our model demonstrated by
strong empirical results.


When Image Denoising Meets High-Level Vision Tasks: A Deep Learning
  Approach

  Conventionally, image denoising and high-level vision tasks are handled
separately in computer vision. In this paper, we cope with the two jointly and
explore the mutual influence between them. First we propose a convolutional
neural network for image denoising which achieves the state-of-the-art
performance. Second we propose a deep neural network solution that cascades two
modules for image denoising and various high-level tasks, respectively, and use
the joint loss for updating only the denoising network via back-propagation. We
demonstrate that on one hand, the proposed denoiser has the generality to
overcome the performance degradation of different high-level vision tasks. On
the other hand, with the guidance of high-level vision information, the
denoising network can generate more visually appealing results. To the best of
our knowledge, this is the first work investigating the benefit of exploiting
image semantics simultaneously for image denoising and high-level vision tasks
via deep learning. The code is available online
https://github.com/Ding-Liu/DeepDenoising.


An All-in-One Network for Dehazing and Beyond

  This paper proposes an image dehazing model built with a convolutional neural
network (CNN), called All-in-One Dehazing Network (AOD-Net). It is designed
based on a re-formulated atmospheric scattering model. Instead of estimating
the transmission matrix and the atmospheric light separately as most previous
models did, AOD-Net directly generates the clean image through a light-weight
CNN. Such a novel end-to-end design makes it easy to embed AOD-Net into other
deep models, e.g., Faster R-CNN, for improving high-level task performance on
hazy images. Experimental results on both synthesized and natural hazy image
datasets demonstrate our superior performance than the state-of-the-art in
terms of PSNR, SSIM and the subjective visual quality. Furthermore, when
concatenating AOD-Net with Faster R-CNN and training the joint pipeline from
end to end, we witness a large improvement of the object detection performance
on hazy images.


Robust Emotion Recognition from Low Quality and Low Bit Rate Video: A
  Deep Learning Approach

  Emotion recognition from facial expressions is tremendously useful,
especially when coupled with smart devices and wireless multimedia
applications. However, the inadequate network bandwidth often limits the
spatial resolution of the transmitted video, which will heavily degrade the
recognition reliability. We develop a novel framework to achieve robust emotion
recognition from low bit rate video. While video frames are downsampled at the
encoder side, the decoder is embedded with a deep network model for joint
super-resolution (SR) and recognition. Notably, we propose a novel max-mix
training strategy, leading to a single "One-for-All" model that is remarkably
robust to a vast range of downsampling factors. That makes our framework well
adapted for the varied bandwidths in real transmission scenarios, without
hampering scalability or efficiency. The proposed framework is evaluated on the
AVEC 2016 benchmark, and demonstrates significantly improved stand-alone
recognition performance, as well as rate-distortion (R-D) performance, than
either directly recognizing from LR frames, or separating SR and recognition.


End-to-End United Video Dehazing and Detection

  The recent development of CNN-based image dehazing has revealed the
effectiveness of end-to-end modeling. However, extending the idea to end-to-end
video dehazing has not been explored yet. In this paper, we propose an
End-to-End Video Dehazing Network (EVD-Net), to exploit the temporal
consistency between consecutive video frames. A thorough study has been
conducted over a number of structure options, to identify the best temporal
fusion strategy. Furthermore, we build an End-to-End United Video Dehazing and
Detection Network(EVDD-Net), which concatenates and jointly trains EVD-Net with
a video object detection model. The resulting augmented end-to-end pipeline has
demonstrated much more stable and accurate detection results in hazy video.


Benchmarking Single Image Dehazing and Beyond

  We present a comprehensive study and evaluation of existing single image
dehazing algorithms, using a new large-scale benchmark consisting of both
synthetic and real-world hazy images, called REalistic Single Image DEhazing
(RESIDE). RESIDE highlights diverse data sources and image contents, and is
divided into five subsets, each serving different training or evaluation
purposes. We further provide a rich variety of criteria for dehazing algorithm
evaluation, ranging from full-reference metrics, to no-reference metrics, to
subjective evaluation and the novel task-driven evaluation. Experiments on
RESIDE shed light on the comparisons and limitations of state-of-the-art
dehazing algorithms, and suggest promising future directions.


Enhance Visual Recognition under Adverse Conditions via Deep Networks

  Visual recognition under adverse conditions is a very important and
challenging problem of high practical value, due to the ubiquitous existence of
quality distortions during image acquisition, transmission, or storage. While
deep neural networks have been extensively exploited in the techniques of
low-quality image restoration and high-quality image recognition tasks
respectively, few studies have been done on the important problem of
recognition from very low-quality images. This paper proposes a deep learning
based framework for improving the performance of image and video recognition
models under adverse conditions, using robust adverse pre-training or its
aggressive variant. The robust adverse pre-training algorithms leverage the
power of pre-training and generalizes conventional unsupervised pre-training
and data augmentation methods. We further develop a transfer learning approach
to cope with real-world datasets of unknown adverse conditions. The proposed
framework is comprehensively evaluated on a number of image and video
recognition benchmarks, and obtains significant performance improvements under
various single or mixed adverse conditions. Our visualization and analysis
further add to the explainability of results.


Learning Simple Thresholded Features with Sparse Support Recovery

  The thresholded feature has recently emerged as an extremely efficient, yet
rough empirical approximation, of the time-consuming sparse coding inference
process. Such an approximation has not yet been rigorously examined, and
standard dictionaries often lead to non-optimal performance when used for
computing thresholded features. In this paper, we first present two theoretical
recovery guarantees for the thresholded feature to exactly recover the nonzero
support of the sparse code. Motivated by them, we then formulate the Dictionary
Learning for Thresholded Features (DLTF) model, which learns an optimized
dictionary for applying the thresholded feature. In particular, for the $(k,
2)$ norm involved, a novel proximal operator with log-linear time complexity
$O(m\log m)$ is derived. We evaluate the performance of DLTF on a vast range of
synthetic and real-data tasks, where DLTF demonstrates remarkable efficiency,
effectiveness and robustness in all experiments. In addition, we briefly
discuss the potential link between DLTF and deep learning building blocks.


Improved Techniques for Learning to Dehaze and Beyond: A Collective
  Study

  Here we explore two related but important tasks based on the recently
released REalistic Single Image DEhazing (RESIDE) benchmark dataset: (i) single
image dehazing as a low-level image restoration problem; and (ii) high-level
visual understanding (e.g., object detection) of hazy images. For the first
task, we investigated a variety of loss functions and show that
perception-driven loss significantly improves dehazing performance. In the
second task, we provide multiple solutions including using advanced modules in
the dehazing-detection cascade and domain-adaptive object detectors. In both
tasks, our proposed solutions significantly improve performance. GitHub
repository URL is: https://github.com/guanlongzhao/dehaze


U-Finger: Multi-Scale Dilated Convolutional Network for Fingerprint
  Image Denoising and Inpainting

  This paper studies the challenging problem of fingerprint image denoising and
inpainting. To tackle the challenge of suppressing complicated artifacts (blur,
brightness, contrast, elastic transformation, occlusion, scratch, resolution,
rotation, and so on) while preserving fine textures, we develop a multi-scale
convolutional network, termed U- Finger. Based on the domain expertise, we show
that the usage of dilated convolutions as well as the removal of padding have
important positive impacts on the final restoration performance, in addition to
multi-scale cascaded feature modules. Our model achieves the overall ranking of
No.2 in the ECCV 2018 Chalearn LAP Inpainting Competition Track 3 (Fingerprint
Denoising and Inpainting). Among all participating teams, we obtain the MSE of
0.0231 (rank 2), PSNR 16.9688 dB (rank 2), and SSIM 0.8093 (rank 3) on the
hold-out testing set.


Theoretical Linear Convergence of Unfolded ISTA and its Practical
  Weights and Thresholds

  In recent years, unfolding iterative algorithms as neural networks has become
an empirical success in solving sparse recovery problems. However, its
theoretical understanding is still immature, which prevents us from fully
utilizing the power of neural networks. In this work, we study unfolded ISTA
(Iterative Shrinkage Thresholding Algorithm) for sparse signal recovery. We
introduce a weight structure that is necessary for asymptotic convergence to
the true sparse signal. With this structure, unfolded ISTA can attain a linear
convergence, which is better than the sublinear convergence of ISTA/FISTA in
general cases. Furthermore, we propose to incorporate thresholding in the
network to perform support selection, which is easy to implement and able to
boost the convergence rate both theoretically and empirically. Extensive
simulations, including sparse vector recovery and a compressive sensing
experiment on real image data, corroborate our theoretical results and
demonstrate their practical usefulness. We have made our codes publicly
available: https://github.com/xchen-tamu/linear-lista-cpss.


Can We Gain More from Orthogonality Regularizations in Training Deep
  CNNs?

  This paper seeks to answer the question: as the (near-) orthogonality of
weights is found to be a favorable property for training deep convolutional
neural networks, how can we enforce it in more effective and easy-to-use ways?
We develop novel orthogonality regularizations on training deep CNNs, utilizing
various advanced analytical tools such as mutual coherence and restricted
isometry property. These plug-and-play regularizations can be conveniently
incorporated into training almost any CNN without extra hassle. We then
benchmark their effects on state-of-the-art models: ResNet, WideResNet, and
ResNeXt, on several most popular computer vision datasets: CIFAR-10, CIFAR-100,
SVHN and ImageNet. We observe consistent performance gains after applying those
proposed regularizations, in terms of both the final accuracies achieved, and
faster and more stable convergences. We have made our codes and pre-trained
models publicly available:
https://github.com/nbansal90/Can-we-Gain-More-from-Orthogonality.


Single Image Deraining: A Comprehensive Benchmark Analysis

  We present a comprehensive study and evaluation of existing single image
deraining algorithms, using a new large-scale benchmark consisting of both
synthetic and real-world rainy images.This dataset highlights diverse data
sources and image contents, and is divided into three subsets (rain streak,
rain drop, rain and mist), each serving different training or evaluation
purposes. We further provide a rich variety of criteria for dehazing algorithm
evaluation, ranging from full-reference metrics, to no-reference metrics, to
subjective evaluation and the novel task-driven evaluation. Experiments on the
dataset shed light on the comparisons and limitations of state-of-the-art
deraining algorithms, and suggest promising future directions.


Subspace Network: Deep Multi-Task Censored Regression for Modeling
  Neurodegenerative Diseases

  Over the past decade a wide spectrum of machine learning models have been
developed to model the neurodegenerative diseases, associating biomarkers,
especially non-intrusive neuroimaging markers, with key clinical scores
measuring the cognitive status of patients. Multi-task learning (MTL) has been
commonly utilized by these studies to address high dimensionality and small
cohort size challenges. However, most existing MTL approaches are based on
linear models and suffer from two major limitations: 1) they cannot explicitly
consider upper/lower bounds in these clinical scores; 2) they lack the
capability to capture complicated non-linear interactions among the variables.
In this paper, we propose Subspace Network, an efficient deep modeling approach
for non-linear multi-task censored regression. Each layer of the subspace
network performs a multi-task censored regression to improve upon the
predictions from the last layer via sketching a low-dimensional subspace to
perform knowledge transfer among learning tasks. Under mild assumptions, for
each layer the parametric subspace can be recovered using only one pass of
training data. Empirical results demonstrate that the proposed subspace network
quickly picks up the correct parameter subspaces, and outperforms
state-of-the-arts in predicting neurodegenerative clinical scores using
information in brain imaging.


$L_p$-Norm Constrained Coding With Frank-Wolfe Network

  We investigate the problem of $L_p$-norm constrained coding, i.e. converting
signal into code that lies inside an $L_p$-ball and most faithfully
reconstructs the signal. While previous works known as sparse coding have
addressed the cases of $L_0$ and $L_1$ norms, more general cases with other $p$
values, especially with unknown $p$, remain a difficulty. We propose the
Frank-Wolfe Network (F-W Net), whose architecture is inspired by unrolling and
truncating the Frank-Wolfe algorithm for solving an $L_p$-norm constrained
problem. We show that the Frank-Wolfe solver for the $L_p$-norm constraint
leads to a novel closed-form nonlinear unit, which is parameterized by $p$ and
termed $pool_p$. The $pool_p$ unit links the conventional pooling, activation,
and normalization operations, making F-W Net distinct from existing deep
networks either heuristically designed or converted from projected gradient
descent algorithms. We further show that the hyper-parameter $p$ can be made
learnable instead of pre-chosen in F-W Net, which gracefully solves the
$L_p$-norm constrained coding problem with unknown $p$. We evaluate the
performance of F-W Net on an extensive range of simulations as well as the task
of handwritten digit recognition, where F-W Net exhibits strong learning
capability. We then propose a convolutional version of F-W Net, and apply the
convolutional F-W Net into image denoising and super-resolution tasks, where
F-W Net all demonstrates impressive effectiveness, flexibility, and robustness.


DeepAffinity: Interpretable Deep Learning of Compound-Protein Affinity
  through Unified Recurrent and Convolutional Neural Networks

  Motivation: Drug discovery demands rapid quantification of compound-protein
interaction (CPI). However, there is a lack of methods that can predict
compound-protein affinity from sequences alone with high applicability,
accuracy, and interpretability.
  Results: We present a seamless integration of domain knowledges and
learning-based approaches. Under novel representations of
structurally-annotated protein sequences, a semi-supervised deep learning model
that unifies recurrent and convolutional neural networks has been proposed to
exploit both unlabeled and labeled data, for jointly encoding molecular
representations and predicting affinities. Our representations and models
outperform conventional options in achieving relative error in IC$_{50}$ within
5-fold for test cases and 20-fold for protein classes not included for
training. Performances for new protein classes with few labeled data are
further improved by transfer learning. Furthermore, separate and joint
attention mechanisms are developed and embedded to our model to add to its
interpretability, as illustrated in case studies for predicting and explaining
selective drug-target interactions. Lastly, alternative representations using
protein sequences or compound graphs and a unified RNN/GCNN-CNN model using
graph CNN (GCNN) are also explored to reveal algorithmic challenges ahead.
  Availability: Data and source codes are available at
https://github.com/Shen-Lab/DeepAffinity
  Supplementary Information: Supplementary data are available at
http://shen-lab.github.io/deep-affinity-bioinf18-supp-rev.pdf


DADA: Deep Adversarial Data Augmentation for Extremely Low Data Regime
  Classification

  Deep learning has revolutionized the performance of classification, but
meanwhile demands sufficient labeled data for training. Given insufficient
data, while many techniques have been developed to help combat overfitting, the
challenge remains if one tries to train deep networks, especially in the
ill-posed extremely low data regimes: only a small set of labeled data are
available, and nothing -- including unlabeled data -- else. Such regimes arise
from practical situations where not only data labeling but also data collection
itself is expensive. We propose a deep adversarial data augmentation (DADA)
technique to address the problem, in which we elaborately formulate data
augmentation as a problem of training a class-conditional and supervised
generative adversarial network (GAN). Specifically, a new discriminator loss is
proposed to fit the goal of data augmentation, through which both real and
augmented samples are enforced to contribute to and be consistent in finding
the decision boundaries. Tailored training techniques are developed
accordingly. To quantitatively validate its effectiveness, we first perform
extensive simulations to show that DADA substantially outperforms both
traditional data augmentation and a few GAN-based options. We then extend
experiments to three real-world small labeled datasets where existing data
augmentation and/or transfer learning strategies are either less effective or
infeasible. All results endorse the superior capability of DADA in enhancing
the generalization ability of deep networks trained in practical extremely low
data regimes. Source code is available at
https://github.com/SchafferZhang/DADA.


Connecting Image Denoising and High-Level Vision Tasks via Deep Learning

  Image denoising and high-level vision tasks are usually handled independently
in the conventional practice of computer vision, and their connection is
fragile. In this paper, we cope with the two jointly and explore the mutual
influence between them with the focus on two questions, namely (1) how image
denoising can help improving high-level vision tasks, and (2) how the semantic
information from high-level vision tasks can be used to guide image denoising.
First for image denoising we propose a convolutional neural network in which
convolutions are conducted in various spatial resolutions via downsampling and
upsampling operations in order to fuse and exploit contextual information on
different scales. Second we propose a deep neural network solution that
cascades two modules for image denoising and various high-level tasks,
respectively, and use the joint loss for updating only the denoising network
via back-propagation. We experimentally show that on one hand, the proposed
denoiser has the generality to overcome the performance degradation of
different high-level vision tasks. On the other hand, with the guidance of
high-level vision information, the denoising network produces more visually
appealing results. Extensive experiments demonstrate the benefit of exploiting
image semantics simultaneously for image denoising and high-level vision tasks
via deep learning. The code is available online:
https://github.com/Ding-Liu/DeepDenoising


Adaptive Activity Monitoring with Uncertainty Quantification in
  Switching Gaussian Process Models

  Emerging wearable sensors have enabled the unprecedented ability to
continuously monitor human activities for healthcare purposes. However, with so
many ambient sensors collecting different measurements, it becomes important
not only to maintain good monitoring accuracy, but also low power consumption
to ensure sustainable monitoring. This power-efficient sensing scheme can be
achieved by deciding which group of sensors to use at a given time, requiring
an accurate characterization of the trade-off between sensor energy usage and
the uncertainty in ignoring certain sensor signals while monitoring. To address
this challenge in the context of activity monitoring, we have designed an
adaptive activity monitoring framework. We first propose a switching Gaussian
process to model the observed sensor signals emitting from the underlying
activity states. To efficiently compute the Gaussian process model likelihood
and quantify the context prediction uncertainty, we propose a block circulant
embedding technique and use Fast Fourier Transforms (FFT) for inference. By
computing the Bayesian loss function tailored to switching Gaussian processes,
an adaptive monitoring procedure is developed to select features from available
sensors that optimize the trade-off between sensor power consumption and the
prediction performance quantified by state prediction entropy. We demonstrate
the effectiveness of our framework on the popular benchmark of UCI Human
Activity Recognition using Smartphones.


Convolutional Sparse Coding for Compressed Sensing CT Reconstruction

  Over the past few years, dictionary learning (DL)-based methods have been
successfully used in various image reconstruction problems. However,
traditional DL-based computed tomography (CT) reconstruction methods are
patch-based and ignore the consistency of pixels in overlapped patches. In
addition, the features learned by these methods always contain shifted versions
of the same features. In recent years, convolutional sparse coding (CSC) has
been developed to address these problems. In this paper, inspired by several
successful applications of CSC in the field of signal processing, we explore
the potential of CSC in sparse-view CT reconstruction. By directly working on
the whole image, without the necessity of dividing the image into overlapped
patches in DL-based methods, the proposed methods can maintain more details and
avoid artifacts caused by patch aggregation. With predetermined filters, an
alternating scheme is developed to optimize the objective function. Extensive
experiments with simulated and real CT data were performed to validate the
effectiveness of the proposed methods. Qualitative and quantitative results
demonstrate that the proposed methods achieve better performance than several
existing state-of-the-art methods.


UG$^{2+}$ Track 2: A Collective Benchmark Effort for Evaluating and
  Advancing Image Understanding in Poor Visibility Environments

  The UG$^{2+}$ challenge in IEEE CVPR 2019 aims to evoke a comprehensive
discussion and exploration about how low-level vision techniques can benefit
the high-level automatic visual recognition in various scenarios. In its second
track, we focus on object or face detection in poor visibility enhancements
caused by bad weathers (haze, rain) and low light conditions. While existing
enhancement methods are empirically expected to help the high-level end task,
that is observed to not always be the case in practice. To provide a more
thorough examination and fair comparison, we introduce three benchmark sets
collected in real-world hazy, rainy, and low-light conditions, respectively,
with annotate objects/faces annotated. To our best knowledge, this is the first
and currently largest effort of its kind. Baseline results by cascading
existing enhancement and detection models are reported, indicating the highly
challenging nature of our new data as well as the large room for further
technical innovations. We expect a large participation from the broad research
community to address these challenges together.


Bridging the Gap Between Computational Photography and Visual
  Recognition

  What is the current state-of-the-art for image restoration and enhancement
applied to degraded images acquired under less than ideal circumstances? Can
the application of such algorithms as a pre-processing step to improve image
interpretability for manual analysis or automatic visual recognition to
classify scene content? While there have been important advances in the area of
computational photography to restore or enhance the visual quality of an image,
the capabilities of such techniques have not always translated in a useful way
to visual recognition tasks. Consequently, there is a pressing need for the
development of algorithms that are designed for the joint problem of improving
visual appearance and recognition, which will be an enabling factor for the
deployment of visual recognition tools in many real-world scenarios. To address
this, we introduce the UG^2 dataset as a large-scale benchmark composed of
video imagery captured under challenging conditions, and two enhancement tasks
designed to test algorithmic impact on visual quality and automatic object
recognition. Furthermore, we propose a set of metrics to evaluate the joint
improvement of such tasks as well as individual algorithmic advances, including
a novel psychophysics-based evaluation regime for human assessment and a
realistic set of quantitative measures for object recognition performance. We
introduce six new algorithms for image restoration or enhancement, which were
created as part of the IARPA sponsored UG^2 Challenge workshop held at CVPR
2018. Under the proposed evaluation regime, we present an in-depth analysis of
these algorithms and a host of deep learning-based and classic baseline
approaches. From the observed results, it is evident that we are in the early
days of building a bridge between computational photography and visual
recognition, leaving many opportunities for innovation in this area.


