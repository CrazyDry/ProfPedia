Some new solutions to the Klein-Gordon equation in 1-1D space-time in
  the presence of time dependent potentials

  We find three exact solutions to the Klein-Gordon equation in 1-1 dimensional
space-time for different time dependent potentials. In two cases we consider a
time dependent scalar potential and in one case a time dependent electric
potential.


Indirect Searches for Kaluza-Klein Dark Matter

  In this talk, we discuss the potential for the indirect detection of
Kaluza-Klein dark matter using neutrino telescopes and cosmic positron
experiments. We find that future kilometer-scale neutrino telescopes, such as
IceCube, as well as future experiments capable of measuring the cosmic positron
spectrum, such as PAMELA and AMS-02, will be quite sensitive to this scenario.
Current data from the HEAT experiment can also be explained by the presence of
Kaluza-Klein dark matter in the Galactic halo.


Kaluza-Klein Dark Matter and the Positron Excess

  The excess of cosmic positrons observed by the HEAT experiment may be the
result of Kaluza-Klein dark matter annihilating in the galactic halo.
Kaluza-Klein dark matter annihilates dominantly into charged leptons that yield
a large number and hard spectrum of positrons per annihilation. Given a
Kaluza-Klein dark matter particle with a mass in the range of 300-400 GeV, no
exceptional substructure or clumping is needed in the local distribution of
dark matter to generate a positron flux that explains the HEAT observations.
This is in contrast to supersymmetric dark matter that requires unnaturally
large amounts of dark substructure to produce the observed positron excess.
Future astrophysical and collider tests are outlined that will confirm or rule
out this explanation of the HEAT data.


Interplay of the Aharonov-Bohm effect and Klein tunneling in graphene

  We numerically investigate the effect of Klein tunneling on the Aharonov-Bohm
oscillations in graphene rings using a tight-binding model with
nearest-neighbor couplings. In order to introduce Klein tunneling into the
system, we apply an electrostatic potential to one of the arms of the ring,
such that this arm together with the two adjacent leads form either a $nn'n$-
or $npn$-junction ($n,n'$: conduction band transport, $p$: valence band
transport). The former case corresponds to normal tunneling and the latter case
to Klein tunneling. We find that the transmission properties strongly depend on
the smoothness of the $pn$-interfaces. In particular, for sharp junctions the
amplitude profile is symmetric around the charge neutrality point in the gated
arm, whereas for smooth junctions the Aharonov-Bohm oscillations are strongly
suppressed in the Klein tunneling as compared to the normal tunneling regime.


Kaluza-Klein Dark Matter, Electrons and Gamma Ray Telescopes

  Kaluza-Klein dark matter particles can annihilate efficiently into
electron-positron pairs, providing a discrete feature (a sharp edge) in the
cosmic $e^+ e^-$ spectrum at an energy equal to the particle's mass (typically
several hundred GeV to one TeV). Although this feature is probably beyond the
reach of satellite or balloon-based cosmic ray experiments (those that
distinguish the charge and mass of the primary particle), gamma ray telescopes
may provide an alternative detection method. Designed to observe very
high-energy gamma-rays, ACTs also observe the diffuse flux of electron-induced
electromagnetic showers. The GLAST satellite, designed for gamma ray astronomy,
will also observe any high energy showers (several hundred GeV and above) in
its calorimeter. We show that high-significance detections of an
electron-positron feature from Kaluza-Klein dark matter annihilations are
possible with GLAST, and also with ACTs such as HESS, VERITAS or MAGIC.


Particle Dark Matter: Evidence, Candidates and Constraints

  In this review article, we discuss the current status of particle dark
matter, including experimental evidence and theoretical motivations. We discuss
a wide array of candidates for particle dark matter, but focus on neutralinos
in models of supersymmetry and Kaluza-Klein dark matter in models of universal
extra dimensions. We devote much of our attention to direct and indirect
detection techniques, the constraints placed by these experiments and the reach
of future experimental efforts.


Searching for Dark Matter with Future Cosmic Positron Experiments

  Dark matter particles annihilating in the Galactic halo can provide a flux of
positrons potentially observable in upcoming experiments, such as PAMELA and
AMS-02. We discuss the spectral features which may be associated with dark
matter annihilation in the positron spectrum and assess the prospects for
observing such features in future experiments. Although we focus on some
specific dark matter candidates, neutralinos and Kaluza-Klein states, we carry
out our study in a model independent fashion. We also revisit the positron
spectrum observed by HEAT.


Capturing Semantic Similarity for Entity Linking with Convolutional
  Neural Networks

  A key challenge in entity linking is making effective use of contextual
information to disambiguate mentions that might refer to different entities in
different contexts. We present a model that uses convolutional neural networks
to capture semantic correspondence between a mention's context and a proposed
target entity. These convolutional networks operate at multiple granularities
to exploit various kinds of topic information, and their rich parameterization
gives them the capacity to learn which n-grams characterize different topics.
We combine these networks with a sparse linear model to achieve
state-of-the-art performance on multiple entity linking datasets, outperforming
the prior systems of Durrett and Klein (2014) and Nguyen et al. (2014).


Multilingual Constituency Parsing with Self-Attention and Pre-Training

  We extend our previous work on constituency parsing (Kitaev and Klein, 2018)
by incorporating pre-training for ten additional languages, and compare the
benefits of no pre-training, ELMo (Peters et al., 2018), and BERT (Devlin et
al., 2018). Pre-training is effective across all languages evaluated, and BERT
outperforms ELMo in large part due to the benefits of increased model capacity.
Our parser obtains new state-of-the-art results for 11 languages, including
English (95.8 F1) and Chinese (91.8 F1).


Indirect Detection of Dirac Right-Handed Neutrino Dark Matter

  We present the signatures and prospects for the indirect detection of a Dirac
right-handed neutrino dark matter candidate in neutrino telescopes, cosmic
positron experiments and gamma-ray telescopes. An example of such a dark matter
candidate can be found in extra-dimensional models. In some constructions,
Kaluza--Klein states with the gauge quantum numbers of a right-handed neutrino
can have sizable gauge interactions with Standard Model particles. For
instance, in 5D warped Grand Unified Theories, it has been shown that a
Kaluza--Klein right-handed neutrino may be stable and otherwise a
phenomenologically viable dark matter candidate. We find that the prospects for
the indirect detection of such a WIMP are encouraging, particularly for
neutrino telescopes and cosmic positron experiments.


The PAMELA and ATIC Signals From Kaluza-Klein Dark Matter

  In this letter, we study the possibility that Kaluza-Klein dark matter in a
model with one universal extra dimension is responsible for the recent
observations of the PAMELA and ATIC experiments. In this model, the dark matter
particles annihilate largely to charged leptons, which enables them to produce
a spectrum of cosmic ray electrons and positrons consistent with the PAMELA and
ATIC measurements. To normalize to the observed signal, however, large boost
factors (~10^3) are required. Despite these large boost factors and significant
annihilation to hadronic modes (35%), we find that the constraints from cosmic
ray antiproton measurements can be satisfied. Relic abundance considerations in
this model force us to consider a rather specific range of masses
(approximately 600-900 GeV) which is very similar to the range required to
generate the ATIC spectral feature. The results presented here can also be used
as a benchmark for model-independent constraints on dark matter annihilation to
hadronic modes.


Kaluza-Klein Dark Matter And Neutrinos From Annihilation In The Sun

  In models with one universal extra dimension (UED), the first Kaluza-Klein
excitations of the hypercharge gauge boson, B^(1), and the neutral component of
isospin gauge boson, W^3(1), are each viable dark matter candidates. In either
case, such particles are predicted to accumulate in the core of the Sun, where
they annihilate to generate a potentially observable flux of high energy
neutrinos. In this article, we calculate the flux of neutrinos produced in this
model and determine the constraints that can be placed on the UED parameter
space from current IceCube data. For the case of B^(1) dark matter, we find
that the present limits from IceCube are stronger than those from direct dark
matter detection experiments such as CDMS and XENON10. For W^3(1) dark matter,
the present IceCube data provides a constraint slightly weaker than direct
detection experiments. In addition, we also present the projected regions of
UED parameter space that can be probed by IceCube/DeepCore in the near future
and compare them to the prospects for future direct detection experiments.


Spinless photon dark matter from two universal extra dimensions

  We explore the properties of dark matter in theories with two universal extra
dimensions, where the lightest Kaluza-Klein state is a spin-0 neutral particle,
representing a six-dimensional photon polarized along the extra dimensions.
Annihilation of this 'spinless photon' proceeds predominantly through Higgs
boson exchange, and is largely independent of other Kaluza-Klein particles. The
measured relic abundance sets an upper limit on the spinless photon mass of 500
GeV, which decreases to almost 200 GeV if the Higgs boson is light. The
phenomenology of this dark matter candidate is strikingly different from
Kaluza-Klein dark matter in theories with one universal extra dimension.
Elastic scattering of the spinless photon with quarks is helicity suppressed,
making its direct detection challenging, although possible at upcoming
experiments. The prospects for indirect detection with gamma rays and
antimatter are similar to those of neutralinos. The rates predicted at neutrino
telescopes are below the sensitivity of next-generation experiments.


Global well-posedness for the massive Maxwell-Klein-Gordon equation with
  small critical Sobolev data

  In this paper we prove global well-posedness and modified scattering for the
massive Maxwell-Klein-Gordon equation in the Coulomb gauge on
$\mathbb{R}^{1+d}$ $(d \geq 4)$ for data with small critical Sobolev norm. This
extends to the general case $ m^2 > 0 $ the results of Krieger-Sterbenz-Tataru
($d=4,5 $) and Rodnianski-Tao ($ d \geq 6 $), who considered the case $ m=0$.
  We proceed by generalizing the global parametrix construction for the
covariant wave operator and the functional framework from the massless case to
the Klein-Gordon setting. The equation exhibits a trilinear cancelation
structure identified by Machedon-Sterbenz. To treat it one needs sharp $ L^2 $
null form bounds, which we prove by estimating renormalized solutions in null
frames spaces similar to the ones considered by Bejenaru-Herr. To overcome
logarithmic divergences we rely on an embedding property of $ \Box^{-1} $ in
conjunction with endpoint Strichartz estimates in Lorentz spaces.


Long-ranged attraction between disordered heterogeneous surfaces

  Long-ranged attractions across water between two surfaces that are randomly
covered with (mobile) positive and negative charge domains have been attributed
to induced correlation of the charges (positive lining up with negative) as the
surfaces approach. Here we show, by directly measuring normal forces under a
rapid shear field, that these attractions may not in fact be due to such
correlations. It is rather the inherent interaction-asymmetry between equally-
and between oppositely-charged domains that results in the long-ranged
attraction even in the complete absence of any charge correlation.


Learning to Compose Neural Networks for Question Answering

  We describe a question answering model that applies to both images and
structured knowledge bases. The model uses natural language strings to
automatically assemble neural networks from a collection of composable modules.
Parameters for these modules are learned jointly with network-assembly
parameters via reinforcement learning, with only (world, question, answer)
triples as supervision. Our approach, which we term a dynamic neural model
network, achieves state-of-the-art results on benchmark datasets in both visual
and structured domains.


Abstract Syntax Networks for Code Generation and Semantic Parsing

  Tasks like code generation and semantic parsing require mapping unstructured
(or partially structured) inputs to well-formed, executable outputs. We
introduce abstract syntax networks, a modeling framework for these problems.
The outputs are represented as abstract syntax trees (ASTs) and constructed by
a decoder with a dynamically-determined modular structure paralleling the
structure of the output tree. On the benchmark Hearthstone dataset for code
generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy,
compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we
perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with
no task-specific engineering.


Fine-Grained Entity Typing with High-Multiplicity Assignments

  As entity type systems become richer and more fine-grained, we expect the
number of types assigned to a given entity to increase. However, most
fine-grained typing work has focused on datasets that exhibit a low degree of
type multiplicity. In this paper, we consider the high-multiplicity regime
inherent in data sources such as Wikipedia that have semi-open type systems. We
introduce a set-prediction approach to this problem and show that our model
outperforms unstructured baselines on a new Wikipedia-based fine-grained typing
corpus.


Alignment-based compositional semantics for instruction following

  This paper describes an alignment-based model for interpreting natural
language instructions in context. We approach instruction following as a search
over plans, scoring sequences of actions conditioned on structured observations
of text and the environment. By explicitly modeling both the low-level
compositional structure of individual actions and the high-level structure of
full plans, we are able to learn both grounded representations of sentence
meaning and pragmatic constraints on interpretation. To demonstrate the model's
flexibility, we apply it to a diverse set of benchmark tasks. On every task, we
outperform strong task-specific baselines, and achieve several new
state-of-the-art results.


Reasoning About Pragmatics with Neural Listeners and Speakers

  We present a model for pragmatically describing scenes, in which contrastive
behavior results from a combination of inference-driven pragmatics and learned
semantics. Like previous learned approaches to language generation, our model
uses a simple feature-driven architecture (here a pair of neural "listener" and
"speaker" models) to ground language in the world. Like inference-driven
approaches to pragmatics, our model actively reasons about listener behavior
when selecting utterances. For training, our approach requires only ordinary
captions, annotated _without_ demonstration of the pragmatic behavior the model
ultimately exhibits. In human evaluations on a referring expression game, our
approach succeeds 81% of the time, compared to a 69% success rate using
existing techniques.


A Minimal Span-Based Neural Constituency Parser

  In this work, we present a minimal neural model for constituency parsing
based on independent scoring of labels and spans. We show that this model is
not only compatible with classical dynamic programming techniques, but also
admits a novel greedy top-down inference algorithm based on recursive
partitioning of the input. We demonstrate empirically that both prediction
schemes are competitive with recent work, and when combined with basic
extensions to the scoring model are capable of achieving state-of-the-art
single-model performance on the Penn Treebank (91.79 F1) and strong performance
on the French Treebank (82.23 F1).


Analogs of Linguistic Structure in Deep Representations

  We investigate the compositional structure of message vectors computed by a
deep network trained on a communication game. By comparing truth-conditional
representations of encoder-produced message vectors to human-produced referring
expressions, we are able to identify aligned (vector, utterance) pairs with the
same meaning. We then search for structured relationships among these aligned
pairs to discover simple vector space transformations corresponding to
negation, conjunction, and disjunction. Our results suggest that neural
representations are capable of spontaneously developing a "syntax" with
functional analogues to qualitative properties of natural language.


Searching For Dark Matter with Neutrino Telescopes

  One of the most interesting mysteries of astrophysics is the puzzle of dark
matter. Although numerous techniques have been explored and developed to detect
this elusive substance, its nature remains unknown. One such method uses large
high-energy neutrino telescopes to look for the annihilation products of dark
matter annihilations. In this summary article, we briefly review this
technique. We describe the calculations used to find the rate of capture of
WIMPs in the Sun or Earth and the spectrum of neutrinos produced in the
resulting dark matter annihilations. We will discuss these calculations within
the context of supersymmetry and models with universal extra dimensions, the
lightest supersymmetric particle and lightest Kaluza-Klein particle providing
the WIMP candidate in these cases, respectively. We will also discuss the
status of some of the experiments relevant to these searches: AMANDA, IceCube
and ANTARES.


Improved Bounds on Universal Extra Dimensions and Consequences for LKP
  Dark Matter

  We study constraints on models with a flat "Universal'' Extra Dimension in
which all Standard Model fields propagate in the bulk. A significantly improved
constraint on the compactification scale is obtained from the extended set of
electroweak precision observables accurately measured at LEP1 and LEP2. We find
a lower bound of M_c = R^{-1} > 700 (800) GeV at the 99% (95%) confidence
level. We also discuss the implications of this constraint on the prospects for
the direct and indirect detection of Kaluza-Klein dark matter in this model.


Distinguishing Supersymmetry From Universal Extra Dimensions or Little
  Higgs Models With Dark Matter Experiments

  There are compelling reasons to think that new physics will appear at or
below the TeV-scale. It is not known what form this new physics will take,
however. Although The Large Hadron collider is very likely to discover new
particles associated with the TeV-scale, it may be difficult for it to
determine the nature of those particles, whether superpartners, Kaluza-Klein
modes or other states. In this article, we consider how direct and indirect
dark matter detection experiments may provide information complementary to
hadron colliders, which can be used to discriminate between supersymmetry,
models with universal extra dimensions, and Little Higgs theories. We find
that, in many scenarios, dark matter experiments can be effectively used to
distinguish between these possibilities.


Quantization of heterotic strings in a Goedel/Anti de Sitter spacetime
  and chronology protection

  We show that a Goedel-like deformation of AdS3 in heterotic string theory can
be realized as an exact string background. Indeed this class of solutions is
obtained as an exactly marginal deformation of the conformal field theory
describing the NS5/F1 heterotic background. It can also be embedded in type II
superstrings as a Kaluza-Klein reduction. We compute the spectrum of this model
as well as the genus one modular invariant partition function. We discuss the
issue of closed timelike curves and the propagation of long strings. They
destabilize completely the background, although we construct another exact
string background that may describe the result of the condensation of these
long strings. Closed timelike curves are avoided in that case.


Probing Kaluza-Klein Dark Matter with Neutrino Telescopes

  In models in which all of the Standard Model fields live in extra universal
dimensions, the lightest Kaluza-Klein (KK) particle can be stable. Calculations
of the one-loop radiative corrections to the masses of the KK modes suggest
that the identity of the lightest KK particle (LKP) is mostly the first KK
excitation of the hypercharge gauge boson. This LKP is a viable dark matter
candidate with an ideal present-day relic abundance if its mass is moderately
large, between 600 to 1200 GeV. Such weakly interacting dark matter particles
are expected to become gravitationally trapped in large bodies, such as the
Sun, and annihilate into neutrinos or other particles that decay into
neutrinos. We calculate the annihilation rate, neutrino flux and the resulting
event rate in present and future neutrino telescopes. The relatively large mass
implies that the neutrino energy spectrum is expected to be well above the
energy threshold of AMANDA and IceCube. We find that the event rate in IceCube
is between a few to tens of events per year.


Global well-posedness of high dimensional Maxwell-Dirac for small
  critical data

  In this paper, we prove global well-posedness of the massless Maxwell-Dirac
equation in Coulomb gauge on $\mathbb{R}^{1+d}$ $(d \geq 4)$ for data with
small scale-critical Sobolev norm, as well as modified scattering of the
solutions. Main components of our proof are A) uncovering null structure of
Maxwell-Dirac in the Coulomb gauge, and B) proving solvability of the
underlying covariant Dirac equation. A key step for achieving both is to
exploit (and justify) a deep analogy between Maxwell-Dirac and
Maxwell-Klein-Gordon (for which an analogous result was proved earlier by
Krieger-Sterbenz-Tataru), which says that the most difficult part of
Maxwell-Dirac takes essentially the same form as Maxwell-Klein-Gordon.


Exotic Neutrino Interactions at the Pierre Auger Observatory

  The Pierre Auger Observatory for cosmic rays provides a laboratory for
studying fundamental interactions at energies well beyond those available at
colliders. In addition to hadrons or photons, Auger is sensitive to ultra-high
energy neutrinos in the cosmic radiation and models for new physics can be
explored by observing neutrino interactions at center-of-mass energies beyond
the TeV scale. By comparing the rate for quasi-horizontal, deeply penetrating
air showers triggered by all types of neutrinos with the rate for slightly
upgoing showers generated by Earth-skimming tau neutrinos, any deviation of the
neutrino-nucleon cross-section from the Standard Model expectation can be
constrained. We show that this can test models of low-scale quantum gravity
(including processes such as Kaluza-Klein graviton exchange, microscopic black
hole production and string resonances), as well as non-perturbative electroweak
instanton mediated processes. Moreover, the observed ratios of neutrino flavors
would severely constrain the possibility of neutrino decay.


Thermodynamics of five-dimensional static three-charge STU black holes
  with squashed horizons

  We present a new expression for the five-dimensional static Kaluza-Klein
black hole solution with squashed $S^3$ horizons and three different charge
parameters. This black hole solution belongs to $D = 5$ $N = 2$ supergravity
theory, its spacetime is locally asymptotically flat and has a spatial infinity
$R \times S^1 \hookrightarrow S^2$. The form of the solution is extraordinary
simple and permits us very conveniently to calculate its conserved charges by
using the counterterm method. It is further shown that our thermodynamical
quantities perfectly obey both the differential and the integral first laws of
black hole thermodynamics if the length of the compact extra-dimension can be
viewed as a thermodynamical variable.


Learning Dependency-Based Compositional Semantics

  Suppose we want to build a system that answers a natural language question by
representing its semantics as a logical form and computing the answer given a
structured database of facts. The core part of such a system is the semantic
parser that maps questions to logical forms. Semantic parsers are typically
trained from examples of questions annotated with their target logical forms,
but this type of annotation is expensive.
  Our goal is to learn a semantic parser from question-answer pairs instead,
where the logical form is modeled as a latent variable. Motivated by this
challenging learning problem, we develop a new semantic formalism,
dependency-based compositional semantics (DCS), which has favorable linguistic,
statistical, and computational properties. We define a log-linear distribution
over DCS logical forms and estimate the parameters using a simple procedure
that alternates between beam search and numerical optimization. On two standard
semantic parsing benchmarks, our system outperforms all existing
state-of-the-art systems, despite using no annotated logical forms.


Mixture-of-Parents Maximum Entropy Markov Models

  We present the mixture-of-parents maximum entropy Markov model (MoP-MEMM), a
class of directed graphical models extending MEMMs. The MoP-MEMM allows
tractable incorporation of long-range dependencies between nodes by restricting
the conditional distribution of each node to be a mixture of distributions
given the parents. We show how to efficiently compute the exact marginal
posterior node distributions, regardless of the range of the dependencies. This
enables us to model non-sequential correlations present within text documents,
as well as between interconnected documents, such as hyperlinked web pages. We
apply the MoP-MEMM to a named entity recognition task and a web page
classification task. In each, our model shows significant improvement over the
basic MEMM, and is competitive with other long-range sequence models that use
approximate inference.


Neural Module Networks

  Visual question answering is fundamentally compositional in nature---a
question like "where is the dog?" shares substructure with questions like "what
color is the dog?" and "where is the cat?" This paper seeks to simultaneously
exploit the representational capacity of deep networks and the compositional
linguistic structure of questions. We describe a procedure for constructing and
learning *neural module networks*, which compose collections of jointly-trained
neural "modules" into deep networks for question answering. Our approach
decomposes questions into their linguistic substructures, and uses these
structures to dynamically instantiate modular networks (with reusable
components for recognizing dogs, classifying colors, etc.). The resulting
compound networks are jointly trained. We evaluate our approach on two
challenging datasets for visual question answering, achieving state-of-the-art
results on both the VQA natural image dataset and a new dataset of complex
questions about abstract shapes.


Learning-Based Single-Document Summarization with Compression and
  Anaphoricity Constraints

  We present a discriminative model for single-document summarization that
integrally combines compression and anaphoricity constraints. Our model selects
textual units to include in the summary based on a rich set of sparse features
whose weights are learned on a large corpus. We allow for the deletion of
content within a sentence when that deletion is licensed by compression rules;
in our framework, these are implemented as dependencies between subsentential
units of text. Anaphoricity constraints then improve cross-sentence coherence
by guaranteeing that, for each pronoun included in the summary, the pronoun's
antecedent is included as well or the pronoun is rewritten as a full mention.
When trained end-to-end, our final system outperforms prior work on both ROUGE
as well as on human judgments of linguistic quality.


Translating Neuralese

  Several approaches have recently been proposed for learning decentralized
deep multiagent policies that coordinate via a differentiable communication
channel. While these policies are effective for many tasks, interpretation of
their induced communication strategies has remained a challenge. Here we
propose to interpret agents' messages by translating them. Unlike in typical
machine translation problems, we have no parallel data to learn from. Instead
we develop a translation model based on the insight that agent messages and
natural language strings mean the same thing if they induce the same belief
about the world in a listener. We present theoretical guarantees and empirical
evidence that our approach preserves both the semantics and pragmatics of
messages by ensuring that players communicating through a translation layer do
not suffer a substantial loss in reward relative to players with a common
language.


On the accuracy of self-normalized log-linear models

  Calculation of the log-normalizer is a major computational obstacle in
applications of log-linear models with large output spaces. The problem of fast
normalizer computation has therefore attracted significant attention in the
theoretical and applied machine learning literature. In this paper, we analyze
a recently proposed technique known as "self-normalization", which introduces a
regularization term in training to penalize log normalizers for deviating from
zero. This makes it possible to use unnormalized model scores as approximate
probabilities. Empirical evidence suggests that self-normalization is extremely
effective, but a theoretical understanding of why it should work, and how
generally it can be applied, is largely lacking. We prove generalization bounds
on the estimated variance of normalizers and upper bounds on the loss in
accuracy due to self-normalization, describe classes of input distributions
that self-normalize easily, and construct explicit examples of high-variance
input distributions. Our theoretical results make predictions about the
difficulty of fitting self-normalized models to several classes of
distributions, and we conclude with empirical validation of these predictions.


Neural CRF Parsing

  This paper describes a parsing model that combines the exact dynamic
programming of CRF parsing with the rich nonlinear featurization of neural net
approaches. Our model is structurally a CRF that factors over anchored rule
productions, but instead of linear potential functions based on sparse
features, we use nonlinear potentials computed via a feedforward neural
network. Because potentials are still local to anchored rules, structured
inference (CKY) is unchanged from the sparse case. Computing gradients during
learning involves backpropagating an error signal formed from standard CRF
sufficient statistics (expected rule counts). Using only dense features, our
neural CRF already exceeds a strong baseline CRF model (Hall et al., 2014). In
combination with sparse features, our system achieves 91.1 F1 on section 23 of
the Penn Treebank, and more generally outperforms the best prior single parser
results on a range of languages.


Wave-particle duality coming from a bead oscillator in an elastic
  medium, theoretical study and quantum similarities

  We introduce a dual wave-particle macroscopic system, where a bead oscillator
oscillates in an elastic medium which obeys the Klein-Gordon equation. This
theoretical system is mostly inspired by bouncing droplets experiments and bead
sliding on a vibrating string experiments. This system is studied using a
common and simple mathematical formalism. We compute the motion equation of the
bead as well as the wave equation of the system. We introduce the effective
velocity of the bead with respect to the elastic medium and the wave $\psi$,
created by the bead, which modulates the natural wave of the medium. Provided
some conditions, $\psi$ obeys an equation analogous to the free Schr\"odinger
equation. In the case of linear and spherical cavities, the particle-like
characteristics of the bead, expressed with its effective velocity, are
proportional to the corresponding wave-like characteristics of the system.
  This paper is a translation of Dualit\'e onde-corpuscule form\'ee par une
masselotte oscillante dans un milieu \'elastique : \'etude th\'eorique et
similitudes quantiques.


Modular Multitask Reinforcement Learning with Policy Sketches

  We describe a framework for multitask deep reinforcement learning guided by
policy sketches. Sketches annotate tasks with sequences of named subtasks,
providing information about high-level structural relationships among tasks but
not how to implement them---specifically not providing the detailed guidance
used by much previous work on learning policy abstractions for RL (e.g.
intermediate rewards, subtask completion signals, or intrinsic motivations). To
learn from sketches, we present a model that associates every subtask with a
modular subpolicy, and jointly maximizes reward over full task-specific
policies by tying parameters across shared subpolicies. Optimization is
accomplished via a decoupled actor--critic training objective that facilitates
learning common behaviors from multiple dissimilar reward functions. We
evaluate the effectiveness of our approach in three environments featuring both
discrete and continuous control, and with sparse rewards that can be obtained
only after completing a number of high-level subgoals. Experiments show that
using our approach to learn policies guided by sketches gives better
performance than existing techniques for learning task-specific or shared
policies, while naturally inducing a library of interpretable primitive
behaviors that can be recombined to rapidly adapt to new tasks.


Improving Neural Parsing by Disentangling Model Combination and
  Reranking Effects

  Recent work has proposed several generative neural models for constituency
parsing that achieve state-of-the-art results. Since direct search in these
generative models is difficult, they have primarily been used to rescore
candidate outputs from base parsers in which decoding is more straightforward.
We first present an algorithm for direct search in these generative models. We
then demonstrate that the rescoring results are at least partly due to implicit
model combination rather than reranking effects. Finally, we show that explicit
model combination can improve performance even further, resulting in new
state-of-the-art numbers on the PTB of 94.25 F1 when training only on gold data
and 94.66 F1 when using external data.


Parsing with Traces: An $O(n^4)$ Algorithm and a Structural
  Representation

  General treebank analyses are graph structured, but parsers are typically
restricted to tree structures for efficiency and modeling reasons. We propose a
new representation and algorithm for a class of graph structures that is
flexible enough to cover almost all treebank structures, while still admitting
efficient learning and inference. In particular, we consider directed, acyclic,
one-endpoint-crossing graph structures, which cover most long-distance
dislocation, shared argumentation, and similar tree-violating linguistic
phenomena. We describe how to convert phrase structure parses, including
traces, to our new representation in a reversible manner. Our dynamic program
uniquely decomposes structures, is sound and complete, and covers 97.3% of the
Penn English Treebank. We also implement a proof-of-concept parser that
recovers a range of null elements and trace types.


Effective Inference for Generative Neural Parsing

  Generative neural models have recently achieved state-of-the-art results for
constituency parsing. However, without a feasible search procedure, their use
has so far been limited to reranking the output of external parsers in which
decoding is more tractable. We describe an alternative to the conventional
action-level beam search used for discriminative neural models that enables us
to decode directly in these generative models. We then show that by improving
our basic candidate selection strategy and using a coarse pruning function, we
can improve accuracy while exploring significantly less of the search space.
Applied to the model of Choe and Charniak (2016), our inference procedure
obtains 92.56 F1 on section 23 of the Penn Treebank, surpassing prior
state-of-the-art results for single-model systems.


Learning with Latent Language

  The named concepts and compositional operators present in natural language
provide a rich source of information about the kinds of abstractions humans use
to navigate the world. Can this linguistic background knowledge improve the
generality and efficiency of learned classifiers and control policies? This
paper aims to show that using the space of natural language strings as a
parameter space is an effective way to capture natural task structure. In a
pretraining phase, we learn a language interpretation model that transforms
inputs (e.g. images) into outputs (e.g. labels) given natural language
descriptions. To learn a new concept (e.g. a classifier), we search directly in
the space of descriptions to minimize the interpreter's loss on training
examples. Crucially, our models do not require language data to learn these
concepts: language is used only in pretraining to impose structure on
subsequent learning. Results on image classification, text editing, and
reinforcement learning show that, in all settings, models with a linguistic
parameterization outperform those without.


Unified Pragmatic Models for Generating and Following Instructions

  We show that explicit pragmatic inference aids in correctly generating and
following natural language instructions for complex, sequential tasks. Our
pragmatics-enabled models reason about why speakers produce certain
instructions, and about how listeners will react upon hearing them. Like
previous pragmatic models, we use learned base listener and speaker models to
build a pragmatic speaker that uses the base listener to simulate the
interpretation of candidate descriptions, and a pragmatic listener that reasons
counterfactually about alternative descriptions. We extend these models to
tasks with sequential structure. Evaluation of language generation and
interpretation shows that pragmatic inference improves state-of-the-art
listener models (at correctly interpreting human instructions) and speaker
models (at producing instructions correctly interpreted by humans) in diverse
settings.


What's Going On in Neural Constituency Parsers? An Analysis

  A number of differences have emerged between modern and classic approaches to
constituency parsing in recent years, with structural components like grammars
and feature-rich lexicons becoming less central while recurrent neural network
representations rise in popularity. The goal of this work is to analyze the
extent to which information provided directly by the model structure in
classical systems is still being captured by neural methods. To this end, we
propose a high-performance neural model (92.08 F1 on PTB) that is
representative of recent work and perform a series of investigative
experiments. We find that our model implicitly learns to encode much of the
same information that was explicitly provided by grammars and lexicons in the
past, indicating that this scaffolding can largely be subsumed by powerful
general-purpose neural machinery.


Constituency Parsing with a Self-Attentive Encoder

  We demonstrate that replacing an LSTM encoder with a self-attentive
architecture can lead to improvements to a state-of-the-art discriminative
constituency parser. The use of attention makes explicit the manner in which
information is propagated between different locations in the sentence, which we
use to both analyze our model and propose potential improvements. For example,
we find that separating positional and content information in the encoder can
lead to improved parsing accuracy. Additionally, we evaluate different
approaches for lexical representation. Our parser achieves new state-of-the-art
results for single models trained on the Penn Treebank: 93.55 F1 without the
use of any external data, and 95.13 F1 when using pre-trained word
representations. Our parser also outperforms the previous best-published
accuracy figures on 8 of the 9 languages in the SPMRL dataset.


Policy Gradient as a Proxy for Dynamic Oracles in Constituency Parsing

  Dynamic oracles provide strong supervision for training constituency parsers
with exploration, but must be custom defined for a given parser's transition
system. We explore using a policy gradient method as a parser-agnostic
alternative. In addition to directly optimizing for a tree-level metric such as
F1, policy gradient has the potential to reduce exposure bias by allowing
exploration during training; moreover, it does not require a dynamic oracle for
supervision. On four constituency parsers in three languages, the method
substantially outperforms static oracle likelihood training in almost all
settings. For parsers where a dynamic oracle is available (including a novel
oracle which we define for the transition system of Dyer et al. 2016), policy
gradient typically recaptures a substantial fraction of the performance gain
afforded by the dynamic oracle.


Triplet Lifetime in Gaseous Argon

  MiniCLEAN is a single-phase liquid argon dark matter experiment. During the
initial cooling phase, impurities within the cold gas ($<$140 K) were monitored
by measuring the scintillation light triplet lifetime, and ultimately a triplet
lifetime of 3.480 $\pm$ 0.001 (stat.) $\pm$ 0.064 (sys.) $\mu$s was obtained,
indicating ultra-pure argon. This is the longest argon triplet time constant
ever reported. The effect of quenching of separate components of the
scintillation light is also investigated.


Pragmatically Informative Text Generation

  We improve the informativeness of models for conditional text generation
using techniques from computational pragmatics. These techniques formulate
language production as a game between speakers and listeners, in which a
speaker should generate output text that a listener can use to correctly
identify the original input that the text describes. While such approaches are
widely used in cognitive science and grounded language learning, they have
received less attention for more standard language generation tasks. We
consider two pragmatic modeling methods for text generation: one where
pragmatics is imposed by information preservation, and another where pragmatics
is imposed by explicit modeling of distractors. We find that these methods
improve the performance of strong existing systems for abstractive
summarization and generation from structured meaning representations.


Prospects For Detecting Dark Matter With GLAST In Light Of The WMAP Haze

  Observations by the WMAP experiment have identified an excess of microwave
emission from the center of the Milky Way. It has previously been shown that
this "WMAP Haze" could be synchrotron emission from relativistic electrons and
positrons produced in the annihilations of dark matter particles. In
particular, the intensity, spectrum and angular distribution of the WMAP Haze
is consistent with an electroweak scale dark matter particle (such as a
supersymmetric neutralino or Kaluza-Klein dark matter in models with universal
extra dimensions) annihilating with a cross section on the order of sigma
v~3x10^-26 cm^3/s and distributed with a cusped halo profile. No further exotic
astrophysical or annihilation boost factors are required. If dark matter
annihilations are in fact responsible for the observed Haze, then other
annihilation products will also be produced, including gamma rays. In this
article, we study the prospects for the GLAST satellite to detect gamma rays
from dark matter annihilations in the Galactic Center region in this scenario.
We find that by studying only the inner 0.1 degrees around the Galactic Center,
GLAST will be able to detect dark matter annihilating to heavy quarks or gauge
bosons over astrophysical backgrounds with 5sigma (3sigma) significance if they
are lighter than approximately 320-500 GeV (500-750 GeV). If the angular window
is broadened to study the dark matter halo profile's angular extension (while
simultaneously reducing the astrophysical backgrounds), WIMPs as heavy as
several TeV can be identified by GLAST with high significance. Only if the dark
matter particles annihilate mostly to electrons or muons will GLAST be unable
to identify the gamma ray spectrum associated with the WMAP Haze.


