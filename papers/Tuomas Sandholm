Strong Nash equilibria and mixed strategies

  In this paper we consider strong Nash equilibria, in mixed strategies, forfinite games. Any strong Nash equilibrium outcome is Pareto efficient for eachcoalition. First, we analyze the two--player setting. Our main result, in itssimplest form, states that if a game has a strong Nash equilibrium with fullsupport (that is, both players randomize among all pure strategies), then thegame is strictly competitive. In order to get our result we use theindifference principle fulfilled by any Nash equilibrium, and the classical KKTconditions (in the vector setting), that are necessary conditions for Paretoefficiency. Our characterization enables us to design astrong-Nash-equilibrium-finding algorithm with complexity inSmoothed-$\mathcal{P}$. So, this problem---that Conitzer and Sandholm[Conitzer, V., Sandholm, T., 2008. New complexity results about Nashequilibria. Games Econ. Behav. 63, 621--641] proved to be computationally hardin the worst case---is generically easy. Hence, although the worst casecomplexity of finding a strong Nash equilibrium is harder than that of findinga Nash equilibrium, once small perturbations are applied, finding a strong Nashis easier than finding a Nash equilibrium. Next we switch to the setting withmore than two players. We demonstrate that a strong Nash equilibrium can existin which an outcome that is strictly Pareto dominated by a Nash equilibriumoccurs with positive probability. Finally, we prove that games that have astrong Nash equilibrium where at least one player puts positive probability onat least two pure strategies are extremely rare: they are of zero measure.

Common Voting Rules as Maximum Likelihood Estimators

  Voting is a very general method of preference aggregation. A voting ruletakes as input every voter's vote (typically, a ranking of the alternatives),and produces as output either just the winning alternative or a ranking of thealternatives. One potential view of voting is the following. There exists a'correct' outcome (winner/ranking), and each voter's vote corresponds to anoisy perception of this correct outcome. If we are given the noise model, thenfor any vector of votes, we can

Combining local search techniques and path following for bimatrix games

  Computing a Nash equilibrium (NE) is a central task in computer science. AnNE is a particularly appropriate solution concept for two-agent settingsbecause coalitional deviations are not an issue. However, even in this case,finding an NE is PPAD-complete. In this paper, we combine path followingalgorithms with local search techniques to design new algorithms for findingexact and approximate NEs. We show that our algorithms largely outperform thestate of the art and that almost all the known benchmark game classes areeasily solvable or approximable (except for the GAMUT CovariantGameRand class).

Reduced Space and Faster Convergence in Imperfect-Information Games via  Regret-Based Pruning

  Counterfactual Regret Minimization (CFR) is the most popular iterativealgorithm for solving zero-sum imperfect-information games. Regret-BasedPruning (RBP) is an improvement that allows poorly-performing actions to betemporarily pruned, thus speeding up CFR. We introduce Total RBP, a new form ofRBP that reduces the space requirements of CFR as actions are pruned. We provethat in zero-sum games it asymptotically prunes any action that is not part ofa best response to some Nash equilibrium. This leads to provably fasterconvergence and lower space requirements. Experiments show that Total RBPresults in an order of magnitude reduction in space, and the reduction factorincreases with game size.

On the Verification and Computation of Strong Nash Equilibrium

  Computing equilibria of games is a central task in computer science. A largenumber of results are known for \emph{Nash equilibrium} (NE). However, thesecan be adopted only when coalitions are not an issue. When instead agents canform coalitions, NE is inadequate and an appropriate solution concept is\emph{strong Nash equilibrium} (SNE). Few computational results are known aboutSNE. In this paper, we first study the problem of verifying whether a strategyprofile is an SNE, showing that the problem is in $\mathcal{P}$. We then designa spatial branch--and--bound algorithm to find an SNE, and we experimentallyevaluate the algorithm.

Effectiveness of Preference Elicitation in Combinatorial Auctions

  Combinatorial auctions where agents can bid on bundles of items are desirablebecause they allow the agents to express complementarity and substitutabilitybetween the items. However, expressing one's preferences can require bidding onall bundles. Selective incremental preference elicitation by the auctioneer wasrecently proposed to address this problem (Conen & Sandholm 2001), but the ideawas not evaluated. In this paper we show, experimentally and theoretically,that automated elicitation provides a drastic benefit. In all of theelicitation schemes under study, as the number of items for sale increases, theamount of information elicited is a vanishing fraction of the informationcollected in traditional ``direct revelation mechanisms'' where bidders revealall their valuation information. Most of the elicitation schemes also maintainthe benefit as the number of agents increases. We develop more effectiveelicitation policies for existing query types. We also present a new query typethat takes the incremental nature of elicitation to a new level by allowingagents to give approximate answers that are refined only on an as-needed basis.In the process, we present methods for evaluating different types ofelicitation policies.

Vote Elicitation: Complexity and Strategy-Proofness

  Preference elicitation is a central problem in AI, and has receivedsignificant attention in single-agent settings. It is also a key problem inmultiagent systems, but has received little attention here so far. In thissetting, the agents may have different preferences that often must beaggregated using voting. This leads to interesting issues because what, if any,information should be elicited from an agent depends on what other agents haverevealed about their preferences so far.  In this paper we study effective elicitation, and its impediments, for themost common voting protocols. It turns out that in the Single Transferable Voteprotocol, even knowing when to terminate elicitation is mathcal NP-complete,while this is easy for all the other protocols under study. Even for theseprotocols, determining how to elicit effectively is NP-complete, even withperfect suspicions about how the agents will vote. The exception is thePlurality protocol where such effective elicitation is easy.  We also show that elicitation introduces additional opportunities forstrategic manipulation by the voters. We demonstrate how to curtail the spaceof elicitation schemes so that no such additional strategic issues arise.

Complexity Results about Nash Equilibria

  Noncooperative game theory provides a normative framework for analyzingstrategic interactions. However, for the toolbox to be operational, thesolutions it defines will have to be computed. In this paper, we provide asingle reduction that 1) demonstrates NP-hardness of determining whether Nashequilibria with certain natural properties exist, and 2) demonstrates the#P-hardness of counting Nash equilibria (or connected sets of Nash equilibria).We also show that 3) determining whether a pure-strategy Bayes-Nash equilibriumexists is NP-hard, and that 4) determining whether a pure-strategy Nashequilibrium exists in a stochastic (Markov) game is PSPACE-hard even if thegame is invisible (this remains NP-hard if the game is finite). All of ourhardness results hold even if there are only two players and the game issymmetric.  Keywords: Nash equilibrium; game theory; computational complexity;noncooperative game theory; normal form game; stochastic game; Markov game;Bayes-Nash equilibrium; multiagent systems.

Complexity of Mechanism Design

  The aggregation of conflicting preferences is a central problem in multiagentsystems. The key difficulty is that the agents may report their preferencesinsincerely. Mechanism design is the art of designing the rules of the game sothat the agents are motivated to report their preferences truthfully and a(socially) desirable outcome is chosen. We propose an approach where amechanism is automatically created for the preference aggregation setting athand. This has several advantages, but the downside is that the mechanismdesign optimization problem needs to be solved anew each time. Focusing onsettings where side payments are not possible, we show that the mechanismdesign problem is NP-complete for deterministic mechanisms. This holds both fordominant-strategy implementation and for Bayes-Nash implementation. We thenshow that if we allow randomized mechanisms, the mechanism design problembecomes tractable. In other words, the coordinator can tackle the computationalcomplexity introduced by its uncertainty about the agents' preferences bymaking the agents face additional uncertainty. This comes at no loss, and insome cases at a gain, in the (social) objective.

AWESOME: A General Multiagent Learning Algorithm that Converges in  Self-Play and Learns a Best Response Against Stationary Opponents

  A satisfactory multiagent learning algorithm should, {\em at a minimum},learn to play optimally against stationary opponents and converge to a Nashequilibrium in self-play. The algorithm that has come closest, WoLF-IGA, hasbeen proven to have these two properties in 2-player 2-action repeatedgames--assuming that the opponent's (mixed) strategy is observable. In thispaper we present AWESOME, the first algorithm that is guaranteed to have thesetwo properties in {\em all} repeated (finite) games. It requires only that theother players' actual actions (not their strategies) can be observed at eachstep. It also learns to play optimally against opponents that {\em eventuallybecome} stationary. The basic idea behind AWESOME ({\em Adapt When Everybody isStationary, Otherwise Move to Equilibrium}) is to try to adapt to the others'strategies when they appear stationary, but otherwise to retreat to aprecomputed equilibrium strategy. The techniques used to prove the propertiesof AWESOME are fundamentally different from those used for previous algorithms,and may help in analyzing other multiagent learning algorithms also.

Definition and Complexity of Some Basic Metareasoning Problems

  In most real-world settings, due to limited time or other resources, an agentcannot perform all potentially useful deliberation and information gatheringactions. This leads to the metareasoning problem of selecting such actions.Decision-theoretic methods for metareasoning have been studied in AI, but thereare few theoretical results on the complexity of metareasoning.  We derive hardness results for three settings which most real metareasoningsystems would have to encompass as special cases. In the first, the agent hasto decide how to allocate its deliberation time across anytime algorithmsrunning on different problem instances. We show this to be$\mathcal{NP}$-complete. In the second, the agent has to (dynamically) allocateits deliberation or information gathering resources across multiple actionsthat it has to choose among. We show this to be $\mathcal{NP}$-hard even whenevaluating each individual action is extremely simple. In the third, the agenthas to (dynamically) choose a limited number of deliberation or informationgathering actions to disambiguate the state of the world. We show that this is$\mathcal{NP}$-hard under a natural restriction, and $\mathcal{PSPACE}$-hard ingeneral.

Algorithms for Closed Under Rational Behavior (CURB) Sets

  We provide a series of algorithms demonstrating that solutions according tothe fundamental game-theoretic solution concept of closed under rationalbehavior (CURB) sets in two-player, normal-form games can be computed inpolynomial time (we also discuss extensions to n-player games). First, wedescribe an algorithm that identifies all of a player's best responsesconditioned on the belief that the other player will play from within a givensubset of its strategy space. This algorithm serves as a subroutine in a seriesof polynomial-time algorithms for finding all minimal CURB sets, one minimalCURB set, and the smallest minimal CURB set in a game. We then show that thecomplexity of finding a Nash equilibrium can be exponential only in the size ofa game's smallest CURB set. Related to this, we show that the smallest CURB setcan be an arbitrarily small portion of the game, but it can also be arbitrarilylarger than the supports of its only enclosed Nash equilibrium. We test ouralgorithms empirically and find that most commonly studied academic games tendto have either very large or very small minimal CURB sets.

Complexity of Mechanism Design

  The aggregation of conflicting preferences is a central problem in multiagentsystems. The key difficulty is that the agents may report their preferencesinsincerely. Mechanism design is the art of designing the rules of the game sothat the agents are motivated to report their preferences truthfully and a(socially) desirable outcome is chosen. We propose an approach where amechanism is automatically created for the preference aggregation setting athand. This has several advantages, but the downside is that the mechanismdesign optimization problem needs to be solved anew each time. Focusing onsettings where side payments are not possible, we show that the mechanismdesign problem is NP-complete for deterministic mechanisms. This holds both fordominant-strategy implementation and for Bayes-Nash implementation. We thenshow that if we allow randomized mechanisms, the mechanism design problembecomes tractable. In other words, the coordinator can tackle the computationalcomplexity introduced by its uncertainty about the agents preferences BY makingthe agents face additional uncertainty.This comes at no loss, AND IN SOME casesat a gain, IN the(social) objective.

Small Representations of Big Kidney Exchange Graphs

  Kidney exchanges are organized markets where patients swap willing butincompatible donors. In the last decade, kidney exchanges grew from small andregional to large and national---and soon, international. This growth resultsin more lives saved, but exacerbates the empirical hardness of the$\mathcal{NP}$-complete problem of optimally matching patients to donors.State-of-the-art matching engines use integer programming techniques to clearfielded kidney exchanges, but these methods must be tailored to specific modelsand objective functions, and may fail to scale to larger exchanges. In thispaper, we observe that if the kidney exchange compatibility graph can beencoded by a constant number of patient and donor attributes, the clearingproblem is solvable in polynomial time. We give necessary and sufficientconditions for losslessly shrinking the representation of an arbitrarycompatibility graph. Then, using real compatibility graphs from the UNOSnationwide kidney exchange, we show how many attributes are needed to encodereal compatibility graphs. The experiments show that, indeed, small numbers ofattributes suffice.

Hardness of the Pricing Problem for Chains in Barter Exchanges

  Kidney exchange is a barter market where patients trade willing but medicallyincompatible donors. These trades occur via cycles, where each patient-donorpair both gives and receives a kidney, and via chains, which begin with analtruistic donor who does not require a kidney in return. For logisticalreasons, the maximum length of a cycle is typically limited to a smallconstant, while chains can be much longer. Given a compatibility graph ofpatient-donor pairs, altruists, and feasible potential transplants betweenthem, finding even a maximum-cardinality set of vertex-disjoint cycles andchains is NP-hard. There has been much work on developing provably optimalsolvers that are efficient in practice. One of the leading techniques has beenbranch and price, where column generation is used to incrementally bring cyclesand chains into the optimization model on an as-needed basis. In particular,only positive-price columns need to be brought into the model. We prove thatfinding a positive-price chain is NP-complete. This shows incorrectness of twoleading branch-and-price solvers that suggested polynomial-time chain pricingalgorithms.

Safe and Nested Subgame Solving for Imperfect-Information Games

  In imperfect-information games, the optimal strategy in a subgame may dependon the strategy in other, unreached subgames. Thus a subgame cannot be solvedin isolation and must instead consider the strategy for the entire game as awhole, unlike perfect-information games. Nevertheless, it is possible to firstapproximate a solution for the whole game and then improve it by solvingindividual subgames. This is referred to as subgame solving. We introducesubgame-solving techniques that outperform prior methods both in theory andpractice. We also show how to adapt them, and past subgame-solving techniques,to respond to opponent actions that are outside the original actionabstraction; this significantly outperforms the prior state-of-the-artapproach, action translation. Finally, we show that subgame solving can berepeated as the game progresses down the game tree, leading to far lowerexploitability. These techniques were a key component of Libratus, the first AIto defeat top humans in heads-up no-limit Texas hold'em poker.

Regret Minimization in Behaviorally-Constrained Zero-Sum Games

  No-regret learning has emerged as a powerful tool for solving extensive-formgames. This was facilitated by the counterfactual-regret minimization (CFR)framework, which relies on the instantiation of regret minimizers for simplexesat each information set of the game. We use an instantiation of the CFRframework to develop algorithms for solving behaviorally-constrained (and, as aspecial case, perturbed in the Selten sense) extensive-form games, which allowsus to compute approximate Nash equilibrium refinements. Nash equilibriumrefinements are motivated by a major deficiency in Nash equilibrium: itprovides virtually no guarantees on how it will play in parts of the game treethat are reached with zero probability. Refinements can mend this issue, buthave not been adopted in practice, mostly due to a lack of scalable algorithms.We show that, compared to standard algorithms, our method finds solutions thathave substantially better refinement properties, while enjoying a convergencerate that is comparable to that of state-of-the-art algorithms for Nashequilibrium computation both in theory and practice.

Robust Stackelberg Equilibria in Extensive-Form Games and Extension to  Limited Lookahead

  Stackelberg equilibria have become increasingly important as a solutionconcept in computational game theory, largely inspired by practical problemssuch as security settings. In practice, however, there is typically uncertaintyregarding the model about the opponent. This paper is, to our knowledge, thefirst to investigate Stackelberg equilibria under uncertainty in extensive-formgames, one of the broadest classes of game. We introduce robust Stackelbergequilibria, where the uncertainty is about the opponent's payoffs, as well asones where the opponent has limited lookahead and the uncertainty is about theopponent's node evaluation function. We develop a new mixed-integer program forthe deterministic limited-lookahead setting. We then extend the program to therobust setting for Stackelberg equilibrium under unlimited and under limitedlookahead by the opponent. We show that for the specific case of intervaluncertainty about the opponent's payoffs (or about the opponent's nodeevaluations in the case of limited lookahead), robust Stackelberg equilibriacan be computed with a mixed-integer program that is of the same asymptoticsize as that for the deterministic setting.

Depth-Limited Solving for Imperfect-Information Games

  A fundamental challenge in imperfect-information games is that states do nothave well-defined values. As a result, depth-limited search algorithms used insingle-agent settings and perfect-information games do not apply. This paperintroduces a principled way to conduct depth-limited solving inimperfect-information games by allowing the opponent to choose among a numberof strategies for the remainder of the game at the depth limit. Each one ofthese strategies results in a different set of values for leaf nodes. Thisforces an agent to be robust to the different strategies an opponent mayemploy. We demonstrate the effectiveness of this approach by building amaster-level heads-up no-limit Texas hold'em poker AI that defeats two priortop agents using only a 4-core CPU and 16 GB of memory. Developing such apowerful agent would have previously required a supercomputer.

Solving Imperfect-Information Games via Discounted Regret Minimization

  Counterfactual regret minimization (CFR) is a family of iterative algorithmsthat are the most popular and, in practice, fastest approach to approximatelysolving large imperfect-information games. In this paper we introduce novel CFRvariants that 1) discount regrets from earlier iterations in various ways (insome cases differently for positive and negative regrets), 2) reweightiterations in various ways to obtain the output strategies, 3) use anon-standard regret minimizer and/or 4) leverage "optimistic regret matching".They lead to dramatically improved performance in many settings. For one, weintroduce a variant that outperforms CFR+, the prior state-of-the-artalgorithm, in every game tested, including large-scale realistic settings. CFR+is a formidable benchmark: no other algorithm has been able to outperform it.Finally, we show that, unlike CFR+, many of the important new variants arecompatible with modern imperfect-information-game pruning techniques and one isalso compatible with sampling in the game tree.

Deep Counterfactual Regret Minimization

  Counterfactual Regret Minimization (CFR) is the leading algorithm for solvinglarge imperfect-information games. It iteratively traverses the game tree inorder to converge to a Nash equilibrium. In order to deal with extremely largegames, CFR typically uses domain-specific heuristics to simplify the targetgame in a process known as abstraction. This simplified game is solved withtabular CFR, and its solution is mapped back to the full game. This paperintroduces Deep Counterfactual Regret Minimization (Deep CFR), a form of CFRthat obviates the need for abstraction by instead using deep neural networks toapproximate the behavior of CFR in the full game. We show that Deep CFR isprincipled and achieves strong performance in large poker games. This is thefirst non-tabular variant of CFR to be successful in large games.

Regret Circuits: Composability of Regret Minimizers

  Regret minimization is a powerful tool for solving large-scale problems; itwas recently used in breakthrough results for large-scale extensive-form gamesolving. This was achieved by composing simplex regret minimizers into anoverall regret-minimization framework for extensive-form game strategy spaces.In this paper we study the general composability of regret minimizers. Wederive a calculus for constructing regret minimizers for composite convex setsthat are obtained from convexity-preserving operations on simpler convex sets.We show that local regret minimizers for the simpler sets can be combined withadditional regret minimizers into an aggregate regret minimizer for thecomposite set. As one application, we show that the CFR framework can beconstructed easily from our framework. We also show ways to include curtailing(constraining) operations into our framework. For one, they enables theconstruction of CFR generalization for extensive-form games with general convexstrategy constraints that can cut across decision points.

Quasi-Perfect Stackelberg Equilibrium

  Equilibrium refinements are important in extensive-form (i.e., tree-form)games, where they amend weaknesses of the Nash equilibrium concept by requiringsequential rationality and other beneficial properties. One of the mostattractive refinement concepts is quasi-perfect equilibrium. Whilequasi-perfection has been studied in extensive-form games, it is poorlyunderstood in Stackelberg settings---that is, settings where a leader cancommit to a strategy---which are important for modeling, for example, securitygames. In this paper, we introduce the axiomatic definition of quasi-perfectStackelberg equilibrium. We develop a broad class of game perturbation schemesthat lead to them in the limit. Our class of perturbation schemes strictlygeneralizes prior perturbation schemes introduced for the computation of(non-Stackelberg) quasi-perfect equilibria. Based on our perturbation schemes,we develop a branch-and-bound algorithm for computing a quasi-perfectStackelberg equilibrium. It leverages a perturbed variant of the linear programfor computing a Stackelberg extensive-form correlated equilibrium. Experimentsshow that our algorithm can be used to find an approximate quasi-perfectStackelberg equilibrium in games with thousands of nodes.

Stable-Predictive Optimistic Counterfactual Regret Minimization

  The CFR framework has been a powerful tool for solving large-scaleextensive-form games in practice. However, the theoretical rate at which pastCFR-based algorithms converge to the Nash equilibrium is on the order of$O(T^{-1/2})$, where $T$ is the number of iterations. In contrast, first-ordermethods can be used to achieve a $O(T^{-1})$ dependence on iterations, yetthese methods have been less successful in practice. In this work we presentthe first CFR variant that breaks the square-root dependence on iterations. Bycombining and extending recent advances on predictive and stable regretminimizers for the matrix-game setting we show that it is possible to leverage"optimistic" regret minimizers to achieve a $O(T^{-3/4})$ convergence ratewithin CFR. This is achieved by introducing a new notion ofstable-predictivity, and by setting the stability of each counterfactual regretminimizer relative to its location in the decision tree. Experiments show thatthis method is faster than the original CFR algorithm, although not as fast asnewer variants, in spite of their worst-case $O(T^{-1/2})$ dependence oniterations.

Limited Lookahead in Imperfect-Information Games

  Limited lookahead has been studied for decades in complete-information games.We initiate a new direction via two simultaneous deviation points:generalization to incomplete-information games and a game-theoretic approach.We study how one should act when facing an opponent whose lookahead is limited.We study this for opponents that differ based on their lookahead depth, basedon whether they, too, have incomplete information, and based on how they breakties. We characterize the hardness of finding a Nash equilibrium or an optimalcommitment strategy for either player, showing that in some of these variationsthe problem can be solved in polynomial time while in others it is PPAD-hard orNP-hard. We proceed to design algorithms for computing optimal commitmentstrategies---for when the opponent breaks ties favorably, according to a fixedrule, or adversarially. We then experimentally investigate the impact oflimited lookahead. The limited-lookahead player often obtains the value of thegame if she knows the expected values of nodes in the game tree for someequilibrium---but we prove this is not sufficient in general. Finally, we studythe impact of noise in those estimates and different lookahead depths. Thisuncovers an incomplete-information game lookahead pathology.

Anytime Coalition Structure Generation with Worst Case Guarantees

  Coalition formation is a key topic in multiagent systems. One would prefer acoalition structure that maximizes the sum of the values of the coalitions, butoften the number of coalition structures is too large to allow exhaustivesearch for the optimal one. But then, can the coalition structure found via apartial search be guaranteed to be within a bound from optimum? We show thatnone of the previous coalition structure generation algorithms can establishany bound because they search fewer nodes than a threshold that we shownecessary for establishing a bound. We present an algorithm that establishes atight bound within this minimal amount of search, and show that any otheralgorithm would have to search strictly more. The fraction of nodes needed tobe searched approaches zero as the number of agents grows. If additional timeremains, our anytime algorithm searches further, and establishes aprogressively lower tight bound. Surprisingly, just searching one more nodedrops the bound in half. As desired, our algorithm lowers the bound rapidlyearly on, and exhibits diminishing returns to computation. It also drasticallyoutperforms its obvious contenders. Finally, we show how to distribute thedesired search across self-interested manipulative agents.

Complexity of Manipulating Elections with Few Candidates

  In multiagent settings where the agents have different preferences,preference aggregation is a central issue. Voting is a general method forpreference aggregation, but seminal results have shown that all general votingprotocols are manipulable. One could try to avoid manipulation by using votingprotocols where determining a beneficial manipulation is hard. Especially amongcomputational agents, it is reasonable to measure this hardness bycomputational complexity. Some earlier work has been done in this area, but itwas assumed that the number of voters and candidates is unbounded. We derivehardness results for practical multiagent settings where the number ofcandidates is small but the number of voters can be large. We show that withcomplete information about the others' votes, individual manipulation is easy,and coalitional manipulation is easy with unweighted voters. However,constructive coalitional manipulation with weighted voters is intractable forall of the voting protocols under study, except for the nonrandomized Cup.Destructive manipulation tends to be easier. Randomizing over instantiations ofthe protocols (such as schedules of the Cup protocol) can be used to makemanipulation hard. Finally, we show that under weak assumptions, if weightedcoalitional manipulation with complete information about the others' votes ishard in some voting protocol, then individual and unweighted manipulation ishard when there is uncertainty about the others' votes.

How many candidates are needed to make elections hard to manipulate?

  In multiagent settings where the agents have different preferences,preference aggregation is a central issue. Voting is a general method forpreference aggregation, but seminal results have shown that all general votingprotocols are manipulable. One could try to avoid manipulation by using votingprotocols where determining a beneficial manipulation is hard computationally.The complexity of manipulating realistic elections where the number ofcandidates is a small constant was recently studied (Conitzer 2002), but theemphasis was on the question of whether or not a protocol becomes hard tomanipulate for some constant number of candidates. That work, in many cases,left open the question: How many candidates are needed to make elections hardto manipulate? This is a crucial question when comparing the relativemanipulability of different voting protocols. In this paper we answer thatquestion for the voting protocols of the earlier study: plurality, Borda, STV,Copeland, maximin, regular cup, and randomized cup. We also answer thatquestion for two voting protocols for which no results on the complexity ofmanipulation have been derived before: veto and plurality with runoff. It turnsout that the voting protocols under study become hard to manipulate at 3candidates, 4 candidates, 7 candidates, or never.

BL-WoLF: A Framework For Loss-Bounded Learnability In Zero-Sum Games

  We present BL-WoLF, a framework for learnability in repeated zero-sum gameswhere the cost of learning is measured by the losses the learning agent accrues(rather than the number of rounds). The game is adversarially chosen from somefamily that the learner knows. The opponent knows the game and the learner'slearning strategy. The learner tries to either not accrue losses, or to quicklylearn about the game so as to avoid future losses (this is consistent with theWin or Learn Fast (WoLF) principle; BL stands for ``bounded loss''). Ourframework allows for both probabilistic and approximate learning. The resultantnotion of {\em BL-WoLF}-learnability can be applied to any class of games, andallows us to measure the inherent disadvantage to a player that does not knowwhich game in the class it is in. We present {\em guaranteedBL-WoLF-learnability} results for families of games with deterministic payoffsand families of games with stochastic payoffs. We demonstrate that thesefamilies are {\em guaranteed approximately BL-WoLF-learnable} with lower cost.We then demonstrate families of games (both stochastic and deterministic) thatare not guaranteed BL-WoLF-learnable. We show that those families,nevertheless, are {\em BL-WoLF-learnable}. To prove these results, we use a keylemma which we derive.

Complexity of Determining Nonemptiness of the Core

  Coalition formation is a key problem in automated negotiation amongself-interested agents, and other multiagent applications. A coalition ofagents can sometimes accomplish things that the individual agents cannot, orcan do things more efficiently. However, motivating the agents to abide to asolution requires careful analysis: only some of the solutions are stable inthe sense that no group of agents is motivated to break off and form a newcoalition. This constraint has been studied extensively in cooperative gametheory. However, the computational questions around this constraint havereceived less attention. When it comes to coalition formation among softwareagents (that represent real-world parties), these questions become increasinglyexplicit.  In this paper we define a concise general representation for games incharacteristic form that relies on superadditivity, and show that it allows forefficient checking of whether a given outcome is in the core. We then show thatdetermining whether the core is nonempty is $\mathcal{NP}$-complete both withand without transferable utility. We demonstrate that what makes the problemhard in both cases is determining the collaborative possibilities (the set ofoutcomes possible for the grand coalition), by showing that if these are given,the problem becomes tractable in both cases. However, we then demonstrate thatfor a hybrid version of the problem, where utility transfer is possible onlywithin the grand coalition, the problem remains $\mathcal{NP}$-complete evenwhen the collaborative possibilities are given.

Universal Voting Protocol Tweaks to Make Manipulation Hard

  Voting is a general method for preference aggregation in multiagent settings,but seminal results have shown that all (nondictatorial) voting protocols aremanipulable. One could try to avoid manipulation by using voting protocolswhere determining a beneficial manipulation is hard computationally. A numberof recent papers study the complexity of manipulating existing protocols. Thispaper is the first work to take the next step of designing new protocols thatare especially hard to manipulate. Rather than designing these new protocolsfrom scratch, we instead show how to tweak existing protocols to makemanipulation hard, while leaving much of the original nature of the protocolintact. The tweak studied consists of adding one elimination preround to theelection. Surprisingly, this extremely simple and universal tweak makes typicalprotocols hard to manipulate! The protocols become NP-hard, #P-hard, orPSPACE-hard to manipulate, depending on whether the schedule of the preround isdetermined before the votes are collected, after the votes are collected, orthe scheduling and the vote collecting are interleaved, respectively. We provegeneral sufficient conditions on the protocols for this tweak to introduce thehardness, and show that the most common voting protocols satisfy thoseconditions. These are the first results in voting settings where manipulationis in a higher complexity class than NP (presuming PSPACE $\neq$ NP).

On the complexity of strong Nash equilibrium: Hard-to-solve instances  and smoothed complexity

  The computational characterization of game-theoretic solution concepts is acentral topic in artificial intelligence, with the aim of developingcomputationally efficient tools for finding optimal ways to behave in strategicinteractions. The central solution concept in game theory is Nash equilibrium(NE). However, it fails to capture the possibility that agents can formcoalitions (even in the 2-agent case). Strong Nash equilibrium (SNE) refines NEto this setting. It is known that finding an SNE is NP-complete when the numberof agents is constant. This hardness is solely due to the existence ofmixed-strategy SNEs, given that the problem of enumerating all pure-strategySNEs is trivially in P. Our central result is that, in order for a game to haveat least one non-pure-strategy SNE, the agents' payoffs restricted to theagents' supports must, in the case of 2 agents, lie on the same line, and, inthe case of n agents, lie on an (n - 1)-dimensional hyperplane. Leveraging thisresult, we provide two contributions. First, we develop worst-case instancesfor support-enumeration algorithms. These instances have only one SNE and thesupport size can be chosen to be of any size-in particular, arbitrarily large.Second, we prove that, unlike NE, finding an SNE is in smoothed polynomialtime: generic game instances (i.e., all instances except knife-edge cases) haveonly pure-strategy SNEs.

Imperfect-Recall Abstractions with Bounds in Games

  Imperfect-recall abstraction has emerged as the leading paradigm forpractical large-scale equilibrium computation in incomplete-information games.However, imperfect-recall abstractions are poorly understood, and only weakalgorithm-specific guarantees on solution quality are known. In this paper, weshow the first general, algorithm-agnostic, solution quality guarantees forNash equilibria and approximate self-trembling equilibria computed inimperfect-recall abstractions, when implemented in the original(perfect-recall) game. Our results are for a class of games that generalizesthe only previously known class of imperfect-recall abstractions where anyresults had been obtained. Further, our analysis is tighter in two ways, eachof which can lead to an exponential reduction in the solution quality errorbound.  We then show that for extensive-form games that satisfy certain properties,the problem of computing a bound-minimizing abstraction for a single level ofthe game reduces to a clustering problem, where the increase in our bound isthe distance function. This reduction leads to the first imperfect-recallabstraction algorithm with solution quality bounds. We proceed to show a dividein the class of abstraction problems. If payoffs are at the same scale at allinformation sets considered for abstraction, the input forms a metric space.Conversely, if this condition is not satisfied, we show that the input does notform a metric space. Finally, we use these results to experimentallyinvestigate the quality of our bound for single-level abstraction.

Sample Complexity of Automated Mechanism Design

  The design of revenue-maximizing combinatorial auctions, i.e. multi-itemauctions over bundles of goods, is one of the most fundamental problems incomputational economics, unsolved even for two bidders and two items for sale.In the traditional economic models, it is assumed that the bidders' valuationsare drawn from an underlying distribution and that the auction designer hasperfect knowledge of this distribution. Despite this strong and oftentimesunrealistic assumption, it is remarkable that the revenue-maximizingcombinatorial auction remains unknown. In recent years, automated mechanismdesign has emerged as one of the most practical and promising approaches todesigning high-revenue combinatorial auctions. The most scalable automatedmechanism design algorithms take as input samples from the bidders' valuationdistribution and then search for a high-revenue auction in a rich auctionclass. In this work, we provide the first sample complexity analysis for thestandard hierarchy of deterministic combinatorial auction classes used inautomated mechanism design. In particular, we provide tight sample complexitybounds on the number of samples needed to guarantee that the empirical revenueof the designed mechanism on the samples is close to its expected revenue onthe underlying, unknown distribution over bidder valuations, for each of theauction classes in the hierarchy. In addition to helping set automatedmechanism design on firm foundations, our results also push the boundaries oflearning theory. In particular, the hypothesis functions used in our contextsare defined through multi-stage combinatorial optimization procedures, ratherthan simple decision boundaries, as are common in machine learning.

Theoretical and Practical Advances on Smoothing for Extensive-Form Games

  Sparse iterative methods, in particular first-order methods, are known to beamong the most effective in solving large-scale two-player zero-sumextensive-form games. The convergence rates of these methods depend heavily onthe properties of the distance-generating function that they are based on. Weinvestigate the acceleration of first-order methods for solving extensive-formgames through better design of the dilated entropy function---a class ofdistance-generating functions related to the domains associated with theextensive-form games. By introducing a new weighting scheme for the dilatedentropy function, we develop the first distance-generating function for thestrategy spaces of sequential games that has no dependence on the branchingfactor of the player. This result improves the convergence rate of severalfirst-order methods by a factor of $\Omega(b^dd)$, where $b$ is the branchingfactor of the player, and $d$ is the depth of the game tree.  Thus far, counterfactual regret minimization methods have been faster inpractice, and more popular, than first-order methods despite theirtheoretically inferior convergence rates. Using our new weighting scheme andpractical tuning we show that, for the first time, the excessive gap techniquecan be made faster than the fastest counterfactual regret minimizationalgorithm, CFR+, in practice.

A General Theory of Sample Complexity for Multi-Item Profit Maximization

  The design of profit-maximizing multi-item mechanisms is a notoriouslychallenging problem with tremendous real-world impact. The mechanism designer'sgoal is to field a mechanism with high expected profit on the distribution overbuyers' values. Unfortunately, if the set of mechanisms he optimizes over iscomplex, a mechanism may have high empirical profit over a small set of samplesbut low expected profit. This raises the question, how many samples aresufficient to ensure that the empirically optimal mechanism is nearly optimalin expectation? We uncover structure shared by a myriad of pricing, auction,and lottery mechanisms that allows us to prove strong sample complexity bounds:for any set of buyers' values, profit is a piecewise linear function of themechanism's parameters. We prove new bounds for mechanism classes not yetstudied in the sample-based mechanism design literature and match or improveover the best known guarantees for many classes. The profit functions we studyare significantly different from well-understood functions in machine learning,so our analysis requires a sharp understanding of the interplay betweenmechanism parameters and buyer values. We strengthen our main results withdata-dependent bounds when the distribution over buyers' values is"well-behaved." Finally, we investigate a fundamental tradeoff in sample-basedmechanism design: complex mechanisms often have higher profit than simplemechanisms, but more samples are required to ensure that empirical and expectedprofit are close. We provide techniques for optimizing this tradeoff.

Smoothing Method for Approximate Extensive-Form Perfect Equilibrium

  Nash equilibrium is a popular solution concept for solvingimperfect-information games in practice. However, it has a major drawback: itdoes not preclude suboptimal play in branches of the game tree that are notreached in equilibrium. Equilibrium refinements can mend this issue, but haveexperienced little practical adoption. This is largely due to a lack ofscalable algorithms.  Sparse iterative methods, in particular first-order methods, are known to beamong the most effective algorithms for computing Nash equilibria inlarge-scale two-player zero-sum extensive-form games. In this paper, weprovide, to our knowledge, the first extension of these methods to equilibriumrefinements. We develop a smoothing approach for behavioral perturbations ofthe convex polytope that encompasses the strategy spaces of players in anextensive-form game. This enables one to compute an approximate variant ofextensive-form perfect equilibria. Experiments show that our smoothing approachleads to solutions with dramatically stronger strategies at information setsthat are reached with low probability in approximate Nash equilibria, whileretaining the overall convergence rate associated with fast algorithms for Nashequilibrium. This has benefits both in approximate equilibrium finding (suchapproximation is necessary in practice in large games) where some probabilitiesare low while possibly heading toward zero in the limit, and exact equilibriumcomputation where the low probabilities are actually zero.

Operation Frames and Clubs in Kidney Exchange

  A kidney exchange is a centrally-administered barter market where patientsswap their willing yet incompatible donors. Modern kidney exchanges use2-cycles, 3-cycles, and chains initiated by non-directed donors (altruists whoare willing to give a kidney to anyone) as the means for swapping.  We propose significant generalizations to kidney exchange. We allow more thanone donor to donate in exchange for their desired patient receiving a kidney.We also allow for the possibility of a donor willing to donate if any of anumber of patients receive kidneys. Furthermore, we combine these notions andgeneralize them. The generalization is to exchange among organ clubs, where aclub is willing to donate organs outside the club if and only if the clubreceives organs from outside the club according to given specifications. Weprove that unlike in the standard model, the uncapped clearing problem isNP-complete.  We also present the notion of operation frames that can be used to sequencethe operations across batches, and present integer programming formulations forthe market clearing problems for these new types of organ exchanges.  Experiments show that in the single-donation setting, operation framesimprove planning by 34%--51%. Allowing up to two donors to donate in exchangefor one kidney donated to their designated patient yields a further increase insocial welfare.

Learning to Branch

  Tree search algorithms, such as branch-and-bound, are the most widely usedtools for solving combinatorial and nonconvex problems. For example, they arethe foremost method for solving (mixed) integer programs and constraintsatisfaction problems. Tree search algorithms recursively partition the searchspace to find an optimal solution. In order to keep the tree size small, it iscrucial to carefully decide, when expanding a tree node, which question(typically variable) to branch on at that node in order to partition theremaining space. Numerous partitioning techniques (e.g., variable selection)have been proposed, but there is no theory describing which technique isoptimal. We show how to use machine learning to determine an optimal weightingof any set of partitioning procedures for the instance distribution at handusing samples from the distribution. We provide the first sample complexityguarantees for tree search algorithm configuration. These guarantees bound thenumber of samples sufficient to ensure that the empirical performance of analgorithm over the samples nearly matches its expected performance on theunknown instance distribution. This thorough theoretical investigationnaturally gives rise to our learning algorithm. Via experiments, we show thatlearning an optimal weighting of partitioning procedures can dramaticallyreduce tree size, and we prove that this reduction can even be exponential.Through theory and experiments, we show that learning to branch is bothpractical and hugely beneficial.

Online Convex Optimization for Sequential Decision Processes and  Extensive-Form Games

  Regret minimization is a powerful tool for solving large-scale extensive-formgames. State-of-the-art methods rely on minimizing regret locally at eachdecision point. In this work we derive a new framework for regret minimizationon sequential decision problems and extensive-form games with general compactconvex sets at each decision point and general convex losses, as opposed toprior work which has been for simplex decision points and linear losses. Wecall our framework laminar regret decomposition. It generalizes the CFRalgorithm to this more general setting. Furthermore, our framework enables anew proof of CFR even in the known setting, which is derived from a perspectiveof decomposing polytope regret, thereby leading to an arguably simplerinterpretation of the algorithm. Our generalization to convex compact sets andconvex losses allows us to develop new algorithms for several problems:regularized sequential decision making, regularized Nash equilibria inextensive-form games, and computing approximate extensive-form perfectequilibria. Our generalization also leads to the first regret-minimizationalgorithm for computing reduced-normal-form quantal response equilibria basedon minimizing local regrets. Experiments show that our framework leads toalgorithms that scale at a rate comparable to the fastest variants ofcounterfactual regret minimization for computing Nash equilibrium, andtherefore our approach leads to the first algorithm for computing quantalresponse equilibria in extremely large games. Finally we show that ourframework enables a new kind of scalable opponent exploitation approach.

Solving Large Sequential Games with the Excessive Gap Technique

  There has been tremendous recent progress on equilibrium-finding algorithmsfor zero-sum imperfect-information extensive-form games, but there has been apuzzling gap between theory and practice. First-order methods havesignificantly better theoretical convergence rates than anycounterfactual-regret minimization (CFR) variant. Despite this, CFR variantshave been favored in practice. Experiments with first-order methods have onlybeen conducted on small- and medium-sized games because those methods arecomplicated to implement in this setting, and because CFR variants have beenenhanced extensively for over a decade they perform well in practice. In thispaper we show that a particular first-order method, a state-of-the-art variantof the excessive gap technique---instantiated with the dilated entropy distancefunction---can efficiently solve large real-world problems competitively withCFR and its variants. We show this on large endgames encountered by theLibratus poker AI, which recently beat top human poker specialist professionalsat no-limit Texas hold'em. We show experimental results on our variant of theexcessive gap technique as well as a prior version. We introduce a numericallyfriendly implementation of the smoothed best response computation associatedwith first-order methods for extensive-form game solving. We present, to ourknowledge, the first GPU implementation of a first-order method forextensive-form games. We present comparisons of several excessive gap techniqueand CFR variants.

Estimating Approximate Incentive Compatibility

  In practice, most mechanisms for selling, buying, matching, voting, and so onare not incentive compatible. We present techniques for estimating how far amechanism is from incentive compatible. Given samples from the agents' typedistribution, we show how to estimate the extent to which an agent can improvehis utility by misreporting his type. We do so by first measuring the maximumutility an agent can gain by misreporting his type on average over the samples,assuming his true and reported types are from a finite subset -- which ourtechnique constructs -- of the type space. The challenge is that by measuringutility gains over a finite subset of the type space, we might miss pairs oftypes $\theta$ and $\hat{\theta}$ where an agent with type $\theta$ can greatlyimprove his utility by reporting the type $\hat{\theta}$. Our techniquediscretizes the type space by constructing a learning-theoretic cover in ahigher-dimensional space. The key technical contribution is proving that themaximum utility gain over this finite subset nearly matches the maximum utilitygain overall, despite the volatility of the utility functions we study. Weapply our tools to the single-item and combinatorial first-price auctions,generalized second-price auction, discriminatory auction, uniform-priceauction, and second-price auction with spiteful bidders. To our knowledge,these are the first guarantees for estimating approximate incentivecompatibility from the mechanism designer's perspective.

Ignorance is Almost Bliss: Near-Optimal Stochastic Matching With Few  Queries

  The stochastic matching problem deals with finding a maximum matching in agraph whose edges are unknown but can be accessed via queries. This is aspecial case of stochastic $k$-set packing, where the problem is to find amaximum packing of sets, each of which exists with some probability. In thispaper, we provide edge and set query algorithms for these two problems,respectively, that provably achieve some fraction of the omniscient optimalsolution.  Our main theoretical result for the stochastic matching (i.e., $2$-setpacking) problem is the design of an \emph{adaptive} algorithm that queriesonly a constant number of edges per vertex and achieves a $(1-\epsilon)$fraction of the omniscient optimal solution, for an arbitrarily small$\epsilon>0$. Moreover, this adaptive algorithm performs the queries in only aconstant number of rounds. We complement this result with a \emph{non-adaptive}(i.e., one round of queries) algorithm that achieves a $(0.5 - \epsilon)$fraction of the omniscient optimum. We also extend both our results tostochastic $k$-set packing by designing an adaptive algorithm that achieves a$(\frac{2}{k} - \epsilon)$ fraction of the omniscient optimal solution, againwith only $O(1)$ queries per element. This guarantee is close to the best knownpolynomial-time approximation ratio of $\frac{3}{k+1} -\epsilon$ for the\emph{deterministic} $k$-set packing problem [Furer and Yu, 2013]  We empirically explore the application of (adaptations of) these algorithmsto the kidney exchange problem, where patients with end-stage renal failureswap willing but incompatible donors. We show on both generated data and onreal data from the first 169 match runs of the UNOS nationwide kidney exchangethat even a very small number of non-adaptive edge queries per vertex resultsin large gains in expected successful matches.

Position-Indexed Formulations for Kidney Exchange

  A kidney exchange is an organized barter market where patients in need of akidney swap willing but incompatible donors. Determining an optimal set ofexchanges is theoretically and empirically hard. Traditionally, exchanges tookplace in cycles, with each participating patient-donor pair both giving andreceiving a kidney. The recent introduction of chains, where a donor without apaired patient triggers a sequence of donations without requiring a kidney inreturn, increased the efficacy of fielded kidney exchanges---while alsodramatically raising the empirical computational hardness of clearing themarket in practice. While chains can be quite long, unbounded-length chains arenot desirable: planned donations can fail before transplant for a variety ofreasons, and the failure of a single donation causes the rest of that chain tofail, so parallel shorter chains are better in practice.  In this paper, we address the tractable clearing of kidney exchanges withshort cycles and chains that are long but bounded. This corresponds to thepractice at most modern fielded kidney exchanges. We introduce three newinteger programming formulations, two of which are compact. Furthermore, one ofthese models has a linear programming relaxation that is exactly as tight asthe previous tightest formulation (which was not compact) for instances inwhich each donor has a paired patient. On real data from the UNOS nationwideexchange in the United States and the NLDKSS nationwide exchange in the UnitedKingdom, as well as on generated realistic large-scale data, we show that ournew models are competitive with all existing solvers---in many casesoutperforming all other solvers by orders of magnitude.

Efficiency and Budget Balance in General Quasi-linear Domains

  We study efficiency and budget balance for designing mechanisms in generalquasi-linear domains. Green and Laffont (1979) proved that one cannotgenerically achieve both. We consider strategyproof budget-balanced mechanismsthat are approximately efficient. For deterministic mechanisms, we show that astrategyproof and budget-balanced mechanism must have a sink agent whosevaluation function is ignored in selecting an alternative, and she iscompensated with the payments made by the other agents. We assume thevaluations of the agents come from a bounded open interval. Using this result,we find a tight lower bound on the inefficiencies of strategyproof,budget-balanced mechanisms in this domain. The bound shows that theinefficiency asymptotically disappears when the number of agents is large---aresult close in spirit to Green and Laffont (1979, Theorem 9.4). However, ourresults provide worst-case bounds and the best possible rate of convergence.  Next, we consider minimizing any convex combination of inefficiency andbudget imbalance. We show that if the valuations are unrestricted, nodeterministic mechanism can do asymptotically better than minimizinginefficiency alone.  Finally, we investigate randomized mechanisms and provide improved lowerbounds on expected inefficiency. We give a tight lower bound for an interestingclass of strategyproof, budget-balanced, randomized mechanisms. We also use anoptimization-based approach---in the spirit of automated mechanism design---toprovide a lower bound on the minimum achievable inefficiency of any randomizedmechanism.  Experiments with real data from two applications show that the inefficiencyfor a simple randomized mechanism is 5--100 times smaller than the worst case.This relative difference increases with the number of agents.

