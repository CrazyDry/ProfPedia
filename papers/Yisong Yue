Hierarchical Exploration for Accelerating Contextual Bandits

  Contextual bandit learning is an increasingly popular approach to optimizingrecommender systems via user feedback, but can be slow to converge in practicedue to the need for exploring a large feature space. In this paper, we proposea coarse-to-fine hierarchical approach for encoding prior knowledge thatdrastically reduces the amount of exploration required. Intuitively, userpreferences can be reasonably embedded in a coarse low-dimensional featurespace that can be explored efficiently, requiring exploration in thehigh-dimensional space only as necessary. We introduce a bandit algorithm thatexplores within this coarse-to-fine spectrum, and prove performance guaranteesthat depend on how well the coarse space captures the user's preferences. Wedemonstrate substantial improvement over conventional bandit algorithms throughextensive simulation as well as a live user study in the setting ofpersonalized news recommendation.

Coordinated Multi-Agent Imitation Learning

  We study the problem of imitation learning from demonstrations of multiplecoordinating agents. One key challenge in this setting is that learning a goodmodel of coordination can be difficult, since coordination is often implicit inthe demonstrations and must be inferred as a latent variable. We propose ajoint approach that simultaneously learns a latent coordination model alongwith the individual policies. In particular, our method integrates unsupervisedstructure learning with conventional imitation learning. We illustrate thepower of our approach on a difficult problem of learning multiple policies forfine-grained behavior modeling in team sports, where different players occupydifferent roles in the coordinated team strategy. We show that having acoordination model to infer the roles of players yields substantially improvedimitation loss compared to conventional baselines.

A General Method for Amortizing Variational Filtering

  We introduce the variational filtering EM algorithm, a simple,general-purpose method for performing variational inference in dynamical latentvariable models using information from only past and present variables, i.e.filtering. The algorithm is derived from the variational objective in thefiltering setting and consists of an optimization procedure at each time step.By performing each inference optimization procedure with an iterative amortizedinference model, we obtain a computationally efficient implementation of thealgorithm, which we call amortized variational filtering. We presentexperiments demonstrating that this general-purpose method improves performanceacross several deep dynamical latent variable models.

Learning Policies for Contextual Submodular Prediction

  Many prediction domains, such as ad placement, recommendation, trajectoryprediction, and document summarization, require predicting a set or list ofoptions. Such lists are often evaluated using submodular reward functions thatmeasure both quality and diversity. We propose a simple, efficient, andprovably near-optimal approach to optimizing such prediction problems based onno-regret learning. Our method leverages a surprising result from onlinesubmodular optimization: a single no-regret online learner can compete with anoptimal sequence of predictions. Compared to previous work, which either learna sequence of classifiers or rely on stronger assumptions such asrealizability, we ensure both data-efficiency as well as performance guaranteesin the fully agnostic setting. Experiments validate the efficiency andapplicability of the approach on a wide range of problems including manipulatortrajectory optimization, news recommendation and document summarization.

Knapsack Constrained Contextual Submodular List Prediction with  Application to Multi-document Summarization

  We study the problem of predicting a set or list of options under knapsackconstraint. The quality of such lists are evaluated by a submodular rewardfunction that measures both quality and diversity. Similar to DAgger (Ross etal., 2010), by a reduction to online learning, we show how to adapt twosequence prediction models to imitate greedy maximization under knapsackconstraint problems: CONSEQOPT (Dey et al., 2012) and SCP (Ross et al., 2013).Experiments on extractive multi-document summarization show that our approachoutperforms existing state-of-the-art methods.

Smooth Imitation Learning for Online Sequence Prediction

  We study the problem of smooth imitation learning for online sequenceprediction, where the goal is to train a policy that can smoothly imitatedemonstrated behavior in a dynamic and continuous environment in response toonline, sequential context input. Since the mapping from context to behavior isoften complex, we take a learning reduction approach to reduce smooth imitationlearning to a regression problem using complex function classes that areregularized to ensure smoothness. We present a learning meta-algorithm thatachieves fast and stable convergence to a good policy. Our approach enjoysseveral attractive properties, including being fully deterministic, employingan adaptive learning rate that can provably yield larger policy improvementscompared to previous approaches, and the ability to ensure stable convergence.Our empirical results demonstrate significant performance gains over previousapproaches.

A Rotation Invariant Latent Factor Model for Moveme Discovery from  Static Poses

  We tackle the problem of learning a rotation invariant latent factor modelwhen the training data is comprised of lower-dimensional projections of theoriginal feature space. The main goal is the discovery of a set of 3-D basesposes that can characterize the manifold of primitive human motions, ormovemes, from a training set of 2-D projected poses obtained from still imagestaken at various camera angles. The proposed technique for basis discovery isdata-driven rather than hand-designed. The learned representation is rotationinvariant, and can reconstruct any training instance from multiple viewingangles. We apply our method to modeling human poses in sports (via the LeedsSports Dataset), and demonstrate the effectiveness of the learned bases in arange of applications such as activity classification, inference of dynamicsfrom a single frame, and synthetic representation of movements.

Learning recurrent representations for hierarchical behavior modeling

  We propose a framework for detecting action patterns from motion sequencesand modeling the sensory-motor relationship of animals, using a generativerecurrent neural network. The network has a discriminative part (classifyingactions) and a generative part (predicting motion), whose recurrent cells arelaterally connected, allowing higher levels of the network to represent highlevel phenomena. We test our framework on two types of data, fruit fly behaviorand online handwriting. Our results show that 1) taking advantage of unlabeledsequences, by predicting future motion, significantly improves action detectionperformance when training labels are scarce, 2) the network learns to representhigh level phenomena such as writer identity and fly gender, withoutsupervision, and 3) simulated motion trajectories, generated by treating motionprediction as input to the network, look realistic and may be used toqualitatively evaluate whether the model has learnt generative control rules.

Multi-dueling Bandits with Dependent Arms

  The dueling bandits problem is an online learning framework for learning frompairwise preference feedback, and is particularly well-suited for modelingsettings that elicit subjective or implicit human feedback. In this paper, westudy the problem of multi-dueling bandits with dependent arms, which extendsthe original dueling bandits setting by simultaneously dueling multiple arms aswell as modeling dependencies between arms. These extensions capture keycharacteristics found in many real-world applications, and allow for theopportunity to develop significantly more efficient algorithms than werepossible in the original setting. We propose the \selfsparring algorithm, whichreduces the multi-dueling bandits problem to a conventional bandit setting thatcan be solved using a stochastic bandit algorithm such as Thompson Sampling,and can naturally model dependencies using a Gaussian process prior. We presenta no-regret analysis for multi-dueling setting, and demonstrate theeffectiveness of our algorithm empirically on a wide range of simulationsettings.

Generating Long-term Trajectories Using Deep Hierarchical Networks

  We study the problem of modeling spatiotemporal trajectories over long timehorizons using expert demonstrations. For instance, in sports, agents oftenchoose action sequences with long-term goals in mind, such as achieving acertain strategic position. Conventional policy learning approaches, such asthose based on Markov decision processes, generally fail at learning cohesivelong-term behavior in such high-dimensional state spaces, and are onlyeffective when myopic modeling lead to the desired behavior. The key difficultyis that conventional approaches are "shallow" models that only learn a singlestate-action policy. We instead propose a hierarchical policy class thatautomatically reasons about both long-term and short-term goals, which weinstantiate as a hierarchical neural network. We showcase our approach in acase study on learning to imitate demonstrated basketball trajectories, andshow that it generates significantly more realistic trajectories compared tonon-hierarchical baselines as judged by professional sports analysts.

Correlational Dueling Bandits with Application to Clinical Treatment in  Large Decision Spaces

  We consider sequential decision making under uncertainty, where the goal isto optimize over a large decision space using noisy comparative feedback. Thisproblem can be formulated as a $K$-armed Dueling Bandits problem where $K$ isthe total number of decisions. When $K$ is very large, existing dueling banditsalgorithms suffer huge cumulative regret before converging on the optimal arm.This paper studies the dueling bandits problem with a large number of arms thatexhibit a low-dimensional correlation structure. Our problem is motivated by aclinical decision making process in large decision space. We propose anefficient algorithm CorrDuel which optimizes the exploration/exploitationtradeoff in this large decision space of clinical treatments. More broadly, ourapproach can be applied to other sequential decision problems with large andstructured decision spaces. We derive regret bounds, and evaluate performancein simulation experiments as well as on a live clinical trial of therapeuticspinal cord stimulation. To our knowledge, this marks the first time an onlinelearning algorithm was applied towards spinal cord injury treatments. Ourexperimental results show the effectiveness and efficiency of our approach.

Fine-Grained Retrieval of Sports Plays using Tree-Based Alignment of  Trajectories

  We propose a novel method for effective retrieval of multi-agentspatiotemporal tracking data. Retrieval of spatiotemporal tracking data offersseveral unique challenges compared to conventional text-based retrievalsettings. Most notably, the data is fine-grained meaning that the specificlocation of agents is important in describing behavior. Additionally, the dataoften contains tracks of multiple agents (e.g., multiple players in a sportsgame), which generally leads to a permutational alignment problem whenperforming relevance estimation. Due to the frequent position swap of agents,it is difficult to maintain the correspondence of agents, and such issues makethe pairwise comparison problematic for multi-agent spatiotemporal data. Toaddress this issue, we propose a tree-based method to estimate the relevancebetween multi-agent spatiotemporal tracks. It uses a hierarchical structure toperform multi-agent data alignment and partitioning in a coarse-to-finefashion. We validate our approach via user studies with domain experts. Ourresults show that our method boosts performance in retrieving similar sportsplays -- especially in interactive situations where the user selects a subsetof trajectories compared to current state-of-the-art methods.

Long-term Forecasting using Tensor-Train RNNs

  We present Tensor-Train RNN (TT-RNN), a novel family of neural sequencearchitectures for multivariate forecasting in environments with nonlineardynamics. Long-term forecasting in such systems is highly challenging, sincethere exist long-term temporal dependencies, higher-order correlations andsensitivity to error propagation. Our proposed tensor recurrent architectureaddresses these issues by learning the nonlinear dynamics directly using higherorder moments and high-order state transition functions. Furthermore, wedecompose the higher-order structure using the tensor-train (TT) decompositionto reduce the number of parameters while preserving the model performance. Wetheoretically establish the approximation properties of Tensor-Train RNNs forgeneral sequence inputs, and such guarantees are not available for usual RNNs.We also demonstrate significant long-term prediction improvements over generalRNN and LSTM architectures on a range of simulated environments with nonlineardynamics, as well on real-world climate and traffic data.

Multi-resolution Tensor Learning for Large-Scale Spatial Data

  High-dimensional tensor models are notoriously computationally expensive totrain. We present a meta-learning algorithm, MMT, that can significantly speedup the process for spatial tensor models. MMT leverages the property thatspatial data can be viewed at multiple resolutions, which are related bycoarsening and finegraining from one resolution to another. Using thisproperty, MMT learns a tensor model by starting from a coarse resolution anditeratively increasing the model complexity. In order to not "over-train" oncoarse resolution models, we investigate an information-theoretic fine-grainingcriterion to decide when to transition into higher-resolution models. Weprovide both theoretical and empirical evidence for the advantages of thisapproach. When applied to two real-world large-scale spatial datasets forbasketball player and animal behavior modeling, our approach demonstrate 3 keybenefits: 1) it efficiently captures higher-order interactions (i.e., tensorlatent factors), 2) it is orders of magnitude faster than fixed resolutionlearning and scales to very fine-grained spatial resolutions, and 3) itreliably yields accurate and interpretable models.

Teaching Categories to Human Learners with Visual Explanations

  We study the problem of computer-assisted teaching with explanations.Conventional approaches for machine teaching typically only provide feedback atthe instance level e.g., the category or label of the instance. However, it isintuitive that clear explanations from a knowledgeable teacher cansignificantly improve a student's ability to learn a new concept. To addressthese existing limitations, we propose a teaching framework that providesinterpretable explanations as feedback and models how the learner incorporatesthis additional information. In the case of images, we show that we canautomatically generate explanations that highlight the parts of the image thatare responsible for the class label. Experiments on human learners illustratethat, on average, participants achieve better test set performance onchallenging categorization tasks when taught with our interpretable approachcompared to existing methods.

Hierarchical Imitation and Reinforcement Learning

  We study how to effectively leverage expert feedback to learn sequentialdecision-making policies. We focus on problems with sparse rewards and longtime horizons, which typically pose significant challenges in reinforcementlearning. We propose an algorithmic framework, called hierarchical guidance,that leverages the hierarchical structure of the underlying problem tointegrate different modes of expert interaction. Our framework can incorporatedifferent combinations of imitation learning (IL) and reinforcement learning(RL) at different levels, leading to dramatic reductions in both expert effortand cost of exploration. Using long-horizon benchmarks, including Montezuma'sRevenge, we demonstrate that our approach can learn significantly faster thanhierarchical RL, and be significantly more label-efficient than standard IL. Wealso theoretically analyze labeling cost for certain instantiations of ourframework.

Detecting Adversarial Examples via Neural Fingerprinting

  Deep neural networks are vulnerable to adversarial examples, whichdramatically alter model output using small input changes. We propose NeuralFingerprinting, a simple, yet effective method to detect adversarial examplesby verifying whether model behavior is consistent with a set of secretfingerprints, inspired by the use of biometric and cryptographic signatures.The benefits of our method are that 1) it is fast, 2) it is prohibitivelyexpensive for an attacker to reverse-engineer which fingerprints were used, and3) it does not assume knowledge of the adversary. In this work, we pose aformal framework to analyze fingerprints under various threat models, andcharacterize Neural Fingerprinting for linear models. For complex neuralnetworks, we empirically demonstrate that Neural Fingerprinting significantlyimproves on state-of-the-art detection mechanisms by detecting the strongestknown adversarial attacks with 98-100% AUC-ROC scores on the MNIST, CIFAR-10and MiniImagenet (20 classes) datasets. In particular, the detection accuracyof Neural Fingerprinting generalizes well to unseen test-data under variousblack- and whitebox threat models, and is robust over a wide range ofhyperparameters and choices of fingerprints.

Generating Multi-Agent Trajectories using Programmatic Weak Supervision

  We study the problem of training sequential generative models for capturingcoordinated multi-agent trajectory behavior, such as offensive basketballgameplay. When modeling such settings, it is often beneficial to designhierarchical models that can capture long-term coordination using intermediatevariables. Furthermore, these intermediate variables should capture interestinghigh-level behavioral semantics in an interpretable and manipulatable way. Wepresent a hierarchical framework that can effectively learn such sequentialgenerative models. Our approach is inspired by recent work on leveragingprogrammatically produced weak labels, which we extend to the spatiotemporalregime. In addition to synthetic settings, we show how to instantiate ourframework to effectively model complex interactions between basketball playersand generate realistic multi-agent trajectories of basketball gameplay overlong time periods. We validate our approach using both quantitative andqualitative evaluations, including a user study comparison conducted withprofessional sports analysts.

Learning to Search via Retrospective Imitation

  We study the problem of learning a good search policy from demonstrations forcombinatorial search spaces. We propose retrospective imitation learning,which, after initial training by an expert, improves itself by learning fromits own retrospective solutions. That is, when the policy eventually reaches afeasible solution in a search tree after making mistakes and backtracks, itretrospectively constructs an improved search trace to the solution by removingbacktracks, which is then used to further train the policy. A key feature ofour approach is that it can iteratively scale up, or transfer, to largerproblem sizes than the initial expert demonstrations, thus dramaticallyexpanding its applicability beyond that of conventional imitation learning. Weshowcase the effectiveness of our approach on two tasks: synthetic mazesolving, and integer program based risk-aware path planning.

Stagewise Safe Bayesian Optimization with Gaussian Processes

  Enforcing safety is a key aspect of many problems pertaining to sequentialdecision making under uncertainty, which require the decisions made at everystep to be both informative of the optimal decision and also safe. For example,we value both efficacy and comfort in medical therapy, and efficiency andsafety in robotic control. We consider this problem of optimizing an unknownutility function with absolute feedback or preference feedback subject tounknown safety constraints. We develop an efficient safe Bayesian optimizationalgorithm, StageOpt, that separates safe region expansion and utility functionmaximization into two distinct stages. Compared to existing approaches whichinterleave between expansion and optimization, we show that StageOpt is moreefficient and naturally applicable to a broader class of problems. We providetheoretical guarantees for both the satisfaction of safety constraints as wellas convergence to the optimal utility value. We evaluate StageOpt on both avariety of synthetic experiments, as well as in clinical practice. Wedemonstrate that StageOpt is more effective than existing safe optimizationapproaches, and is able to safely and effectively optimize spinal cordstimulation therapy in our clinical experiments.

Iterative Amortized Inference

  Inference models are a key component in scaling variational inference to deeplatent variable models, most notably as encoder networks in variationalauto-encoders (VAEs). By replacing conventional optimization-based inferencewith a learned model, inference is amortized over data examples and thereforemore computationally efficient. However, standard inference models arerestricted to direct mappings from data to approximate posterior estimates. Thefailure of these models to reach fully optimized approximate posteriorestimates results in an amortization gap. We aim toward closing this gap byproposing iterative inference models, which learn to perform inferenceoptimization through repeatedly encoding gradients. Our approach generalizesstandard inference models in VAEs and provides insight into several empiricalfindings, including top-down inference techniques. We demonstrate the inferenceoptimization capabilities of iterative inference models and show that theyoutperform standard inference models on several benchmark data sets of imagesand text.

Barrier Certificates for Assured Machine Teaching

  Machine teaching has received significant attention in the past few years asa paradigm shift from machine learning. While machine learning is oftenconcerned with improving the performance of learners, machine teaching pertainsto the efficiency of teachers. For example, machine teaching seeks to find theoptimal (minimum) number of data samples needed for teaching a targethypothesis to a learner. Hence, it is natural to raise the question of how canwe provide assurances for teaching given a machine teaching algorithm. In thispaper, we address this question by borrowing notions from control theory. Webegin by proposing a model based on partially observable Markov decisionprocesses (POMDPs) for a class of machine teaching problems. We then show thatthe POMDP formulation can be cast as a special hybrid system, i.e., adiscrete-time switched system. Subsequently, we use barrier certificates toverify properties of this special hybrid system. We show how the computation ofthe barrier certificate can be decomposed and numerically implemented as thesolution to a sum-of-squares (SOS) program. For illustration, we show how theproposed framework based on control theory can be used to verify the teachingperformance of two well-known machine teaching methods.

A General Framework for Multi-fidelity Bayesian Optimization with  Gaussian Processes

  How can we efficiently gather information to optimize an unknown function,when presented with multiple, mutually dependent information sources withdifferent costs? For example, when optimizing a robotic system, intelligentlytrading off computer simulations and real robot testings can lead tosignificant savings. Existing methods, such as multi-fidelity GP-UCB or EntropySearch-based approaches, either make simplistic assumptions on the interactionamong different fidelities or use simple heuristics that lack theoreticalguarantees. In this paper, we study multi-fidelity Bayesian optimization withcomplex structural dependencies among multiple outputs, and proposeMF-MI-Greedy, a principled algorithmic framework for addressing this problem.In particular, we model different fidelities using additive Gaussian processesbased on shared latent structures with the target function. Then we usecost-sensitive mutual information gain for efficient Bayesian globaloptimization. We propose a simple notion of regret which incorporates the costof different fidelities, and prove that MF-MI-Greedy achieves low regret. Wedemonstrate the strong empirical performance of our algorithm on both syntheticand real-world datasets.

Optimizing Photonic Nanostructures via Multi-fidelity Gaussian Processes

  We apply numerical methods in combination with finite-difference-time-domain(FDTD) simulations to optimize transmission properties of plasmonic mirrorcolor filters using a multi-objective figure of merit over a five-dimensionalparameter space by utilizing novel multi-fidelity Gaussian processes approach.We compare these results with conventional derivative-free global searchalgorithms, such as (single-fidelity) Gaussian Processes optimization scheme,and Particle Swarm Optimization---a commonly used method in nanophotonicscommunity, which is implemented in Lumerical commercial photonics software. Wedemonstrate the performance of various numerical optimization approaches onseveral pre-collected real-world datasets and show that by properly trading offexpensive information sources with cheap simulations, one can more effectivelyoptimize the transmission properties with a fixed budget.

NAOMI: Non-Autoregressive Multiresolution Sequence Imputation

  Missing value imputation is a fundamental problem in modeling spatiotemporalsequences, from motion tracking to the dynamics of physical systems. In thispaper, we take a non-autoregressive approach and propose a novel deepgenerative model: Non-AutOregressive Multiresolution Imputation (NAOMI) forimputing long-range spatiotemporal sequences given arbitrary missing patterns.In particular, NAOMI exploits the multiresolution structure of spatiotemporaldata to interpolate recursively from coarse to fine-grained resolutions. Wefurther enhance our model with adversarial training using an imitation learningobjective. When trained on billiards and basketball trajectories, NAOMIdemonstrates significant improvement in imputation accuracy (reducing averageprediction error by 60% compared to autoregressive counterparts) andgeneralization capability for long range trajectories in systems of bothdeterministic and stochastic dynamics.

Episodic Learning with Control Lyapunov Functions for Uncertain Robotic  Systems

  Many modern nonlinear control methods aim to endow systems with guaranteedproperties, such as stability or safety, and have been successfully applied tothe domain of robotics. However, model uncertainty remains a persistentchallenge, weakening theoretical guarantees and causing implementation failureson physical systems. This paper develops a machine learning framework centeredaround Control Lyapunov Functions (CLFs) to adapt to parametric uncertainty andunmodeled dynamics in general robotic systems. Our proposed method proceeds byiteratively updating estimates of Lyapunov function derivatives and improvingcontrollers, ultimately yielding a stabilizing quadratic program model-basedcontroller. We validate our approach on a planar Segway simulation,demonstrating substantial performance improvements by iteratively refining on abase model-free controller.

A Control Lyapunov Perspective on Episodic Learning via Projection to  State Stability

  The goal of this paper is to understand the impact of learning on controlsynthesis from a Lyapunov function perspective. In particular, rather thanconsider uncertainties in the full system dynamics, we employ Control LyapunovFunctions (CLFs) as low-dimensional projections. To understand and characterizethe uncertainty that these projected dynamics introduce in the system, weintroduce a new notion: Projection to State Stability (PSS). PSS can be viewedas a variant of Input to State Stability defined on projected dynamics, andenables characterizing robustness of a CLF with respect to the data used tolearn system uncertainties. We use PSS to bound uncertainty in affine control,and demonstrate that a practical episodic learning approach can use PSS tocharacterize uncertainty in the CLF for robust control synthesis.

Batch Policy Learning under Constraints

  When learning policies for real-world domains, two important questions arise:(i) how to efficiently use pre-collected off-policy, non-optimal behavior data;and (ii) how to mediate among different competing objectives and constraints.We thus study the problem of batch policy learning under multiple constraints,and offer a systematic solution. We first propose a flexible meta-algorithmthat admits any batch reinforcement learning and online learning procedure assubroutines. We then present a specific algorithmic instantiation and provideperformance guarantees for the main objective and all constraints. To certifyconstraint satisfaction, we propose a new and simple method for off-policypolicy evaluation (OPE) and derive PAC-style bounds. Our algorithm achievesstrong empirical results in different domains, including in a challengingproblem of simulated car driving subject to multiple constraints such as lanekeeping and smooth driving. We also show experimentally that our OPE methodoutperforms other popular OPE techniques on a standalone basis, especially in ahigh-dimensional setting.

Understanding the Role of Adaptivity in Machine Teaching: The Case of  Version Space Learners

  In real-world applications of education, an effective teacher adaptivelychooses the next example to teach based on the learner's current state.However, most existing work in algorithmic machine teaching focuses on thebatch setting, where adaptivity plays no role. In this paper, we study the caseof teaching consistent, version space learners in an interactive setting. Atany time step, the teacher provides an example, the learner performs an update,and the teacher observes the learner's new state. We highlight that adaptivitydoes not speed up the teaching process when considering existing models ofversion space learners, such as "worst-case" (the learner picks the nexthypothesis randomly from the version space) and "preference-based" (the learnerpicks hypothesis according to some global preference). Inspired by humanteaching, we propose a new model where the learner picks hypotheses accordingto some local preference defined by the current hypothesis. We show that ourmodel exhibits several desirable properties, e.g., adaptivity plays a key role,and the learner's transitions over hypotheses are smooth/interpretable. Wedevelop efficient teaching algorithms and demonstrate our results viasimulation and user studies.

Teaching Multiple Concepts to a Forgetful Learner

  How can we help a forgetful learner learn multiple concepts within a limitedtime frame? For long-term learning, it is crucial to devise teaching strategiesthat leverage the underlying forgetting mechanisms of the learner. In thispaper, we cast the problem of adaptively teaching a forgetful learner as anovel discrete optimization problem, where we seek to optimize a naturalobjective function that characterizes the learner's expected performancethroughout the teaching session. We then propose a simple greedy teachingstrategy and derive strong performance guarantees based on two intuitivedata-dependent properties, which capture the degree of diminishing returns ofteaching each concept. We show that, given some assumptions about the learner'smemory model, one can efficiently compute the performance bounds. Furthermore,we identify parameter settings of the memory model where the greedy strategy isguaranteed to achieve high performance. We demonstrate the effectiveness of ouralgorithm using extensive simulations along with user studies in two concreteapplications, namely (i) an educational app for online vocabulary teaching and(ii) an app for teaching novices how to recognize animal species from images.

