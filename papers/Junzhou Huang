Error Compensated Quantized SGD and its Applications to Large-scale  Distributed Optimization

  Large-scale distributed optimization is of great importance in variousapplications. For data-parallel based distributed learning, the inter-nodegradient communication often becomes the performance bottleneck. In this paper,we propose the error compensated quantized stochastic gradient descentalgorithm to improve the training efficiency. Local gradients are quantized toreduce the communication overhead, and accumulated quantization error isutilized to speed up the convergence. Furthermore, we present theoreticalanalysis on the convergence behaviour, and demonstrate its advantage overcompetitors. Extensive experiments indicate that our algorithm can compressgradients by a factor of up to two magnitudes without performance degradation.

The Benefit of Group Sparsity

  This paper develops a theory for group Lasso using a concept called stronggroup sparsity. Our result shows that group Lasso is superior to standard Lassofor strongly group-sparse signals. This provides a convincing theoreticaljustification for using group sparse regularization when the underlying groupstructure is consistent with the data. Moreover, the theory predicts somelimitations of the group Lasso formulation that are confirmed by simulationstudies.

On the Acceleration of L-BFGS with Second-Order Information and  Stochastic Batches

  This paper proposes a framework of L-BFGS based on the (approximate)second-order information with stochastic batches, as a novel approach to thefinite-sum minimization problems. Different from the classical L-BFGS wherestochastic batches lead to instability, we use a smooth estimate for theevaluations of the gradient differences while achieving acceleration bywell-scaling the initial Hessians. We provide theoretical analyses for bothconvex and nonconvex cases. In addition, we demonstrate that within the popularapplications of least-square and cross-entropy losses, the algorithm admits asimple implementation in the distributed environment. Numerical experimentssupport the efficiency of our algorithms.

Hyperparameter Learning via Distributional Transfer

  Bayesian optimisation is a popular technique for hyperparameter learning buttypically requires initial 'exploration' even in cases where potentiallysimilar prior tasks have been solved. We propose to transfer information acrosstasks using kernel embeddings of distributions of training datasets used inthose tasks. The resulting method has a faster convergence compared to existingbaselines, in some cases requiring only a few evaluations of the targetobjective.

Adaptive Sampling Towards Fast Graph Representation Learning

  Graph Convolutional Networks (GCNs) have become a crucial tool on learningrepresentations of graph vertices. The main challenge of adapting GCNs onlarge-scale graphs is the scalability issue that it incurs heavy cost both incomputation and memory due to the uncontrollable neighborhood expansion acrosslayers. In this paper, we accelerate the training of GCNs through developing anadaptive layer-wise sampling method. By constructing the network layer by layerin a top-down passway, we sample the lower layer conditioned on the top one,where the sampled neighborhoods are shared by different parent nodes and theover expansion is avoided owing to the fixed-size sampling. More importantly,the proposed sampler is adaptive and applicable for explicit variancereduction, which in turn enhances the training of our method. Furthermore, wepropose a novel and economical approach to promote the message passing overdistant nodes by applying skip connections. Intensive experiments on severalbenchmarks verify the effectiveness of our method regarding the classificationaccuracy while enjoying faster convergence speed.

End-to-End Learning of Motion Representation for Video Understanding

  Despite the recent success of end-to-end learned representations,hand-crafted optical flow features are still widely used in video analysistasks. To fill this gap, we propose TVNet, a novel end-to-end trainable neuralnetwork, to learn optical-flow-like features from data. TVNet subsumes aspecific optical flow solver, the TV-L1 method, and is initialized by unfoldingits optimization iterations as neural layers. TVNet can therefore be useddirectly without any extra learning. Moreover, it can be naturally concatenatedwith other task-specific networks to formulate an end-to-end architecture, thusmaking our method more efficient than current multi-stage approaches byavoiding the need to pre-compute and store features on disk. Finally, theparameters of the TVNet can be further fine-tuned by end-to-end training. Thisenables TVNet to learn richer and task-specific patterns beyond exact opticalflow. Extensive experiments on two action recognition benchmarks verify theeffectiveness of the proposed approach. Our TVNet achieves better accuraciesthan all compared methods, while being competitive with the fastest counterpartin terms of features extraction time.

An Efficient Approach to Informative Feature Extraction from Multimodal  Data

  One primary focus in multimodal feature extraction is to find therepresentations of individual modalities that are maximally correlated. As awell-known measure of dependence, the Hirschfeld-Gebelein-R\'{e}nyi (HGR)maximal correlation becomes an appealing objective because of its operationalmeaning and desirable properties. However, the strict whitening constraintsformalized in the HGR maximal correlation limit its application. To addressthis problem, this paper proposes Soft-HGR, a novel framework to extractinformative features from multiple data modalities. Specifically, our frameworkprevents the "hard" whitening constraints, while simultaneously preserving thesame feature geometry as in the HGR maximal correlation. The objective ofSoft-HGR is straightforward, only involving two inner products, whichguarantees the efficiency and stability in optimization. We further generalizethe framework to handle more than two modalities and missing modalities. Whenlabels are partially available, we enhance the discriminative power of thefeature representations by making a semi-supervised adaptation. Empiricalevaluation implies that our approach learns more informative feature mappingsand is more efficient to optimize.

Weakly Supervised Dense Event Captioning in Videos

  Dense event captioning aims to detect and describe all events of interestcontained in a video. Despite the advanced development in this area, existingmethods tackle this task by making use of dense temporal annotations, which isdramatically source-consuming. This paper formulates a new problem: weaklysupervised dense event captioning, which does not require temporal segmentannotations for model training. Our solution is based on the one-to-onecorrespondence assumption, each caption describes one temporal segment, andeach temporal segment has one caption, which holds in current benchmarkdatasets and most real-world cases. We decompose the problem into a pair ofdual problems: event captioning and sentence localization and present a cyclesystem to train our model. Extensive experimental results are provided todemonstrate the ability of our model on both dense event captioning andsentence localization in videos.

Controllable Image-to-Video Translation: A Case Study on Facial  Expression Generation

  The recent advances in deep learning have made it possible to generatephoto-realistic images by using neural networks and even to extrapolate videoframes from an input video clip. In this paper, for the sake of both furtheringthis exploration and our own interest in a realistic application, we studyimage-to-video translation and particularly focus on the videos of facialexpressions. This problem challenges the deep neural networks by anothertemporal dimension comparing to the image-to-image translation. Moreover, itssingle input image fails most existing video generation methods that rely onrecurrent models. We propose a user-controllable approach so as to generatevideo clips of various lengths from a single face image. The lengths and typesof the expressions are controlled by users. To this end, we design a novelneural network architecture that can incorporate the user input into its skipconnections and propose several improvements to the adversarial training methodfor the neural network. Experiments and user studies verify the effectivenessof our approach. Especially, we would like to highlight that even for the faceimages in the wild (downloaded from the Web and the authors' own photos), ourmodel can generate high-quality facial expression videos of which about 50\%are labeled as real by Amazon Mechanical Turk workers.

Progressive Feature Alignment for Unsupervised Domain Adaptation

  Unsupervised domain adaptation (UDA) transfers knowledge from a label-richsource domain to a fully-unlabeled target domain. To tackle this task, recentapproaches resort to discriminative domain transfer in virtue of pseudo-labelsto enforce the class-level distribution alignment across the source and targetdomains. These methods, however, are vulnerable to the error accumulation andthus incapable of preserving cross-domain category consistency, as thepseudo-labeling accuracy is not guaranteed explicitly. In this paper, wepropose the Progressive Feature Alignment Network (PFAN) to align thediscriminative features across domains progressively and effectively, viaexploiting the intra-class variation in the target domain. To be specific, wefirst develop an Easy-to-Hard Transfer Strategy (EHTS) and an AdaptivePrototype Alignment (APA) step to train our model iteratively andalternatively. Moreover, upon observing that a good domain adaptation usuallyrequires a non-saturated source classifier, we consider a simple yet efficientway to retard the convergence speed of the source classification loss byfurther involving a temperature variate into the soft-max function. Theextensive experimental results reveal that the proposed PFAN exceeds thestate-of-the-art performance on three UDA datasets.

Learning with Structured Sparsity

  This paper investigates a new learning formulation called structuredsparsity, which is a natural extension of the standard sparsity concept instatistical learning and compressive sensing. By allowing arbitrary structureson the feature set, this concept generalizes the group sparsity idea that hasbecome popular in recent years. A general theory is developed for learning withstructured sparsity, based on the notion of coding complexity associated withthe structure. It is shown that if the coding complexity of the target signalis small, then one can achieve improved performance by using coding complexityregularization methods, which generalize the standard sparse regularization.Moreover, a structured greedy algorithm is proposed to efficiently solve thestructured sparsity problem. It is shown that the greedy algorithmapproximately solves the coding complexity optimization problem underappropriate conditions. Experiments are included to demonstrate the advantageof structured sparsity over standard sparsity on some real applications.

Fast Iteratively Reweighted Least Squares Algorithms for Analysis-Based  Sparsity Reconstruction

  In this paper, we propose a novel algorithm for analysis-based sparsityreconstruction. It can solve the generalized problem by structured sparsityregularization with an orthogonal basis and total variation regularization. Theproposed algorithm is based on the iterative reweighted least squares (IRLS)model, which is further accelerated by the preconditioned conjugate gradientmethod. The convergence rate of the proposed algorithm is almost the same asthat of the traditional IRLS algorithms, that is, exponentially fast. Moreover,with the specifically devised preconditioner, the computational cost for eachiteration is significantly less than that of traditional IRLS algorithms, whichenables our approach to handle large scale problems. In addition to the fastconvergence, it is straightforward to apply our method to standard sparsity,group sparsity, overlapping group sparsity and TV based problems. Experimentsare conducted on a practical application: compressive sensing magneticresonance imaging. Extensive results demonstrate that the proposed algorithmachieves superior performance over 14 state-of-the-art algorithms in terms ofboth accuracy and computational cost.

Track Facial Points in Unconstrained Videos

  Tracking Facial Points in unconstrained videos is challenging due to thenon-rigid deformation that changes over time. In this paper, we propose toexploit incremental learning for person-specific alignment in wild conditions.Our approach takes advantage of part-based representation and cascaderegression for robust and efficient alignment on each frame. Unlike existingmethods that usually rely on models trained offline, we incrementally updatethe representation subspace and the cascade of regressors in a unifiedframework to achieve personalized modeling on the fly. To alleviate thedrifting issue, the fitting results are evaluated using a deep neural network,where well-aligned faces are picked out to incrementally update therepresentation and fitting models. Both image and video datasets are employedto valid the proposed method. The results demonstrate the superior performanceof our approach compared with existing approaches in terms of fitting accuracyand efficiency.

Intra-protein binding peptide fragments have specific and intrinsic  sequence patterns

  The key finding in the DNA double helix model is the specific pairing orbinding between nucleotides A-T and C-G, and the pairing rules are the moleculebasis of genetic code. Unfortunately, no such rules have been discovered forproteins. Here we show that similar rules and intrinsic sequence patternsbetween intra-protein binding peptide fragments do exist, and they can beextracted using a deep learning algorithm. Multi-millions of binding andnon-binding peptide fragments from currently available protein X-ray structuresare classified with an accuracy of up to 93%. This discovery has the potentialin helping solve protein folding and protein-protein interaction problems, twoopen and fundamental problems in molecular biology.

Group-driven Reinforcement Learning for Personalized mHealth  Intervention

  Due to the popularity of smartphones and wearable devices nowadays, mobilehealth (mHealth) technologies are promising to bring positive and wide impactson people's health. State-of-the-art decision-making methods for mHealth relyon some ideal assumptions. Those methods either assume that the users arecompletely homogenous or completely heterogeneous. However, in reality, a usermight be similar with some, but not all, users. In this paper, we propose anovel group-driven reinforcement learning method for the mHealth. We aim tounderstand how to share information among similar users to better convert thelimited user information into sharper learned RL policies. Specifically, weemploy the K-means clustering method to group users based on their trajectoryinformation similarity and learn a shared RL policy for each group. Extensiveexperiment results have shown that our method can achieve clear gains over thestate-of-the-art RL methods for mHealth.

Learning Graph While Training: An Evolving Graph Convolutional Neural  Network

  Convolution Neural Networks on Graphs are important generalization andextension of classical CNNs. While previous works generally assumed that thegraph structures of samples are regular with unified dimensions, in manyapplications, they are highly diverse or even not well defined. Under somecircumstances, e.g. chemical molecular data, clustering or coarsening forsimplifying the graphs is hard to be justified chemically. In this paper, wepropose a more general and flexible graph convolution network (EGCN) fed bybatch of arbitrarily shaped data together with their evolving graph Laplacianstrained in supervised fashion. Extensive experiments have been conducted todemonstrate the superior performance in terms of both the acceleration ofparameter fitting and the significantly improved prediction accuracy onmultiple graph-structured datasets.

Adaptive Graph Convolutional Neural Networks

  Graph Convolutional Neural Networks (Graph CNNs) are generalizations ofclassical CNNs to handle graph data such as molecular data, point could andsocial networks. Current filters in graph CNNs are built for fixed and sharedgraph structure. However, for most real data, the graph structures varies inboth size and connectivity. The paper proposes a generalized and flexible graphCNN taking data of arbitrary graph structure as input. In that way atask-driven adaptive graph is learned for each graph data while training. Toefficiently learn the graph, a distance metric learning is proposed. Extensiveexperiments on nine graph-structured datasets have demonstrated the superiorperformance improvement on both convergence speed and predictive accuracy.

Robust Actor-Critic Contextual Bandit for Mobile Health (mHealth)  Interventions

  We consider the actor-critic contextual bandit for the mobile health(mHealth) intervention. State-of-the-art decision-making algorithms generallyignore the outliers in the dataset. In this paper, we propose a novel robustcontextual bandit method for the mHealth. It can achieve the conflicting goalof reducing the influence of outliers while seeking for a similar solutioncompared with the state-of-the-art contextual bandit methods on the datasetswithout outliers. Such performance relies on two technologies: (1) thecapped-$\ell_{2}$ norm; (2) a reliable method to set the thresholdinghyper-parameter, which is inspired by one of the most fundamental techniques inthe statistics. Although the model is non-convex and non-differentiable, wepropose an effective reweighted algorithm and provide solid theoreticalanalyses. We prove that the proposed algorithm can find sufficiently decreasingpoints after each iteration and finally converges after a finite number ofiterations. Extensive experiment results on two datasets demonstrate that ourmethod can achieve almost identical results compared with state-of-the-artcontextual bandit methods on the dataset without outliers, and significantlyoutperform those state-of-the-art methods on the badly noised dataset withoutliers in a variety of parameter settings.

Adaptive Cost-sensitive Online Classification

  Cost-Sensitive Online Classification has drawn extensive attention in recentyears, where the main approach is to directly online optimize two well-knowncost-sensitive metrics: (i) weighted sum of sensitivity and specificity; (ii)weighted misclassification cost. However, previous existing methods onlyconsidered first-order information of data stream. It is insufficient inpractice, since many recent studies have proved that incorporating second-orderinformation enhances the prediction performance of classification models. Thus,we propose a family of cost-sensitive online classification algorithms withadaptive regularization in this paper. We theoretically analyze the proposedalgorithms and empirically validate their effectiveness and properties inextensive experiments. Then, for better trade off between the performance andefficiency, we further introduce the sketching technique into our algorithms,which significantly accelerates the computational speed with quite slightperformance loss. Finally, we apply our algorithms to tackle several onlineanomaly detection tasks from real world. Promising results prove that theproposed algorithms are effective and efficient in solving cost-sensitiveonline classification problems in various real-world domains.

Adversarial Learning with Local Coordinate Coding

  Generative adversarial networks (GANs) aim to generate realistic data fromsome prior distribution (e.g., Gaussian noises). However, such priordistribution is often independent of real data and thus may lose semanticinformation (e.g., geometric structure or content in images) of data. Inpractice, the semantic information might be represented by some latentdistribution learned from data, which, however, is hard to be used for samplingin GANs. In this paper, rather than sampling from the pre-defined priordistribution, we propose a Local Coordinate Coding (LCC) based sampling methodto improve GANs. We derive a generalization bound for LCC based GANs and provethat a small dimensional input is sufficient to achieve good generalization.Extensive experiments on various real-world datasets demonstrate theeffectiveness of the proposed method.

Nonparametric Topic Modeling with Neural Inference

  This work focuses on combining nonparametric topic models with Auto-EncodingVariational Bayes (AEVB). Specifically, we first propose iTM-VAE, where thetopics are treated as trainable parameters and the document-specific topicproportions are obtained by a stick-breaking construction. The inference ofiTM-VAE is modeled by neural networks such that it can be computed in a simplefeed-forward manner. We also describe how to introduce a hyper-prior intoiTM-VAE so as to model the uncertainty of the prior parameter. Actually, thehyper-prior technique is quite general and we show that it can be applied toother AEVB based models to alleviate the {\it collapse-to-prior} problemelegantly. Moreover, we also propose HiTM-VAE, where the document-specifictopic distributions are generated in a hierarchical manner. HiTM-VAE is evenmore flexible and can generate topic distributions with better variability.Experimental results on 20News and Reuters RCV1-V2 datasets show that theproposed models outperform the state-of-the-art baselines significantly. Theadvantages of the hyper-prior technique and the hierarchical model constructionare also confirmed by experiments.

Weakly Supervised Deep Learning for Thoracic Disease Classification and  Localization on Chest X-rays

  Chest X-rays is one of the most commonly available and affordableradiological examinations in clinical practice. While detecting thoracicdiseases on chest X-rays is still a challenging task for machine intelligence,due to 1) the highly varied appearance of lesion areas on X-rays from patientsof different thoracic disease and 2) the shortage of accurate pixel-levelannotations by radiologists for model training. Existing machine learningmethods are unable to deal with the challenge that thoracic diseases usuallyhappen in localized disease-specific areas. In this article, we propose aweakly supervised deep learning framework equipped with squeeze-and-excitationblocks, multi-map transfer, and max-min pooling for classifying thoracicdiseases as well as localizing suspicious lesion regions. The comprehensiveexperiments and discussions are performed on the ChestX-ray14 dataset. Bothnumerical and visual results have demonstrated the effectiveness of theproposed model and its better performance against the state-of-the-artpipelines.

Dual Reconstruction Nets for Image Super-Resolution with Gradient  Sensitive Loss

  Deep neural networks have exhibited promising performance in imagesuper-resolution (SR) due to the power in learning the non-linear mapping fromlow-resolution (LR) images to high-resolution (HR) images. However, most deeplearning methods employ feed-forward architectures, and thus the dependenciesbetween LR and HR images are not fully exploited, leading to limited learningperformance. Moreover, most deep learning based SR methods apply the pixel-wisereconstruction error as the loss, which, however, may fail to capturehigh-frequency information and produce perceptually unsatisfying results,whilst the recent perceptual loss relies on some pre-trained deep model andthey may not generalize well. In this paper, we introduce a mask to separatethe image into low- and high-frequency parts based on image gradient magnitude,and then devise a gradient sensitive loss to well capture the structures in theimage without sacrificing the recovery of low-frequency content. Moreover, byinvestigating the duality in SR, we develop a dual reconstruction network (DRN)to improve the SR performance. We provide theoretical analysis on thegeneralization performance of our method and demonstrate its effectiveness andsuperiority with thorough experiments.

Exploring Fast and Communication-Efficient Algorithms in Large-scale  Distributed Networks

  The communication overhead has become a significant bottleneck indata-parallel network with the increasing of model size and data samples. Inthis work, we propose a new algorithm LPC-SVRG with quantized gradients and itsacceleration ALPC-SVRG to effectively reduce the communication complexity whilemaintaining the same convergence as the unquantized algorithms. Specifically,we formulate the heuristic gradient clipping technique within the quantizationscheme and show that unbiased quantization methods in related works [3, 33, 38]are special cases of ours. We introduce double sampling in the acceleratedalgorithm ALPC-SVRG to fully combine the gradients of full-precision andlow-precision, and then achieve acceleration with fewer communication overhead.Our analysis focuses on the nonsmooth composite problem, which makes ouralgorithms more general. The experiments on linear models and deep neuralnetworks validate the effectiveness of algorithms.

Forest Sparsity for Multi-channel Compressive Sensing

  In this paper, we investigate a new compressive sensing model formulti-channel sparse data where each channel can be represented as ahierarchical tree and different channels are highly correlated. Therefore, thefull data could follow the forest structure and we call this property as\emph{forest sparsity}. It exploits both intra- and inter- channel correlationsand enriches the family of existing model-based compressive sensing theories.The proposed theory indicates that only $\mathcal{O}(Tk+\log(N/k))$measurements are required for multi-channel data with forest sparsity, where$T$ is the number of channels, $N$ and $k$ are the length and sparsity numberof each channel respectively. This result is much better than$\mathcal{O}(Tk+T\log(N/k))$ of tree sparsity, $\mathcal{O}(Tk+k\log(N/k))$ ofjoint sparsity, and far better than $\mathcal{O}(Tk+Tk\log(N/k))$ of standardsparsity. In addition, we extend the forest sparsity theory to the multiplemeasurement vectors problem, where the measurement matrix is a block-diagonalmatrix. The result shows that the required measurement bound can be the same asthat for dense random measurement matrix, when the data shares equal energy ineach channel. A new algorithm is developed and applied on four exampleapplications to validate the benefit of the proposed model. Extensiveexperiments demonstrate the effectiveness and efficiency of the proposed theoryand algorithm.

SIRF: Simultaneous Image Registration and Fusion in A Unified Framework

  In this paper, we propose a novel method for image fusion with ahigh-resolution panchromatic image and a low-resolution multispectral image atthe same geographical location. The fusion is formulated as a convexoptimization problem which minimizes a linear combination of a least-squaresfitting term and a dynamic gradient sparsity regularizer. The former is topreserve accurate spectral information of the multispectral image, while thelatter is to keep sharp edges of the high-resolution panchromatic image. Wefurther propose to simultaneously register the two images during the fusingprocess, which is naturally achieved by virtue of the dynamic gradient sparsityproperty. An efficient algorithm is then devised to solve the optimizationproblem, accomplishing a linear computational complexity in the size of theoutput image in each iteration. We compare our method against sevenstate-of-the-art image fusion methods on multispectral image datasets from foursatellites. Extensive experimental results demonstrate that the proposed methodsubstantially outperforms the others in terms of both spatial and spectralqualities. We also show that our method can provide high-quality products fromcoarsely registered real-world datasets. Finally, a MATLAB implementation isprovided to facilitate future research.

Robust Contextual Bandit via the Capped-$\ell_{2}$ norm

  This paper considers the actor-critic contextual bandit for the mobile health(mHealth) intervention. The state-of-the-art decision-making methods in mHealthgenerally assume that the noise in the dynamic system follows the Gaussiandistribution. Those methods use the least-square-based algorithm to estimatethe expected reward, which is prone to the existence of outliers. To deal withthe issue of outliers, we propose a novel robust actor-critic contextual banditmethod for the mHealth intervention. In the critic updating, thecapped-$\ell_{2}$ norm is used to measure the approximation error, whichprevents outliers from dominating our objective. A set of weights could beachieved from the critic updating. Considering them gives a weighted objectivefor the actor updating. It provides the badly noised sample in the criticupdating with zero weights for the actor updating. As a result, the robustnessof both actor-critic updating is enhanced. There is a key parameter in thecapped-$\ell_{2}$ norm. We provide a reliable method to properly set it bymaking use of one of the most fundamental definitions of outliers instatistics. Extensive experiment results demonstrate that our method canachieve almost identical results compared with the state-of-the-art methods onthe dataset without outliers and dramatically outperform them on the datasetsnoised by outliers.

Discrimination-aware Channel Pruning for Deep Neural Networks

  Channel pruning is one of the predominant approaches for deep modelcompression. Existing pruning methods either train from scratch with sparsityconstraints on channels, or minimize the reconstruction error between thepre-trained feature maps and the compressed ones. Both strategies suffer fromsome limitations: the former kind is computationally expensive and difficult toconverge, whilst the latter kind optimizes the reconstruction error but ignoresthe discriminative power of channels. To overcome these drawbacks, weinvestigate a simple-yet-effective method, called discrimination-aware channelpruning, to choose those channels that really contribute to discriminativepower. To this end, we introduce additional losses into the network to increasethe discriminative power of intermediate layers and then select the mostdiscriminative channels for each layer by considering the additional loss andthe reconstruction error. Last, we propose a greedy algorithm to conductchannel selection and parameter optimization in an iterative way. Extensiveexperiments demonstrate the effectiveness of our method. For example, onILSVRC-12, our pruned ResNet-50 with 30% reduction of channels even outperformsthe original model by 0.39% in top-1 accuracy.

Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual  Representation Learning

  In existing visual representation learning tasks, deep convolutional neuralnetworks (CNNs) are often trained on images annotated with single tags, such asImageNet. However, a single tag cannot describe all important contents of oneimage, and some useful visual information may be wasted during training. Inthis work, we propose to train CNNs from images annotated with multiple tags,to enhance the quality of visual representation of the trained CNN model. Tothis end, we build a large-scale multi-label image database with 18M images and11K categories, dubbed Tencent ML-Images. We efficiently train the ResNet-101model with multi-label outputs on Tencent ML-Images, taking 90 hours for 60epochs, based on a large-scale distributed deep learning framework,i.e.,TFplus.The good quality of the visual representation of the Tencent ML-Imagescheckpoint is verified through three transfer learning tasks, includingsingle-label image classification on ImageNet and Caltech-256, object detectionon PASCAL VOC 2007, and semantic segmentation on PASCAL VOC 2012. The TencentML-Images database, the checkpoints of ResNet-101, and all the trainingcodehave been released at https://github.com/Tencent/tencent-ml-images. It isexpected to promote other vision tasks in the research and industry community.

Semi-Supervised Graph Classification: A Hierarchical Graph Perspective

  Node classification and graph classification are two graph learning problemsthat predict the class label of a node and the class label of a graphrespectively. A node of a graph usually represents a real-world entity, e.g., auser in a social network, or a protein in a protein-protein interactionnetwork. In this work, we consider a more challenging but practically usefulsetting, in which a node itself is a graph instance. This leads to ahierarchical graph perspective which arises in many domains such as socialnetwork, biological network and document collection. For example, in a socialnetwork, a group of people with shared interests forms a user group, whereas anumber of user groups are interconnected via interactions or common members. Westudy the node classification problem in the hierarchical graph where a `node'is a graph instance, e.g., a user group in the above example. As labels areusually limited in real-world data, we design two novel semi-supervisedsolutions named \underline{SE}mi-supervised gr\underline{A}phc\underline{L}assification via \underline{C}autious/\underline{A}ctive\underline{I}teration (or SEAL-C/AI in short). SEAL-C/AI adopt an iterativeframework that takes turns to build or update two classifiers, one working atthe graph instance level and the other at the hierarchical graph level. Tosimplify the representation of the hierarchical graph, we propose a novelsupervised, self-attentive graph embedding method called SAGE, which embedsgraph instances of arbitrary size into fixed-length vectors. Throughexperiments on synthetic data and Tencent QQ group data, we demonstrate thatSEAL-C/AI not only outperform competing methods by a significant margin interms of accuracy/Macro-F1, but also generate meaningful interpretations of thelearned representations.

Cohesion-based Online Actor-Critic Reinforcement Learning for mHealth  Intervention

  In the wake of the vast population of smart device users worldwide, mobilehealth (mHealth) technologies are hopeful to generate positive and wideinfluence on people's health. They are able to provide flexible, affordable andportable health guides to device users. Current online decision-making methodsfor mHealth assume that the users are completely heterogeneous. They share noinformation among users and learn a separate policy for each user. However,data for each user is very limited in size to support the separate onlinelearning, leading to unstable policies that contain lots of variances. Besides,we find the truth that a user may be similar with some, but not all, users, andconnected users tend to have similar behaviors. In this paper, we propose anetwork cohesion constrained (actor-critic) Reinforcement Learning (RL) methodfor mHealth. The goal is to explore how to share information among similarusers to better convert the limited user information into sharper learnedpolicies. To the best of our knowledge, this is the first online actor-criticRL for mHealth and first network cohesion constrained (actor-critic) RL methodin all applications. The network cohesion is important to derive effectivepolicies. We come up with a novel method to learn the network by using the warmstart trajectory, which directly reflects the users' property. The optimizationof our model is difficult and very different from the general supervisedlearning due to the indirect observation of values. As a contribution, wepropose two algorithms for the proposed online RLs. Apart from mHealth, theproposed methods can be easily applied or adapted to other health-relatedtasks. Extensive experiment results on the HeartSteps dataset demonstrates thatin a variety of parameter settings, the proposed two methods obtain obviousimprovements over the state-of-the-art methods.

