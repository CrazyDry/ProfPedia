WSAT(cc) - a fast local-search ASP solver

  We describe WSAT(cc), a local-search solver for computing models of theoriesin the language of propositional logic extended by cardinality atoms. WSAT(cc)is a processing back-end for the logic PS+, a recently proposed formalism foranswer-set programming.

Origins of Answer-Set Programming - Some Background And Two Personal  Accounts

  We discuss the evolution of aspects of nonmonotonic reasoning towards thecomputational paradigm of answer-set programming (ASP). We give a generaloverview of the roots of ASP and follow up with the personal perspective onresearch developments that helped verbalize the main principles of ASP anddifferentiated it from the classical logic programming.

Logic programs with monotone abstract constraint atoms

  We introduce and study logic programs whose clauses are built out of monotoneconstraint atoms. We show that the operational concept of the one-stepprovability operator generalizes to programs with monotone constraint atoms,but the generalization involves nondeterminism. Our main results demonstratethat our formalism is a common generalization of (1) normal logic programmingwith its semantics of models, supported models and stable models, (2) logicprogramming with weight atoms (lparse programs) with the semantics of stablemodels, as defined by Niemela, Simons and Soininen, and (3) of disjunctivelogic programming with the possible-model semantics of Sakama and Inoue.

aspps --- an implementation of answer-set programming with propositional  schemata

  We present an implementation of an answer-set programming paradigm, calledaspps (short for answer-set programming with propositional schemata). Thesystem aspps is designed to process PS+ theories. It consists of two basicmodules. The first module, psgrnd, grounds an PS+ theory. The second module,referred to as aspps, is a solver. It computes models of ground PS+ theories.

Computing stable models: worst-case performance estimates

  We study algorithms for computing stable models of propositional logicprograms and derive estimates on their worst-case performance that areasymptotically better than the trivial bound of O(m 2^n), where m is the sizeof an input program and n is the number of its atoms. For instance, forprograms, whose clauses consist of at most two literals (counting the head) wedesign an algorithm to compute stable models that works in time O(m\times1.44225^n). We present similar results for several broader classes of programs,as well.

On graph equivalences preserved under extensions

  Let R be an equivalence relation on graphs. By the strengthening of R we meanthe relation R' such that graphs G and H are in the relation R' if for everygraph F, the union of the graphs G and F is in the relation R with the union ofthe graphs H and F. We study strengthenings of equivalence relations on graphs.The most important case that we consider concerns equivalence relations definedby graph properties. We obtain results on the strengthening of equivalencerelations determined by the properties such as being a k-connected graph,k-colorable, hamiltonian and planar.

Stable models and an alternative logic programming paradigm

  In this paper we reexamine the place and role of stable model semantics inlogic programming and contrast it with a least Herbrand model approach to Hornprograms. We demonstrate that inherent features of stable model semanticsnaturally lead to a logic programming system that offers an interestingalternative to more traditional logic programming styles of Horn logicprogramming, stratified logic programming and logic programming withwell-founded semantics. The proposed approach is based on the interpretation ofprogram clauses as constraints. In this setting programs do not describe asingle intended model, but a family of stable models. These stable modelsencode solutions to the constraint satisfaction problem described by theprogram. Our approach imposes restrictions on the syntax of logic programs. Inparticular, function symbols are eliminated from the language. We argue thatthe resulting logic programming system is well-attuned to problems in the classNP, has a well-defined domain of applications, and an emerging methodology ofprogramming. We point out that what makes the whole approach viable is recentprogress in implementations of algorithms to compute stable models ofpropositional logic programs.

Local Diagnosis

  In an earlier work, we have presented operations of belief change which onlyaffect the relevant part of a belief base. In this paper, we propose theapplication of the same strategy to the problem of model-based diangosis. Wefirst isolate the subset of the system description which is relevant for agiven observation and then solve the diagnosis problem for this subset.

Extremal problems in logic programming and stable model computation

  We study the following problem: given a class of logic programs C, determinethe maximum number of stable models of a program from C. We establish themaximum for the class of all logic programs with at most n clauses, and for theclass of all logic programs of size at most n. We also characterize theprograms for which the maxima are attained. We obtain similar results for theclass of all disjunctive logic programs with at most n clauses, each of lengthat most m, and for the class of all disjunctive logic programs of size at mostn. Our results on logic programs have direct implication for the design ofalgorithms to compute stable models. Several such algorithms, similar in spiritto the Davis-Putnam procedure, are described in the paper. Our results implythat there is an algorithm that finds all stable models of a program with nclauses after considering the search space of size O(3^{n/3}) in the worstcase. Our results also provide some insights into the question ofrepresentability of families of sets as families of stable models of logicprograms.

On the accuracy and running time of GSAT

  Randomized algorithms for deciding satisfiability were shown to be effectivein solving problems with thousands of variables. However, these algorithms arenot complete. That is, they provide no guarantee that a satisfying assignment,if one exists, will be found. Thus, when studying randomized algorithms, thereare two important characteristics that need to be considered: the running timeand, even more importantly, the accuracy --- a measure of likelihood that asatisfying assignment will be found, provided one exists. In fact, we arguethat without a reference to the accuracy, the notion of the running time forrandomized algorithms is not well-defined. In this paper, we introduce a formalnotion of accuracy. We use it to define a concept of the running time. We useboth notions to study the random walk strategy GSAT algorithm. We investigatethe dependence of accuracy on properties of input formulas such asclause-to-variable ratio and the number of satisfying assignments. Wedemonstrate that the running time of GSAT grows exponentially in the number ofvariables of the input formula for randomly generated 3-CNF formulas and forthe formulas encoding 3- and 4-colorability of graphs.

On the problem of computing the well-founded semantics

  The well-founded semantics is one of the most widely studied and usedsemantics of logic programs with negation. In the case of finite propositionalprograms, it can be computed in polynomial time, more specifically, inO(|At(P)|size(P)) steps, where size(P) denotes the total number of occurrencesof atoms in a logic program P. This bound is achieved by an algorithmintroduced by Van Gelder and known as the alternating-fixpoint algorithm.Improving on the alternating-fixpoint algorithm turned out to be difficult. Inthis paper we study extensions and modifications of the alternating-fixpointapproach. We then restrict our attention to the class of programs whose ruleshave no more than one positive occurrence of an atom in their bodies. Forprograms in that class we propose a new implementation of thealternating-fixpoint method in which false atoms are computed in a top-downfashion. We show that our algorithm is faster than other known algorithms andthat for a wide class of programs it is linear and so, asymptotically optimal.

Annotated revision programs

  Revision programming is a formalism to describe and enforce updates of beliefsets and databases. That formalism was extended by Fitting who assignedannotations to revision atoms. Annotations provide a way to quantify theconfidence (probability) that a revision atom holds. The main goal of our paperis to reexamine the work of Fitting, argue that his semantics does not alwaysprovide results consistent with intuition, and to propose an alternativetreatment of annotated revision programs. Our approach differs from thatproposed by Fitting in two key aspects: we change the notion of a model of aprogram and we change the notion of a justified revision. We show that underthis new approach fundamental properties of justified revisions of standardrevision programs extend to the annotated case.

Propositional satisfiability in answer-set programming

  We show that propositional logic and its extensions can support answer-setprogramming in the same way stable logic programming and disjunctive logicprogramming do. To this end, we introduce a logic based on the logic ofpropositional schemata and on a version of the Closed World Assumption. We callit the extended logic of propositional schemata with CWA (PS+, in symbols). Animportant feature of this logic is that it supports explicit modeling ofconstraints on cardinalities of sets. In the paper, we characterize the classof problems that can be solved by finite PS+ theories. We implement aprogramming system based on the logic PS+ and design and implement a solver forprocessing theories in PS+. We present encouraging performance results for ourapproach --- we show it to be competitive with smodels, a state-of-the-artanswer-set programming system based on stable logic programming.

Ultimate approximations in nonmonotonic knowledge representation systems

  We study fixpoints of operators on lattices. To this end we introduce thenotion of an approximation of an operator. We order approximations by means ofa precision ordering. We show that each lattice operator O has a unique mostprecise or ultimate approximation. We demonstrate that fixpoints of thisultimate approximation provide useful insights into fixpoints of the operatorO.  We apply our theory to logic programming and introduce the ultimateKripke-Kleene, well-founded and stable semantics. We show that the ultimateKripke-Kleene and well-founded semantics are more precise then their standardcounterparts We argue that ultimate semantics for logic programming haveattractive epistemological properties and that, while in general they arecomputationally more complex than the standard semantics, for many classes oftheories, their complexity is no worse.

Local-search techniques for propositional logic extended with  cardinality constraints

  We study local-search satisfiability solvers for propositional logic extendedwith cardinality atoms, that is, expressions that provide explicit ways tomodel constraints on cardinalities of sets. Adding cardinality atoms to thelanguage of propositional logic facilitates modeling search problems and oftenresults in concise encodings. We propose two ``native'' local-search solversfor theories in the extended language. We also describe techniques to reducethe problem to standard propositional satisfiability and allow us to useoff-the-shelf SAT solvers. We study these methods experimentally. Our generalfinding is that native solvers designed specifically for the extended languageperform better than indirect methods relying on SAT solvers.

Logic programs with monotone cardinality atoms

  We investigate mca-programs, that is, logic programs with clauses built ofmonotone cardinality atoms of the form kX, where k is a non-negative integerand X is a finite set of propositional atoms. We develop a theory ofmca-programs. We demonstrate that the operational concept of the one-stepprovability operator generalizes to mca-programs, but the generalizationinvolves nondeterminism. Our main results show that the formalism ofmca-programs is a common generalization of (1) normal logic programming withits semantics of models, supported models and stable models, (2) logicprogramming with cardinality atoms and with the semantics of stable models, asdefined by Niemela, Simons and Soininen, and (3) of disjunctive logicprogramming with the possible-model semantics of Sakama and Inoue.

Satisfiability and computing van der Waerden numbers

  In this paper we bring together the areas of combinatorics and propositionalsatisfiability. Many combinatorial theorems establish, often constructively,the existence of positive integer functions, without actually providing theirclosed algebraic form or tight lower and upper bounds. The area of Ramseytheory is especially rich in such results. Using the problem of computing vander Waerden numbers as an example, we show that these problems can berepresented by parameterized propositional theories in such a way thatdecisions concerning their satisfiability determine the numbers (function) inquestion. We show that by using general-purpose complete and local-searchtechniques for testing propositional satisfiability, this approach becomeseffective -- competitive with specialized approaches. By following it, we wereable to obtain several new results pertaining to the problem of computing vander Waerden numbers. We also note that due to their properties, especiallytheir structural simplicity and computational hardness, propositional theoriesthat arise in this research can be of use in development, testing andbenchmarking of SAT solvers.

Trichotomy and Dichotomy Results on the Complexity of Reasoning with  Disjunctive Logic Programs

  We present trichotomy results characterizing the complexity of reasoning withdisjunctive logic programs. To this end, we introduce a certain definitionschema for classes of programs based on a set of allowed arities of rules. Weshow that each such class of programs has a finite representation, and for eachof the classes definable in the schema we characterize the complexity of theexistence of an answer set problem. Next, we derive similar characterizationsof the complexity of skeptical and credulous reasoning with disjunctive logicprograms. Such results are of potential interest. On the one hand, they revealsome reasons responsible for the hardness of computing answer sets. On theother hand, they identify classes of problem instances, for which the problemis "easy" (in P) or "easier than in general" (in NP). We obtain similar resultsfor the complexity of reasoning with disjunctive programs under thesupported-model semantics. To appear in Theory and Practice of LogicProgramming (TPLP)

Transition Systems for Model Generators - A Unifying Approach

  A fundamental task for propositional logic is to compute models ofpropositional formulas. Programs developed for this task are calledsatisfiability solvers. We show that transition systems introduced byNieuwenhuis, Oliveras, and Tinelli to model and analyze satisfiability solverscan be adapted for solvers developed for two other propositional formalisms:logic programming under the answer-set semantics, and the logic PC(ID). We showthat in each case the task of computing models can be seen as "satisfiabilitymodulo answer-set programming," where the goal is to find a model of a theorythat also is an answer set of a certain program. The unifying perspective wedevelop shows, in particular, that solvers CLASP and MINISATID are closelyrelated despite being developed for different formalisms, one for answer-setprogramming and the latter for the logic PC(ID).

Constructions of asymptotically shortest k-radius sequences

  Let k be a positive integer. A sequence s over an n-element alphabet A iscalled a k-radius sequence if every two symbols from A occur in s at distanceof at most k. Let f_k(n) denote the length of a shortest k-radius sequence overA. We provide constructions demonstrating that (1) for every fixed k and forevery fixed e>0, f_k(n) = n^2/(2k) +O(n^(1+e)) and (2) for every k, where k isthe integer part of n^a for some fixed real a such that 0 < a <1, f_k(n) =n^2/(2k) +O(n^b), for some b <2-a. Since f_k(n) >= n^2/(2k) - n/(2k), theconstructions give asymptotically optimal k-radius sequences. Finally, (3) weconstruct optimal 2-radius sequences for a 2p-element alphabet, where p is aprime.

Revisiting Epistemic Specifications

  In 1991, Michael Gelfond introduced the language of epistemic specifications.The goal was to develop tools for modeling problems that require some form ofmeta-reasoning, that is, reasoning over multiple possible worlds. Despite theirrelevance to knowledge representation, epistemic specifications have receivedrelatively little attention so far. In this paper, we revisit the formalism ofepistemic specification. We offer a new definition of the formalism, proposeseveral semantics (one of which, under syntactic restrictions we assume, turnsout to be equivalent to the original semantics by Gelfond), derive somecomplexity results and, finally, show the effectiveness of the formalism formodeling problems requiring meta-reasoning considered recently by Faber andWoltran. All these results show that epistemic specifications deserve much moreattention that has been afforded to them so far.

The View-Update Problem for Indefinite Databases

  This paper introduces and studies a declarative framework for updating viewsover indefinite databases. An indefinite database is a database with nullvalues that are represented, following the standard database approach, by asingle null constant. The paper formalizes views over such databases asindefinite deductive databases, and defines for them several classes ofdatabase repairs that realize view-update requests. Most notable is the classof constrained repairs. Constrained repairs change the database "minimally" andavoid making arbitrary commitments. They narrow down the space of alternativeways to fulfill the view-update request to those that are grounded, in acertain strong sense, in the database, the view and the view-update request.

A Measure of Arbitrariness in Abductive Explanations

  We study the framework of abductive logic programming extended with integrityconstraints. For this framework, we introduce a new measure of the simplicityof an explanation based on its degree of \emph{arbitrariness}: the morearbitrary the explanation, the less appealing it is, with explanations havingno arbitrariness - they are called constrained - being the preferred ones. Inthe paper, we study basic properties of constrained explanations. For the casewhen programs in abductive theories are stratified we establish resultsproviding a detailed picture of the complexity of the problem to decide whetherconstrained explanations exist. (To appear in Theory and Practice of LogicProgramming (TPLP).)

Representation Theory for Default Logic

  Default logic can be regarded as a mechanism to represent families of beliefsets of a reasoning agent. As such, it is inherently second-order. In thispaper, we study the problem of representability of a family of theories as theset of extensions of a default theory. We give a complete solution to therepresentability by means of normal default theories. We obtain partial resultson representability by arbitrary default theories. We construct examples ofdenumerable families of non-including theories that are not representable. Wealso study the concept of equivalence between default theories.

dcs: An Implementation of DATALOG with Constraints

  Answer-set programming (ASP) has emerged recently as a viable programmingparadigm. We describe here an ASP system, DATALOG with constraints or DC, basedon non-monotonic logic. Informally, DC theories consist of propositionalclauses (constraints) and of Horn rules. The semantics is a simple and naturalextension of the semantics of the propositional logic. However, thanks to thepresence of Horn rules in the system, modeling of transitive closure becomesstraightforward. We describe the syntax, use and implementation of DC andprovide experimental results.

Abstract Modular Systems and Solvers

  Integrating diverse formalisms into modular knowledge representation systemsoffers increased expressivity, modeling convenience and computational benefits.We introduce concepts of abstract modules and abstract modular systems to studygeneral principles behind the design and analysis of model-finding programs, orsolvers, for integrated heterogeneous multi-logic systems. We show how abstractmodules and abstract modular systems give rise to transition systems, which area natural and convenient representation of solvers pioneered by the SATcommunity. We illustrate our approach by showing how it applies to answer setprogramming and propositional logic, and to multi-logic systems based on thesetwo formalisms.

On Equivalence of Infinitary Formulas under the Stable Model Semantics

  Propositional formulas that are equivalent in intuitionistic logic, or in itsextension known as the logic of here-and-there, have the same stable models. Weextend this theorem to propositional formulas with infinitely long conjunctionsand disjunctions and show how to apply this generalization to provingproperties of aggregates in answer set programming. To appear in Theory andPractice of Logic Programming (TPLP).

Computing minimal models, stable models and answer sets

  We propose and study algorithms to compute minimal models, stable models andanswer sets of t-CNF theories, and normal and disjunctive t-programs. We areespecially interested in algorithms with non-trivial worst-case performancebounds. The bulk of the paper is concerned with the classes of 2- and 3-CNFtheories, and normal and disjunctive 2- and 3-programs, for which we obtainsignificantly stronger results than those implied by our generalconsiderations. We show that one can find all minimal models of 2-CNF theoriesand all answer sets of disjunctive 2-programs in time O(m 1.4422..^n). Our mainresults concern computing stable models of normal 3-programs, minimal models of3-CNF theories and answer sets of disjunctive 3-programs. We design algorithmsthat run in time O(m 1.6701..^n), in the case of the first problem, and in timeO(mn^2 2.2782..^n), in the case of the latter two. All these bounds improve byexponential factors the best algorithms known previously. We also obtainclosely related upper bounds on the number of minimal models, stable models andanswer sets a t-CNF theory, a normal t-program or a disjunctive t-program mayhave.  To appear in Theory and Practice of Logic Programming (TPLP).

Computing large and small stable models

  In this paper, we focus on the problem of existence and computing of smalland large stable models. We show that for every fixed integer k, there is alinear-time algorithm to decide the problem LSM (large stable models problem):does a logic program P have a stable model of size at least |P|-k. In contrast,we show that the problem SSM (small stable models problem) to decide whether alogic program P has a stable model of size at most k is much harder. We presenttwo algorithms for this problem but their running time is given by polynomialsof order depending on k. We show that the problem SSM is fixed-parameterintractable by demonstrating that it is W[2]-hard. This result implies that itis unlikely, an algorithm exists to compute stable models of size at most kthat would run in time O(n^c), where c is a constant independent of k. We alsoprovide an upper bound on the fixed-parameter complexity of the problem SSM byshowing that it belongs to the class W[3].

Uniform semantic treatment of default and autoepistemic logics

  We revisit the issue of connections between two leading formalisms innonmonotonic reasoning: autoepistemic logic and default logic. For each logicwe develop a comprehensive semantic framework based on the notion of a beliefpair. The set of all belief pairs together with the so called knowledgeordering forms a complete lattice. For each logic, we introduce severalsemantics by means of fixpoints of operators on the lattice of belief pairs.Our results elucidate an underlying isomorphism of the respective semanticconstructions. In particular, we show that the interpretation of defaults asmodal formulas proposed by Konolige allows us to represent all semantics fordefault logic in terms of the corresponding semantics for autoepistemic logic.Thus, our results conclusively establish that default logic can indeed beviewed as a fragment of autoepistemic logic. However, as we also demonstrate,the semantics of Moore and Reiter are given by different operators and occupydifferent locations in their corresponding families of semantics. This resultexplains the source of the longstanding difficulty to formally relate these twosemantics. In the paper, we also discuss approximating skeptical reasoning withautoepistemic and default logics and establish constructive principles behindsuch approximations.

Proceedings of the 8th International Workshop on Non-Monotonic  Reasoning, NMR'2000

  The papers gathered in this collection were presented at the 8thInternational Workshop on Nonmonotonic Reasoning, NMR2000. The series wasstarted by John McCarthy in 1978. The first international NMR workshop was heldat Mohonk Mountain House, New Paltz, New York in June, 1984, and was organizedby Ray Reiter and Bonnie Webber.  In the last 10 years the area of nonmonotonic reasoning has seen a number ofimportant developments. Significant theoretical advances were made in theunderstanding of general abstract principles underlying nonmonotonicity. Keyresults on the expressibility and computational complexity of nonmonotoniclogics were established. The role of nonmonotonic reasoning in belief revision,abduction, reasoning about action, planing and uncertainty was furtherclarified. Several successful NMR systems were built and used in applicationssuch as planning, scheduling, logic programming and constraint satisfaction.  The papers in the proceedings reflect these recent advances in the field.They are grouped into sections corresponding to special sessions as they wereheld at the workshop:  1. General NMR track  2. Abductive reasonig  3. Belief revision: theory and practice  4. Representing action and planning  5. Systems descriptions and demonstrations  6. Uncertainty frameworks in NMR

Propositional satisfiability in declarative programming

  Answer-set programming (ASP) paradigm is a way of using logic to solve searchproblems. Given a search problem, to solve it one designs a theory in the logicso that models of this theory represent problem solutions. To compute asolution to a problem one needs to compute a model of the corresponding theory.Several answer-set programming formalisms have been developed on the basis oflogic programming with the semantics of stable models. In this paper we showthat also the logic of predicate calculus gives rise to effectiveimplementations of the ASP paradigm, similar in spirit to logic programmingwith stable model semantics and with a similar scope of applicability.Specifically, we propose two logics based on predicate calculus as formalismsfor encoding search problems. We show that the expressive power of these logicsis given by the class NP-search. We demonstrate how to use them in programmingand develop computational tools for model finding. In the case of one of thelogics our techniques reduce the problem to that of propositionalsatisfiability and allow one to use off-the-shelf satisfiability solvers. Thelanguage of the other logic has more complex syntax and provides explicit meansto model some high-level constraints. For theories in this logic, we designedour own solver that takes advantage of the expanded syntax. We presentexperimental results demonstrating computational effectiveness of the overallapproach.

Reiter's Default Logic Is a Logic of Autoepistemic Reasoning And a Good  One, Too

  A fact apparently not observed earlier in the literature of nonmonotonicreasoning is that Reiter, in his default logic paper, did not directlyformalize informal defaults. Instead, he translated a default into a certainnatural language proposition and provided a formalization of the latter. A fewyears later, Moore noted that propositions like the one used by Reiter arefundamentally different than defaults and exhibit a certain autoepistemicnature. Thus, Reiter had developed his default logic as a formalization ofautoepistemic propositions rather than of defaults.  The first goal of this paper is to show that some problems of Reiter'sdefault logic as a formal way to reason about informal defaults are directlyattributable to the autoepistemic nature of default logic and to the mismatchbetween informal defaults and the Reiter's formal defaults, the latter being aformal expression of the autoepistemic propositions Reiter used as arepresentation of informal defaults.  The second goal of our paper is to compare the work of Reiter and Moore.While each of them attempted to formalize autoepistemic propositions, the modesof reasoning in their respective logics were different. We revisit Moore's andReiter's intuitions and present them from the perspective of autotheoremhood,where theories can include propositions referring to the theory's own theorems.We then discuss the formalization of this perspective in the logics of Mooreand Reiter, respectively, using the unifying semantic framework for default andautoepistemic logics that we developed earlier. We argue that Reiter's defaultlogic is a better formalization of Moore's intuitions about autoepistemicpropositions than Moore's own autoepistemic logic.

Fixed-parameter complexity of semantics for logic programs

  A decision problem is called parameterized if its input is a pair of strings.One of these strings is referred to as a parameter. The problem: given apropositional logic program P and a non-negative integer k, decide whether Phas a stable model of size no more than k, is an example of a parameterizeddecision problem with k serving as a parameter. Parameterized problems that areNP-complete often become solvable in polynomial time if the parameter is fixed.The problem to decide whether a program P has a stable model of size no morethan k, where k is fixed and not a part of input, can be solved in timeO(mn^k), where m is the size of P and n is the number of atoms in P. Thus, thisproblem is in the class P. However, algorithms with the running time given by apolynomial of order k are not satisfactory even for relatively small values ofk.  The key question then is whether significantly better algorithms (with thedegree of the polynomial not dependent on k) exist. To tackle it, we use theframework of fixed-parameter complexity. We establish the fixed-parametercomplexity for several parameterized decision problems involving models,supported models and stable models of logic programs. We also establish thefixed-parameter complexity for variants of these problems resulting fromrestricting attention to Horn programs and to purely negative programs. Most ofthe problems considered in the paper have high fixed-parameter complexity.Thus, it is unlikely that fixing bounds on models (supported models, stablemodels) will lead to fast algorithms to decide the existence of such models.

Relativized hyperequivalence of logic programs for modular programming

  A recent framework of relativized hyperequivalence of programs offers aunifying generalization of strong and uniform equivalence. It seems to beespecially well suited for applications in program optimization and modularprogramming due to its flexibility that allows us to restrict, independently ofeach other, the head and body alphabets in context programs. We studyrelativized hyperequivalence for the three semantics of logic programs given bystable, supported and supported minimal models. For each semantics, we identifyfour types of contexts, depending on whether the head and body alphabets aregiven directly or as the complement of a given set. Hyperequivalence relativeto contexts where the head and body alphabets are specified directly has beenstudied before. In this paper, we establish the complexity of decidingrelativized hyperequivalence with respect to the three other types of contextprograms.  To appear in Theory and Practice of Logic Programming (TPLP).

Strong Equivalence of Qualitative Optimization Problems

  We introduce the framework of qualitative optimization problems (or, simply,optimization problems) to represent preference theories. The formalism usesseparate modules to describe the space of outcomes to be compared (thegenerator) and the preferences on outcomes (the selector). We consider twotypes of optimization problems. They differ in the way the generator, which wemodel by a propositional theory, is interpreted: by the standard propositionallogic semantics, and by the equilibrium-model (answer-set) semantics. Under thelatter interpretation of generators, optimization problems directly generalizeanswer-set optimization programs proposed previously. We study strongequivalence of optimization problems, which guarantees their interchangeabilitywithin any larger context. We characterize several versions of strongequivalence obtained by restricting the class of optimization problems that canbe used as extensions and establish the complexity of associated reasoningtasks. Understanding strong equivalence is essential for modular representationof optimization problems and rewriting techniques to simplify them withoutchanging their inherent properties.

New Models for Generating Hard Random Boolean Formulas and Disjunctive  Logic Programs

  We propose two models of random quantified boolean formulas and their naturalrandom disjunctive logic program counterparts. The models extend the standardmodels of random k-CNF formulas and the Chen-Interian model of random 2QBFs.The first model controls the generation of programs and QSAT formulas byimposing a specific structure on rules and clauses, respectively. The secondmodel is based on a family of QSAT formulas in a non-clausal form. We providetheoretical bounds for the phase transition region in our models, and showexperimentally the presence of the easy-hard-easy pattern and its alignmentwith the location of the phase transition. We show that boolean formulas andlogic programs from our models are significantly harder than those obtainedfrom the standard k-CNF and Chen-Interian models, and that their combinationyields formulas and programs that are "super-hard" to evaluate. We also provideevidence suggesting that formulas from one of our models are well suited forassessing solvers tuned to real-world instances. Finally, it is noteworthythat, to the best of our knowledge, our models and results on randomdisjunctive logic programs are the first of their kind.

DATALOG with constraints - an answer-set programming system

  Answer-set programming (ASP) has emerged recently as a viable programmingparadigm well attuned to search problems in AI, constraint satisfaction andcombinatorics. Propositional logic is, arguably, the simplest ASP system withan intuitive semantics supporting direct modeling of problem constraints.However, for some applications, especially those requiring that transitiveclosure be computed, it requires additional variables and results in largetheories. Consequently, it may not be a practical computational tool for suchproblems. On the other hand, ASP systems based on nonmonotonic logics, such asstable logic programming, can handle transitive closure computation efficientlyand, in general, yield very concise theories as problem representations. Theirsemantics is, however, more complex. Searching for the middle ground, in thispaper we introduce a new nonmonotonic logic, DATALOG with constraints or DC.Informally, DC theories consist of propositional clauses (constraints) and ofHorn rules. The semantics is a simple and natural extension of the semantics ofthe propositional logic. However, thanks to the presence of Horn rules in thesystem, modeling of transitive closure becomes straightforward. We describe thesyntax and semantics of DC, and study its properties. We discuss animplementation of DC and present results of experimental study of theeffectiveness of DC, comparing it with CSAT, a satisfiability checker andSMODELS implementation of stable logic programming. Our results show that DC iscompetitive with the other two approaches, in case of many search problems,often yielding much more efficient solutions.

ASPMT(QS): Non-Monotonic Spatial Reasoning with Answer Set Programming  Modulo Theories

  The systematic modelling of \emph{dynamic spatial systems} [9] is a keyrequirement in a wide range of application areas such as comonsense cognitiverobotics, computer-aided architecture design, dynamic geographic informationsystems. We present ASPMT(QS), a novel approach and fully-implemented prototypefor non-monotonic spatial reasoning ---a crucial requirement within dynamicspatial systems-- based on Answer Set Programming Modulo Theories (ASPMT).ASPMT(QS) consists of a (qualitative) spatial representation module (QS) and amethod for turning tight ASPMT instances into Sat Modulo Theories (SMT)instances in order to compute stable models by means of SMT solvers. Weformalise and implement concepts of default spatial reasoning and spatial frameaxioms using choice formulas. Spatial reasoning is performed by encodingspatial relations as systems of polynomial constraints, and solving via SMTwith the theory of real nonlinear arithmetic. We empirically evaluate ASPMT(QS)in comparison with other prominent contemporary spatial reasoning systems. Ourresults show that ASPMT(QS) is the only existing system that is capable ofreasoning about indirect spatial effects (i.e. addressing the ramificationproblem), and integrating geometric and qualitative spatial information withina non-monotonic spatial reasoning context.

Dual-normal Logic Programs - the Forgotten Class

  Disjunctive Answer Set Programming is a powerful declarative programmingparadigm with complexity beyond NP. Identifying classes of programs for whichthe consistency problem is in NP is of interest from the theoretical standpointand can potentially lead to improvements in the design of answer setprogramming solvers. One of such classes consists of dual-normal programs,where the number of positive body atoms in proper rules is at most one. Unlikeother classes of programs, dual-normal programs have received little attentionso far. In this paper we study this class. We relate dual-normal programs topropositional theories and to normal programs by presenting severalinter-translations. With the translation from dual-normal to normal programs athand, we introduce the novel class of body-cycle free programs, which are inmany respects dual to head-cycle free programs. We establish the expressivepower of dual-normal programs in terms of SE- and UE-models, and compare themto normal programs. We also discuss the complexity of deciding whetherdual-normal programs are strongly and uniformly equivalent.

The informal semantics of Answer Set Programming: A Tarskian perspective

  In Knowledge Representation, it is crucial that knowledge engineers have agood understanding of the formal expressions that they write. What formalexpressions state intuitively about the domain of discourse is studied in thetheory of the informal semantics of a logic. In this paper we study theinformal semantics of Answer Set Programming. The roots of answer setprogramming lie in the language of Extended Logic Programming, which wasintroduced initially as an epistemic logic for default and autoepistemicreasoning. In 1999, the seminal papers on answer set programming proposed touse this logic for a different purpose, namely, to model and solve searchproblems. Currently, the language is used primarily in this new role. However,the original epistemic intuitions lose their explanatory relevance in this newcontext. How answer set programs are connected to the specifications ofproblems they model is more easily explained in a classical Tarskian semantics,in which models correspond to possible worlds, rather than to belief states ofan epistemic agent. In this paper, we develop a new theory of the informalsemantics of answer set programming, which is formulated in the Tarskiansetting and based on Frege's compositionality principle. It differssubstantially from the earlier epistemic theory of informal semantics,providing a different view on the meaning of the connectives in answer setprogramming and on its relation to other logics, in particular classical logic.

