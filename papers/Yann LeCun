Convolutional Matching Pursuit and Dictionary Training

  Matching pursuit and K-SVD is demonstrated in the translation invariantsetting

Stacked What-Where Auto-encoders

  We present a novel architecture, the "stacked what-where auto-encoders"(SWWAE), which integrates discriminative and generative pathways and provides aunified approach to supervised, semi-supervised and unsupervised learningwithout relying on sampling during training. An instantiation of SWWAE uses aconvolutional net (Convnet) (LeCun et al. (1998)) to encode the input, andemploys a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce thereconstruction. The objective function includes reconstruction terms thatinduce the hidden states in the Deconvnet to be similar to those of theConvnet. Each pooling layer produces two sets of variables: the "what" whichare fed to the next layer, and its complementary variable "where" that are fedto the corresponding layer in the generative decoder.

Fast Inference in Sparse Coding Algorithms with Applications to Object  Recognition

  Adaptive sparse coding methods learn a possibly overcomplete set of basisfunctions, such that natural image patches can be reconstructed by linearlycombining a small subset of these bases. The applicability of these methods tovisual object recognition tasks has been limited because of the prohibitivecost of the optimization algorithms required to compute the sparserepresentation. In this work we propose a simple and efficient algorithm tolearn basis functions. After training, this model also provides a fast andsmooth approximator to the optimal representation, achieving even betteraccuracy than exact sparse coding algorithms on visual object recognitiontasks.

Efficient Learning of Sparse Invariant Representations

  We propose a simple and efficient algorithm for learning sparse invariantrepresentations from unlabeled data with fast inference. When trained on shortmovies sequences, the learned features are selective to a range of orientationsand spatial frequencies, but robust to a wide range of positions, similar tocomplex cells in the primary visual cortex. We give a hierarchical version ofthe algorithm, and give guarantees of fast convergence under certainconditions.

Learning Representations by Maximizing Compression

  We give an algorithm that learns a representation of data throughcompression. The algorithm 1) predicts bits sequentially from those previouslyseen and 2) has a structure and a number of computations similar to anautoencoder. The likelihood under the model can be calculated exactly, andarithmetic coding can be used directly for compression. When training on digitsthe algorithm learns filters similar to those of restricted boltzman machinesand denoising autoencoders. Independent samples can be drawn from the model bya single sweep through the pixels. The algorithm has a good compressionperformance when compared to other methods that work under random ordering ofpixels.

No More Pesky Learning Rates

  The performance of stochastic gradient descent (SGD) depends critically onhow learning rates are tuned and decreased over time. We propose a method toautomatically adjust multiple learning rates so as to minimize the expectederror at any one time. The method relies on local gradient variations acrosssamples. In our approach, learning rates can increase as well as decrease,making it suitable for non-stationary problems. Using a number of convex andnon-convex learning tasks, we show that the resulting algorithm matches theperformance of SGD or other adaptive approaches with their best settingsobtained through systematic search, and effectively removes the need forlearning rate tuning.

Pedestrian Detection with Unsupervised Multi-Stage Feature Learning

  Pedestrian detection is a problem of considerable practical interest. Addingto the list of successful applications of deep learning methods to vision, wereport state-of-the-art and competitive results on all major pedestriandatasets with a convolutional network model. The model uses a few new twists,such as multi-stage features, connections that skip layers to integrate globalshape information with local distinctive motif information, and an unsupervisedmethod based on convolutional sparse coding to pre-train the filters at eachstage.

Causal graph-based video segmentation

  Numerous approaches in image processing and computer vision are making use ofsuper-pixels as a pre-processing step. Among the different methods producingsuch over-segmentation of an image, the graph-based approach of Felzenszwalband Huttenlocher is broadly employed. One of its interesting properties is thatthe regions are computed in a greedy manner in quasi-linear time. The algorithmmay be trivially extended to video segmentation by considering a video as a 3Dvolume, however, this can not be the case for causal segmentation, whensubsequent frames are unknown. We propose an efficient video segmentationapproach that computes temporally consistent pixels in a causal manner, fillingthe need for causal and real time applications.

Indoor Semantic Segmentation using depth information

  This work addresses multi-class segmentation of indoor scenes with RGB-Dinputs. While this area of research has gained much attention recently, mostworks still rely on hand-crafted features. In contrast, we apply a multiscaleconvolutional network to learn features directly from the images and the depthinformation. We obtain state-of-the-art on the NYU-v2 depth dataset with anaccuracy of 64.5%. We illustrate the labeling of indoor scenes in videossequences that could be processed in real-time using appropriate hardware suchas an FPGA.

Saturating Auto-Encoders

  We introduce a simple new regularizer for auto-encoders whose hidden-unitactivation functions contain at least one zero-gradient (saturated) region.This regularizer explicitly encourages activations in the saturated region(s)of the corresponding activation function. We call these SaturatingAuto-Encoders (SATAE). We show that the saturation regularizer explicitlylimits the SATAE's ability to reconstruct inputs which are not near the datamanifold. Furthermore, we show that a wide variety of features can be learnedwhen different activation functions are used. Finally, connections areestablished with the Contractive and Sparse Auto-Encoders.

Signal Recovery from Pooling Representations

  In this work we compute lower Lipschitz bounds of $\ell_p$ pooling operatorsfor $p=1, 2, \infty$ as well as $\ell_p$ pooling operators preceded byhalf-rectification layers. These give sufficient conditions for the design ofinvertible neural network layers. Numerical experiments on MNIST and imagepatches confirm that pooling layers can be inverted with phase recoveryalgorithms. Moreover, the regularity of the inverse pooling, controlled by thelower Lipschitz constant, is empirically verified with a nearest neighborregression.

Joint Training of a Convolutional Network and a Graphical Model for  Human Pose Estimation

  This paper proposes a new hybrid architecture that consists of a deepConvolutional Network and a Markov Random Field. We show how this architectureis successfully applied to the challenging problem of articulated human poseestimation in monocular images. The architecture can exploit structural domainconstraints such as geometric relationships between body joint locations. Weshow that joint training of these two model paradigms improves performance andallows us to significantly outperform existing state-of-the-art techniques.

Computing the Stereo Matching Cost with a Convolutional Neural Network

  We present a method for extracting depth information from a rectified imagepair. We train a convolutional neural network to predict how well two imagepatches match and use it to compute the stereo matching cost. The cost isrefined by cross-based cost aggregation and semiglobal matching, followed by aleft-right consistency check to eliminate errors in the occluded regions. Ourstereo method achieves an error rate of 2.61 % on the KITTI stereo dataset andis currently (August 2014) the top performing method on this dataset.

MoDeep: A Deep Learning Framework Using Motion Features for Human Pose  Estimation

  In this work, we propose a novel and efficient method for articulated humanpose estimation in videos using a convolutional network architecture, whichincorporates both color and motion features. We propose a new human body posedataset, FLIC-motion, that extends the FLIC dataset with additional motionfeatures. We apply our architecture to this dataset and report significantlybetter performance than current state-of-the-art pose detection systems.

Spectral classification using convolutional neural networks

  There is a great need for accurate and autonomous spectral classificationmethods in astrophysics. This thesis is about training a convolutional neuralnetwork (ConvNet) to recognize an object class (quasar, star or galaxy) fromone-dimension spectra only. Author developed several scripts and C programs fordatasets preparation, preprocessing and postprocessing of the data. EBLearnlibrary (developed by Pierre Sermanet and Yann LeCun) was used to createConvNets. Application on dataset of more than 60000 spectra yielded successrate of nearly 95%. This thesis conclusively proved great potential ofconvolutional neural networks and deep learning methods in astrophysics.

Unsupervised Feature Learning from Temporal Data

  Current state-of-the-art classification and detection algorithms rely onsupervised training. In this work we study unsupervised feature learning in thecontext of temporally coherent video data. We focus on feature learning fromunlabeled video data, using the assumption that adjacent video frames containsemantically similar information. This assumption is exploited to train aconvolutional pooling auto-encoder regularized by slowness and sparsity. Weestablish a connection between slow feature learning to metric learning andshow that the trained encoder can be used to define a more temporally andsemantically coherent metric.

Learning to Linearize Under Uncertainty

  Training deep feature hierarchies to solve supervised learning tasks hasachieved state of the art performance on many problems in computer vision.However, a principled way in which to train such hierarchies in theunsupervised setting has remained elusive. In this work we suggest a newarchitecture and loss for training deep feature hierarchies that linearize thetransformations observed in unlabeled natural video sequences. This is done bytraining a generative model to predict video frames. We also address theproblem of inherent uncertainty in prediction by introducing latent variablesthat are non-deterministic functions of the input into the networkarchitecture.

Eigenvalues of the Hessian in Deep Learning: Singularity and Beyond

  We look at the eigenvalues of the Hessian of a loss function before and aftertraining. The eigenvalue distribution is seen to be composed of two parts, thebulk which is concentrated around zero, and the edges which are scattered awayfrom zero. We present empirical evidence for the bulk indicating howover-parametrized the system is, and for the edges that depend on the inputdata.

Prediction Under Uncertainty with Error-Encoding Networks

  In this work we introduce a new framework for performing temporal predictionsin the presence of uncertainty. It is based on a simple idea of disentanglingcomponents of the future state which are predictable from those which areinherently unpredictable, and encoding the unpredictable components into alow-dimensional latent variable which is fed into a forward model. Our methoduses a supervised training objective which is fast and easy to train. Weevaluate it in the context of video prediction on multiple datasets and showthat it is able to consistently generate diverse predictions without the needfor alternating minimization over a latent space or adversarial training.

Distributed stochastic optimization for deep learning (thesis)

  We study the problem of how to distribute the training of large-scale deeplearning models in the parallel computing environment. We propose a newdistributed stochastic optimization method called Elastic Averaging SGD(EASGD). We analyze the convergence rate of the EASGD method in the synchronousscenario and compare its stability condition with the existing ADMM method inthe round-robin scheme. An asynchronous and momentum variant of the EASGDmethod is applied to train deep convolutional neural networks for imageclassification on the CIFAR and ImageNet datasets. Our approach accelerates thetraining and furthermore achieves better test accuracy. It also requires a muchsmaller amount of communication than other common baseline approaches such asthe DOWNPOUR method.  We then investigate the limit in speedup of the initial and the asymptoticphase of the mini-batch SGD, the momentum SGD, and the EASGD methods. We findthat the spread of the input data distribution has a big impact on theirinitial convergence rate and stability region. We also find a surprisingconnection between the momentum SGD and the EASGD method with a negative movingaverage rate. A non-convex case is also studied to understand when EASGD canget trapped by a saddle point.  Finally, we scale up the EASGD method by using a tree structured networktopology. We show empirically its advantage and challenge. We also establish aconnection between the EASGD and the DOWNPOUR method with the classical Jacobiand the Gauss-Seidel method, thus unifying a class of distributed stochasticoptimization methods.

Emergence of Complex-Like Cells in a Temporal Product Network with Local  Receptive Fields

  We introduce a new neural architecture and an unsupervised algorithm forlearning invariant representations from temporal sequence of images. The systemuses two groups of complex cells whose outputs are combined multiplicatively:one that represents the content of the image, constrained to be constant overseveral consecutive frames, and one that represents the precise location offeatures, which is allowed to vary over time but constrained to be sparse. Thearchitecture uses an encoder to extract features, and a decoder to reconstructthe input from the features. The method was applied to patches extracted fromconsecutive movie frames and produces orientation and frequency selective unitsanalogous to the complex cells in V1. An extension of the method is proposed totrain a network composed of units with local receptive field spread over alarge image of arbitrary size. A layer of complex cells, subject to sparsityconstraints, pool feature units over overlapping local neighborhoods, whichcauses the feature units to organize themselves into pinwheel patterns oforientation-selective receptive fields, similar to those observed in themammalian visual cortex. A feed-forward encoder efficiently computes thefeature representation of full images.

Fast approximations to structured sparse coding and applications to  object classification

  We describe a method for fast approximation of sparse coding. The input spaceis subdivided by a binary decision tree, and we simultaneously learn adictionary and assignment of allowed dictionary elements for each leaf of thetree. We store a lookup table with the assignments and the pseudoinverses foreach node, allowing for very fast inference. We give an algorithm for learningthe tree, the dictionary and the dictionary element assignment, and In theprocess of describing this algorithm, we discuss the more general problem oflearning the groups in group structured sparse modelling. We show that ourmethod creates good sparse representations by using it in the objectrecognition framework of \cite{lazebnik06,yang-cvpr-09}. Implementing our ownfast version of the SIFT descriptor the whole system runs at 20 frames persecond on $321 \times 481$ sized images on a laptop with a quad-core cpu, whilesacrificing very little accuracy on the Caltech 101 and 15 scenes benchmarks.

Convolutional Neural Networks Applied to House Numbers Digit  Classification

  We classify digits of real-world house numbers using convolutional neuralnetworks (ConvNets). ConvNets are hierarchical feature learning neural networkswhose structure is biologically inspired. Unlike many popular vision approachesthat are hand-designed, ConvNets can automatically learn a unique set offeatures optimized for a given task. We augmented the traditional ConvNetarchitecture by learning multi-stage features and by using Lp pooling andestablish a new state-of-the-art of 94.85% accuracy on the SVHN dataset (45.2%error improvement). Furthermore, we analyze the benefits of different poolingmethods and multi-stage features in ConvNets. The source code and a tutorialare available at eblearn.sf.net.

Pushing Stochastic Gradient towards Second-Order Methods --  Backpropagation Learning with Transformations in Nonlinearities

  Recently, we proposed to transform the outputs of each hidden neuron in amulti-layer perceptron network to have zero output and zero slope on average,and use separate shortcut connections to model the linear dependencies instead.We continue the work by firstly introducing a third transformation to normalizethe scale of the outputs of each hidden neuron, and secondly by analyzing theconnections to second order optimization methods. We show that thetransformations make a simple stochastic gradient behave closer to second-orderoptimization methods and thus speed up learning. This is shown both in theoryand with experiments. The experiments on the third transformation show thatwhile it further increases the speed of learning, it can also hurt performanceby converging to a worse local optimum, where both the inputs and outputs ofmany hidden neurons are close to zero.

Learning Stable Group Invariant Representations with Convolutional  Networks

  Transformation groups, such as translations or rotations, effectively expresspart of the variability observed in many recognition problems. The groupstructure enables the construction of invariant signal representations withappealing mathematical properties, where convolutions, together with poolingoperators, bring stability to additive and geometric perturbations of theinput. Whereas physical transformation groups are ubiquitous in image and audioapplications, they do not account for all the variability of complex signalclasses.  We show that the invariance properties built by deep convolutional networkscan be cast as a form of stable group invariance. The network wiringarchitecture determines the invariance group, while the trainable filtercoefficients characterize the group action. We give explanatory examples whichillustrate how the network architecture controls the resulting invariancegroup. We also explore the principle by which additional convolutional layersinduce a group factorization enabling more abstract, powerful invariantrepresentations.

Adaptive learning rates and parallelization for stochastic, sparse,  non-smooth gradients

  Recent work has established an empirically successful framework for adaptinglearning rates for stochastic gradient descent (SGD). This effectively removesall needs for tuning, while automatically reducing learning rates over time onstationary problems, and permitting learning rates to grow appropriately innon-stationary tasks. Here, we extend the idea in three directions, addressingproper minibatch parallelization, including reweighted updates for sparse ororthogonal gradients, improving robustness on non-smooth loss functions, in theprocess replacing the diagonal Hessian estimation procedure that may not alwaysbe available by a robust finite-difference approximation. The final algorithmintegrates all these components, has linear complexity and is hyper-parameterfree.

Discriminative Recurrent Sparse Auto-Encoders

  We present the discriminative recurrent sparse auto-encoder model, comprisinga recurrent encoder of rectified linear units, unrolled for a fixed number ofiterations, and connected to two linear decoders that reconstruct the input andpredict its supervised classification. Training viabackpropagation-through-time initially minimizes an unsupervised sparsereconstruction error; the loss function is then augmented with a discriminativeterm on the supervised classification. The depth implicit in thetemporally-unrolled form allows the system to exhibit all the power of deepnetworks, while substantially reducing the number of trainable parameters.  From an initially unstructured network the hidden units differentiate intocategorical-units, each of which represents an input prototype with awell-defined class; and part-units representing deformations of theseprototypes. The learned organization of the recurrent encoder is hierarchical:part-units are driven directly by the input, whereas the activity ofcategorical-units builds up over time through interactions with the part-units.Even using a small number of hidden units per layer, discriminative recurrentsparse auto-encoders achieve excellent performance on MNIST.

Understanding Deep Architectures using a Recursive Convolutional Network

  A key challenge in designing convolutional network models is sizing themappropriately. Many factors are involved in these decisions, including numberof layers, feature maps, kernel sizes, etc. Complicating this further is thefact that each of these influence not only the numbers and dimensions of theactivation units, but also the total number of parameters. In this paper wefocus on assessing the independent contributions of three of these linkedvariables: The numbers of layers, feature maps, and parameters. To accomplishthis, we employ a recursive convolutional network whose weights are tiedbetween layers; this allows us to vary each of the three factors in acontrolled setting. We find that while increasing the numbers of layers andparameters each have clear benefit, the number of feature maps (and hencedimensionality of the representation) appears ancillary, and finds most of itsbenefit through the introduction of more weights. Our results (i) empiricallyconfirm the notion that adding layers alone increases computational power,within the context of convolutional layers, and (ii) suggest that precisesizing of convolutional feature map dimensions is itself of little concern;more attention should be paid to the number of parameters in these layersinstead.

Fast Training of Convolutional Networks through FFTs

  Convolutional networks are one of the most widely employed architectures incomputer vision and machine learning. In order to leverage their ability tolearn complex functions, large amounts of data are required for training.Training a large convolutional network to produce state-of-the-art results cantake weeks, even when using modern GPUs. Producing labels using a trainednetwork can also be costly when dealing with web-scale datasets. In this work,we present a simple algorithm which accelerates training and inference by asignificant factor, and can yield improvements of over an order of magnitudecompared to existing state-of-the-art implementations. This is done bycomputing convolutions as pointwise products in the Fourier domain whilereusing the same transformed feature map many times. The algorithm isimplemented on a GPU architecture and addresses a number of related challenges.

Spectral Networks and Locally Connected Networks on Graphs

  Convolutional Neural Networks are extremely efficient architectures in imageand audio recognition tasks, thanks to their ability to exploit the localtranslational invariance of signal classes over their domain. In this paper weconsider possible generalizations of CNNs to signals defined on more generaldomains without the action of a translation group. In particular, we proposetwo constructions, one based upon a hierarchical clustering of the domain, andanother based on the spectrum of the graph Laplacian. We show throughexperiments that for low-dimensional graphs it is possible to learnconvolutional layers with a number of parameters independent of the input size,resulting in efficient deep architectures.

OverFeat: Integrated Recognition, Localization and Detection using  Convolutional Networks

  We present an integrated framework for using Convolutional Networks forclassification, localization and detection. We show how a multiscale andsliding window approach can be efficiently implemented within a ConvNet. Wealso introduce a novel deep learning approach to localization by learning topredict object boundaries. Bounding boxes are then accumulated rather thansuppressed in order to increase detection confidence. We show that differenttasks can be learned simultaneously using a single shared network. Thisintegrated framework is the winner of the localization task of the ImageNetLarge Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained verycompetitive results for the detection and classifications tasks. Inpost-competition work, we establish a new state of the art for the detectiontask. Finally, we release a feature extractor from our best model calledOverFeat.

Exploiting Linear Structure Within Convolutional Networks for Efficient  Evaluation

  We present techniques for speeding up the test-time evaluation of largeconvolutional networks, designed for object recognition tasks. These modelsdeliver impressive accuracy but each image evaluation requires millions offloating point operations, making their deployment on smartphones andInternet-scale clusters problematic. The computation is dominated by theconvolution operations in the lower layers of the model. We exploit the linearstructure present within the convolutional filters to derive approximationsthat significantly reduce the required computation. Using largestate-of-the-art models, we demonstrate we demonstrate speedups ofconvolutional layers on both CPU and GPU by a factor of 2x, while keeping theaccuracy within 1% of the original model.

Fast Approximation of Rotations and Hessians matrices

  A new method to represent and approximate rotation matrices is introduced.The method represents approximations of a rotation matrix $Q$ with linearithmiccomplexity, i.e. with $\frac{1}{2}n\lg(n)$ rotations over pairs of coordinates,arranged in an FFT-like fashion. The approximation is "learned" using gradientdescent. It allows to represent symmetric matrices $H$ as $QDQ^T$ where $D$ isa diagonal matrix. It can be used to approximate covariance matrix of Gaussianmodels in order to speed up inference, or to estimate and track the inverseHessian of an objective function by relating changes in parameters to changesin gradient along the trajectory followed by the optimization procedure.Experiments were conducted to approximate synthetic matrices, covariancematrices of real data, and Hessian matrices of objective functions involved inmachine learning problems.

Efficient Object Localization Using Convolutional Networks

  Recent state-of-the-art performance on human-body pose estimation has beenachieved with Deep Convolutional Networks (ConvNets). Traditional ConvNetarchitectures include pooling and sub-sampling layers which reducecomputational requirements, introduce invariance and prevent over-training.These benefits of pooling come at the cost of reduced localization accuracy. Weintroduce a novel architecture which includes an efficient `positionrefinement' model that is trained to estimate the joint offset location withina small region of the image. This refinement model is jointly trained incascade with a state-of-the-art ConvNet model to achieve improved accuracy inhuman joint location estimation. We show that the variance of our detectorapproaches the variance of human annotations on the FLIC dataset andoutperforms all existing approaches on the MPII-human-pose dataset.

Unsupervised Learning of Spatiotemporally Coherent Metrics

  Current state-of-the-art classification and detection algorithms rely onsupervised training. In this work we study unsupervised feature learning in thecontext of temporally coherent video data. We focus on feature learning fromunlabeled video data, using the assumption that adjacent video frames containsemantically similar information. This assumption is exploited to train aconvolutional pooling auto-encoder regularized by slowness and sparsity. Weestablish a connection between slow feature learning to metric learning andshow that the trained encoder can be used to define a more temporally andsemantically coherent metric.

Explorations on high dimensional landscapes

  Finding minima of a real valued non-convex function over a high dimensionalspace is a major challenge in science. We provide evidence that some suchfunctions that are defined on high dimensional domains have a narrow band ofvalues whose pre-image contains the bulk of its critical points. This is incontrast with the low dimensional picture in which this band is wide. Oursimulations agree with the previous theoretical work on spin glasses thatproves the existence of such a band when the dimension of the domain tends toinfinity. Furthermore our experiments on teacher-student networks with theMNIST dataset establish a similar phenomenon in deep networks. We finallyobserve that both the gradient descent and the stochastic gradient descentmethods can reach this level within the same number of steps.

Audio Source Separation with Discriminative Scattering Networks

  In this report we describe an ongoing line of research for solvingsingle-channel source separation problems. Many monaural signal decompositiontechniques proposed in the literature operate on a feature space consisting ofa time-frequency representation of the input data. A challenge faced by theseapproaches is to effectively exploit the temporal dependencies of the signalsat scales larger than the duration of a time-frame. In this work we propose totackle this problem by modeling the signals using a time-frequencyrepresentation with multiple temporal resolutions. The proposed representationconsists of a pyramid of wavelet scattering operators, which generalizesConstant Q Transforms (CQT) with extra layers of convolution and complexmodulus. We first show that learning standard models with this multi-resolutionsetting improves source separation results over fixed-resolution methods. Asstudy case, we use Non-Negative Matrix Factorizations (NMF) that has beenwidely considered in many audio application. Then, we investigate the inclusionof the proposed multi-resolution setting into a discriminative training regime.We discuss several alternatives using different deep neural networkarchitectures.

Fast Convolutional Nets With fbfft: A GPU Performance Evaluation

  We examine the performance profile of Convolutional Neural Network trainingon the current generation of NVIDIA Graphics Processing Units. We introduce twonew Fast Fourier Transform convolution implementations: one based on NVIDIA'scuFFT library, and another based on a Facebook authored FFT implementation,fbfft, that provides significant speedups over cuFFT (over 1.5x) for wholeCNNs. Both of these convolution implementations are available in open source,and are faster than NVIDIA's cuDNN implementation for many common convolutionallayers (up to 23.5x for some synthetic kernel configurations). We discussdifferent performance regimes of convolutions, comparing areas wherestraightforward time domain convolutions outperform Fourier frequency domainconvolutions. Details on algorithmic applications of NVIDIA GPU hardwarespecifics in the implementation of fbfft are also provided.

Text Understanding from Scratch

  This article demontrates that we can apply deep learning to textunderstanding from character-level inputs all the way up to abstract textconcepts, using temporal convolutional networks (ConvNets). We apply ConvNetsto various large-scale datasets, including ontology classification, sentimentanalysis, and text categorization. We show that temporal ConvNets can achieveastonishing performance without the knowledge of words, phrases, sentences andany other syntactic or semantic structures with regards to a human language.Evidence shows that our models can work for both English and Chinese.

Deep Convolutional Networks on Graph-Structured Data

  Deep Learning's recent successes have mostly relied on ConvolutionalNetworks, which exploit fundamental statistical properties of images, soundsand video data: the local stationarity and multi-scale compositional structure,that allows expressing long range interactions in terms of shorter, localizedinteractions. However, there exist other important examples, such as textdocuments or bioinformatic data, that may lack some or all of these strongstatistical regularities.  In this paper we consider the general question of how to construct deeparchitectures with small learning complexity on general non-Euclidean domains,which are typically unknown and need to be estimated from the data. Inparticular, we develop an extension of Spectral Networks which incorporates aGraph Estimation procedure, that we test on large-scale classificationproblems, matching or improving over Dropout Networks with far less parametersto estimate.

Character-level Convolutional Networks for Text Classification

  This article offers an empirical exploration on the use of character-levelconvolutional networks (ConvNets) for text classification. We constructedseveral large-scale datasets to show that character-level convolutionalnetworks could achieve state-of-the-art or competitive results. Comparisons areoffered against traditional models such as bag of words, n-grams and theirTFIDF variants, and deep learning models such as word-based ConvNets andrecurrent neural networks.

Stereo Matching by Training a Convolutional Neural Network to Compare  Image Patches

  We present a method for extracting depth information from a rectified imagepair. Our approach focuses on the first stage of many stereo algorithms: thematching cost computation. We approach the problem by learning a similaritymeasure on small image patches using a convolutional neural network. Trainingis carried out in a supervised manner by constructing a binary classificationdata set with examples of similar and dissimilar pairs of patches. We examinetwo network architectures for this task: one tuned for speed, the other foraccuracy. The output of the convolutional neural network is used to initializethe stereo matching cost. A series of post-processing steps follow: cross-basedcost aggregation, semiglobal matching, a left-right consistency check, subpixelenhancement, a median filter, and a bilateral filter. We evaluate our method onthe KITTI 2012, KITTI 2015, and Middlebury stereo data sets and show that itoutperforms other approaches on all three data sets.

Universum Prescription: Regularization using Unlabeled Data

  This paper shows that simply prescribing "none of the above" labels tounlabeled data has a beneficial regularization effect to supervised learning.We call it universum prescription by the fact that the prescribed labels cannotbe one of the supervised labels. In spite of its simplicity, universumprescription obtained competitive results in training deep convolutionalnetworks for CIFAR-10, CIFAR-100, STL-10 and ImageNet datasets. A qualitativejustification of these approaches using Rademacher complexity is presented. Theeffect of a regularization parameter -- probability of sampling from unlabeleddata -- is also studied empirically.

Universal halting times in optimization and machine learning

  The authors present empirical distributions for the halting time (measured bythe number of iterations to reach a given accuracy) of optimization algorithmsapplied to two random systems: spin glasses and deep learning. Given analgorithm, which we take to be both the optimization routine and the form ofthe random landscape, the fluctuations of the halting time follow adistribution that, after centering and scaling, remains unchanged even when thedistribution on the landscape is changed. We observe two qualitative classes: AGumbel-like distribution that appears in Google searches, human decision times,the QR eigenvalue algorithm and spin glasses, and a Gaussian-like distributionthat appears in conjugate gradient method, deep network with MNIST input dataand deep network with random input data. This empirical evidence suggestspresence of a class of distributions for which the halting time is independentof the underlying distribution under some conditions.

Recurrent Orthogonal Networks and Long-Memory Tasks

  Although RNNs have been shown to be powerful tools for processing sequentialdata, finding architectures or optimization strategies that allow them to modelvery long term dependencies is still an active area of research. In this work,we carefully analyze two synthetic datasets originally outlined in (Hochreiterand Schmidhuber, 1997) which are used to evaluate the ability of RNNs to storeinformation over many time steps. We explicitly construct RNN solutions tothese problems, and using these constructions, illuminate both the problemsthemselves and the way in which RNNs store different types of information intheir hidden states. These constructions furthermore explain the success ofrecent methods that specify unitary initializations or constraints on thetransition matrices.

Phase 1: DCL System Research Using Advanced Approaches for Land-based or  Ship-based Real-Time Recognition and Localization of Marine Mammals - HPC  System Implementation

  We aim to investigate advancing the state of the art of detection,classification and localization (DCL) in the field of bioacoustics. The twoprimary goals are to develop transferable technologies for detection andclassification in: (1) the area of advanced algorithms, such as deep learningand other methods; and (2) advanced systems, capable of real-time and archivaland processing. This project will focus on long-term, continuous datasets toprovide automatic recognition, minimizing human time to annotate the signals.Effort will begin by focusing on several years of multi-channel acoustic datacollected in the Stellwagen Bank National Marine Sanctuary (SBNMS) between 2006and 2010. Our efforts will incorporate existing technologies in thebioacoustics signal processing community, advanced high performance computing(HPC) systems, and new approaches aimed at automatically detecting-classifyingand measuring features for species-specific marine mammal sounds within passiveacoustic data.

Phase 3: DCL System Using Deep Learning Approaches for Land-based or  Ship-based Real-Time Recognition and Localization of Marine Mammals -  Bioacoustic Applicaitons

  Goals of this research phase is to investigate advanced detection andclassification pardims useful for data-mining passive large passive acousticarchives. Technical objectives are to develop and refine a High PerformanceComputing, Acoustic Data Accelerator (HPC-ADA) along with MATLAB based softwarebased on time series acoustic signal Detection cLassification using Machinelearning Algorithms, called DeLMA. Data scientists and biologists integrate touse the HPC-ADA and DeLMA technologies to explore data using newly developedtechniques aimed at inspection of data extracted at large spatial and temporalscales.

What is the Best Feature Learning Procedure in Hierarchical Recognition  Architectures?

  (This paper was written in November 2011 and never published. It is posted onarXiv.org in its original form in June 2016). Many recent object recognitionsystems have proposed using a two phase training procedure to learn sparseconvolutional feature hierarchies: unsupervised pre-training followed bysupervised fine-tuning. Recent results suggest that these methods providelittle improvement over purely supervised systems when the appropriatenonlinearities are included. This paper presents an empirical exploration ofthe space of learning procedures for sparse convolutional networks to assesswhich method produces the best performance. In our study, we introduce anaugmentation of the Predictive Sparse Decomposition method that includes adiscriminative term (DPSD). We also introduce a new single phase supervisedlearning procedure that places an L1 penalty on the output state of each layerof the network. This forces the network to produce sparse codes without theexpensive pre-training phase. Using DPSD with a new, complex predictor thatincorporates lateral inhibition, combined with multi-scale feature pooling, andsupervised refinement, the system achieves a 70.6\% recognition rate onCaltech-101. With the addition of convolutional training, a 77\% recognitionwas obtained on the CIfAR-10 dataset.

Very Deep Convolutional Networks for Text Classification

  The dominant approach for many NLP tasks are recurrent neural networks, inparticular LSTMs, and convolutional neural networks. However, thesearchitectures are rather shallow in comparison to the deep convolutionalnetworks which have pushed the state-of-the-art in computer vision. We presenta new architecture (VDCNN) for text processing which operates directly at thecharacter level and uses only small convolutions and pooling operations. We areable to show that the performance of this model increases with depth: using upto 29 convolutional layers, we report improvements over the state-of-the-art onseveral public text classification tasks. To the best of our knowledge, this isthe first time that very deep convolutional nets have been applied to textprocessing.

Fast Incremental Learning for Off-Road Robot Navigation

  A promising approach to autonomous driving is machine learning. In suchsystems, training datasets are created that capture the sensory input to avehicle as well as the desired response. A disadvantage of using a learnednavigation system is that the learning process itself may require a huge numberof training examples and a large amount of computing. To avoid the need tocollect a large training set of driving examples, we describe a system thattakes advantage of the huge number of training examples provided by ImageNet,but is able to adapt quickly using a small training set for the specificdriving environment.

