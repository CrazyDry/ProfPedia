Unsupervised Learning of Geometry with Edge-aware Depth-Normal  Consistency

  Learning to reconstruct depths in a single image by watching unlabeled videosvia deep convolutional network (DCN) is attracting significant attention inrecent years. In this paper, we introduce a surface normal representation forunsupervised depth estimation framework. Our estimated depths are constrainedto be compatible with predicted normals, yielding more robust geometry results.Specifically, we formulate an edge-aware depth-normal consistency term, andsolve it by constructing a depth-to-normal layer and a normal-to-depth layerinside of the DCN. The depth-to-normal layer takes estimated depths as input,and computes normal directions using cross production based on neighboringpixels. Then given the estimated normals, the normal-to-depth layer outputs aregularized depth map through local planar smoothness. Both layers are computedwith awareness of edges inside the image to help address the issue ofdepth/normal discontinuity and preserve sharp edges. Finally, to train thenetwork, we apply the photometric error and gradient smoothness for both depthand normal predictions. We conducted experiments on both outdoor (KITTI) andindoor (NYUv2) datasets, and show that our algorithm vastly outperforms stateof the art, which demonstrates the benefits from our approach.

