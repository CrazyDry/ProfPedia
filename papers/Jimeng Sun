Generating Multi-label Discrete Patient Records using Generative  Adversarial Networks

  Access to electronic health record (EHR) data has motivated computationaladvances in medical research. However, various concerns, particularly overprivacy, can limit access to and collaborative use of EHR data. Sharingsynthetic EHR data could mitigate risk. In this paper, we propose a newapproach, medical Generative Adversarial Network (medGAN), to generaterealistic synthetic patient records. Based on input real patient records,medGAN can generate high-dimensional discrete variables (e.g., binary and countfeatures) via a combination of an autoencoder and generative adversarialnetworks. We also propose minibatch averaging to efficiently avoid modecollapse, and increase the learning efficiency with batch normalization andshortcut connections. To demonstrate feasibility, we showed that medGANgenerates synthetic patient records that achieve comparable performance to realdata on many experiments including distribution statistics, predictive modelingtasks and a medical expert review. We also empirically observe a limitedprivacy risk in both identity and attribute disclosure using medGAN.

SLEEPNET: Automated Sleep Staging System via Deep Learning

  Sleep disorders, such as sleep apnea, parasomnias, and hypersomnia, affect50-70 million adults in the United States (Hillman et al., 2006). Overnightpolysomnography (PSG), including brain monitoring using electroencephalography(EEG), is a central component of the diagnostic evaluation for sleep disorders.While PSG is conventionally performed by trained technologists, the recent riseof powerful neural network learning algorithms combined with largephysiological datasets offers the possibility of automation, potentially makingexpert-level sleep analysis more widely available. We propose SLEEPNET (SleepEEG neural network), a deployed annotation tool for sleep staging. SLEEPNETuses a deep recurrent neural network trained on the largest sleep physiologydatabase assembled to date, consisting of PSGs from over 10,000 patients fromthe Massachusetts General Hospital (MGH) Sleep Laboratory. SLEEPNET achieveshuman-level annotation performance on an independent test set of 1,000 EEGs,with an average accuracy of 85.76% and algorithm-expert inter-rater agreement(IRA) of kappa = 79.46%, comparable to expert-expert IRA.

Scalable Latent Tree Model and its Application to Health Analytics

  We present an integrated approach to structure and parameter estimation inlatent tree graphical models, where some nodes are hidden. Our overall approachfollows a "divide-and-conquer" strategy that learns models over small groups ofvariables and iteratively merges into a global solution. The structure learninginvolves combinatorial operations such as minimum spanning tree constructionand local recursive grouping; the parameter learning is based on the method ofmoments and on tensor decompositions. Our method is guaranteed to correctlyrecover the unknown tree structure and the model parameters with low samplecomplexity for the class of linear multivariate latent tree models whichincludes discrete and Gaussian distributions, and Gaussian mixtures. Our bulkasynchronous parallel algorithm is implemented in parallel using the OpenMPframework and scales logarithmically with the number of variables and linearlywith dimensionality of each variable. Our experiments confirm a high degree ofefficiency and accuracy on large datasets of electronic health records. Theproposed algorithm also generates intuitive and clinically meaningful diseasehierarchies.

Multi-layer Representation Learning for Medical Concepts

  Learning efficient representations for concepts has been proven to be animportant basis for many applications such as machine translation or documentclassification. Proper representations of medical concepts such as diagnosis,medication, procedure codes and visits will have broad applications inhealthcare analytics. However, in Electronic Health Records (EHR) the visitsequences of patients include multiple concepts (diagnosis, procedure, andmedication codes) per visit. This structure provides two types of relationalinformation, namely sequential order of visits and co-occurrence of the codeswithin each visit. In this work, we propose Med2Vec, which not only learnsdistributed representations for both medical codes and visits from a large EHRdataset with over 3 million visits, but also allows us to interpret the learnedrepresentations confirmed positively by clinical experts. In the experiments,Med2Vec displays significant improvement in key medical applications comparedto popular baselines such as Skip-gram, GloVe and stacked autoencoder, whileproviding clinically meaningful interpretation.

Causal Regularization

  In application domains such as healthcare, we want accurate predictive modelsthat are also causally interpretable. In pursuit of such models, we propose acausal regularizer to steer predictive models towards causally-interpretablesolutions and theoretically study its properties. In a large-scale analysis ofElectronic Health Records (EHR), our causally-regularized model outperforms itsL1-regularized counterpart in causal accuracy and is competitive in predictiveperformance. We perform non-linear causality analysis by causally regularizinga special neural network architecture. We also show that the proposed causalregularizer can be used together with neural representation learning algorithmsto yield up to 20% improvement over multilayer perceptron in detectingmultivariate causation, a situation common in healthcare, where many causalfactors should occur simultaneously to have an effect on the target variable.

Federated Tensor Factorization for Computational Phenotyping

  Tensor factorization models offer an effective approach to convert massiveelectronic health records into meaningful clinical concepts (phenotypes) fordata analysis. These models need a large amount of diverse samples to avoidpopulation bias. An open challenge is how to derive phenotypes jointly acrossmultiple hospitals, in which direct patient-level data sharing is not possible(e.g., due to institutional policies). In this paper, we developed a novelsolution to enable federated tensor factorization for computational phenotypingwithout sharing patient-level data. We developed secure data harmonization andfederated computation procedures based on alternating direction method ofmultipliers (ADMM). Using this method, the multiple hospitals iterativelyupdate tensors and transfer secure summarized information to a central server,and the server aggregates the information to generate phenotypes. Wedemonstrated with real medical datasets that our method resembles thecentralized training model (based on combined datasets) in terms of accuracyand phenotypes discovery while respecting privacy.

Explainable Prediction of Medical Codes from Clinical Text

  Clinical notes are text documents that are created by clinicians for eachpatient encounter. They are typically accompanied by medical codes, whichdescribe the diagnosis and treatment. Annotating these codes is labor intensiveand error prone; furthermore, the connection between the codes and the text isnot annotated, obscuring the reasons and details behind specific diagnoses andtreatments. We present an attentional convolutional network that predictsmedical codes from clinical text. Our method aggregates information across thedocument using a convolutional neural network, and uses an attention mechanismto select the most relevant segments for each of the thousands of possiblecodes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of0.54, which are both better than the prior state of the art. Furthermore,through an interpretability evaluation by a physician, we show that theattention mechanism identifies meaningful explanations for each code assignment

GAMENet: Graph Augmented MEmory Networks for Recommending Medication  Combination

  Recent progress in deep learning is revolutionizing the healthcare domainincluding providing solutions to medication recommendations, especiallyrecommending medication combination for patients with complex healthconditions. Existing approaches either do not customize based on patient healthhistory, or ignore existing knowledge on drug-drug interactions (DDI) thatmight lead to adverse outcomes. To fill this gap, we propose the GraphAugmented Memory Networks (GAMENet), which integrates the drug-druginteractions knowledge graph by a memory module implemented as a graphconvolutional networks, and models longitudinal patient records as the query.It is trained end-to-end to provide safe and personalized recommendation ofmedication combination. We demonstrate the effectiveness and safety of GAMENetby comparing with several state-of-the-art methods on real EHR data. GAMENetoutperformed all baselines in all effectiveness measures, and also achieved3.60% DDI rate reduction from existing EHR data.

AWE: Asymmetric Word Embedding for Textual Entailment

  Textual entailment is a fundamental task in natural language processing. Itrefers to the directional relation between text fragments such that the"premise" can infer "hypothesis". In recent years deep learning methods haveachieved great success in this task. Many of them have considered theinter-sentence word-word interactions between the premise-hypothesis pairs,however, few of them considered the "asymmetry" of these interactions.Different from paraphrase identification or sentence similarity evaluation,textual entailment is essentially determining a directional (asymmetric)relation between the premise and the hypothesis. In this paper, we propose asimple but effective way to enhance existing textual entailment algorithms byusing asymmetric word embeddings. Experimental results on SciTail and SNLIdatasets show that the learned asymmetric word embeddings could significantlyimprove the word-word interaction based textual entailment models. It isnoteworthy that the proposed AWE-DeIsTe model can get 2.1% accuracy improvementover prior state-of-the-art on SciTail.

MiME: Multilevel Medical Embedding of Electronic Health Records for  Predictive Healthcare

  Deep learning models exhibit state-of-the-art performance for many predictivehealthcare tasks using electronic health records (EHR) data, but these modelstypically require training data volume that exceeds the capacity of mosthealthcare systems. External resources such as medical ontologies are used tobridge the data volume constraint, but this approach is often not directlyapplicable or useful because of inconsistencies with terminology. To solve thedata insufficiency challenge, we leverage the inherent multilevel structure ofEHR data and, in particular, the encoded relationships among medical codes. Wepropose Multilevel Medical Embedding (MiME) which learns the multilevelembedding of EHR data while jointly performing auxiliary prediction tasks thatrely on this inherent EHR structure without the need for external labels. Weconducted two prediction tasks, heart failure prediction and sequential diseaseprediction, where MiME outperformed baseline methods in diverse evaluationsettings. In particular, MiME consistently outperformed all baselines whenpredicting heart failure on datasets of different volumes, especiallydemonstrating the greatest performance improvement (15% relative gain in PR-AUCover the best baseline) on the smallest dataset, demonstrating its ability toeffectively model the multilevel structure of EHR data.

CarePre: An Intelligent Clinical Decision Assistance System

  Clinical decision support systems (CDSS) are widely used to assist withmedical decision making. However, CDSS typically require manually curated rulesand other data which are difficult to maintain and keep up-to-date. Recentsystems leverage advanced deep learning techniques and electronic healthrecords (EHR) to provide more timely and precise results. Many of thesetechniques have been developed with a common focus on predicting upcomingmedical events. However, while the prediction results from these approaches arepromising, their value is limited by their lack of interpretability. To addressthis challenge, we introduce CarePre, an intelligent clinical decisionassistance system. The system extends a state-of-the-art deep learning model topredict upcoming diagnosis events for a focal patient based on his/herhistorical medical records. The system includes an interactive frameworktogether with intuitive visualizations designed to support the diagnosis,treatment outcome analysis, and the interpretation of the analysis results. Wedemonstrate the effectiveness and usefulness of CarePre system by reportingresults from a quantities evaluation of the prediction algorithm and a casestudy and three interviews with senior physicians.

RETAIN: An Interpretable Predictive Model for Healthcare using Reverse  Time Attention Mechanism

  Accuracy and interpretability are two dominant features of successfulpredictive models. Typically, a choice must be made in favor of complex blackbox models such as recurrent neural networks (RNN) for accuracy versus lessaccurate but more interpretable traditional models such as logistic regression.This tradeoff poses challenges in medicine where both accuracy andinterpretability are important. We addressed this challenge by developing theREverse Time AttentIoN model (RETAIN) for application to Electronic HealthRecords (EHR) data. RETAIN achieves high accuracy while remaining clinicallyinterpretable and is based on a two-level neural attention model that detectsinfluential past visits and significant clinical variables within those visits(e.g. key diagnoses). RETAIN mimics physician practice by attending the EHRdata in a reverse time order so that recent clinical visits are likely toreceive higher attention. RETAIN was tested on a large health system EHRdataset with 14 million visits completed by 263K patients over an 8 year periodand demonstrated predictive accuracy and computational scalability comparableto state-of-the-art methods such as RNN, and ease of interpretabilitycomparable to traditional models.

Doctor AI: Predicting Clinical Events via Recurrent Neural Networks

  Leveraging large historical data in electronic health record (EHR), wedeveloped Doctor AI, a generic predictive model that covers observed medicalconditions and medication uses. Doctor AI is a temporal model using recurrentneural networks (RNN) and was developed and applied to longitudinal timestamped EHR data from 260K patients over 8 years. Encounter records (e.g.diagnosis codes, medication codes or procedure codes) were input to RNN topredict (all) the diagnosis and medication categories for a subsequent visit.Doctor AI assesses the history of patients to make multilabel predictions (onelabel for each diagnosis or medication category). Based on separate blind testset evaluation, Doctor AI can perform differential diagnosis with up to 79%recall@30, significantly higher than several baselines. Moreover, wedemonstrate great generalizability of Doctor AI by adapting the resultingmodels from one institution to another without losing substantial accuracy.

Medical Concept Representation Learning from Electronic Health Records  and its Application on Heart Failure Prediction

  Objective: To transform heterogeneous clinical data from electronic healthrecords into clinically meaningful constructed features using data drivenmethod that rely, in part, on temporal relations among data. Materials andMethods: The clinically meaningful representations of medical concepts andpatients are the key for health analytic applications. Most of existingapproaches directly construct features mapped to raw data (e.g., ICD or CPTcodes), or utilize some ontology mapping such as SNOMED codes. However, none ofthe existing approaches leverage EHR data directly for learning such conceptrepresentation. We propose a new way to represent heterogeneous medicalconcepts (e.g., diagnoses, medications and procedures) based on co-occurrencepatterns in longitudinal electronic health records. The intuition behind themethod is to map medical concepts that are co-occuring closely in time tosimilar concept vectors so that their distance will be small. We also derive asimple method to construct patient vectors from the related medical conceptvectors. Results: For qualitative evaluation, we study similar medical conceptsacross diagnosis, medication and procedure. In quantitative evaluation, ourproposed representation significantly improves the predictive modelingperformance for onset of heart failure (HF), where classification methods (e.g.logistic regression, neural network, support vector machine and K-nearestneighbors) achieve up to 23% improvement in area under the ROC curve (AUC)using this proposed representation. Conclusion: We proposed an effective methodfor patient and medical concept representation learning. The resultingrepresentation can map relevant concepts together and also improves predictivemodeling performance.

FLASH: Fast Bayesian Optimization for Data Analytic Pipelines

  Modern data science relies on data analytic pipelines to organizeinterdependent computational steps. Such analytic pipelines often involvedifferent algorithms across multiple steps, each with its own hyperparameters.To achieve the best performance, it is often critical to select optimalalgorithms and to set appropriate hyperparameters, which requires largecomputational efforts. Bayesian optimization provides a principled way forsearching optimal hyperparameters for a single algorithm. However, manychallenges remain in solving pipeline optimization problems withhigh-dimensional and highly conditional search space. In this work, we proposeFast LineAr SearcH (FLASH), an efficient method for tuning analytic pipelines.FLASH is a two-layer Bayesian optimization framework, which firstly uses aparametric model to select promising algorithms, then computes a nonparametricmodel to fine-tune hyperparameters of the promising algorithms. FLASH alsoincludes an effective caching algorithm which can further accelerate the searchprocess. Extensive experiments on a number of benchmark datasets havedemonstrated that FLASH significantly outperforms previous state-of-the-artmethods in both search speed and accuracy. Using 50% of the time budget, FLASHachieves up to 20% improvement on test error rate compared to the baselines.FLASH also yields state-of-the-art performance on a real-world application forhealthcare predictive modeling.

Phenotyping using Structured Collective Matrix Factorization of  Multi--source EHR Data

  The increased availability of electronic health records (EHRs) havespearheaded the initiative for precision medicine using data driven approaches.Essential to this effort is the ability to identify patients with certainmedical conditions of interest from simple queries on EHRs, or EHR-basedphenotypes. Existing rule--based phenotyping approaches are extremely laborintensive. Instead, dimensionality reduction and latent factor estimationtechniques from machine learning can be adapted for phenotype extraction withno (or minimal) human supervision.  We propose to identify an easily interpretable latent space shared acrossvarious sources of EHR data as potential candidates for phenotypes. Byincorporating multiple EHR data sources (e.g., diagnosis, medications, and labreports) available in heterogeneous datatypes in a generalized\textit{Collective Matrix Factorization (CMF)}, our methods can generate richphenotypes. Further, easy interpretability in phenotyping application requiressparse representations of the candidate phenotypes, for example each phenotypederived from patients' medication and diagnosis data should preferably berepresented by handful of diagnosis and medications, ($5$--$10$ activecomponents). We propose a constrained formulation of CMF for estimating sparsephenotypes. We demonstrate the efficacy of our model through an extensiveempirical study on EHR data from Vanderbilt University Medical Center.

Sparse Hierarchical Tucker Factorization and its Application to  Healthcare

  We propose a new tensor factorization method, called the SparseHierarchical-Tucker (Sparse H-Tucker), for sparse and high-order data tensors.Sparse H-Tucker is inspired by its namesake, the classical Hierarchical Tuckermethod, which aims to compute a tree-structured factorization of an input dataset that may be readily interpreted by a domain expert. However, SparseH-Tucker uses a nested sampling technique to overcome a key scalability problemin Hierarchical Tucker, which is the creation of an unwieldy intermediate densecore tensor; the result of our approach is a faster, more space-efficient, andmore accurate method. We extensively test our method on a real healthcaredataset, which is collected from 30K patients and results in an 18th ordersparse data tensor. Unlike competing methods, Sparse H-Tucker can analyze thefull data set on a single multi-threaded machine. It can also do so moreaccurately and in less time than the state-of-the-art: on a 12th order subsetof the input data, Sparse H-Tucker is 18x more accurate and 7.5x faster than apreviously state-of-the-art method. Even for analyzing low order tensors (e.g.,4-order), our method requires close to an order of magnitude less time and overtwo orders of magnitude less memory, as compared to traditional tensorfactorization methods such as CP and Tucker. Moreover, we observe that SparseH-Tucker scales nearly linearly in the number of non-zero tensor elements. Theresulting model also provides an interpretable disease hierarchy, which isconfirmed by a clinical expert.

GRAM: Graph-based Attention Model for Healthcare Representation Learning

  Deep learning methods exhibit promising performance for predictive modelingin healthcare, but two important challenges remain: -Data insufficiency:Oftenin healthcare predictive modeling, the sample size is insufficient for deeplearning methods to achieve satisfactory results. -Interpretation:Therepresentations learned by deep learning methods should align with medicalknowledge. To address these challenges, we propose a GRaph-based AttentionModel, GRAM that supplements electronic health records (EHR) with hierarchicalinformation inherent to medical ontologies. Based on the data volume and theontology structure, GRAM represents a medical concept as a combination of itsancestors in the ontology via an attention mechanism. We compared predictiveperformance (i.e. accuracy, data needs, interpretability) of GRAM to variousmethods including the recurrent neural network (RNN) in two sequentialdiagnoses prediction tasks and one heart failure prediction task. Compared tothe basic RNN, GRAM achieved 10% higher accuracy for predicting diseases rarelyobserved in the training data and 3% improved area under the ROC curve forpredicting heart failure using an order of magnitude less training data.Additionally, unlike other methods, the medical concept representations learnedby GRAM are well aligned with the medical ontology. Finally, GRAM exhibitsintuitive attention behaviors by adaptively generalizing to higher levelconcepts when facing data insufficiency at the lower level concepts.

SPARTan: Scalable PARAFAC2 for Large & Sparse Data

  In exploratory tensor mining, a common problem is how to analyze a set ofvariables across a set of subjects whose observations do not align naturally.For example, when modeling medical features across a set of patients, thenumber and duration of treatments may vary widely in time, meaning there is nomeaningful way to align their clinical records across time points for analysispurposes. To handle such data, the state-of-the-art tensor model is theso-called PARAFAC2, which yields interpretable and robust output and cannaturally handle sparse data. However, its main limitation up to now has beenthe lack of efficient algorithms that can handle large-scale datasets.  In this work, we fill this gap by developing a scalable method to compute thePARAFAC2 decomposition of large and sparse datasets, called SPARTan. Our methodexploits special structure within PARAFAC2, leading to a novel algorithmicreformulation that is both fast (in absolute time) and more memory-efficientthan prior work. We evaluate SPARTan on both synthetic and real datasets,showing 22X performance gains over the best previous implementation and alsohandling larger problem instances for which the baseline fails. Furthermore, weare able to apply SPARTan to the mining of temporally-evolving phenotypes ondata taken from real and medically complex pediatric patients. The clinicalmeaningfulness of the phenotypes identified in this process, as well as theirtemporal evolution over time for several patients, have been endorsed byclinical experts.

SUSTain: Scalable Unsupervised Scoring for Tensors and its Application  to Phenotyping

  This paper presents a new method, which we call SUSTain, that extendsreal-valued matrix and tensor factorizations to data where values are integers.Such data are common when the values correspond to event counts or ordinalmeasures. The conventional approach is to treat integer data as real, and thenapply real-valued factorizations. However, doing so fails to preserve importantcharacteristics of the original data, thereby making it hard to interpret theresults. Instead, our approach extracts factor values from integer datasets asscores that are constrained to take values from a small integer set. Thesescores are easy to interpret: a score of zero indicates no feature contributionand higher scores indicate distinct levels of feature importance.  At its core, SUSTain relies on: a) a problem partitioning intointeger-constrained subproblems, so that they can be optimally solved in anefficient manner; and b) organizing the order of the subproblems' solution, topromote reuse of shared intermediate results. We propose two variants,SUSTain_M and SUSTain_T, to handle both matrix and tensor inputs, respectively.We evaluate SUSTain against several state-of-the-art baselines on bothsynthetic and real Electronic Health Record (EHR) datasets. Comparing to thosebaselines, SUSTain shows either significantly better fit or orders of magnitudespeedups that achieve a comparable fit (up to 425X faster). We apply SUSTain toEHR datasets to extract patient phenotypes (i.e., clinically meaningful patientclusters). Furthermore, 87% of them were validated as clinically meaningfulphenotypes related to heart failure by a cardiologist.

RAIM: Recurrent Attentive and Intensive Model of Multimodal Patient  Monitoring Data

  With the improvement of medical data capturing, vast amount of continuouspatient monitoring data, e.g., electrocardiogram (ECG), real-time vital signsand medications, become available for clinical decision support at intensivecare units (ICUs). However, it becomes increasingly challenging to model suchdata, due to high density of the monitoring data, heterogeneous data types andthe requirement for interpretable models. Integration of these high-densitymonitoring data with the discrete clinical events (including diagnosis,medications, labs) is challenging but potentially rewarding since richness andgranularity in such multimodal data increase the possibilities for accuratedetection of complex problems and predicting outcomes (e.g., length of stay andmortality). We propose Recurrent Attentive and Intensive Model (RAIM) forjointly analyzing continuous monitoring data and discrete clinical events. RAIMintroduces an efficient attention mechanism for continuous monitoring data(e.g., ECG), which is guided by discrete clinical events (e.g, medicationusage). We apply RAIM in predicting physiological decompensation and length ofstay in those critically ill patients at ICU. With evaluations on MIMIC- IIIWaveform Database Matched Subset, we obtain an AUC-ROC score of 90.18% forpredicting decompensation and an accuracy of 86.82% for forecasting length ofstay with our final model, which outperforms our six baseline models.

RDPD: Rich Data Helps Poor Data via Imitation

  In many situations, we have both rich- and poor- data environments: in arich-data environment (e.g., intensive care units), we have high-qualitymulti-modality data. On the other hand, in a poor-data environment (e.g., athome), we often only have access to a single data modality with low quality.How can we learn an accurate and efficient model for the poor-data environmentby leveraging multi-modality data from the rich-data environment? In this work,we propose a knowledge distillation model RDPD to enhance a small model trainedon poor data with a complex model trained on rich data. In an end-to-endfashion, RDPD trains a student model built on a single modality data (poordata) to imitate the behavior and performance of a teacher model frommultimodal data (rich data) via jointly optimizing the combined loss ofattention imitation and target imitation. We evaluated RDPD on three real-worlddatasets. RDPD consistently outperformed all baselines across all threedatasets, especially achieving the greatest performance improvement over astandard neural network model trained on the common features (Direct model) by24.56% on PR-AUC and 12.21% on ROC-AUC, and over the standard knowledgedistillation model by 5.91% on PR-AUC and 4.44% on ROC-AUC.

HAMLET: Interpretable Human And Machine co-LEarning Technique

  Efficient label acquisition processes are key to obtaining robustclassifiers. However, data labeling is often challenging and subject to highlevels of label noise. This can arise even when classification targets are welldefined, if instances to be labeled are more difficult than the prototypes usedto define the class, leading to disagreements among the expert community. Here,we enable efficient training of deep neural networks. From low-confidencelabels, we iteratively improve their quality by simultaneous learning ofmachines and experts. We call it Human And Machine co-LEarning Technique(HAMLET). Throughout the process, experts become more consistent, while thealgorithm provides them with explainable feedback for confirmation. HAMLET usesa neural embedding function and a memory module filled with diverse referenceembeddings from different classes. Its output includes classification labelsand highly relevant reference embeddings as explanation. We took the study ofbrain monitoring at intensive care unit (ICU) as an application of HAMLET oncontinuous electroencephalography (cEEG) data. Although cEEG monitoring yieldslarge volumes of data, labeling costs and difficulty make it hard to build aclassifier. Additionally, while experts agree on the labels of clear-cutexamples of cEEG patterns, labeling many real-world cEEG data can be extremelychallenging. Thus, a large minority of sequences might be mislabeled. HAMLEThas shown significant performance gain against deep learning and otherbaselines, increasing accuracy from 7.03% to 68.75% on challenging inputs.Besides improved performance, clinical experts confirmed the interpretabilityof those reference embeddings in helping explaining the classification resultsby HAMLET.

COPA: Constrained PARAFAC2 for Sparse & Large Datasets

  PARAFAC2 has demonstrated success in modeling irregular tensors, where thetensor dimensions vary across one of the modes. An example scenario is modelingtreatments across a set of patients with the varying number of medicalencounters over time. Despite recent improvements on unconstrained PARAFAC2,its model factors are usually dense and sensitive to noise which limits theirinterpretability. As a result, the following open challenges remain: a) variousmodeling constraints, such as temporal smoothness, sparsity and non-negativity,are needed to be imposed for interpretable temporal modeling and b) a scalableapproach is required to support those constraints efficiently for largedatasets. To tackle these challenges, we propose a {\it CO}nstrained {\itPA}RAFAC2 (COPA) method, which carefully incorporates optimization constraintssuch as temporal smoothness, sparsity, and non-negativity in the resultingfactors. To efficiently support all those constraints, COPA adopts a hybridoptimization framework using alternating optimization and alternating directionmethod of multiplier (AO-ADMM). As evaluated on large electronic health record(EHR) datasets with hundreds of thousands of patients, COPA achievessignificant speedups (up to 36 times faster) over prior PARAFAC2 approachesthat only attempt to handle a subset of the constraints that COPA enables.Overall, our method outperforms all the baselines attempting to handle a subsetof the constraints in terms of speed, while achieving the same level ofaccuracy. Through a case study on temporal phenotyping of medically complexchildren, we demonstrate how the constraints imposed by COPA reveal concisephenotypes and meaningful temporal profiles of patients. The clinicalinterpretation of both the phenotypes and the temporal profiles was confirmedby a medical expert.

RetainVis: Visual Analytics with Interpretable and Interactive Recurrent  Neural Networks on Electronic Medical Records

  We have recently seen many successful applications of recurrent neuralnetworks (RNNs) on electronic medical records (EMRs), which contain historiesof patients' diagnoses, medications, and other various events, in order topredict the current and future states of patients. Despite the strongperformance of RNNs, it is often challenging for users to understand why themodel makes a particular prediction. Such black-box nature of RNNs can impedeits wide adoption in clinical practice. Furthermore, we have no establishedmethods to interactively leverage users' domain expertise and prior knowledgeas inputs for steering the model. Therefore, our design study aims to provide avisual analytics solution to increase interpretability and interactivity ofRNNs via a joint effort of medical experts, artificial intelligence scientists,and visual analytics researchers. Following the iterative design processbetween the experts, we design, implement, and evaluate a visual analytics toolcalled RetainVis, which couples a newly improved, interpretable and interactiveRNN-based model called RetainEX and visualizations for users' exploration ofEMR data in the context of prediction tasks. Our study shows the effective useof RetainVis for gaining insights into how individual medical codes contributeto making risk predictions, using EMRs of patients with heart failure andcataract symptoms. Our study also demonstrates how we made substantial changesto the state-of-the-art RNN model called RETAIN in order to make use oftemporal information and increase interactivity. This study will provide auseful guideline for researchers that aim to design an interpretable andinteractive visual analytics tool for RNNs.

