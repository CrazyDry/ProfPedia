Using Sets of Probability Measures to Represent Uncertainty

  I explore the use of sets of probability measures as a representation ofuncertainty.

CoRR: A Computing Research Repository

  Discusses how CoRR was set up and some policy issues involved with setting upsuch a repository.

A Modification of the Halpern-Pearl Definition of Causality

  The original Halpern-Pearl definition of causality [Halpern and Pearl, 2001]was updated in the journal version of the paper [Halpern and Pearl, 2005] todeal with some problems pointed out by Hopkins and Pearl [2003]. Here thedefinition is modified yet again, in a way that (a) leads to a simplerdefinition, (b) handles the problems pointed out by Hopkins and Pearl, and manyothers, (c) gives reasonable answers (that agree with those of the original andupdated definition) in the standard problematic examples of causality, and (d)has lower complexity than either the original or updated definitions.

Why Bother With Syntax?

  This short note discusses the role of syntax vs. semantics and the interplaybetween logic, philosophy, and language in computer science and game theory.

Characterizing Solution Concepts in Terms of Common Knowledge of  Rationality

  Characterizations of Nash equilibrium, correlated equilibrium, andrationalizability in terms of common knowledge of rationality are well known.Analogous characterizations of sequential equilibrium, (trembling hand) perfectequilibrium, and quasi-perfect equilibrium using results of Halpern [2009].

An Introduction to Logics of Knowledge and Belief

  This chapter provides an introduction to some basic concepts of epistemiclogic, basic formal languages, their semantics, and proof systems. It alsocontains an overview of the handbook, and a brief history of epistemic logicand pointers to the literature.

Cox's Theorem Revisited

  The assumptions needed to prove Cox's Theorem are discussed and examined.Various sets of assumptions under which a Cox-style theorem can be proved areprovided, although all are rather strong and, arguably, not natural.

A response to the commentaries on CoRR

  This is a response to the commentaries on "CoRR: A Computing ResearchRepository".

Conditional Plausibility Measures and Bayesian Networks

  A general notion of algebraic conditional plausibility measures is defined.Probability measures, ranking functions, possibility measures, and (under theappropriate definitions) sets of probability measures can all be viewed asdefining algebraic conditional plausibility measures. It is shown thatalgebraic conditional plausibility measures can be represented using Bayesiannetworks.

A computer scientist looks at game theory

  I consider issues in distributed computation that should be of relevance togame theory. In particular, I focus on (a) representing knowledge anduncertainty, (b) dealing with failures, and (c) specification of mechanisms.

Great Expectations. Part II: Generalized Expected Utility as a Universal  Decision Rule

  Many different rules for decision making have been introduced in theliterature. We show that a notion of generalized expected utility proposed inPart I of this paper is a universal decision rule, in the sense that it canrepresent essentially all other decision rules.

Conditional Plausibility Measures and Bayesian Networks

  A general notion of algebraic conditional plausibility measures is defined.Probability measures, ranking functions, possibility measures, and (under theappropriate definitions) sets of probability measures can all be viewed asdefining algebraic conditional plausibility measures. It is shown that thetechnology of Bayesian networks can be applied to algebraic conditionalplausibility measures.

Towards Formal Definitions of Blameworthiness, Intention, and Moral  Responsibility

  We provide formal definitions of degree of blameworthiness and intentionrelative to an epistemic state (a probability over causal models and a utilityfunction on outcomes). These, together with a definition of actual causality,provide the key ingredients for moral responsibility judgments. We show thatthese definitions give insight into commonsense intuitions in a variety ofpuzzling cases from the literature.

Actual causation and the art of modeling

  We look more carefully at the modeling of causality using structuralequations. It is clear that the structural equations can have a major impact onthe conclusions we draw about causality. In particular, the choice of variablesand their values can also have a significant impact on causality. These choicesare, to some extent, subjective. We consider what counts as an appropriatechoice. More generally, we consider what makes a model an appropriate model,especially if we want to take defaults into account, as was argued is necessaryin recent work.

Using Counterfactuals in Knowledge-Based Programming

  This paper adds counterfactuals to the framework of knowledge-based programsof Fagin, Halpern, Moses, and Vardi. The use of counterfactuals is illustratedby designing a protocol in which an agent stops sending messages once it knowsthat it is safe to do so. Such behavior is difficult to capture in the originalframework because it involves reasoning about counterfactual executions,including ones that are not consistent with the protocol. Attempts to formalizethese notions without counterfactuals are shown to lead to rathercounterintuitive behavior.

Responsibility and blame: a structural-model approach

  Causality is typically treated an all-or-nothing concept; either A is a causeof B or it is not. We extend the definition of causality introduced by Halpernand Pearl [2001] to take into account the degree of responsibility of A for B.For example, if someone wins an election 11--0, then each person who votes forhim is less responsible for the victory than if he had won 6--5. We then definea notion of degree of blame, which takes into account an agent's epistemicstate. Roughly speaking, the degree of blame of A for B is the expected degreeof responsibility of A for B, taken over the epistemic state of an agent.

Sleeping Beauty Reconsidered: Conditioning and Reflection in  Asynchronous Systems

  A careful analysis of conditioning in the Sleeping Beauty problem is done,using the formal model for reasoning about knowledge and probability developedby Halpern and Tuttle. While the Sleeping Beauty problem has been viewed asrevealing problems with conditioning in the presence of imperfect recall, theanalysis done here reveals that the problems are not so much due to imperfectrecall as to asynchrony. The implications of this analysis for van Fraassen'sReflection Principle and Savage's Sure-Thing Principle are considered.

Defaults and Normality in Causal Structures

  A serious defect with the Halpern-Pearl (HP) definition of causality isrepaired by combining a theory of causality with a theory of defaults. Inaddition, it is shown that (despite a claim to the contrary) a cause accordingto the HP condition need not be a single conjunct. A definition of causalitymotivated by Wright's NESS test is shown to always hold for a single conjunct.Moreover, conditions that hold for all the examples considered by HP are giventhat guarantee that causality according to (this version) of the NESS test isequivalent to the HP definition.

Common knowledge revisited

  We consider the common-knowledge paradox raised by Halpern and Moses: commonknowledge is necessary for agreement and coordination, but common knowledge isunattainable in the real world because of temporal imprecision. We discuss twosolutions to this paradox: (1) modeling the world with a coarser granularity,and (2) relaxing the requirements for coordination.

The Computational Complexity of Structure-Based Causality

  Halpern and Pearl introduced a definition of actual causality; Eiter andLukasiewicz showed that computing whether X=x is a cause of Y=y is NP-completein binary models (where all variables can take on only two values) and\Sigma_2^P-complete in general models. In the final version of their paper,Halpern and Pearl slightly modified the definition of actual cause, in order todeal with problems pointed by Hopkins and Pearl. As we show, this modificationhas a nontrivial impact on the complexity of computing actual cause. Tocharacterize the complexity, a new family D_k^P, k= 1, 2, 3, ..., of complexityclasses is introduced, which generalizes the class DP introduced byPapadimitriou and Yannakakis (DP is just D_1^P). %joe2 %We show that thecomplexity of computing causality is $\D_2$-complete %under the new definition.Chockler and Halpern \citeyear{CH04} extended the We show that the complexityof computing causality under the updated definition is $D_2^P$-complete.  Chockler and Halpern extended the definition of causality by introducingnotions of responsibility and blame. The complexity of determining the degreeof responsibility and blame using the original definition of causality wascompletely characterized. Again, we show that changing the definition ofcausality affects the complexity, and completely characterize it using theupdated definition.

A decision-theoretic approach to reliable message delivery

  We argue that the tools of decision theory need to be taken more seriously inthe specification and analysis of systems. We illustrate this by considering asimple problem involving reliable communication, showing how considerations ofutility and probability can be used to decide when it is worth sendingheartbeat messages and, if they are sent, how often they should be sent.

Causes and Explanations: A Structural-Model Approach, Part I: Causes

  We propose a new definition of actual cause, using structural equations tomodel counterfactuals. We show that the definition yields a plausible andelegant account of causation that handles well examples which have causedproblems for other definitions and resolves major difficulties in thetraditional account.

On the NP-completeness of Finding an Optimal Strategy in Games with  Common Payoffs

  Consider a very simple class of (finite) games: after an initial move bynature, each player makes one move. Moreover, the players have commoninterests: at each node, all the players get the same payoff. We show that theproblem of determining whether there exists a joint strategy where each playerhas an expected payoff of at least r is NP-complete as a function of the numberof nodes in the extensive-form representation of the game.

Lexicographic probability, conditional probability, and nonstandard  probability

  The relationship between Popper spaces (conditional probability spaces thatsatisfy some regularity conditions), lexicographic probability systems (LPS's),and nonstandard probability spaces (NPS's) is considered. If countableadditivity is assumed, Popper spaces and a subclass of LPS's are equivalent;without the assumption of countable additivity, the equivalence no longerholds. If the state space is finite, LPS's are equivalent to NPS's. However, ifthe state space is infinite, NPS's are shown to be more general than LPS's.

A logic for reasoning about upper probabilities

  We present a propositional logic %which can be used to reason about theuncertainty of events, where the uncertainty is modeled by a set of probabilitymeasures assigning an interval of probability to each event. We give a soundand complete axiomatization for the logic, and show that the satisfiabilityproblem is NP-complete, no harder than satisfiability for propositional logic.

Great Expectations. Part I: On the Customizability of Generalized  Expected Utility

  We propose a generalization of expected utility that we call generalized EU(GEU), where a decision maker's beliefs are represented by plausibilitymeasures, and the decision maker's tastes are represented by general (i.e.,notnecessarily real-valued) utility functions. We show that every agent,``rational'' or not, can be modeled as a GEU maximizer. We then show that wecan customize GEU by selectively imposing just the constraints we want. Inparticular, we show how each of Savage's postulates corresponds to constraintson GEU.

Intransitivity and Vagueness

  There are many examples in the literature that suggest thatindistinguishability is intransitive, despite the fact that theindistinguishability relation is typically taken to be an equivalence relation(and thus transitive). It is shown that if the uncertainty perception and thequestion of when an agent reports that two things are indistinguishable areboth carefully modeled, the problems disappear, and indistinguishability canindeed be taken to be an equivalence relation. Moreover, this model alsosuggests a logic of vagueness that seems to solve many of the problems relatedto vagueness discussed in the philosophical literature. In particular, it isshown here how the logic can handle the sorites paradox.

Expressing Security Properties Using Selective Interleaving Functions

  McLean's notion of Selective Interleaving Functions (SIFs) is perhaps thebest-known attempt to construct a framework for expressing various securityproperties. We examine the expressive power of SIFs carefully. We show thatSIFs cannot capture nondeducibility on strategies (NOS). We also prove that theset of security properties expressed with SIFs is not closed under conjunction,from which it follows that separability is strictly stronger than doublegeneralized noninterference. However, we show that if we generalize the notionof SIF in a natural way, then NOS is expressible, and the set of securityproperties expressible by generalized SIFs is closed under conjunction.

Rational Secret Sharing and Multiparty Computation: Extended Abstract

  We consider the problems of secret sharing and multiparty computation,assuming that agents prefer to get the secret (resp., function value) to notgetting it, and secondarily, prefer that as few as possible of the other agentsget it. We show that, under these assumptions, neither secret sharing normultiparty function computation is possible using a mechanism that has a fixedrunning time. However, we show that both are possible using randomizedmechanisms with constant expected running time.

Characterizing Solution Concepts in Games Using Knowledge-Based Programs

  We show how solution concepts in games such as Nash equilibrium, correlatedequilibrium, rationalizability, and sequential equilibrium can be given auniform definition in terms of \emph{knowledge-based programs}. Intuitively,all solution concepts are implementations of two knowledge-based programs, oneappropriate for games represented in normal form, the other for gamesrepresented in extensive form. These knowledge-based programs can be viewed asembodying rationality. The representation works even if (a) information sets donot capture an agent's knowledge, (b) uncertainty is not represented byprobability, or (c) the underlying game is not common knowledge.

Computer Science and Game Theory: A Brief Survey

  There has been a remarkable increase in work at the interface of computerscience and game theory in the past decade. In this article I survey some ofthe main themes of work in the area, with a focus on the work in computerscience. Given the length constraints, I make no attempt at beingcomprehensive, especially since other surveys are also available, and acomprehensive survey book will appear shortly.

From Qualitative to Quantitative Proofs of Security Properties Using  First-Order Conditional Logic

  A first-order conditional logic is considered, with semantics given by avariant of epsilon-semantics, where p -> q means that Pr(q | p) approaches 1super-polynomially --faster than any inverse polynomial. This type ofconvergence is needed for reasoning about security protocols. A completeaxiomatization is provided for this semantics, and it is shown how aqualitative proof of the correctness of a security protocol can beautomatically converted to a quantitative proof appropriate for reasoning aboutconcrete security.

Viewpoint: Journals for Certification, Conferences for Rapid  Dissemination

  The publication culture in Computer Science is different from that of allother disciplines. Whereas other disciplines focus on journal publication, thestandard practice in CS has been to publish in a conference and then(sometimes) publish a journal version of the conference paper. We discuss therole of journal publication in CS.  Indeed, it is through publication in selective, leading conferences that thequality of CS research is typically assessed.

Causes and Explanations: A Structural-Model Approach --- Part 1: Causes

  We propose a new definition of actual causes, using structural equations tomodel counterfactuals.We show that the definitions yield a plausible andelegant account ofcausation that handles well examples which have causedproblems forother definitions and resolves major difficulties in thetraditionalaccount. In a companion paper, we show how the definition ofcausality can beused to give an elegant definition of (causal) explanation.

Graded Causation and Defaults

  Recent work in psychology and experimental philosophy has shown thatjudgments of actual causation are often influenced by consideration ofdefaults, typicality, and normality. A number of philosophers and computerscientists have also suggested that an appeal to such factors can help dealwith problems facing existing accounts of actual causation. This paper developsa flexible formal framework for incorporating defaults, typicality, andnormality into an account of actual causation. The resulting account takesactual causation to be both graded and comparative. We then show how ouraccount would handle a number of standard cases.

Compact Representations of Extended Causal Models

  Judea Pearl was the first to propose a definition of actual causation usingcausal models. A number of authors have suggested that an adequate account ofactual causation must appeal not only to causal structure, but also toconsiderations of normality. In earlier work, we provided a definition ofactual causation using extended causal models, which include information aboutboth causal structure and normality. Extended causal models are potentiallyvery complex. In this paper, we show how it is possible to achieve a compactrepresentation of extended causal models.

A logic for reasoning about ambiguity

  Standard models of multi-agent modal logic do not capture the fact thatinformation is often \emph{ambiguous}, and may be interpreted in different waysby different agents. We propose a framework that can model this, and considerdifferent semantics that capture different assumptions about the agents'beliefs regarding whether or not there is ambiguity. We examine the expressivepower of logics of ambiguity compared to logics that cannot model ambiguity,with respect to the different semantics that we propose.

A Logic for Reasoning about Evidence

  We introduce a logic for reasoning about evidence, that essentially viewsevidence as a function from prior beliefs (before making an observation) toposterior beliefs (after making the observation). We provide a sound andcomplete axiomatization for the logic, and consider the complexity of thedecision problem. Although the reasoning in the logic is mainly propositional,we allow variables representing numbers and quantification over them. Thisexpressive power seems necessary to capture important properties of evidence

A Logic for Reasoning about Upper Probabilities

  We present a propositional logic to reason about the uncertainty of events,where the uncertainty is modeled by a set of probability measures assigning aninterval of probability to each event. We give a sound and completeaxiomatization for the logic, and show that the satisfiability problem isNP-complete, no harder than satisfiability for propositional logic.

Algorithmic Rationality: Game Theory with Costly Computation

  We develop a general game-theoretic framework for reasoning about strategicagents performing possibly costly computation. In this framework, manytraditional game-theoretic results (such as the existence of a Nashequilibrium) no longer hold. Nevertheless, we can use the framework to providepsychologically appealing explanations of observed behavior in well-studiedgames (such as finitely repeated prisoner's dilemma and rock-paper-scissors).Furthermore, we provide natural conditions on games sufficient to guaranteethat equilibria exist.

Cause, Responsibility, and Blame: oA Structural-Model Approach

  A definition of causality introduced by Halpern and Pearl, which usesstructural equations, is reviewed. A more refined definition is thenconsidered, which takes into account issues of normality and typicality, whichare well known to affect causal ascriptions. Causality is typically anall-or-nothing notion: either A is a cause of B or it is not. An extension ofthe definition of causality to capture notions of degree of responsibility anddegree of blame, due to Chockler and Halpern, is reviewed. For example, ifsomeone wins an election 11-0, then each person who votes for him is lessresponsible for the victory than if he had won 6-5. Degree of blame takes intoaccount an agent's epistemic state. Roughly speaking, the degree of blame of Afor B is the expected degree of responsibility of A for B, taken over theepistemic state of an agent. Finally, the structural-equations definition ofcausality is compared to Wright's NESS test.

Multi-Agent Only Knowing

  Levesque introduced a notion of ``only knowing'', with the goal of capturingcertain types of nonmonotonic reasoning. Levesque's logic dealt with only thecase of a single agent. Recently, both Halpern and Lakemeyer independentlyattempted to extend Levesque's logic to the multi-agent case. Although thereare a number of similarities in their approaches, there are some significantdifferences. In this paper, we reexamine the notion of only knowing, going backto first principles. In the process, we simplify Levesque's completeness proof,and point out some problems with the earlier definitions. This leads us toreconsider what the properties of only knowing ought to be. We provide an axiomsystem that captures our desiderata, and show that it has a semantics thatcorresponds to it. The axiom system has an added feature of interest: itincludes a modal operator for satisfiability, and thus provides a completeaxiomatization for satisfiability in the logic K45.

What Causes a System to Satisfy a Specification?

  Even when a system is proven to be correct with respect to a specification,there is still a question of how complete the specification is, and whether itreally covers all the behaviors of the system. Coverage metrics attempt tocheck which parts of a system are actually relevant for the verificationprocess to succeed. Recent work on coverage in model checking suggests severalcoverage metrics and algorithms for finding parts of the system that are notcovered by the specification. The work has already proven to be effective inpractice, detecting design errors that escape early verification efforts inindustrial settings. In this paper, we relate a formal definition of causalitygiven by Halpern and Pearl [2001] to coverage. We show that it givessignificant insight into unresolved issues regarding the definition of coverageand leads to potentially useful extensions of coverage. In particular, weintroduce the notion of responsibility, which assigns to components of a systema quantitative measure of their relevance to the satisfaction of thespecification.

A Knowledge-Based Analysis of Global Function Computation

  Consider a distributed system N in which each agent has an input value andeach communication link has a weight. Given a global function, that is, afunction f whose value depends on the whole network, the goal is for everyagent to eventually compute the value f(N). We call this problem globalfunction computation. Various solutions for instances of this problem, such asBoolean function computation, leader election, (minimum) spanning treeconstruction, and network determination, have been proposed, each underparticular assumptions about what processors know about the system and how thisknowledge can be acquired. We give a necessary and sufficient condition for theproblem to be solvable that generalizes a number of well-known results. We thenprovide a knowledge-based (kb) program (like those of Fagin, Halpern, Moses,and Vardi) that solves global function computation whenever possible. Finally,we improve the message overhead inherent in our initial kb program by giving acounterfactual belief-based program that also solves the global functioncomputation whenever possible, but where agents send messages only when theybelieve it is necessary to do so. The latter program is shown to be implementedby a number of well-known algorithms for solving leader election.

Reasoning About Knowledge of Unawareness Revisited

  In earlier work, we proposed a logic that extends the Logic of GeneralAwareness of Fagin and Halpern [1988] by allowing quantification over primitivepropositions. This makes it possible to express the fact that an agent knowsthat there are some facts of which he is unaware. In that logic, it is notpossible to model an agent who is uncertain about whether he is aware of allformulas. To overcome this problem, we keep the syntax of the earlier paper,but allow models where, with each world, a possibly different language isassociated. We provide a sound and complete axiomatization for this logic andshow that, under natural assumptions, the quantifier-free fragment of the logicis characterized by exactly the same axioms as the logic of Heifetz, Meier, andSchipper [2008].

Weighted regret-based likelihood: a new approach to describing  uncertainty

  Recently, Halpern and Leung suggested representing uncertainty by a weightedset of probability measures, and suggested a way of making decisions based onthis representation of uncertainty: maximizing weighted regret. Their paperdoes not answer an apparently simpler question: what it means, according tothis representation of uncertainty, for an event E to be more likely than anevent E'. In this paper, a notion of comparative likelihood when uncertainty isrepresented by a weighted set of probability measures is defined. Itgeneralizes the ordering defined by probability (and by lower probability) in anatural way; a generalization of upper probability can also be defined. Acomplete axiomatic characterization of this notion of regret-based likelihoodis given.

Interactive Unawareness Revisited

  We analyze a model of interactive unawareness introduced by Heifetz, Meierand Schipper (HMS). We consider two axiomatizations for their model, whichcapture different notions of validity. These axiomatizations allow us tocompare the HMS approach to both the standard (S5) epistemic logic and twoother approaches to unawareness: that of Fagin and Halpern and that of Modicaand Rustichini. We show that the differences between the HMS approach and theothers are mainly due to the notion of validity used and the fact that the HMSis based on a 3-valued propositional logic.

Appropriate Causal Models and the Stability of Causation

  Causal models defined in terms of structural equations have proved to bequite a powerful way of representing knowledge regarding causality. However, anumber of authors have given examples that seem to show that the Halpern-Pearl(HP) definition of causality gives intuitively unreasonable answers. Here it isshown that, for each of these examples, we can give two stories consistent withthe description in the example, such that intuitions regarding causality arequite different for each story. By adding additional variables, we candisambiguate the stories. Moreover, in the resulting causal models, the HPdefinition of causality gives the intuitively correct answer. It is also shownthat, by adding extra variables, a modification to the original HP definitionmade to deal with an example of Hopkins and Pearl may not be necessary. Givenhow much can be done by adding extra variables, there might be a concern thatthe notion of causality is somewhat unstable. Can adding extra variables in a"conservative" way (i.e., maintaining all the relations between the variablesin the original model) cause the answer to the question "Is X=x a cause of Y=y"to alternate between "yes" and "no"? It is shown that we can have suchalternation infinitely often, but if we take normality into consideration, wecannot. Indeed, under appropriate normality assumptions. adding an extravariable can change the answer from "yes" to "no", but after that, it cannotcannot change back to "yes".

Complete Axiomatizations for Reasoning About Knowledge and Time

  Sound and complete axiomatizations are provided for a number of differentlogics involving modalities for knowledge and time. These logics arise fromdifferent choices for various parameters. All the logics considered involve thediscrete time linear temporal logic operators `next' and `until' and anoperator for the knowledge of each of a number of agents. Both the single agentand multiple agent cases are studied: in some instances of the latter there isalso an operator for the common knowledge of the group of all agents. Fourdifferent semantic properties of agents are considered: whether they have aunique initial state, whether they operate synchronously, whether they haveperfect recall, and whether they learn. The property of no learning isessentially dual to perfect recall. Not all settings of these parameters leadto recursively axiomatizable logics, but sound and complete axiomatizations arepresented for all the ones that do.

Set-Theoretic Completeness for Epistemic and Conditional Logic

  The standard approach to logic in the literature in philosophy andmathematics, which has also been adopted in computer science, is to define alanguage (the syntax), an appropriate class of models together with aninterpretation of formulas in the language (the semantics), a collection ofaxioms and rules of inference characterizing reasoning (the proof theory), andthen relate the proof theory to the semantics via soundness and completenessresults. Here we consider an approach that is more common in the economicsliterature, which works purely at the semantic, set-theoretic level. We provideset-theoretic completeness results for a number of epistemic and conditionallogics, and contrast the expressive power of the syntactic and set-theoreticapproaches

