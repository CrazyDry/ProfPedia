The Regularity of Powers of Edge Ideals

  In this paper we prove the existence of a special order on the set of minimalmonomial generators of powers of edge ideals of arbitrary graphs. Using thisorder we find new upper bounds on the regularity of powers of edge ideals ofgraphs whose complement does not have any induced four cycle.

Regularity of Path Ideals of Gap Free Graphs

  In this paper we study the Castelnuovo-Mumford regularity of the path idealsof finite simple graphs. We find new upper bounds for various path ideals ofgap free graphs. In particular we prove that the path ideals of gap free andclaw graphs have linear minimal free resolutions.

Powers of edge ideals of regularity three bipartite graphs

  In this paper we prove that if $I(G)$ is a bipartite edge ideal withregularity three then for all $s\geq 2$ the regularity of $I(G)^s$ is exactly$2s+1$.

Construction of a few Quantum mechanical Hamiltonians via  L$\acute{e}$vi-Leblond type Linearization:Spinor states and Supersymmetry

  A number of new L$\acute{e}$vi-Leblond type equations admitting fourcomponent spinor solutions have been proposed. The pair of linearized equationsthus obtained in each case lead to Hamiltonians with characteristic featureslike L-S coupling and supersymmetry. The relevant momentum operators have oftenbeen understood in terms of Clifford algebraic bases producingSchr$\ddot{o}$dinger Hamiltonians with L-S coupling. As for exampleHamiltonians representing Rashba effect or three dimensional harmonicoscillator have been constructed. The supersymmetric nature of one dimensionaloscillator has also been appreciated.

Properties of Lyubeznik numbers under localization and polarization

  We exhibit a global bound for the Lyubeznik numbers of a ring of primecharacteristic. In addition, we show that for a monomial ideal, the Lyubezniknumbers of the quotient rings of its radical and its polarization are the same.Furthermore, we present examples that show striking behavior of the Lyubezniknumbers under localization. We also show related results for generalizations ofthe Lyubeznik numbers.

Regularity of Edge Ideals and Their Powers

  We survey recent studies on the Castelnuovo-Mumford regularity of edge idealsof graphs and their powers. Our focus is on bounds and exact values of $\text{reg } I(G)$ and the asymptotic linear function $\text{ reg } I(G)^q$, for $q\geq 1,$ in terms of combinatorial data of the given graph $G.$

Holographic s-wave condensate with non-linear electrodynamics: A  nontrivial boundary value problem

  In this paper, considering the probe limit, we analytically study the onsetof holographic s-wave condensate in the planar Schwarzschild-AdS background.Inspired by various low energy features of string theory, in the present workwe replace the conventional Maxwell action by a (non-linear) Born-Infeld (BI)action which essentially corresponds to the higher derivative corrections ofthe gauge fields. Based on a variational method, which is commonly known as theSturm-Liouville (SL) eigenvalue problem and considering a non-trivialasymptotic solution for the scalar field, we compute the critical temperaturefor the s-wave condensation. The results thus obtained analytically agree wellwith the numerical findings\cite{hs19}. As a next step, we extend ourperturbative technique to compute the order parameter for the condensation.Interestingly our analytic results are found to be of the same order as thenumerical values obtained earlier.

Existence and Stability of Periodic Orbits in $N$-Dimensional Piecewise  Linear Continuous Maps

  Piecewise smooth maps are known to exhibit a wide range of dynamical featuresincluding numerous types of periodic orbits. Predicting regions in parameterspace where such periodic orbits might occur and determining their stability iscrucial to characterize the dynamics of the system. However, obtaining theconditions of existence and stability of these periodic orbits generally usebrute force methods which require successive application of the iterative mapon a starting point. In this article, we propose a faster and more elegant wayof obtaining those conditions without iterating the complete map. The methodrevolves around direct computation of higher powers of matrices withoutcomputing the lower ones and is applicable on any dimension of the phase space.In the later part of the article, we compare the speed of the proposed methodwith the other popular algorithms which shows the effectiveness of the proposedmethod in higher dimensions. We also illustrate the use of this method incomputing the regions of existence and stability of a particular class ofperiodic orbits in three dimensions.

Gaussian Process Topic Models

  We introduce Gaussian Process Topic Models (GPTMs), a new family of topicmodels which can leverage a kernel among documents while extracting correlatedtopics. GPTMs can be considered a systematic generalization of the CorrelatedTopic Models (CTMs) using ideas from Gaussian Process (GP) based embedding.Since GPTMs work with both a topic covariance matrix and a document kernelmatrix, learning GPTMs involves a novel component-solving a suitable Sylvesterequation capturing both topic and document dependencies. The efficacy of GPTMsis demonstrated with experiments evaluating the quality of both topic modelingand embedding.

Graph Connectivity and Binomial Edge Ideals

  We relate homological properties of a binomial edge ideal $\mathcal{J}_G$ toinvariants that measure the connectivity of a simple graph $G$. Specifically,we show if $R/\mathcal{J}_G$ is a Cohen-Macaulay ring, then graph toughness of$G$ is exactly $\frac{1}{2}$. We also give an inequality between the depth of$R/\mathcal{J}_G$ and the vertex-connectivity of $G$. In addition, we study theHilbert-Samuel multiplicity, and the Hilbert-Kunz multiplicity of$R/\mathcal{J}_G$.

Alternating Estimation for Structured High-Dimensional Multi-Response  Models

  We consider learning high-dimensional multi-response linear models withstructured parameters. By exploiting the noise correlations among responses, wepropose an alternating estimation (AltEst) procedure to estimate the modelparameters based on the generalized Dantzig selector. Under suitable samplesize and resampling assumptions, we show that the error of the estimatesgenerated by AltEst, with high probability, converges linearly to certainminimum achievable level, which can be tersely expressed by a few geometricmeasures, such as Gaussian width of sets related to the parameter structure. Tothe best of our knowledge, this is the first non-asymptotic statisticalguarantee for such AltEst-type algorithm applied to estimation problem withgeneral structures.

Time Series Deinterleaving of DNS Traffic

  Stream deinterleaving is an important problem with various applications inthe cybersecurity domain. In this paper, we consider the specific problem ofdeinterleaving DNS data streams using machine-learning techniques, with theobjective of automating the extraction of malware domain sequences. We firstdevelop a generative model for user request generation and DNS streaminterleaving. Based on these we evaluate various inference strategies fordeinterleaving including augmented HMMs and LSTMs on synthetic datasets. Ourresults demonstrate that state-of-the-art LSTMs outperform more traditionalaugmented HMMs in this application domain.

Packing properties of cubic squarefree monomial ideals

  Let $I$ be an ideal in a Noetherian ring $R$. The $n^{\text{th}}$ symbolicpower of $I$ is defined as $$I^{(n)}=\displaystyle\bigcap_{p\inAss(R)}(I^nR_p\cap R).$$ The symbolic powers, in general, are not equal to theordinary powers. Therefore, one interesting question here is for what classesof ideals ordinary and symbolic powers coincide? The answer to this questionfor squarefree monomial ideals may be packing property. In this paper, we studythe equality between symbolic and ordinary powers for some classes of cubicsquarefree monomial ideals.

An Energy-Efficient VCO-Based Matrix Multiplier Block to Support On-Chip  Image Analysis

  Images typically are represented as uniformly sampled data in the form ofmatrix of pixels/voxels. Therefore, matrix multiply-and-accumulate (MAC) formsthe core of most state-of-the-art image analysis algorithms. While digitalimplementation of MAC has generally been the preferred approach, high powerconsumption is an impediment to adopting it for medical image analysis. In thiswork, we present a time-domain signal processing architecture which performsMAC operations with 7bit accuracy while consuming 400X lower energy thandigital implementation. The proposed architecture performs analog computationusing mostly digital circuits and is suitable for scaled CMOS technologies. Theproposed time-domain MAC architecture is expected to play a central role inempowering the advancement of various on-chip image analysis operations.

Maximally $\cal{N}$-extended super-BMS$_3$ algebras and Generalized 3D  Gravity Solutions

  We consider the maximal $\cal{N}-$extended supergravity theory in 3dimensions with fermionic generators transforming under real but nonnecessarily irreducible representations of the internal algebra. We obtain thesymmetry algebra at null infinity preserving boundary conditions ofasymptotically flat solutions, i.e. the maximal $\cal{N}-$extendedsuper-BMS$_3$ algebra, which possesses non-linear correction in theanti-commutators of supercharges. We present the supersymmetric energy boundand derive the explicit form of the asymptotic Killing spinors. We also findthe most generic circular symmetric ground state of the theory, whichcorresponds to a non-supersymmetric cosmological solutions and derive theirentropy.

Does Cyg X-1 have a small Standard Accretion Disc?

  We analyze several outbursts of a few transient sources using ProportionalCounter Array (PCA) data (2.5-25 keV) as well as All Sky Monitor (ASM) data(1.5-12 keV) of Rossi X-ray Timing Explorer (RXTE) satellite. We find a timedelay between the arrival times of the Keplerian disc component and the halo ofthe Two-Component Advective Flow (TCAF) when the spectral data is fitted withTCAF solution. We compare this time delay from the spectral fits with the TCAFsolution of the transient low mass X-ray binaries (LMXBs) e.g., GX 339-4, H1743-322 and MAXI J1836-194 with that of the high mass X-ray Binary (HMXB), CygX-1. We find that several days of time delays are observed in LMXBs while forCyg X-1 the delay is negligible. We interpret the large delay to be due to theviscous delay of a large Keplerian component to reach the inner region ascompared to nearly free-fall time taken by the low angular momentum halocomponent. The delay is of the order of a few days for the low mass X-raybinaries (LMXBs) where the feeding is primarily through the Roche-lobe.However, it is negligible in a wind-fed system like Cyg X-1 since a very smallKeplerian disc is created here by slowly redistributing the low angularmomentum of the wind. As a consequence, sporadic soft or intermediate spectralstates are observed.

Approximation Algorithms for Bregman Co-clustering and Tensor Clustering

  In the past few years powerful generalizations to the Euclidean k-meansproblem have been made, such as Bregman clustering [7], co-clustering (i.e.,simultaneous clustering of rows and columns of an input matrix) [9,18], andtensor clustering [8,34]. Like k-means, these more general problems also sufferfrom the NP-hardness of the associated optimization. Researchers have developedapproximation algorithms of varying degrees of sophistication for k-means,k-medians, and more recently also for Bregman clustering [2]. However, thereseem to be no approximation algorithms for Bregman co- and tensor clustering.In this paper we derive the first (to our knowledge) guaranteed methods forthese increasingly important clustering settings. Going beyond Bregmandivergences, we also prove an approximation factor for tensor clustering witharbitrary separable metrics. Through extensive experiments we evaluate thecharacteristics of our method, and show that it also has practical impact.

Gap Filling in the Plant Kingdom---Trait Prediction Using Hierarchical  Probabilistic Matrix Factorization

  Plant traits are a key to understanding and predicting the adaptation ofecosystems to environmental changes, which motivates the TRY project aiming atconstructing a global database for plant traits and becoming a standardresource for the ecological community. Despite its unprecedented coverage, alarge percentage of missing data substantially constrains joint trait analysis.Meanwhile, the trait data is characterized by the hierarchical phylogeneticstructure of the plant kingdom. While factorization based matrix completiontechniques have been widely used to address the missing data problem,traditional matrix factorization methods are unable to leverage thephylogenetic structure. We propose hierarchical probabilistic matrixfactorization (HPMF), which effectively uses hierarchical phylogeneticinformation for trait prediction. We demonstrate HPMF's high accuracy,effectiveness of incorporating hierarchical structure and ability to capturetrait correlation through experiments.

Online Alternating Direction Method

  Online optimization has emerged as powerful tool in large scale optimization.In this paper, we introduce efficient online algorithms based on thealternating directions method (ADM). We introduce a new proof technique for ADMin the batch setting, which yields the O(1/T) convergence rate of ADM and formsthe basis of regret analysis in the online setting. We consider two scenariosin the online setting, based on whether the solution needs to lie in thefeasible set or not. In both settings, we establish regret bounds for both theobjective function as well as constraint violation for general and stronglyconvex functions. Preliminary results are presented to illustrate theperformance of the proposed algorithms.

Bregman Alternating Direction Method of Multipliers

  The mirror descent algorithm (MDA) generalizes gradient descent by using aBregman divergence to replace squared Euclidean distance. In this paper, wesimilarly generalize the alternating direction method of multipliers (ADMM) toBregman ADMM (BADMM), which allows the choice of different Bregman divergencesto exploit the structure of problems. BADMM provides a unified framework forADMM and its variants, including generalized ADMM, inexact ADMM and Bethe ADMM.  We establish the global convergence and the $O(1/T)$ iteration complexity forBADMM. In some cases, BADMM can be faster than ADMM by a factor of$O(n/\log(n))$. In solving the linear program of mass transportation problem,BADMM leads to massive parallelism and can easily run on GPU. BADMM is severaltimes faster than highly optimized commercial software Gurobi.

Online Alternating Direction Method (longer version)

  Online optimization has emerged as powerful tool in large scale optimization.In this pa- per, we introduce efficient online optimization algorithms based onthe alternating direction method (ADM), which can solve online convexoptimization under linear constraints where the objective could be non-smooth.We introduce new proof techniques for ADM in the batch setting, which yields aO(1/T) convergence rate for ADM and forms the basis for regret anal- ysis inthe online setting. We consider two scenarios in the online setting, based onwhether an additional Bregman divergence is needed or not. In both settings, weestablish regret bounds for both the objective function as well as constraintsviolation for general and strongly convex functions. We also consider inexactADM updates where certain terms are linearized to yield efficient updates andshow the stochastic convergence rates. In addition, we briefly discuss thatonline ADM can be used as projection- free online learning algorithm in somescenarios. Preliminary results are presented to illustrate the performance ofthe proposed algorithms.

Bethe-ADMM for Tree Decomposition based Parallel MAP Inference

  We consider the problem of maximum a posteriori (MAP) inference in discretegraphical models. We present a parallel MAP inference algorithm calledBethe-ADMM based on two ideas: tree-decomposition of the graph and thealternating direction method of multipliers (ADMM). However, unlike thestandard ADMM, we use an inexact ADMM augmented with a Bethe-divergence basedproximal function, which makes each subproblem in ADMM easy to solve inparallel using the sum-product algorithm. We rigorously prove globalconvergence of Bethe-ADMM. The proposed algorithm is extensively evaluated onboth synthetic and real datasets to illustrate its effectiveness. Further, theparallel Bethe-ADMM is shown to scale almost linearly with increasing number ofcores.

Parallel Direction Method of Multipliers

  We consider the problem of minimizing block-separable convex functionssubject to linear constraints. While the Alternating Direction Method ofMultipliers (ADMM) for two-block linear constraints has been intensivelystudied both theoretically and empirically, in spite of some preliminary work,effective generalizations of ADMM to multiple blocks is still unclear. In thispaper, we propose a randomized block coordinate method named Parallel DirectionMethod of Multipliers (PDMM) to solve the optimization problems withmulti-block linear constraints. PDMM randomly updates some primal and dualblocks in parallel, behaving like parallel randomized block coordinate descent.We establish the global convergence and the iteration complexity for PDMM withconstant step size. We also show that PDMM can do randomized block coordinatedescent on overlapping blocks. Experimental results show that PDMM performsbetter than state-of-the-arts methods in two applications, robust principalcomponent analysis and overlapping group lasso.

Generalized Dantzig Selector: Application to the k-support norm

  We propose a Generalized Dantzig Selector (GDS) for linear models, in whichany norm encoding the parameter structure can be leveraged for estimation. Weinvestigate both computational and statistical aspects of the GDS. Based onconjugate proximal operator, a flexible inexact ADMM framework is designed forsolving GDS, and non-asymptotic high-probability bounds are established on theestimation error, which rely on Gaussian width of unit norm ball and suitableset encompassing estimation error. Further, we consider a non-trivial exampleof the GDS using $k$-support norm. We derive an efficient method to compute theproximal operator for $k$-support norm since existing methods are inapplicablein this setting. For statistical analysis, we provide upper bounds for theGaussian widths needed in the GDS analysis, yielding the first statisticalrecovery guarantee for estimation with the $k$-support norm. The experimentalresults confirm our theoretical analysis.

Randomized Block Coordinate Descent for Online and Stochastic  Optimization

  Two types of low cost-per-iteration gradient descent methods have beenextensively studied in parallel. One is online or stochastic gradient descent(OGD/SGD), and the other is randomzied coordinate descent (RBCD). In thispaper, we combine the two types of methods together and propose onlinerandomized block coordinate descent (ORBCD). At each iteration, ORBCD onlycomputes the partial gradient of one block coordinate of one mini-batchsamples. ORBCD is well suited for the composite minimization problem where onefunction is the average of the losses of a large number of samples and theother is a simple regularizer defined on high dimensional variables. We showthat the iteration complexity of ORBCD has the same order as OGD or SGD. Forstrongly convex functions, by reducing the variance of stochastic gradients, weshow that ORBCD can converge at a geometric rate in expectation, matching theconvergence rate of SGD with variance reduction and RBCD.

A Spectral Algorithm for Inference in Hidden Semi-Markov Models

  Hidden semi-Markov models (HSMMs) are latent variable models which allowlatent state persistence and can be viewed as a generalization of the popularhidden Markov models (HMMs). In this paper, we introduce a novel spectralalgorithm to perform inference in HSMMs. Unlike expectation maximization (EM),our approach correctly estimates the probability of given observation sequencebased on a set of training sequences. Our approach is based on estimatingmoments from the sample, whose number of dimensions depends onlylogarithmically on the maximum length of the hidden state persistence.Moreover, the algorithm requires only a few matrix inversions and is thereforecomputationally efficient. Empirical evaluations on synthetic and real datademonstrate the advantage of the algorithm over EM in terms of speed andaccuracy, especially for large datasets.

Multi-task Sparse Structure Learning

  Multi-task learning (MTL) aims to improve generalization performance bylearning multiple related tasks simultaneously. While sometimes the underlyingtask relationship structure is known, often the structure needs to be estimatedfrom data at hand. In this paper, we present a novel family of models for MTL,applicable to regression and classification problems, capable of learning thestructure of task relationships. In particular, we consider a joint estimationproblem of the task relationship structure and the individual task parameters,which is solved using alternating minimization. The task relationship structurelearning component builds on recent advances in structure learning of Gaussiangraphical models based on sparse estimators of the precision (inversecovariance) matrix. We illustrate the effectiveness of the proposed model on avariety of synthetic and benchmark datasets for regression and classification.We also consider the problem of combining climate model outputs for betterprojections of future climate, with focus on temperature in South America, andshow that the proposed model outperforms several existing methods for theproblem.

Estimation with Norm Regularization

  Analysis of non-asymptotic estimation error and structured statisticalrecovery based on norm regularized regression, such as Lasso, needs to considerfour aspects: the norm, the loss function, the design matrix, and the noisemodel. This paper presents generalizations of such estimation error analysis onall four aspects compared to the existing literature. We characterize therestricted error set where the estimation error vector lies, establishrelations between error sets for the constrained and regularized problems, andpresent an estimation error bound applicable to any norm. Precisecharacterizations of the bound is presented for isotropic as well asanisotropic subGaussian design matrices, subGaussian noise models, and convexloss functions, including least squares and generalized linear models. Genericchaining and associated results play an important role in the analysis. A keyresult from the analysis is that the sample complexity of all such estimatorsdepends on the Gaussian width of a spherical cap corresponding to therestricted error set. Further, once the number of samples $n$ crosses therequired sample complexity, the estimation error decreases as$\frac{c}{\sqrt{n}}$, where $c$ depends on the Gaussian width of the unit normball.

Semi-Markov Switching Vector Autoregressive Model-based Anomaly  Detection in Aviation Systems

  In this work we consider the problem of anomaly detection in heterogeneous,multivariate, variable-length time series datasets. Our focus is on theaviation safety domain, where data objects are flights and time series aresensor readings and pilot switches. In this context the goal is to detectanomalous flight segments, due to mechanical, environmental, or human factorsin order to identifying operationally significant events and provide insightsinto the flight operations and highlight otherwise unavailable potential safetyrisks and precursors to accidents. For this purpose, we propose a frameworkwhich represents each flight using a semi-Markov switching vectorautoregressive (SMS-VAR) model. Detection of anomalies is then based onmeasuring dissimilarities between the model's prediction and data observation.The framework is scalable, due to the inherent parallel nature of mostcomputations, and can be used to perform online anomaly detection. Extensiveexperimental results on simulated and real datasets illustrate that theframework can detect various types of anomalies along with the key parametersinvolved.

Estimating Structured Vector Autoregressive Model

  While considerable advances have been made in estimating high-dimensionalstructured models from independent data using Lasso-type models, limitedprogress has been made for settings when the samples are dependent. We considerestimating structured VAR (vector auto-regressive models), where the structurecan be captured by any suitable norm, e.g., Lasso, group Lasso, order weightedLasso, sparse group Lasso, etc. In VAR setting with correlated noise, althoughthere is strong dependence over time and covariates, we establish bounds on thenon-asymptotic estimation error of structured VAR parameters. Surprisingly, theestimation error is of the same order as that of the corresponding Lasso-typeestimator with independent samples, and the analysis holds for any norm. Ouranalysis relies on results in generic chaining, sub-exponential martingales,and spectral representation of VAR models. Experimental results on syntheticdata with a variety of structures as well as real aviation data are presented,validating theoretical results.

Unified View of Matrix Completion under General Structural Constraints

  In this paper, we present a unified analysis of matrix completion undergeneral low-dimensional structural constraints induced by {\em any} normregularization. We consider two estimators for the general problem ofstructured matrix completion, and provide unified upper bounds on the samplecomplexity and the estimation error. Our analysis relies on results fromgeneric chaining, and we establish two intermediate results of independentinterest: (a) in characterizing the size or complexity of low dimensionalsubsets in high dimensional ambient space, a certain partial complexity measureencountered in the analysis of matrix completion problems is characterized interms of a well understood complexity measure of Gaussian widths, and (b) it isshown that a form of restricted strong convexity holds for matrix completionproblems under general norm regularization. Further, we provide severalnon-trivial examples of structures included in our framework, notably therecently proposed spectral $k$-support norm.

The Matrix Generalized Inverse Gaussian Distribution: Properties and  Applications

  While the Matrix Generalized Inverse Gaussian ($\mathcal{MGIG}$) distributionarises naturally in some settings as a distribution over symmetric positivesemi-definite matrices, certain key properties of the distribution andeffective ways of sampling from the distribution have not been carefullystudied. In this paper, we show that the $\mathcal{MGIG}$ is unimodal, and themode can be obtained by solving an Algebraic Riccati Equation (ARE) equation[7]. Based on the property, we propose an importance sampling method for the$\mathcal{MGIG}$ where the mode of the proposal distribution matches that ofthe target. The proposed sampling method is more efficient than existingapproaches [32, 33], which use proposal distributions that may have the modefar from the $\mathcal{MGIG}$'s mode. Further, we illustrate that the theposterior distribution in latent factor models, such as probabilistic matrixfactorization (PMF) [25], when marginalized over one latent factor has the$\mathcal{MGIG}$ distribution. The characterization leads to a novel CollapsedMonte Carlo (CMC) inference algorithm for such latent factor models. Weillustrate that CMC has a lower log loss or perplexity than MCMC, and needsfewer samples.

Structured Matrix Recovery via the Generalized Dantzig Selector

  In recent years, structured matrix recovery problems have gained considerableattention for its real world applications, such as recommender systems andcomputer vision. Much of the existing work has focused on matrices withlow-rank structure, and limited progress has been made matrices with othertypes of structure. In this paper we present non-asymptotic analysis forestimation of generally structured matrices via the generalized Dantzigselector under generic sub-Gaussian measurements. We show that the estimationerror can always be succinctly expressed in terms of a few geometric measuresof suitable sets which only depend on the structure of the underlying truematrix. In addition, we derive the general bounds on these geometric measuresfor structures characterized by unitarily invariant norms, which is a largefamily covering most matrix norms of practical interest. Examples are providedto illustrate the utility of our theoretical development.

Generalized Direct Change Estimation in Ising Model Structure

  We consider the problem of estimating change in the dependency structurebetween two $p$-dimensional Ising models, based on respectively $n_1$ and $n_2$samples drawn from the models. The change is assumed to be structured, e.g.,sparse, block sparse, node-perturbed sparse, etc., such that it can becharacterized by a suitable (atomic) norm. We present and analyze anorm-regularized estimator for directly estimating the change in structure,without having to estimate the structures of the individual Ising models. Theestimator can work with any norm, and can be generalized to other graphicalmodels under mild assumptions. We show that only one set of samples, say $n_2$,needs to satisfy the sample complexity requirement for the estimator to work,and the estimation error decreases as $\frac{c}{\sqrt{\min(n_1,n_2)}}$, where$c$ depends on the Gaussian width of the unit norm ball. For example, for$\ell_1$ norm applied to $s$-sparse change, the change can be accuratelyestimated with $\min(n_1,n_2)=O(s \log p)$ which is sharper than an existingresult $n_1= O(s^2 \log p)$ and $n_2 = O(n_1^2)$. Experimental resultsillustrating the effectiveness of the proposed estimator are presented.

Structured Stochastic Linear Bandits

  The stochastic linear bandit problem proceeds in rounds where at each roundthe algorithm selects a vector from a decision set after which it receives anoisy linear loss parameterized by an unknown vector. The goal in such aproblem is to minimize the (pseudo) regret which is the difference between thetotal expected loss of the algorithm and the total expected loss of the bestfixed vector in hindsight. In this paper, we consider settings where theunknown parameter has structure, e.g., sparse, group sparse, low-rank, whichcan be captured by a norm, e.g., $L_1$, $L_{(1,2)}$, nuclear norm. We focus onconstructing confidence ellipsoids which contain the unknown parameter acrossall rounds with high-probability. We show the radius of such ellipsoids dependon the Gaussian width of sets associated with the norm capturing the structure.Such characterization leads to tighter confidence ellipsoids and, therefore,sharper regret bounds compared to bounds in the existing literature which arebased on the ambient dimensionality.

Recommendation under Capacity Constraints

  In this paper, we investigate the common scenario where every candidate itemfor recommendation is characterized by a maximum capacity, i.e., number ofseats in a Point-of-Interest (POI) or size of an item's inventory. Despite theprevalence of the task of recommending items under capacity constraints in avariety of settings, to the best of our knowledge, none of the knownrecommender methods is designed to respect capacity constraints. To close thisgap, we extend three state-of-the art latent factor recommendation approaches:probabilistic matrix factorization (PMF), geographical matrix factorization(GeoMF), and bayesian personalized ranking (BPR), to optimize for bothrecommendation accuracy and expected item usage that respects the capacityconstraints. We introduce the useful concepts of user propensity to listen anditem capacity. Our experimental results in real-world datasets, both for thedomain of item recommendation and POI recommendation, highlight the benefit ofour method for the setting of recommendation under capacity constraints.

High Dimensional Structured Superposition Models

  High dimensional superposition models characterize observations usingparameters which can be written as a sum of multiple component parameters, eachwith its own structure, e.g., sum of low rank and sparse matrices, sum ofsparse and rotated sparse vectors, etc. In this paper, we consider generalsuperposition models which allow sum of any number of component parameters, andeach component structure can be characterized by any norm. We present a simpleestimator for such models, give a geometric condition under which thecomponents can be accurately estimated, characterize sample complexity of theestimator, and give high probability non-asymptotic bounds on the componentwiseestimation error. We use tools from empirical processes and generic chainingfor the statistical analysis, and our results, which substantially generalizeprior work on superposition models, are in terms of Gaussian widths of suitablesets.

R2N2: Residual Recurrent Neural Networks for Multivariate Time Series  Forecasting

  Multivariate time-series modeling and forecasting is an important problemwith numerous applications. Traditional approaches such as VAR (vectorauto-regressive) models and more recent approaches such as RNNs (recurrentneural networks) are indispensable tools in modeling time-series data. In manymultivariate time series modeling problems, there is usually a significantlinear dependency component, for which VARs are suitable, and a nonlinearcomponent, for which RNNs are suitable. Modeling such times series with onlyVAR or only RNNs can lead to poor predictive performance or complex models withlarge training times. In this work, we propose a hybrid model called R2N2(Residual RNN), which first models the time series with a simple linear model(like VAR) and then models its residual errors using RNNs. R2N2s can be trainedusing existing algorithms for VARs and RNNs. Through an extensive empiricalevaluation on two real world datasets (aviation and climate domains), we showthat R2N2 is competitive, usually better than VAR or RNN, used alone. We alsoshow that R2N2 is faster to train as compared to an RNN, while requiring lessnumber of hidden units.

Sparse Linear Isotonic Models

  In machine learning and data mining, linear models have been widely used tomodel the response as parametric linear functions of the predictors. To relaxsuch stringent assumptions made by parametric linear models, additive modelsconsider the response to be a summation of unknown transformations applied onthe predictors; in particular, additive isotonic models (AIMs) assume theunknown transformations to be monotone. In this paper, we introduce sparselinear isotonic models (SLIMs) for highdimensional problems by hybridizingideas in parametric sparse linear models and AIMs, which enjoy a few appealingadvantages over both. In the high-dimensional setting, a two-step algorithm isproposed for estimating the sparse parameters as well as the monotone functionsover predictors. Under mild statistical assumptions, we show that the algorithmcan accurately estimate the parameters. Promising preliminary experiments arepresented to support the theoretical results.

Topic Modeling on Health Journals with Regularized Variational Inference

  Topic modeling enables exploration and compact representation of a corpus.The CaringBridge (CB) dataset is a massive collection of journals written bypatients and caregivers during a health crisis. Topic modeling on the CBdataset, however, is challenging due to the asynchronous nature of multipleauthors writing about their health journeys. To overcome this challenge weintroduce the Dynamic Author-Persona topic model (DAP), a probabilisticgraphical model designed for temporal corpora with multiple authors. Thenovelty of the DAP model lies in its representation of authors by a persona ---where personas capture the propensity to write about certain topics over time.Further, we present a regularized variational inference algorithm, which we useto encourage the DAP model's personas to be distinct. Our results showsignificant improvements over competing topic models --- particularly afterregularization, and highlight the DAP model's unique ability to capture commonjourneys shared by different authors.

Regularity of powers of edge ideals: from local properties to global  bounds

  Let $I = I(G)$ be the edge ideal of a graph $G$. We give various generalupper bounds for the regularity function $\text{ reg } I^s$, for $s \ge 1$,addressing a conjecture made by the authors and Alilooee. When $G$ is agap-free graph and locally of regularity 2, we show that $\text{ reg } I^s =2s$ for all $s \ge 2$. This is a slightly weaker version of a conjecture ofNevo and Peeva. Our method is to investigate the regularity function $\text{reg }I^s$, for $s \ge 1$, via local information of $I$.

High Dimensional Data Enrichment: Interpretable, Fast, and  Data-Efficient

  High dimensional structured data enriched model describes groups ofobservations by shared and per-group individual parameters, each with its ownstructure such as sparsity or group sparsity. In this paper, we consider thegeneral form of data enrichment where data comes in a fixed but arbitrarynumber of groups G. Any convex function, e.g., norms, can characterize thestructure of both shared and individual parameters. We propose an estimator forhigh dimensional data enriched model and provide conditions under which itconsistently estimates both shared and individual parameters. We also delineatesample complexity of the estimator and present high probability non-asymptoticbound on estimation error of all parameters. Interestingly the samplecomplexity of our estimator translates to conditions on both per-group samplesizes and the total number of samples. We propose an iterative estimationalgorithm with linear convergence rate and supplement our theoretical analysiswith synthetic and real experimental results. Particularly, we show thepredictive power of data-enriched model along with its interpretable results inanticancer drug sensitivity analysis.

Adversarial Recommendation: Attack of the Learned Fake Users

  Can machine learning models for recommendation be easily fooled? While thequestion has been answered for hand-engineered fake user profiles, it has notbeen explored for machine learned adversarial attacks. This paper attempts toclose this gap.  We propose a framework for generating fake user profiles which, whenincorporated in the training of a recommendation system, can achieve anadversarial intent, while remaining indistinguishable from real user profiles.We formulate this procedure as a repeated general-sum game between two players:an oblivious recommendation system $R$ and an adversarial fake user generator$A$ with two goals: (G1) the rating distribution of the fake users needs to beclose to the real users, and (G2) some objective $f_A$ encoding the attackintent, such as targeting the top-K recommendation quality of $R$ for a subsetof users, needs to be optimized. We propose a learning framework to achieveboth goals, and offer extensive experiments considering multiple types ofattacks highlighting the vulnerability of recommendation systems.

DAPPER: Scaling Dynamic Author Persona Topic Model to Billion Word  Corpora

  Extracting common narratives from multi-author dynamic text corpora requirescomplex models, such as the Dynamic Author Persona (DAP) topic model. However,such models are complex and can struggle to scale to large corpora, oftenbecause of challenging non-conjugate terms. To overcome such challenges, inthis paper we adapt new ideas in approximate inference to the DAP model,resulting in the DAP Performed Exceedingly Rapidly (DAPPER) topic model.Specifically, we develop Conjugate-Computation Variational Inference (CVI)based variational Expectation-Maximization (EM) for learning the model,yielding fast, closed form updates for each document, replacing iterativeoptimization in earlier work. Our results show significant improvements inmodel fit and training time without needing to compromise the model's temporalstructure or the application of Regularized Variation Inference (RVI). Wedemonstrate the scalability and effectiveness of the DAPPER model by extractinghealth journeys from the CaringBridge corpus --- a collection of 9 millionjournals written by 200,000 authors during health crises.

Powers and products of monomial ideals related to determinantal ideals  of maximal minors

  Let $ X $ be an $ m \times n $ matrix of distinct indeterminates over a field$ K $, where $ m \le n $. Set the polynomial ring $K[X] := K[X_{ij} : 1 \le i\le m, 1 \le j \le n] $. Let $ 1 \le k < l \le n $ be such that $ l - k + 1 \gem $. Consider the submatrix $ Y_{kl} $ of consecutive columns of $ X $ from $ k$th column to $ l $th column. Let $ J_{kl} $ be the ideal generated by`diagonal monomials' of all $ m \times m $ submatrices of $ Y_{kl} $, wherediagonal monomial of a square matrix means product of its main diagonalentries. We show that $ J_{k_1 l_1} J_{k_2 l_2} \cdots J_{k_s l_s} $ has alinear free resolution, where $ k_1 \le k_2 \le \cdots \le k_s $ and $ l_1 \lel_2 \le \cdots \le l_s $. This result is a variation of a theorem due to Brunsand Conca. Moreover, our proof is self-contained, elementary and combinatorial.

Enumerating all maximal biclusters in numerical datasets

  Biclustering has proved to be a powerful data analysis technique due to itswide success in various application domains. However, the existing literaturepresents efficient solutions only for enumerating maximal biclusters withconstant values, or heuristic-based approaches which can not find allbiclusters or even support the maximality of the obtained biclusters. Here, wepresent a general family of biclustering algorithms for enumerating all maximalbiclusters with (i) constant values on rows, (ii) constant values on columns,or (iii) coherent values. Versions for perfect and for perturbed biclusters areprovided. Our algorithms have four key properties (just the algorithm forperturbed biclusters with coherent values fails to exhibit the first property):they are (1) efficient (take polynomial time per pattern), (2) complete (findall maximal biclusters), (3) correct (all biclusters attend the user-definedmeasure of similarity), and (4) non-redundant (all the obtained biclusters aremaximal and the same bicluster is not enumerated twice). They are based on ageneralization of an efficient formal concept analysis algorithm calledIn-Close2. Experimental results point to the necessity of having efficientenumerative biclustering algorithms and provide a valuable insight into thescalability of our family of algorithms and its sensitivity to user-definedparameters.

Revisiting Non-Progressive Influence Models: Scalable Influence  Maximization

  While influence maximization in social networks has been studied extensivelyin computer science community for the last decade the focus has been on theprogressive influence models, such as independent cascade (IC) and Linearthreshold (LT) models, which cannot capture the reversibility of choices. Inthis paper, we present the Heat Conduction (HC) model which is anon-progressive influence model with real-world interpretations. We show thatHC unifies, generalizes, and extends the existing nonprogressive models, suchas the Voter model [1] and non-progressive LT [2]. We then prove that selectingthe optimal seed set of influential nodes is NP-hard for HC but by establishingthe submodularity of influence spread, we can tackle the influence maximizationproblem with a scalable and provably near-optimal greedy algorithm. We are thefirst to present a scalable solution for influence maximization undernonprogressive LT model, as a special case of the HC model. In sharp contrastto the other greedy influence maximization methods, our fast and efficientC2GREEDY algorithm benefits from two analytically computable steps: closed-formcomputation for finding the influence spread as well as the greedy seedselection. Through extensive experiments on several large real and syntheticnetworks, we show that C2GREEDY outperforms the state-of-the-art methods, interms of both influence spread and scalability.

Theory-guided Data Science: A New Paradigm for Scientific Discovery from  Data

  Data science models, although successful in a number of commercial domains,have had limited applicability in scientific problems involving complexphysical phenomena. Theory-guided data science (TGDS) is an emerging paradigmthat aims to leverage the wealth of scientific knowledge for improving theeffectiveness of data science models in enabling scientific discovery. Theoverarching vision of TGDS is to introduce scientific consistency as anessential component for learning generalizable models. Further, by producingscientifically interpretable models, TGDS aims to advance our scientificunderstanding by discovering novel domain insights. Indeed, the paradigm ofTGDS has started to gain prominence in a number of scientific disciplines suchas turbulence modeling, material discovery, quantum chemistry, bio-medicalscience, bio-marker discovery, climate science, and hydrology. In this paper,we formally conceptualize the paradigm of TGDS and present a taxonomy ofresearch themes in TGDS. We describe several approaches for integrating domainknowledge in different research themes using illustrative examples fromdifferent disciplines. We also highlight some of the promising avenues of novelresearch for realizing the full potential of theory-guided data science.

Spatial Projection of Multiple Climate Variables using Hierarchical  Multitask Learning

  Future projection of climate is typically obtained by combining outputs frommultiple Earth System Models (ESMs) for several climate variables such astemperature and precipitation. While IPCC has traditionally used a simple modeloutput average, recent work has illustrated potential advantages of using amultitask learning (MTL) framework for projections of individual climatevariables. In this paper we introduce a framework for hierarchical multitasklearning (HMTL) with two levels of tasks such that each super-task, i.e., taskat the top level, is itself a multitask learning problem over sub-tasks. Forclimate projections, each super-task focuses on projections of specific climatevariables spatially using an MTL formulation. For the proposed HMTL approach, agroup lasso regularization is added to couple parameters across thesuper-tasks, which in the climate context helps exploit relationships among thebehavior of different climate variables at a given spatial location. We showthat some recent works on MTL based on learning task dependency structures canbe viewed as special cases of HMTL. Experiments on synthetic and real climatedata show that HMTL produces better results than decoupled MTL methods appliedseparately on the super-tasks and HMTL significantly outperforms baselines forclimate projection.

High-Dimensional Dependency Structure Learning for Physical Processes

  In this paper, we consider the use of structure learning methods forprobabilistic graphical models to identify statistical dependencies inhigh-dimensional physical processes. Such processes are often syntheticallycharacterized using PDEs (partial differential equations) and are observed in avariety of natural phenomena, including geoscience data capturing atmosphericand hydrological phenomena. Classical structure learning approaches such as thePC algorithm and variants are challenging to apply due to their highcomputational and sample requirements. Modern approaches, often based on sparseregression and variants, do come with finite sample guarantees, but are usuallyhighly sensitive to the choice of hyper-parameters, e.g., parameter $\lambda$for sparsity inducing constraint or regularization. In this paper, we presentACLIME-ADMM, an efficient two-step algorithm for adaptive structure learning,which estimates an edge specific parameter $\lambda_{ij}$ in the first step,and uses these parameters to learn the structure in the second step. Both stepsof our algorithm use (inexact) ADMM to solve suitable linear programs, and alliterations can be done in closed form in an efficient block parallel manner. Wecompare ACLIME-ADMM with baselines on both synthetic data simulated by partialdifferential equations (PDEs) that model advection-diffusion processes, andreal data (50 years) of daily global geopotential heights to study informationflow in the atmosphere. ACLIME-ADMM is shown to be efficient, stable, andcompetitive, usually better than the baselines especially on difficultproblems. On real data, ACLIME-ADMM recovers the underlying structure of globalatmospheric circulation, including switches in wind directions at the equatorand tropics entirely from the data.

