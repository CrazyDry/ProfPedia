Regularity of Path Ideals of Gap Free Graphs

  In this paper we study the Castelnuovo-Mumford regularity of the path ideals
of finite simple graphs. We find new upper bounds for various path ideals of
gap free graphs. In particular we prove that the path ideals of gap free and
claw graphs have linear minimal free resolutions.


The Regularity of Powers of Edge Ideals

  In this paper we prove the existence of a special order on the set of minimal
monomial generators of powers of edge ideals of arbitrary graphs. Using this
order we find new upper bounds on the regularity of powers of edge ideals of
graphs whose complement does not have any induced four cycle.


Powers of edge ideals of regularity three bipartite graphs

  In this paper we prove that if $I(G)$ is a bipartite edge ideal with
regularity three then for all $s\geq 2$ the regularity of $I(G)^s$ is exactly
$2s+1$.


Construction of a few Quantum mechanical Hamiltonians via
  L$\acute{e}$vi-Leblond type Linearization:Spinor states and Supersymmetry

  A number of new L$\acute{e}$vi-Leblond type equations admitting four
component spinor solutions have been proposed. The pair of linearized equations
thus obtained in each case lead to Hamiltonians with characteristic features
like L-S coupling and supersymmetry. The relevant momentum operators have often
been understood in terms of Clifford algebraic bases producing
Schr$\ddot{o}$dinger Hamiltonians with L-S coupling. As for example
Hamiltonians representing Rashba effect or three dimensional harmonic
oscillator have been constructed. The supersymmetric nature of one dimensional
oscillator has also been appreciated.


Properties of Lyubeznik numbers under localization and polarization

  We exhibit a global bound for the Lyubeznik numbers of a ring of prime
characteristic. In addition, we show that for a monomial ideal, the Lyubeznik
numbers of the quotient rings of its radical and its polarization are the same.
Furthermore, we present examples that show striking behavior of the Lyubeznik
numbers under localization. We also show related results for generalizations of
the Lyubeznik numbers.


Regularity of Edge Ideals and Their Powers

  We survey recent studies on the Castelnuovo-Mumford regularity of edge ideals
of graphs and their powers. Our focus is on bounds and exact values of $\text{
reg } I(G)$ and the asymptotic linear function $\text{ reg } I(G)^q$, for $q
\geq 1,$ in terms of combinatorial data of the given graph $G.$


Holographic s-wave condensate with non-linear electrodynamics: A
  nontrivial boundary value problem

  In this paper, considering the probe limit, we analytically study the onset
of holographic s-wave condensate in the planar Schwarzschild-AdS background.
Inspired by various low energy features of string theory, in the present work
we replace the conventional Maxwell action by a (non-linear) Born-Infeld (BI)
action which essentially corresponds to the higher derivative corrections of
the gauge fields. Based on a variational method, which is commonly known as the
Sturm-Liouville (SL) eigenvalue problem and considering a non-trivial
asymptotic solution for the scalar field, we compute the critical temperature
for the s-wave condensation. The results thus obtained analytically agree well
with the numerical findings\cite{hs19}. As a next step, we extend our
perturbative technique to compute the order parameter for the condensation.
Interestingly our analytic results are found to be of the same order as the
numerical values obtained earlier.


Existence and Stability of Periodic Orbits in $N$-Dimensional Piecewise
  Linear Continuous Maps

  Piecewise smooth maps are known to exhibit a wide range of dynamical features
including numerous types of periodic orbits. Predicting regions in parameter
space where such periodic orbits might occur and determining their stability is
crucial to characterize the dynamics of the system. However, obtaining the
conditions of existence and stability of these periodic orbits generally use
brute force methods which require successive application of the iterative map
on a starting point. In this article, we propose a faster and more elegant way
of obtaining those conditions without iterating the complete map. The method
revolves around direct computation of higher powers of matrices without
computing the lower ones and is applicable on any dimension of the phase space.
In the later part of the article, we compare the speed of the proposed method
with the other popular algorithms which shows the effectiveness of the proposed
method in higher dimensions. We also illustrate the use of this method in
computing the regions of existence and stability of a particular class of
periodic orbits in three dimensions.


Gaussian Process Topic Models

  We introduce Gaussian Process Topic Models (GPTMs), a new family of topic
models which can leverage a kernel among documents while extracting correlated
topics. GPTMs can be considered a systematic generalization of the Correlated
Topic Models (CTMs) using ideas from Gaussian Process (GP) based embedding.
Since GPTMs work with both a topic covariance matrix and a document kernel
matrix, learning GPTMs involves a novel component-solving a suitable Sylvester
equation capturing both topic and document dependencies. The efficacy of GPTMs
is demonstrated with experiments evaluating the quality of both topic modeling
and embedding.


Alternating Estimation for Structured High-Dimensional Multi-Response
  Models

  We consider learning high-dimensional multi-response linear models with
structured parameters. By exploiting the noise correlations among responses, we
propose an alternating estimation (AltEst) procedure to estimate the model
parameters based on the generalized Dantzig selector. Under suitable sample
size and resampling assumptions, we show that the error of the estimates
generated by AltEst, with high probability, converges linearly to certain
minimum achievable level, which can be tersely expressed by a few geometric
measures, such as Gaussian width of sets related to the parameter structure. To
the best of our knowledge, this is the first non-asymptotic statistical
guarantee for such AltEst-type algorithm applied to estimation problem with
general structures.


Graph Connectivity and Binomial Edge Ideals

  We relate homological properties of a binomial edge ideal $\mathcal{J}_G$ to
invariants that measure the connectivity of a simple graph $G$. Specifically,
we show if $R/\mathcal{J}_G$ is a Cohen-Macaulay ring, then graph toughness of
$G$ is exactly $\frac{1}{2}$. We also give an inequality between the depth of
$R/\mathcal{J}_G$ and the vertex-connectivity of $G$. In addition, we study the
Hilbert-Samuel multiplicity, and the Hilbert-Kunz multiplicity of
$R/\mathcal{J}_G$.


Time Series Deinterleaving of DNS Traffic

  Stream deinterleaving is an important problem with various applications in
the cybersecurity domain. In this paper, we consider the specific problem of
deinterleaving DNS data streams using machine-learning techniques, with the
objective of automating the extraction of malware domain sequences. We first
develop a generative model for user request generation and DNS stream
interleaving. Based on these we evaluate various inference strategies for
deinterleaving including augmented HMMs and LSTMs on synthetic datasets. Our
results demonstrate that state-of-the-art LSTMs outperform more traditional
augmented HMMs in this application domain.


Packing properties of cubic squarefree monomial ideals

  Let $I$ be an ideal in a Noetherian ring $R$. The $n^{\text{th}}$ symbolic
power of $I$ is defined as $$I^{(n)}=\displaystyle\bigcap_{p\in
Ass(R)}(I^nR_p\cap R).$$ The symbolic powers, in general, are not equal to the
ordinary powers. Therefore, one interesting question here is for what classes
of ideals ordinary and symbolic powers coincide? The answer to this question
for squarefree monomial ideals may be packing property. In this paper, we study
the equality between symbolic and ordinary powers for some classes of cubic
squarefree monomial ideals.


An Energy-Efficient VCO-Based Matrix Multiplier Block to Support On-Chip
  Image Analysis

  Images typically are represented as uniformly sampled data in the form of
matrix of pixels/voxels. Therefore, matrix multiply-and-accumulate (MAC) forms
the core of most state-of-the-art image analysis algorithms. While digital
implementation of MAC has generally been the preferred approach, high power
consumption is an impediment to adopting it for medical image analysis. In this
work, we present a time-domain signal processing architecture which performs
MAC operations with 7bit accuracy while consuming 400X lower energy than
digital implementation. The proposed architecture performs analog computation
using mostly digital circuits and is suitable for scaled CMOS technologies. The
proposed time-domain MAC architecture is expected to play a central role in
empowering the advancement of various on-chip image analysis operations.


Maximally $\cal{N}$-extended super-BMS$_3$ algebras and Generalized 3D
  Gravity Solutions

  We consider the maximal $\cal{N}-$extended supergravity theory in 3
dimensions with fermionic generators transforming under real but non
necessarily irreducible representations of the internal algebra. We obtain the
symmetry algebra at null infinity preserving boundary conditions of
asymptotically flat solutions, i.e. the maximal $\cal{N}-$extended
super-BMS$_3$ algebra, which possesses non-linear correction in the
anti-commutators of supercharges. We present the supersymmetric energy bound
and derive the explicit form of the asymptotic Killing spinors. We also find
the most generic circular symmetric ground state of the theory, which
corresponds to a non-supersymmetric cosmological solutions and derive their
entropy.


Does Cyg X-1 have a small Standard Accretion Disc?

  We analyze several outbursts of a few transient sources using Proportional
Counter Array (PCA) data (2.5-25 keV) as well as All Sky Monitor (ASM) data
(1.5-12 keV) of Rossi X-ray Timing Explorer (RXTE) satellite. We find a time
delay between the arrival times of the Keplerian disc component and the halo of
the Two-Component Advective Flow (TCAF) when the spectral data is fitted with
TCAF solution. We compare this time delay from the spectral fits with the TCAF
solution of the transient low mass X-ray binaries (LMXBs) e.g., GX 339-4, H
1743-322 and MAXI J1836-194 with that of the high mass X-ray Binary (HMXB), Cyg
X-1. We find that several days of time delays are observed in LMXBs while for
Cyg X-1 the delay is negligible. We interpret the large delay to be due to the
viscous delay of a large Keplerian component to reach the inner region as
compared to nearly free-fall time taken by the low angular momentum halo
component. The delay is of the order of a few days for the low mass X-ray
binaries (LMXBs) where the feeding is primarily through the Roche-lobe.
However, it is negligible in a wind-fed system like Cyg X-1 since a very small
Keplerian disc is created here by slowly redistributing the low angular
momentum of the wind. As a consequence, sporadic soft or intermediate spectral
states are observed.


Approximation Algorithms for Bregman Co-clustering and Tensor Clustering

  In the past few years powerful generalizations to the Euclidean k-means
problem have been made, such as Bregman clustering [7], co-clustering (i.e.,
simultaneous clustering of rows and columns of an input matrix) [9,18], and
tensor clustering [8,34]. Like k-means, these more general problems also suffer
from the NP-hardness of the associated optimization. Researchers have developed
approximation algorithms of varying degrees of sophistication for k-means,
k-medians, and more recently also for Bregman clustering [2]. However, there
seem to be no approximation algorithms for Bregman co- and tensor clustering.
In this paper we derive the first (to our knowledge) guaranteed methods for
these increasingly important clustering settings. Going beyond Bregman
divergences, we also prove an approximation factor for tensor clustering with
arbitrary separable metrics. Through extensive experiments we evaluate the
characteristics of our method, and show that it also has practical impact.


Bregman Alternating Direction Method of Multipliers

  The mirror descent algorithm (MDA) generalizes gradient descent by using a
Bregman divergence to replace squared Euclidean distance. In this paper, we
similarly generalize the alternating direction method of multipliers (ADMM) to
Bregman ADMM (BADMM), which allows the choice of different Bregman divergences
to exploit the structure of problems. BADMM provides a unified framework for
ADMM and its variants, including generalized ADMM, inexact ADMM and Bethe ADMM.
  We establish the global convergence and the $O(1/T)$ iteration complexity for
BADMM. In some cases, BADMM can be faster than ADMM by a factor of
$O(n/\log(n))$. In solving the linear program of mass transportation problem,
BADMM leads to massive parallelism and can easily run on GPU. BADMM is several
times faster than highly optimized commercial software Gurobi.


Online Alternating Direction Method (longer version)

  Online optimization has emerged as powerful tool in large scale optimization.
In this pa- per, we introduce efficient online optimization algorithms based on
the alternating direction method (ADM), which can solve online convex
optimization under linear constraints where the objective could be non-smooth.
We introduce new proof techniques for ADM in the batch setting, which yields a
O(1/T) convergence rate for ADM and forms the basis for regret anal- ysis in
the online setting. We consider two scenarios in the online setting, based on
whether an additional Bregman divergence is needed or not. In both settings, we
establish regret bounds for both the objective function as well as constraints
violation for general and strongly convex functions. We also consider inexact
ADM updates where certain terms are linearized to yield efficient updates and
show the stochastic convergence rates. In addition, we briefly discuss that
online ADM can be used as projection- free online learning algorithm in some
scenarios. Preliminary results are presented to illustrate the performance of
the proposed algorithms.


Multi-task Sparse Structure Learning

  Multi-task learning (MTL) aims to improve generalization performance by
learning multiple related tasks simultaneously. While sometimes the underlying
task relationship structure is known, often the structure needs to be estimated
from data at hand. In this paper, we present a novel family of models for MTL,
applicable to regression and classification problems, capable of learning the
structure of task relationships. In particular, we consider a joint estimation
problem of the task relationship structure and the individual task parameters,
which is solved using alternating minimization. The task relationship structure
learning component builds on recent advances in structure learning of Gaussian
graphical models based on sparse estimators of the precision (inverse
covariance) matrix. We illustrate the effectiveness of the proposed model on a
variety of synthetic and benchmark datasets for regression and classification.
We also consider the problem of combining climate model outputs for better
projections of future climate, with focus on temperature in South America, and
show that the proposed model outperforms several existing methods for the
problem.


Estimation with Norm Regularization

  Analysis of non-asymptotic estimation error and structured statistical
recovery based on norm regularized regression, such as Lasso, needs to consider
four aspects: the norm, the loss function, the design matrix, and the noise
model. This paper presents generalizations of such estimation error analysis on
all four aspects compared to the existing literature. We characterize the
restricted error set where the estimation error vector lies, establish
relations between error sets for the constrained and regularized problems, and
present an estimation error bound applicable to any norm. Precise
characterizations of the bound is presented for isotropic as well as
anisotropic subGaussian design matrices, subGaussian noise models, and convex
loss functions, including least squares and generalized linear models. Generic
chaining and associated results play an important role in the analysis. A key
result from the analysis is that the sample complexity of all such estimators
depends on the Gaussian width of a spherical cap corresponding to the
restricted error set. Further, once the number of samples $n$ crosses the
required sample complexity, the estimation error decreases as
$\frac{c}{\sqrt{n}}$, where $c$ depends on the Gaussian width of the unit norm
ball.


Parallel Direction Method of Multipliers

  We consider the problem of minimizing block-separable convex functions
subject to linear constraints. While the Alternating Direction Method of
Multipliers (ADMM) for two-block linear constraints has been intensively
studied both theoretically and empirically, in spite of some preliminary work,
effective generalizations of ADMM to multiple blocks is still unclear. In this
paper, we propose a randomized block coordinate method named Parallel Direction
Method of Multipliers (PDMM) to solve the optimization problems with
multi-block linear constraints. PDMM randomly updates some primal and dual
blocks in parallel, behaving like parallel randomized block coordinate descent.
We establish the global convergence and the iteration complexity for PDMM with
constant step size. We also show that PDMM can do randomized block coordinate
descent on overlapping blocks. Experimental results show that PDMM performs
better than state-of-the-arts methods in two applications, robust principal
component analysis and overlapping group lasso.


Generalized Dantzig Selector: Application to the k-support norm

  We propose a Generalized Dantzig Selector (GDS) for linear models, in which
any norm encoding the parameter structure can be leveraged for estimation. We
investigate both computational and statistical aspects of the GDS. Based on
conjugate proximal operator, a flexible inexact ADMM framework is designed for
solving GDS, and non-asymptotic high-probability bounds are established on the
estimation error, which rely on Gaussian width of unit norm ball and suitable
set encompassing estimation error. Further, we consider a non-trivial example
of the GDS using $k$-support norm. We derive an efficient method to compute the
proximal operator for $k$-support norm since existing methods are inapplicable
in this setting. For statistical analysis, we provide upper bounds for the
Gaussian widths needed in the GDS analysis, yielding the first statistical
recovery guarantee for estimation with the $k$-support norm. The experimental
results confirm our theoretical analysis.


Semi-Markov Switching Vector Autoregressive Model-based Anomaly
  Detection in Aviation Systems

  In this work we consider the problem of anomaly detection in heterogeneous,
multivariate, variable-length time series datasets. Our focus is on the
aviation safety domain, where data objects are flights and time series are
sensor readings and pilot switches. In this context the goal is to detect
anomalous flight segments, due to mechanical, environmental, or human factors
in order to identifying operationally significant events and provide insights
into the flight operations and highlight otherwise unavailable potential safety
risks and precursors to accidents. For this purpose, we propose a framework
which represents each flight using a semi-Markov switching vector
autoregressive (SMS-VAR) model. Detection of anomalies is then based on
measuring dissimilarities between the model's prediction and data observation.
The framework is scalable, due to the inherent parallel nature of most
computations, and can be used to perform online anomaly detection. Extensive
experimental results on simulated and real datasets illustrate that the
framework can detect various types of anomalies along with the key parameters
involved.


Estimating Structured Vector Autoregressive Model

  While considerable advances have been made in estimating high-dimensional
structured models from independent data using Lasso-type models, limited
progress has been made for settings when the samples are dependent. We consider
estimating structured VAR (vector auto-regressive models), where the structure
can be captured by any suitable norm, e.g., Lasso, group Lasso, order weighted
Lasso, sparse group Lasso, etc. In VAR setting with correlated noise, although
there is strong dependence over time and covariates, we establish bounds on the
non-asymptotic estimation error of structured VAR parameters. Surprisingly, the
estimation error is of the same order as that of the corresponding Lasso-type
estimator with independent samples, and the analysis holds for any norm. Our
analysis relies on results in generic chaining, sub-exponential martingales,
and spectral representation of VAR models. Experimental results on synthetic
data with a variety of structures as well as real aviation data are presented,
validating theoretical results.


Generalized Direct Change Estimation in Ising Model Structure

  We consider the problem of estimating change in the dependency structure
between two $p$-dimensional Ising models, based on respectively $n_1$ and $n_2$
samples drawn from the models. The change is assumed to be structured, e.g.,
sparse, block sparse, node-perturbed sparse, etc., such that it can be
characterized by a suitable (atomic) norm. We present and analyze a
norm-regularized estimator for directly estimating the change in structure,
without having to estimate the structures of the individual Ising models. The
estimator can work with any norm, and can be generalized to other graphical
models under mild assumptions. We show that only one set of samples, say $n_2$,
needs to satisfy the sample complexity requirement for the estimator to work,
and the estimation error decreases as $\frac{c}{\sqrt{\min(n_1,n_2)}}$, where
$c$ depends on the Gaussian width of the unit norm ball. For example, for
$\ell_1$ norm applied to $s$-sparse change, the change can be accurately
estimated with $\min(n_1,n_2)=O(s \log p)$ which is sharper than an existing
result $n_1= O(s^2 \log p)$ and $n_2 = O(n_1^2)$. Experimental results
illustrating the effectiveness of the proposed estimator are presented.


Structured Stochastic Linear Bandits

  The stochastic linear bandit problem proceeds in rounds where at each round
the algorithm selects a vector from a decision set after which it receives a
noisy linear loss parameterized by an unknown vector. The goal in such a
problem is to minimize the (pseudo) regret which is the difference between the
total expected loss of the algorithm and the total expected loss of the best
fixed vector in hindsight. In this paper, we consider settings where the
unknown parameter has structure, e.g., sparse, group sparse, low-rank, which
can be captured by a norm, e.g., $L_1$, $L_{(1,2)}$, nuclear norm. We focus on
constructing confidence ellipsoids which contain the unknown parameter across
all rounds with high-probability. We show the radius of such ellipsoids depend
on the Gaussian width of sets associated with the norm capturing the structure.
Such characterization leads to tighter confidence ellipsoids and, therefore,
sharper regret bounds compared to bounds in the existing literature which are
based on the ambient dimensionality.


Gap Filling in the Plant Kingdom---Trait Prediction Using Hierarchical
  Probabilistic Matrix Factorization

  Plant traits are a key to understanding and predicting the adaptation of
ecosystems to environmental changes, which motivates the TRY project aiming at
constructing a global database for plant traits and becoming a standard
resource for the ecological community. Despite its unprecedented coverage, a
large percentage of missing data substantially constrains joint trait analysis.
Meanwhile, the trait data is characterized by the hierarchical phylogenetic
structure of the plant kingdom. While factorization based matrix completion
techniques have been widely used to address the missing data problem,
traditional matrix factorization methods are unable to leverage the
phylogenetic structure. We propose hierarchical probabilistic matrix
factorization (HPMF), which effectively uses hierarchical phylogenetic
information for trait prediction. We demonstrate HPMF's high accuracy,
effectiveness of incorporating hierarchical structure and ability to capture
trait correlation through experiments.


Online Alternating Direction Method

  Online optimization has emerged as powerful tool in large scale optimization.
In this paper, we introduce efficient online algorithms based on the
alternating directions method (ADM). We introduce a new proof technique for ADM
in the batch setting, which yields the O(1/T) convergence rate of ADM and forms
the basis of regret analysis in the online setting. We consider two scenarios
in the online setting, based on whether the solution needs to lie in the
feasible set or not. In both settings, we establish regret bounds for both the
objective function as well as constraint violation for general and strongly
convex functions. Preliminary results are presented to illustrate the
performance of the proposed algorithms.


Unified View of Matrix Completion under General Structural Constraints

  In this paper, we present a unified analysis of matrix completion under
general low-dimensional structural constraints induced by {\em any} norm
regularization. We consider two estimators for the general problem of
structured matrix completion, and provide unified upper bounds on the sample
complexity and the estimation error. Our analysis relies on results from
generic chaining, and we establish two intermediate results of independent
interest: (a) in characterizing the size or complexity of low dimensional
subsets in high dimensional ambient space, a certain partial complexity measure
encountered in the analysis of matrix completion problems is characterized in
terms of a well understood complexity measure of Gaussian widths, and (b) it is
shown that a form of restricted strong convexity holds for matrix completion
problems under general norm regularization. Further, we provide several
non-trivial examples of structures included in our framework, notably the
recently proposed spectral $k$-support norm.


Bethe-ADMM for Tree Decomposition based Parallel MAP Inference

  We consider the problem of maximum a posteriori (MAP) inference in discrete
graphical models. We present a parallel MAP inference algorithm called
Bethe-ADMM based on two ideas: tree-decomposition of the graph and the
alternating direction method of multipliers (ADMM). However, unlike the
standard ADMM, we use an inexact ADMM augmented with a Bethe-divergence based
proximal function, which makes each subproblem in ADMM easy to solve in
parallel using the sum-product algorithm. We rigorously prove global
convergence of Bethe-ADMM. The proposed algorithm is extensively evaluated on
both synthetic and real datasets to illustrate its effectiveness. Further, the
parallel Bethe-ADMM is shown to scale almost linearly with increasing number of
cores.


Randomized Block Coordinate Descent for Online and Stochastic
  Optimization

  Two types of low cost-per-iteration gradient descent methods have been
extensively studied in parallel. One is online or stochastic gradient descent
(OGD/SGD), and the other is randomzied coordinate descent (RBCD). In this
paper, we combine the two types of methods together and propose online
randomized block coordinate descent (ORBCD). At each iteration, ORBCD only
computes the partial gradient of one block coordinate of one mini-batch
samples. ORBCD is well suited for the composite minimization problem where one
function is the average of the losses of a large number of samples and the
other is a simple regularizer defined on high dimensional variables. We show
that the iteration complexity of ORBCD has the same order as OGD or SGD. For
strongly convex functions, by reducing the variance of stochastic gradients, we
show that ORBCD can converge at a geometric rate in expectation, matching the
convergence rate of SGD with variance reduction and RBCD.


A Spectral Algorithm for Inference in Hidden Semi-Markov Models

  Hidden semi-Markov models (HSMMs) are latent variable models which allow
latent state persistence and can be viewed as a generalization of the popular
hidden Markov models (HMMs). In this paper, we introduce a novel spectral
algorithm to perform inference in HSMMs. Unlike expectation maximization (EM),
our approach correctly estimates the probability of given observation sequence
based on a set of training sequences. Our approach is based on estimating
moments from the sample, whose number of dimensions depends only
logarithmically on the maximum length of the hidden state persistence.
Moreover, the algorithm requires only a few matrix inversions and is therefore
computationally efficient. Empirical evaluations on synthetic and real data
demonstrate the advantage of the algorithm over EM in terms of speed and
accuracy, especially for large datasets.


The Matrix Generalized Inverse Gaussian Distribution: Properties and
  Applications

  While the Matrix Generalized Inverse Gaussian ($\mathcal{MGIG}$) distribution
arises naturally in some settings as a distribution over symmetric positive
semi-definite matrices, certain key properties of the distribution and
effective ways of sampling from the distribution have not been carefully
studied. In this paper, we show that the $\mathcal{MGIG}$ is unimodal, and the
mode can be obtained by solving an Algebraic Riccati Equation (ARE) equation
[7]. Based on the property, we propose an importance sampling method for the
$\mathcal{MGIG}$ where the mode of the proposal distribution matches that of
the target. The proposed sampling method is more efficient than existing
approaches [32, 33], which use proposal distributions that may have the mode
far from the $\mathcal{MGIG}$'s mode. Further, we illustrate that the the
posterior distribution in latent factor models, such as probabilistic matrix
factorization (PMF) [25], when marginalized over one latent factor has the
$\mathcal{MGIG}$ distribution. The characterization leads to a novel Collapsed
Monte Carlo (CMC) inference algorithm for such latent factor models. We
illustrate that CMC has a lower log loss or perplexity than MCMC, and needs
fewer samples.


Structured Matrix Recovery via the Generalized Dantzig Selector

  In recent years, structured matrix recovery problems have gained considerable
attention for its real world applications, such as recommender systems and
computer vision. Much of the existing work has focused on matrices with
low-rank structure, and limited progress has been made matrices with other
types of structure. In this paper we present non-asymptotic analysis for
estimation of generally structured matrices via the generalized Dantzig
selector under generic sub-Gaussian measurements. We show that the estimation
error can always be succinctly expressed in terms of a few geometric measures
of suitable sets which only depend on the structure of the underlying true
matrix. In addition, we derive the general bounds on these geometric measures
for structures characterized by unitarily invariant norms, which is a large
family covering most matrix norms of practical interest. Examples are provided
to illustrate the utility of our theoretical development.


Recommendation under Capacity Constraints

  In this paper, we investigate the common scenario where every candidate item
for recommendation is characterized by a maximum capacity, i.e., number of
seats in a Point-of-Interest (POI) or size of an item's inventory. Despite the
prevalence of the task of recommending items under capacity constraints in a
variety of settings, to the best of our knowledge, none of the known
recommender methods is designed to respect capacity constraints. To close this
gap, we extend three state-of-the art latent factor recommendation approaches:
probabilistic matrix factorization (PMF), geographical matrix factorization
(GeoMF), and bayesian personalized ranking (BPR), to optimize for both
recommendation accuracy and expected item usage that respects the capacity
constraints. We introduce the useful concepts of user propensity to listen and
item capacity. Our experimental results in real-world datasets, both for the
domain of item recommendation and POI recommendation, highlight the benefit of
our method for the setting of recommendation under capacity constraints.


High Dimensional Structured Superposition Models

  High dimensional superposition models characterize observations using
parameters which can be written as a sum of multiple component parameters, each
with its own structure, e.g., sum of low rank and sparse matrices, sum of
sparse and rotated sparse vectors, etc. In this paper, we consider general
superposition models which allow sum of any number of component parameters, and
each component structure can be characterized by any norm. We present a simple
estimator for such models, give a geometric condition under which the
components can be accurately estimated, characterize sample complexity of the
estimator, and give high probability non-asymptotic bounds on the componentwise
estimation error. We use tools from empirical processes and generic chaining
for the statistical analysis, and our results, which substantially generalize
prior work on superposition models, are in terms of Gaussian widths of suitable
sets.


R2N2: Residual Recurrent Neural Networks for Multivariate Time Series
  Forecasting

  Multivariate time-series modeling and forecasting is an important problem
with numerous applications. Traditional approaches such as VAR (vector
auto-regressive) models and more recent approaches such as RNNs (recurrent
neural networks) are indispensable tools in modeling time-series data. In many
multivariate time series modeling problems, there is usually a significant
linear dependency component, for which VARs are suitable, and a nonlinear
component, for which RNNs are suitable. Modeling such times series with only
VAR or only RNNs can lead to poor predictive performance or complex models with
large training times. In this work, we propose a hybrid model called R2N2
(Residual RNN), which first models the time series with a simple linear model
(like VAR) and then models its residual errors using RNNs. R2N2s can be trained
using existing algorithms for VARs and RNNs. Through an extensive empirical
evaluation on two real world datasets (aviation and climate domains), we show
that R2N2 is competitive, usually better than VAR or RNN, used alone. We also
show that R2N2 is faster to train as compared to an RNN, while requiring less
number of hidden units.


Sparse Linear Isotonic Models

  In machine learning and data mining, linear models have been widely used to
model the response as parametric linear functions of the predictors. To relax
such stringent assumptions made by parametric linear models, additive models
consider the response to be a summation of unknown transformations applied on
the predictors; in particular, additive isotonic models (AIMs) assume the
unknown transformations to be monotone. In this paper, we introduce sparse
linear isotonic models (SLIMs) for highdimensional problems by hybridizing
ideas in parametric sparse linear models and AIMs, which enjoy a few appealing
advantages over both. In the high-dimensional setting, a two-step algorithm is
proposed for estimating the sparse parameters as well as the monotone functions
over predictors. Under mild statistical assumptions, we show that the algorithm
can accurately estimate the parameters. Promising preliminary experiments are
presented to support the theoretical results.


Topic Modeling on Health Journals with Regularized Variational Inference

  Topic modeling enables exploration and compact representation of a corpus.
The CaringBridge (CB) dataset is a massive collection of journals written by
patients and caregivers during a health crisis. Topic modeling on the CB
dataset, however, is challenging due to the asynchronous nature of multiple
authors writing about their health journeys. To overcome this challenge we
introduce the Dynamic Author-Persona topic model (DAP), a probabilistic
graphical model designed for temporal corpora with multiple authors. The
novelty of the DAP model lies in its representation of authors by a persona ---
where personas capture the propensity to write about certain topics over time.
Further, we present a regularized variational inference algorithm, which we use
to encourage the DAP model's personas to be distinct. Our results show
significant improvements over competing topic models --- particularly after
regularization, and highlight the DAP model's unique ability to capture common
journeys shared by different authors.


Regularity of powers of edge ideals: from local properties to global
  bounds

  Let $I = I(G)$ be the edge ideal of a graph $G$. We give various general
upper bounds for the regularity function $\text{ reg } I^s$, for $s \ge 1$,
addressing a conjecture made by the authors and Alilooee. When $G$ is a
gap-free graph and locally of regularity 2, we show that $\text{ reg } I^s =
2s$ for all $s \ge 2$. This is a slightly weaker version of a conjecture of
Nevo and Peeva. Our method is to investigate the regularity function $\text{
reg }I^s$, for $s \ge 1$, via local information of $I$.


High Dimensional Data Enrichment: Interpretable, Fast, and
  Data-Efficient

  High dimensional structured data enriched model describes groups of
observations by shared and per-group individual parameters, each with its own
structure such as sparsity or group sparsity. In this paper, we consider the
general form of data enrichment where data comes in a fixed but arbitrary
number of groups G. Any convex function, e.g., norms, can characterize the
structure of both shared and individual parameters. We propose an estimator for
high dimensional data enriched model and provide conditions under which it
consistently estimates both shared and individual parameters. We also delineate
sample complexity of the estimator and present high probability non-asymptotic
bound on estimation error of all parameters. Interestingly the sample
complexity of our estimator translates to conditions on both per-group sample
sizes and the total number of samples. We propose an iterative estimation
algorithm with linear convergence rate and supplement our theoretical analysis
with synthetic and real experimental results. Particularly, we show the
predictive power of data-enriched model along with its interpretable results in
anticancer drug sensitivity analysis.


Adversarial Recommendation: Attack of the Learned Fake Users

  Can machine learning models for recommendation be easily fooled? While the
question has been answered for hand-engineered fake user profiles, it has not
been explored for machine learned adversarial attacks. This paper attempts to
close this gap.
  We propose a framework for generating fake user profiles which, when
incorporated in the training of a recommendation system, can achieve an
adversarial intent, while remaining indistinguishable from real user profiles.
We formulate this procedure as a repeated general-sum game between two players:
an oblivious recommendation system $R$ and an adversarial fake user generator
$A$ with two goals: (G1) the rating distribution of the fake users needs to be
close to the real users, and (G2) some objective $f_A$ encoding the attack
intent, such as targeting the top-K recommendation quality of $R$ for a subset
of users, needs to be optimized. We propose a learning framework to achieve
both goals, and offer extensive experiments considering multiple types of
attacks highlighting the vulnerability of recommendation systems.


DAPPER: Scaling Dynamic Author Persona Topic Model to Billion Word
  Corpora

  Extracting common narratives from multi-author dynamic text corpora requires
complex models, such as the Dynamic Author Persona (DAP) topic model. However,
such models are complex and can struggle to scale to large corpora, often
because of challenging non-conjugate terms. To overcome such challenges, in
this paper we adapt new ideas in approximate inference to the DAP model,
resulting in the DAP Performed Exceedingly Rapidly (DAPPER) topic model.
Specifically, we develop Conjugate-Computation Variational Inference (CVI)
based variational Expectation-Maximization (EM) for learning the model,
yielding fast, closed form updates for each document, replacing iterative
optimization in earlier work. Our results show significant improvements in
model fit and training time without needing to compromise the model's temporal
structure or the application of Regularized Variation Inference (RVI). We
demonstrate the scalability and effectiveness of the DAPPER model by extracting
health journeys from the CaringBridge corpus --- a collection of 9 million
journals written by 200,000 authors during health crises.


Powers and products of monomial ideals related to determinantal ideals
  of maximal minors

  Let $ X $ be an $ m \times n $ matrix of distinct indeterminates over a field
$ K $, where $ m \le n $. Set the polynomial ring $K[X] := K[X_{ij} : 1 \le i
\le m, 1 \le j \le n] $. Let $ 1 \le k < l \le n $ be such that $ l - k + 1 \ge
m $. Consider the submatrix $ Y_{kl} $ of consecutive columns of $ X $ from $ k
$th column to $ l $th column. Let $ J_{kl} $ be the ideal generated by
`diagonal monomials' of all $ m \times m $ submatrices of $ Y_{kl} $, where
diagonal monomial of a square matrix means product of its main diagonal
entries. We show that $ J_{k_1 l_1} J_{k_2 l_2} \cdots J_{k_s l_s} $ has a
linear free resolution, where $ k_1 \le k_2 \le \cdots \le k_s $ and $ l_1 \le
l_2 \le \cdots \le l_s $. This result is a variation of a theorem due to Bruns
and Conca. Moreover, our proof is self-contained, elementary and combinatorial.


Revisiting Non-Progressive Influence Models: Scalable Influence
  Maximization

  While influence maximization in social networks has been studied extensively
in computer science community for the last decade the focus has been on the
progressive influence models, such as independent cascade (IC) and Linear
threshold (LT) models, which cannot capture the reversibility of choices. In
this paper, we present the Heat Conduction (HC) model which is a
non-progressive influence model with real-world interpretations. We show that
HC unifies, generalizes, and extends the existing nonprogressive models, such
as the Voter model [1] and non-progressive LT [2]. We then prove that selecting
the optimal seed set of influential nodes is NP-hard for HC but by establishing
the submodularity of influence spread, we can tackle the influence maximization
problem with a scalable and provably near-optimal greedy algorithm. We are the
first to present a scalable solution for influence maximization under
nonprogressive LT model, as a special case of the HC model. In sharp contrast
to the other greedy influence maximization methods, our fast and efficient
C2GREEDY algorithm benefits from two analytically computable steps: closed-form
computation for finding the influence spread as well as the greedy seed
selection. Through extensive experiments on several large real and synthetic
networks, we show that C2GREEDY outperforms the state-of-the-art methods, in
terms of both influence spread and scalability.


Enumerating all maximal biclusters in numerical datasets

  Biclustering has proved to be a powerful data analysis technique due to its
wide success in various application domains. However, the existing literature
presents efficient solutions only for enumerating maximal biclusters with
constant values, or heuristic-based approaches which can not find all
biclusters or even support the maximality of the obtained biclusters. Here, we
present a general family of biclustering algorithms for enumerating all maximal
biclusters with (i) constant values on rows, (ii) constant values on columns,
or (iii) coherent values. Versions for perfect and for perturbed biclusters are
provided. Our algorithms have four key properties (just the algorithm for
perturbed biclusters with coherent values fails to exhibit the first property):
they are (1) efficient (take polynomial time per pattern), (2) complete (find
all maximal biclusters), (3) correct (all biclusters attend the user-defined
measure of similarity), and (4) non-redundant (all the obtained biclusters are
maximal and the same bicluster is not enumerated twice). They are based on a
generalization of an efficient formal concept analysis algorithm called
In-Close2. Experimental results point to the necessity of having efficient
enumerative biclustering algorithms and provide a valuable insight into the
scalability of our family of algorithms and its sensitivity to user-defined
parameters.


Theory-guided Data Science: A New Paradigm for Scientific Discovery from
  Data

  Data science models, although successful in a number of commercial domains,
have had limited applicability in scientific problems involving complex
physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm
that aims to leverage the wealth of scientific knowledge for improving the
effectiveness of data science models in enabling scientific discovery. The
overarching vision of TGDS is to introduce scientific consistency as an
essential component for learning generalizable models. Further, by producing
scientifically interpretable models, TGDS aims to advance our scientific
understanding by discovering novel domain insights. Indeed, the paradigm of
TGDS has started to gain prominence in a number of scientific disciplines such
as turbulence modeling, material discovery, quantum chemistry, bio-medical
science, bio-marker discovery, climate science, and hydrology. In this paper,
we formally conceptualize the paradigm of TGDS and present a taxonomy of
research themes in TGDS. We describe several approaches for integrating domain
knowledge in different research themes using illustrative examples from
different disciplines. We also highlight some of the promising avenues of novel
research for realizing the full potential of theory-guided data science.


Spatial Projection of Multiple Climate Variables using Hierarchical
  Multitask Learning

  Future projection of climate is typically obtained by combining outputs from
multiple Earth System Models (ESMs) for several climate variables such as
temperature and precipitation. While IPCC has traditionally used a simple model
output average, recent work has illustrated potential advantages of using a
multitask learning (MTL) framework for projections of individual climate
variables. In this paper we introduce a framework for hierarchical multitask
learning (HMTL) with two levels of tasks such that each super-task, i.e., task
at the top level, is itself a multitask learning problem over sub-tasks. For
climate projections, each super-task focuses on projections of specific climate
variables spatially using an MTL formulation. For the proposed HMTL approach, a
group lasso regularization is added to couple parameters across the
super-tasks, which in the climate context helps exploit relationships among the
behavior of different climate variables at a given spatial location. We show
that some recent works on MTL based on learning task dependency structures can
be viewed as special cases of HMTL. Experiments on synthetic and real climate
data show that HMTL produces better results than decoupled MTL methods applied
separately on the super-tasks and HMTL significantly outperforms baselines for
climate projection.


High-Dimensional Dependency Structure Learning for Physical Processes

  In this paper, we consider the use of structure learning methods for
probabilistic graphical models to identify statistical dependencies in
high-dimensional physical processes. Such processes are often synthetically
characterized using PDEs (partial differential equations) and are observed in a
variety of natural phenomena, including geoscience data capturing atmospheric
and hydrological phenomena. Classical structure learning approaches such as the
PC algorithm and variants are challenging to apply due to their high
computational and sample requirements. Modern approaches, often based on sparse
regression and variants, do come with finite sample guarantees, but are usually
highly sensitive to the choice of hyper-parameters, e.g., parameter $\lambda$
for sparsity inducing constraint or regularization. In this paper, we present
ACLIME-ADMM, an efficient two-step algorithm for adaptive structure learning,
which estimates an edge specific parameter $\lambda_{ij}$ in the first step,
and uses these parameters to learn the structure in the second step. Both steps
of our algorithm use (inexact) ADMM to solve suitable linear programs, and all
iterations can be done in closed form in an efficient block parallel manner. We
compare ACLIME-ADMM with baselines on both synthetic data simulated by partial
differential equations (PDEs) that model advection-diffusion processes, and
real data (50 years) of daily global geopotential heights to study information
flow in the atmosphere. ACLIME-ADMM is shown to be efficient, stable, and
competitive, usually better than the baselines especially on difficult
problems. On real data, ACLIME-ADMM recovers the underlying structure of global
atmospheric circulation, including switches in wind directions at the equator
and tropics entirely from the data.


