Content-Based Book Recommending Using Learning for Text Categorization

  Recommender systems improve access to relevant products and information bymaking personalized suggestions based on previous examples of a user's likesand dislikes. Most existing recommender systems use social filtering methodsthat base recommendations on other users' preferences. By contrast,content-based methods use information about an item itself to make suggestions.This approach has the advantage of being able to recommended previously unrateditems to users with unique interests and to provide explanations for itsrecommendations. We describe a content-based book recommending system thatutilizes information extraction and a machine-learning algorithm for textcategorization. Initial experimental results demonstrate that this approach canproduce accurate recommendations.

Comparative Experiments on Disambiguating Word Senses: An Illustration  of the Role of Bias in Machine Learning

  This paper describes an experimental comparison of seven different learningalgorithms on the problem of learning to disambiguate the meaning of a wordfrom context. The algorithms tested include statistical, neural-network,decision-tree, rule-based, and case-based classification techniques. Thespecific problem tested involves disambiguating six senses of the word ``line''using the words in the current and proceeding sentence as context. Thestatistical and neural-network methods perform the best on this particularproblem and we discuss a potential reason for this observed difference. We alsodiscuss the role of bias in machine learning and its importance in explainingperformance differences observed on specific problems.

Learning Parse and Translation Decisions From Examples With Rich Context

  We present a knowledge and context-based system for parsing and translatingnatural language and evaluate it on sentences from the Wall Street Journal.Applying machine learning techniques, the system uses parse action examplesacquired under supervision to generate a deterministic shift-reduce parser inthe form of a decision structure. It relies heavily on context, as encoded infeatures which describe the morphological, syntactic, semantic and otheraspects of a given parse state.

Using Sentence-Level LSTM Language Models for Script Inference

  There is a small but growing body of research on statistical scripts, modelsof event sequences that allow probabilistic inference of implicit events fromdocuments. These systems operate on structured verb-argument events produced byan NLP pipeline. We compare these systems with recent Recurrent Neural Netmodels that directly operate on raw tokens to predict sentences, finding thelatter to be roughly comparable to the former in terms of predicting missingevents in documents.

Supervised and Unsupervised Ensembling for Knowledge Base Population

  We present results on combining supervised and unsupervised methods toensemble multiple systems for two popular Knowledge Base Population (KBP)tasks, Cold Start Slot Filling (CSSF) and Tri-lingual Entity Discovery andLinking (TEDL). We demonstrate that our combined system along with auxiliaryfeatures outperforms the best performing system for both tasks in the 2015competition, several ensembling baselines, as well as the state-of-the-artstacking approach to ensembling KBP systems. The success of our technique ontwo different and challenging problems demonstrates the power and generality ofour combined approach to ensembling.

Leveraging Discourse Information Effectively for Authorship Attribution

  We explore techniques to maximize the effectiveness of discourse informationin the task of authorship attribution. We present a novel method to embeddiscourse features in a Convolutional Neural Network text classifier, whichachieves a state-of-the-art result by a substantial margin. We empiricallyinvestigate several featurization methods to understand the conditions underwhich discourse features contribute non-trivial performance gains, and analyzediscourse embeddings.

Learning a Policy for Opportunistic Active Learning

  Active learning identifies data points to label that are expected to be themost useful in improving a supervised model. Opportunistic active learningincorporates active learning into interactive tasks that constrain possiblequeries during interactions. Prior work has shown that opportunistic activelearning can be used to improve grounding of natural language descriptions inan interactive object retrieval task. In this work, we use reinforcementlearning for such an object retrieval task, to learn a policy that effectivelytrades off task completion with model improvement that would benefit futuretasks.

Faithful Multimodal Explanation for Visual Question Answering

  AI systems' ability to explain their reasoning is critical to their utilityand trustworthiness. Deep neural networks have enabled significant progress onmany challenging problems such as visual question answering (VQA). However,most of them are opaque black boxes with limited explanatory capability. Thispaper presents a novel approach to developing a high-performing VQA system thatcan elucidate its answers with integrated textual and visual explanations thatfaithfully reflect important aspects of its underlying reasoning whilecapturing the style of comprehensible human explanations. Extensiveexperimental evaluation demonstrates the advantages of this approach comparedto competing methods with both automatic evaluation metrics and humanevaluation metrics.

Training a Multilingual Sportscaster: Using Perceptual Context to Learn  Language

  We present a novel framework for learning to interpret and generate languageusing only perceptual context as supervision. We demonstrate its capabilitiesby developing a system that learns to sportscast simulated robot soccer gamesin both English and Korean without any language-specific prior knowledge.Training employs only ambiguous supervision consisting of a stream ofdescriptive textual comments and a sequence of events extracted from thesimulation trace. The system simultaneously establishes correspondences betweenindividual comments and the events that they describe while building atranslation model that supports both parsing and generation. We also present anovel algorithm for learning which events are worth describing. Humanevaluations of the generated commentaries indicate they are of reasonablequality and in some cases even on par with those produced by humans for ourlimited domain.

Stacking With Auxiliary Features

  Ensembling methods are well known for improving prediction accuracy. However,they are limited in the sense that they cannot discriminate among componentmodels effectively. In this paper, we propose stacking with auxiliary featuresthat learns to fuse relevant information from multiple systems to improveperformance. Auxiliary features enable the stacker to rely on systems that notjust agree on an output but also the provenance of the output. We demonstrateour approach on three very different and difficult problems -- the Cold StartSlot Filling, the Tri-lingual Entity Discovery and Linking and the ImageNetobject detection tasks. We obtain new state-of-the-art results on the first twotasks and substantial improvements on the detection task, thus verifying thepower and generality of our approach.

Joint Image Captioning and Question Answering

  Answering visual questions need acquire daily common knowledge and model thesemantic connection among different parts in images, which is too difficult forVQA systems to learn from images with the only supervision from answers.Meanwhile, image captioning systems with beam search strategy tend to generatesimilar captions and fail to diversely describe images. To address theaforementioned issues, we present a system to have these two tasks compensatewith each other, which is capable of jointly producing image captions andanswering visual questions. In particular, we utilize question and imagefeatures to generate question-related captions and use the generated captionsas additional features to provide new knowledge to the VQA system. For imagecaptioning, our system attains more informative results in term of the relativeimprovements on VQA tasks as well as competitive results using automatedmetrics. Applying our system to the VQA tasks, our results on VQA v2 datasetachieve 65.8% using generated captions and 69.1% using annotated captions invalidation set and 68.4% in the test-standard set. Further, an ensemble of 10models results in 69.7% in the test-standard split.

Executable Trigger-Action Comments

  Natural language elements, e.g., todo comments, are frequently used tocommunicate among the developers and to describe tasks that need to beperformed (actions) when specific conditions hold in the code repository(triggers). As projects evolve, development processes change, and developmentteams reorganize, these comments, because of their informal nature, frequentlybecome irrelevant or forgotten.  We present the first technique, dubbed TrigIt, to specify triggeraction todocomments as executable statements. Thus, actions are executed automaticallywhen triggers evaluate to true. TrigIt specifications are written in the hostlanguage (e.g., Java) and are evaluated as part of the build process. Thetriggers are specified as query statements over abstract syntax trees andabstract representation of build configuration scripts, and the actions arespecified as code transformation steps. We implemented TrigIt for the Javaprogramming language and migrated 20 existing trigger-action comments from 8popular open-source projects. We evaluate the cost of using TrigIt in terms ofthe number of tokens in the executable comments and the time overheadintroduced in the build process.

Improving Grounded Natural Language Understanding through Human-Robot  Dialog

  Natural language understanding for robotics can require substantial domain-and platform-specific engineering. For example, for mobile robots topick-and-place objects in an environment to satisfy human commands, we canspecify the language humans use to issue such commands, and connect conceptwords like red can to physical object properties. One way to alleviate thisengineering for a new domain is to enable robots in human environments to adaptdynamically---continually learning new language constructions and perceptualconcepts. In this work, we present an end-to-end pipeline for translatingnatural language commands to discrete robot actions, and use clarificationdialogs to jointly improve language parsing and concept grounding. We train andevaluate this agent in a virtual setting on Amazon Mechanical Turk, and wetransfer the learned agent to a physical robot platform to demonstrate it inthe real world.

Using Natural Language for Reward Shaping in Reinforcement Learning

  Recent reinforcement learning (RL) approaches have shown strong performancein complex domains such as Atari games, but are often highly sampleinefficient. A common approach to reduce interaction time with the environmentis to use reward shaping, which involves carefully designing reward functionsthat provide the agent intermediate rewards for progress towards the goal.However, designing appropriate shaping rewards is known to be difficult as wellas time-consuming. In this work, we address this problem by using naturallanguage instructions to perform reward shaping. We propose the LanguagE-ActionReward Network (LEARN), a framework that maps free-form natural languageinstructions to intermediate rewards based on actions taken by the agent. Theseintermediate language-based rewards can seamlessly be integrated into anystandard reinforcement learning algorithm. We experiment with Montezuma'sRevenge from the Atari Learning Environment, a popular benchmark in RL. Ourexperiments on a diverse set of 15 tasks demonstrate that, for the same numberof interactions with the environment, language-based rewards lead to successfulcompletion of the task 60% more often on average, compared to learning withoutlanguage.

Representing Meaning with a Combination of Logical and Distributional  Models

  NLP tasks differ in the semantic information they require, and at this timeno single se- mantic representation fulfills all requirements. Logic-basedrepresentations characterize sentence structure, but do not capture the gradedaspect of meaning. Distributional models give graded similarity ratings forwords and phrases, but do not capture sentence structure in the same detail aslogic-based approaches. So it has been argued that the two are complementary.We adopt a hybrid approach that combines logic-based and distributionalsemantics through probabilistic logic inference in Markov Logic Networks(MLNs). In this paper, we focus on the three components of a practical systemintegrating logical and distributional models: 1) Parsing and taskrepresentation is the logic-based part where input problems are represented inprobabilistic logic. This is quite different from representing them in standardfirst-order logic. 2) For knowledge base construction we form weightedinference rules. We integrate and compare distributional information with othersources, notably WordNet and an existing paraphrase collection. In particular,we use our system to evaluate distributional lexical entailment approaches. Weuse a variant of Robinson resolution to determine the necessary inferencerules. More sources can easily be added by mapping them to logical rules; oursystem learns a resource-specific weight that corrects for scaling differencesbetween resources. 3) In discussing probabilistic inference, we show how tosolve the inference problems efficiently. To evaluate our approach, we use thetask of textual entailment (RTE), which can utilize the strengths of bothlogic-based and distributional representations. In particular we focus on theSICK dataset, where we achieve state-of-the-art results.

The SeaQuest Spectrometer at Fermilab

  The SeaQuest spectrometer at Fermilab was designed to detectoppositely-charged pairs of muons (dimuons) produced by interactions between a120 GeV proton beam and liquid hydrogen, liquid deuterium and solid nucleartargets. The primary physics program uses the Drell-Yan process to probeantiquark distributions in the target nucleon. The spectrometer consists of atarget system, two dipole magnets and four detector stations. The upstreammagnet is a closed-aperture solid iron magnet which also serves as the beamdump, while the second magnet is an open aperture magnet. Each of the detectorstations consists of scintillator hodoscopes and a high-resolution trackingdevice. The FPGA-based trigger compares the hodoscope signals to a set ofpre-programmed roads to determine if the event contains oppositely-signed,high-mass muon pairs.

Observation of the rare $B^0_s\toμ^+μ^-$ decay from the combined  analysis of CMS and LHCb data

  A joint measurement is presented of the branching fractions$B^0_s\to\mu^+\mu^-$ and $B^0\to\mu^+\mu^-$ in proton-proton collisions at theLHC by the CMS and LHCb experiments. The data samples were collected in 2011 ata centre-of-mass energy of 7 TeV, and in 2012 at 8 TeV. The combined analysisproduces the first observation of the $B^0_s\to\mu^+\mu^-$ decay, with astatistical significance exceeding six standard deviations, and the bestmeasurement of its branching fraction so far. Furthermore, evidence for the$B^0\to\mu^+\mu^-$ decay is obtained with a statistical significance of threestandard deviations. The branching fraction measurements are statisticallycompatible with SM predictions and impose stringent constraints on severaltheories beyond the SM.

