Surface Normals in the Wild

  We study the problem of single-image depth estimation for images in the wild.
We collect human annotated surface normals and use them to train a neural
network that directly predicts pixel-wise depth. We propose two novel loss
functions for training with surface normal annotations. Experiments on NYU
Depth and our own dataset demonstrate that our approach can significantly
improve the quality of depth estimation in the wild.


Prediction of enthalpy for nitrogen gas revised

  It is shown that the energy spectrum of the pure vibrational levels of the
molecule consisting of two atoms interacting with each other via the modified
Rosen-Morse potential, the analytical expressions for the vibrational partition
function and enthalpy of the diatomic molecule, obtained in the paper
Prediction of enthalpy for nitrogen gas, M. Deng, C.S. Jia, Evr. Phys. J. Plus
133, 258 (2018), are incorrect.


Constructing $2m$-variable Boolean functions with optimal algebraic
  immunity based on polar decomposition of $\mathbb{F}_{2^{2m}}^*$

  Constructing $2m$-variable Boolean functions with optimal algebraic immunity
based on decomposition of additive group of the finite field
$\mathbb{F}_{2^{2m}}$ seems to be a promising approach since Tu and Deng's
work. In this paper, we consider the same problem in a new way. Based on polar
decomposition of the multiplicative group of $\mathbb{F}_{2^{2m}}$, we propose
a new construction of Boolean functions with optimal algebraic immunity. By a
slight modification of it, we obtain a class of balanced Boolean functions
achieving optimal algebraic immunity, which also have optimal algebraic degree
and high nonlinearity. Computer investigations imply that this class of
functions also behave well against fast algebraic attacks.


Stacked Hourglass Networks for Human Pose Estimation

  This work introduces a novel convolutional network architecture for the task
of human pose estimation. Features are processed across all scales and
consolidated to best capture the various spatial relationships associated with
the body. We show how repeated bottom-up, top-down processing used in
conjunction with intermediate supervision is critical to improving the
performance of the network. We refer to the architecture as a "stacked
hourglass" network based on the successive steps of pooling and upsampling that
are done to produce a final set of predictions. State-of-the-art results are
achieved on the FLIC and MPII benchmarks outcompeting all recent methods.


Single-Image Depth Perception in the Wild

  This paper studies single-image depth perception in the wild, i.e.,
recovering depth from a single image taken in unconstrained settings. We
introduce a new dataset "Depth in the Wild" consisting of images in the wild
annotated with relative depth between pairs of random points. We also propose a
new algorithm that learns to estimate metric depth using annotations of
relative depth. Compared to the state of the art, our algorithm is simpler and
performs better. Experiments show that our algorithm, combined with existing
RGB-D data and our new relative depth annotations, significantly improves
single-image depth perception in the wild.


Premise Selection for Theorem Proving by Deep Graph Embedding

  We propose a deep learning-based approach to the problem of premise
selection: selecting mathematical statements relevant for proving a given
conjecture. We represent a higher-order logic formula as a graph that is
invariant to variable renaming but still fully preserves syntactic and semantic
information. We then embed the graph into a vector via a novel embedding method
that preserves the information of edge ordering. Our approach achieves
state-of-the-art results on the HolStep dataset, improving the classification
accuracy from 83% to 90.3%.


Shape from Shading through Shape Evolution

  In this paper, we address the shape-from-shading problem by training deep
networks with synthetic images. Unlike conventional approaches that combine
deep learning and synthetic imagery, we propose an approach that does not need
any external shape dataset to render synthetic images. Our approach consists of
two synergistic processes: the evolution of complex shapes from simple
primitives, and the training of a deep network for shape-from-shading. The
evolution generates better shapes guided by the network training, while the
training improves by using the evolved shapes. We show that our approach
achieves state-of-the-art performance on a shape-from-shading benchmark.


Think Visually: Question Answering through Virtual Imagery

  In this paper, we study the problem of geometric reasoning in the context of
question-answering. We introduce Dynamic Spatial Memory Network (DSMN), a new
deep network architecture designed for answering questions that admit latent
visual representations. DSMN learns to generate and reason over such
representations. Further, we propose two synthetic benchmarks, FloorPlanQA and
ShapeIntersection, to evaluate the geometric reasoning capability of QA
systems. Experimental results validate the effectiveness of our proposed DSMN
for visual thinking tasks.


CornerNet: Detecting Objects as Paired Keypoints

  We propose CornerNet, a new approach to object detection where we detect an
object bounding box as a pair of keypoints, the top-left corner and the
bottom-right corner, using a single convolution neural network. By detecting
objects as paired keypoints, we eliminate the need for designing a set of
anchor boxes commonly used in prior single-stage detectors. In addition to our
novel formulation, we introduce corner pooling, a new type of pooling layer
that helps the network better localize corners. Experiments show that CornerNet
achieves a 42.2% AP on MS COCO, outperforming all existing one-stage detectors.


Speaker Naming in Movies

  We propose a new model for speaker naming in movies that leverages visual,
textual, and acoustic modalities in an unified optimization framework. To
evaluate the performance of our model, we introduce a new dataset consisting of
six episodes of the Big Bang Theory TV show and eighteen full movies covering
different genres. Our experiments show that our multimodal model significantly
outperforms several competitive baselines on the average weighted F-score
metric. To demonstrate the effectiveness of our framework, we design an
end-to-end memory network model that leverages our speaker naming model and
achieves state-of-the-art results on the subtitles task of the MovieQA 2017
Challenge.


DeepV2D: Video to Depth with Differentiable Structure from Motion

  We propose DeepV2D, an end-to-end differentiable deep learning architecture
for predicting depth from a video sequence. We incorporate elements of
classical Structure from Motion into an end-to-end trainable pipeline by
designing a set of differentiable geometric modules. Our full system alternates
between predicting depth and refining camera pose. We estimate depth by
building a cost volume over learned features and apply a multi-scale 3D
convolutional network for stereo matching. The predicted depth is then sent to
the motion module which performs iterative pose updates by mapping optical flow
to a camera motion update. We evaluate our proposed system on NYU, KITTI, and
SUN3D datasets and show improved results over monocular baselines and deep and
classical stereo reconstruction.


Experimental generation of tripartite polarization entangled states of
  bright optical beams

  The multipartite polarization entangled states of bright optical beams
directly associating with the spin states of atomic ensembles are one of the
essential resources in the future quantum information networks, which can be
conveniently utilized to transfer and convert quantum states across a network
composed of many atomic nodes. In this letter, we present the experimental
demonstration of tripartite polarization entanglement described by Stokes
operators of optical field. The tripartite entangled states of light at the
frequency resonant with D1 line of Rubidium atoms are transformed into the
continuous variable polarization entanglement among three bright optical beams
via an optical beam splitter network. The obtained entanglement is confirmed by
the extended criterion for polarization entanglement of multipartite quantized
optical modes.


Establishing and storing of deterministic quantum entanglement among
  three distant atomic ensembles

  It is crucial for physical realization of quantum information networks to
first establish entanglement among multiple space-separated quantum memories
and then at a user-controlled moment to transfer the stored entanglement to
quantum channels for distribution and conveyance of information. Here we
present an experimental demonstration on generation, storage and transfer of
deterministic quantum entanglement among three spatially separated atomic
ensembles. The off-line prepared multipartite entanglement of optical modes is
mapped into three distant atomic ensembles to establish entanglement of atomic
spin waves via electromagnetically-induced-transparency light-matter
interaction. Then the stored atomic entanglement is transferred into a
tripartite quadrature entangled state of light, which is space-separated and
can be dynamically allocated to three quantum channels for conveying quantum
information. The existence of entanglement among released three optical modes
verifies that the system has capacity of preserving multipartite entanglement.
The presented protocol can be directly extended to larger quantum networks with
more nodes.


Deep Learning Inference in Facebook Data Centers: Characterization,
  Performance Optimizations and Hardware Implications

  The application of deep learning techniques resulted in remarkable
improvement of machine learning models. In this paper provides detailed
characterizations of deep learning models used in many Facebook social network
services. We present computational characteristics of our models, describe high
performance optimizations targeting existing systems, point out their
limitations and make suggestions for the future general-purpose/accelerated
inference hardware. Also, we highlight the need for better co-design of
algorithms, numerics and computing platforms to address the challenges of
workloads often run in data centers.


Wavelet filters and infinite-dimensional unitary groups

  In this paper, we study wavelet filters and their dependence on two numbers,
the scale N and the genus g. We show that the wavelet filters, in the
quadrature mirror case, have a harmonic analysis which is based on
representations of the C^*-algebra O_N. A main tool in our analysis is the
infinite-dimensional group of all maps T -> U(N) (where U(N) is the group of
all unitary N-by-N matrices), and we study the extension problem from low-pass
filter to multiresolution filter using this group.


Titanium dioxide hole-blocking layer in ultra-thin-film crystalline
  silicon solar cells

  One of the remaining obstacles to approaching the theoretical efficiency
limit of crystalline silicon (c-Si) solar cells is the exceedingly high
interface recombination loss for minority carriers at the Ohmic contacts. In
ultra-thin-film c-Si solar cells, this contact recombination loss is far more
severe than for traditional thick cells due to the smaller volume and higher
minority carrier concentration of the former. This paper presents a novel
design of an electron passing (Ohmic) contact to n-type Si that is
hole-blocking with significantly reduced hole recombination. This contact is
formed by depositing a thin titanium dioxide (TiO2) layer to form a silicon
metal-insulator-semiconductor (MIS) contact. A 2 {\mu}m thick Si cell with this
TiO2 MIS contact achieved an open circuit voltage (Voc) of 645 mV, which is 10
mV higher than that of an ultra-thin cell with a metal contact. This MIS
contact demonstrates a new path for ultra-thin-film c-Si solar cells to achieve
high efficiencies as high as traditional thick cells, and enables the
fabrication of high-efficiency c-Si solar cells at a lower cost.


Stacked Dense U-Nets with Dual Transformers for Robust Face Alignment

  Facial landmark localisation in images captured in-the-wild is an important
and challenging problem. The current state-of-the-art revolves around certain
kinds of Deep Convolutional Neural Networks (DCNNs) such as stacked U-Nets and
Hourglass networks. In this work, we innovatively propose stacked dense U-Nets
for this task. We design a novel scale aggregation network topology structure
and a channel aggregation building block to improve the model's capacity
without sacrificing the computational complexity and model size. With the
assistance of deformable convolutions inside the stacked dense U-Nets and
coherent loss for outside data transformation, our model obtains the ability to
be spatially invariant to arbitrary input face images. Extensive experiments on
many in-the-wild datasets, validate the robustness of the proposed method under
extreme poses, exaggerated expressions and heavy occlusions. Finally, we show
that accurate 3D face alignment can assist pose-invariant face recognition
where we achieve a new state-of-the-art accuracy on CFP-FP.


Accurate 3D Face Reconstruction with Weakly-Supervised Learning: From
  Single Image to Image Set

  Recently, deep learning based 3D face reconstruction methods have shown
promising results in both quality and efficiency.However, training deep neural
networks typically requires a large volume of data, whereas face images with
ground-truth 3D face shapes are scarce. In this paper, we propose a novel deep
3D face reconstruction approach that 1) leverages a robust, hybrid loss
function for weakly-supervised learning which takes into account both low-level
and perception-level information for supervision, and 2) performs multi-image
face reconstruction by exploiting complementary information from different
images for shape aggregation. Our method is fast, accurate, and robust to
occlusion and large pose. We provide comprehensive experiments on three
datasets, systematically comparing our method with fifteen recent methods and
demonstrating its state-of-the-art performance.


Could the 21-cm absorption be explained by the dark matter suggested by
  $^8$Be transitions?

  The stronger than expected 21-cm absorption was observed by EDGES recently,
and another anomaly of $^8$Be transitions would be signatures of new
interactions. These two issues may be related to each other, e.g., pseudoscalar
$A$ mediated fermionic millicharged dark matter (DM), and the 21-cm absorption
could be induced by photon mediated scattering between MeV millicharged DM and
hydrogen. This will be explored in this paper. For fermionic millicharged DM
$\bar{\chi} \chi$ with masses in a range of $2 m_A < 2 m_{\chi} < 3 m_A$, the
p-wave annihilation $\bar{\chi} \chi \to A A$ would be dominant during DM
freeze-out. The s-wave annihilation $\bar{\chi} \chi$ $\to A, \gamma $ $\to e^+
e^-$ is tolerant by constraints from CMB and the 21-cm absorption. The
millicharged DM can evade constraints from direct detection experiments. The
process of $K^+ \to \pi^+ \pi^0$ with the invisible decay $\pi^0 \to \bar{\chi}
\chi$ could be employed to search for the millicharged DM, and future high
intensity $K^+$ sources, such as NA62, will do the job.


ArcFace: Additive Angular Margin Loss for Deep Face Recognition

  One of the main challenges in feature learning using Deep Convolutional
Neural Networks (DCNNs) for large-scale face recognition is the design of
appropriate loss functions that enhance discriminative power. Centre loss
penalises the distance between the deep features and their corresponding class
centres in the Euclidean space to achieve intra-class compactness. SphereFace
assumes that the linear transformation matrix in the last fully connected layer
can be used as a representation of the class centres in an angular space and
penalises the angles between the deep features and their corresponding weights
in a multiplicative way. Recently, a popular line of research is to incorporate
margins in well-established loss functions in order to maximise face class
separability. In this paper, we propose an Additive Angular Margin Loss
(ArcFace) to obtain highly discriminative features for face recognition. The
proposed ArcFace has a clear geometric interpretation due to the exact
correspondence to the geodesic distance on the hypersphere. We present arguably
the most extensive experimental evaluation of all the recent state-of-the-art
face recognition methods on over 10 face recognition benchmarks including a new
large-scale image database with trillion level of pairs and a large-scale video
dataset. We show that ArcFace consistently outperforms the state-of-the-art and
can be easily implemented with negligible computational overhead. We release
all refined training data, training codes, pre-trained models and training
logs, which will help reproduce the results in this paper.


Acoustic transmission enhancement through a periodically-structured
  stiff plate without any opening

  We report both experimentally and theoretically that the enhanced acoustic
transmission can occur in the subwavelength region through a thin but stiff
structured-plate without any opening. This exotic acoustic phenomenon is
essentially distinct from the previous related studies originated from, either
collectively or individually, the interaction of the incident wave with
openings in previous structures. It is attributed to the structure-induced
resonant excitation of the non-leaky Lamb modes that exist intrinsically in the
uniform elastic plate. Our finding should have impact on ultrasonic
applications.


Gates for one-way quantum computation based on Einstein-Podolsky-Rosen
  entanglement

  Single-mode squeezing and Fourier transformation operations are two essential
logical gates in continuous-variable quantum computation, which have been
experimentally implemented by means of an optical four-mode cluster state. In
this paper, we present a simpler and more efficient protocol based on the use
of Einstein-Podolsky-Rosen two-mode entangled states to realize the same
operations. The theoretical calculations and the experimental results
demonstrate that the presented scheme not only decreases the requirement to the
resource quantum states at the largest extent but also enhances significantly
the squeezing degree and the fidelity of the resultant modes under an identical
resource condition. That is because in our system the influence of the excess
noises deriving from the imperfect squeezing of the resource states is
degraded. The gate operations applying two-mode entanglement can be utilized as
a basic element in a future quantum computer involving a large-scale cluster
state.


Forecasting Human Dynamics from Static Images

  This paper presents the first study on forecasting human dynamics from static
images. The problem is to input a single RGB image and generate a sequence of
upcoming human body poses in 3D. To address the problem, we propose the 3D Pose
Forecasting Network (3D-PFNet). Our 3D-PFNet integrates recent advances on
single-image human pose estimation and sequence prediction, and converts the 2D
predictions into 3D space. We train our 3D-PFNet using a three-step training
strategy to leverage a diverse source of training data, including image and
video based human pose datasets and 3D motion capture (MoCap) data. We
demonstrate competitive performance of our 3D-PFNet on 2D pose forecasting and
3D pose recovery through quantitative and qualitative results.


Temporal Action Localization by Structured Maximal Sums

  We address the problem of temporal action localization in videos. We pose
action localization as a structured prediction over arbitrary-length temporal
windows, where each window is scored as the sum of frame-wise classification
scores. Additionally, our model classifies the start, middle, and end of each
action as separate components, allowing our system to explicitly model each
action's temporal evolution and take advantage of informative temporal
dependencies present in this structure. In this framework, we localize actions
by searching for the structured maximal sum, a problem for which we develop a
novel, provably-efficient algorithmic solution. The frame-wise classification
scores are computed using features from a deep Convolutional Neural Network
(CNN), which are trained end-to-end to directly optimize for a novel structured
objective. We evaluate our system on the THUMOS 14 action detection benchmark
and achieve competitive performance.


Gate sequence for continuous variable one-way quantum computation

  Measurement-based one-way quantum computation (QC) using cluster states as
resources provides an efficient model to perform computation and information
processing of quantum codes. Arbitrary Gaussian QC can be implemented by
sufficiently long single-mode and two-mode gate sequences. However, continuous
variable (CV) gate sequences have not been realized so far due to an absence of
cluster states larger than four submodes. Here we present the first CV gate
sequence consisting of a single-mode squeezing gate and a two-mode
controlled-phase gate based on a six-mode cluster state. The quantum property
of this gate sequence is confirmed by the fidelities and the quantum
entanglement of two output modes, which depend on both the squeezing and
controlled-phase gates. The experiment demonstrates the feasibility of
implementing Gaussian QC by means of accessible gate sequences.


Losses-based test of wave-particle duality with Mach-Zehnder
  interferometers

  Wave-particle duality of photons with losses in the Mach-Zehnder
interferometer (MZI) is investigated experimentally and theoretically. The
experiment is done with the standard MZI with the beam splitter or the beam
merger being continuously varied. The losses are deliberately introduced either
inside the MZI (the two arms between the beam splitter and beam mergers) or
outside the MZI (after the beam merger). It is proved that the unbalanced
losses have great influence on the predictability $P$ (particle nature) and
visibility $V$ (wave nature). For the former case the duality inequality holds
while for the later the duality inequality is ``violated''. We get $P^2+V^2>1$.
This ``violation'' could be eliminated in principle by switching the two paths
and detectors and then averaging the results. The observed results can be
exactly explained theoretically. The experiment is done with coherent beam,
instead of single photons, and we have proved that they are exactly equivalent
in duality experiment with MZI.


Associative Embedding: End-to-End Learning for Joint Detection and
  Grouping

  We introduce associative embedding, a novel method for supervising
convolutional neural networks for the task of detection and grouping. A number
of computer vision problems can be framed in this manner including multi-person
pose estimation, instance segmentation, and multi-object tracking. Usually the
grouping of detections is achieved with multi-stage pipelines, instead we
propose an approach that teaches a network to simultaneously output detections
and group assignments. This technique can be easily integrated into any
state-of-the-art network architecture that produces pixel-wise predictions. We
show how to apply this method to both multi-person pose estimation and instance
segmentation and report state-of-the-art performance for multi-person pose on
the MPII and MS-COCO datasets.


Dynamic Deep Neural Networks: Optimizing Accuracy-Efficiency Trade-offs
  by Selective Execution

  We introduce Dynamic Deep Neural Networks (D2NN), a new type of feed-forward
deep neural network that allows selective execution. Given an input, only a
subset of D2NN neurons are executed, and the particular subset is determined by
the D2NN itself. By pruning unnecessary computation depending on input, D2NNs
provide a way to improve computational efficiency. To achieve dynamic selective
execution, a D2NN augments a feed-forward deep neural network (directed acyclic
graph of differentiable modules) with controller modules. Each controller
module is a sub-network whose output is a decision that controls whether other
modules can execute. A D2NN is trained end to end. Both regular and controller
modules in a D2NN are learnable and are jointly trained to optimize both
accuracy and efficiency. Such training is achieved by integrating
backpropagation with reinforcement learning. With extensive experiments of
various D2NN architectures on image classification tasks, we demonstrate that
D2NNs are general and flexible, and can effectively optimize
accuracy-efficiency trade-offs.


Learning to Detect Human-Object Interactions

  We study the problem of detecting human-object interactions (HOI) in static
images, defined as predicting a human and an object bounding box with an
interaction class label that connects them. HOI detection is a fundamental
problem in computer vision as it provides semantic information about the
interactions among the detected objects. We introduce HICO-DET, a new large
benchmark for HOI detection, by augmenting the current HICO classification
benchmark with instance annotations. To solve the task, we propose Human-Object
Region-based Convolutional Neural Networks (HO-RCNN). At the core of our
HO-RCNN is the Interaction Pattern, a novel DNN input that characterizes the
spatial relations between two bounding boxes. Experiments on HICO-DET
demonstrate that our HO-RCNN, by exploiting human-object spatial relations
through Interaction Patterns, significantly improves the performance of HOI
detection over baseline approaches.


Out-of-plane easy-axis in thin films of diluted magnetic semiconductor
  Ba1-xKx(Zn1-yMny)2As2

  Single-phased, single-oriented thin films of Mn-doped ZnAs-based diluted
magnetic semiconductor (DMS) Ba1-xKx(Zn1-yMny)2As2 (x = 0.03, 0.08; y = 0.15)
have been deposited on Si, SrTiO3, LaAlO3, (La,Sr)(Al,Ta)O3, and MgAl2O4
substrates, respectively. Utilizing a combined synthesis and characterization
system excluding the air and further optimizing the deposition parameters,
high-quality thin films could be obtained and be measured showing that they can
keep inactive-in-air up to more than 90 hours characterized by electrical
transport measurements. In comparison with films of x = 0.03 which possess
relatively higher resistivity, weaker magnetic performances, and larger energy
gap, thin films of x = 0.08 show better electrical and magnetic performances.
Strong magnetic anisotropy was found in films of x = 0.08 grown on
(La,Sr)(Al,Ta)O3 substrate with their magnetic polarization aligned almost
solely on the film growth direction.


Pixels to Graphs by Associative Embedding

  Graphs are a useful abstraction of image content. Not only can graphs
represent details about individual objects in a scene but they can capture the
interactions between pairs of objects. We present a method for training a
convolutional neural network such that it takes in an input image and produces
a full graph definition. This is done end-to-end in a single stage with the use
of associative embeddings. The network learns to simultaneously identify all of
the elements that make up a graph and piece them together. We benchmark on the
Visual Genome dataset, and demonstrate state-of-the-art performance on the
challenging task of scene graph generation.


Scalable Annotation of Fine-Grained Categories Without Experts

  We present a crowdsourcing workflow to collect image annotations for visually
similar synthetic categories without requiring experts. In animals, there is a
direct link between taxonomy and visual similarity: e.g. a collie (type of dog)
looks more similar to other collies (e.g. smooth collie) than a greyhound
(another type of dog). However, in synthetic categories such as cars, objects
with similar taxonomy can have very different appearance: e.g. a 2011 Ford
F-150 Supercrew-HD looks the same as a 2011 Ford F-150 Supercrew-LL but very
different from a 2011 Ford F-150 Supercrew-SVT. We introduce a graph based
crowdsourcing algorithm to automatically group visually indistinguishable
objects together. Using our workflow, we label 712,430 images by ~1,000 Amazon
Mechanical Turk workers; resulting in the largest fine-grained visual dataset
reported to date with 2,657 categories of cars annotated at 1/20th the cost of
hiring experts.


Rethinking the Faster R-CNN Architecture for Temporal Action
  Localization

  We propose TAL-Net, an improved approach to temporal action localization in
video that is inspired by the Faster R-CNN object detection framework. TAL-Net
addresses three key shortcomings of existing approaches: (1) we improve
receptive field alignment using a multi-scale architecture that can accommodate
extreme variation in action durations; (2) we better exploit the temporal
context of actions for both proposal generation and action classification by
appropriately extending receptive fields; and (3) we explicitly consider
multi-stream feature fusion and demonstrate that fusing motion late is
important. We achieve state-of-the-art performance for both action proposal and
localization on THUMOS'14 detection benchmark and competitive performance on
ActivityNet challenge.


Decorrelated Batch Normalization

  Batch Normalization (BN) is capable of accelerating the training of deep
models by centering and scaling activations within mini-batches. In this work,
we propose Decorrelated Batch Normalization (DBN), which not just centers and
scales activations but whitens them. We explore multiple whitening techniques,
and find that PCA whitening causes a problem we call stochastic axis swapping,
which is detrimental to learning. We show that ZCA whitening does not suffer
from this problem, permitting successful learning. DBN retains the desirable
qualities of BN and further improves BN's optimization efficiency and
generalization ability. We design comprehensive experiments to show that DBN
can improve the performance of BN on multilayer perceptrons and convolutional
neural networks. Furthermore, we consistently improve the accuracy of residual
networks on CIFAR-10, CIFAR-100, and ImageNet.


Learning Single-Image Depth from Videos using Quality Assessment
  Networks

  Depth estimation from a single image in the wild remains a challenging
problem. One main obstacle is the lack of high-quality training data for images
in the wild. In this paper we propose a method to automatically generate such
data through Structure-from-Motion (SfM) on Internet videos. The core of this
method is a Quality Assessment Network that identifies high-quality
reconstructions obtained from SfM. Using this method, we collect single-view
depth training data from a large number of YouTube videos and construct a new
dataset called YouTube3D. Experiments show that YouTube3D is useful in training
depth estimation networks and advances the state of the art of single-view
depth estimation in the wild.


SegStereo: Exploiting Semantic Information for Disparity Estimation

  Disparity estimation for binocular stereo images finds a wide range of
applications. Traditional algorithms may fail on featureless regions, which
could be handled by high-level clues such as semantic segments. In this paper,
we suggest that appropriate incorporation of semantic cues can greatly rectify
prediction in commonly-used disparity estimation frameworks. Our method
conducts semantic feature embedding and regularizes semantic cues as the loss
term to improve learning disparity. Our unified model SegStereo employs
semantic features from segmentation and introduces semantic softmax loss, which
helps improve the prediction accuracy of disparity maps. The semantic cues work
well in both unsupervised and supervised manners. SegStereo achieves
state-of-the-art results on KITTI Stereo benchmark and produces decent
prediction on both CityScapes and FlyingThings3D datasets.


Rethinking Numerical Representations for Deep Neural Networks

  With ever-increasing computational demand for deep learning, it is critical
to investigate the implications of the numeric representation and precision of
DNN model weights and activations on computational efficiency. In this work, we
explore unconventional narrow-precision floating-point representations as it
relates to inference accuracy and efficiency to steer the improved design of
future DNN platforms. We show that inference using these custom numeric
representations on production-grade DNNs, including GoogLeNet and VGG, achieves
an average speedup of 7.6x with less than 1% degradation in inference accuracy
relative to a state-of-the-art baseline platform representing the most
sophisticated hardware using single-precision floating point. To facilitate the
use of such customized precision, we also present a novel technique that
drastically reduces the time required to derive the optimal precision
configuration.


You Only Look & Listen Once: Towards Fast and Accurate Visual Grounding

  Visual Grounding (VG) aims to locate the most relevant region in an image,
based on a flexible natural language query but not a pre-defined label, thus it
can be a more useful technique than object detection in practice. Most
state-of-the-art methods in VG operate in a two-stage manner, wherein the first
stage an object detector is adopted to generate a set of object proposals from
the input image and the second stage is simply formulated as a cross-modal
matching problem that finds the best match between the language query and all
region proposals. This is rather inefficient because there might be hundreds of
proposals produced in the first stage that need to be compared in the second
stage, not to mention this strategy performs inaccurately. In this paper, we
propose an simple, intuitive and much more elegant one-stage detection based
method that joints the region proposal and matching stage as a single detection
network. The detection is conditioned on the input query with a stack of novel
Relation-to-Attention modules that transform the image-to-query relationship to
an relation map, which is used to predict the bounding box directly without
proposing large numbers of useless region proposals. During the inference, our
approach is about 20x ~ 30x faster than previous methods and, remarkably, it
achieves 18% ~ 41% absolute performance improvement on top of the
state-of-the-art results on several benchmark datasets. We release our code and
all the pre-trained models at https://github.com/openblack/rvg.


Power-Law Decay of Standing Waves on the Surface of Topological
  Insulators

  We propose a general theory on the standing waves (quasiparticle interference
pattern) caused by the scattering of surface states off step edges in
topological insulators, in which the extremal points on the constant energy
contour of surface band play the dominant role. Experimentally we image the
interference patterns on both Bi$_2$Te$_3$ and Bi$_2$Se$_3$ films by measuring
the local density of states using a scanning tunneling microscope. The observed
decay indices of the standing waves agree excellently with the theoretical
prediction: In Bi$_2$Se$_3$, only a single decay index of -3/2 exists; while in
Bi$_2$Te$_3$ with strongly warped surface band, it varies from -3/2 to -1/2 and
finally to -1 as the energy increases. The -1/2 decay indicates that the
suppression of backscattering due to time-reversal symmetry does not
necessarily lead to a spatial decay rate faster than that in the conventional
two-dimensional electron system. Our formalism can also explain the
characteristic scattering wave vectors of the standing wave caused by
non-magnetic impurities on Bi$_2$Te$_3$.


Interface induced high temperature superconductivity in single unit-cell
  FeSe films on SrTiO3

  Searching for superconducting materials with high transition temperature (TC)
is one of the most exciting and challenging fields in physics and materials
science. Although superconductivity has been discovered for more than 100
years, the copper oxides are so far the only materials with TC above 77 K, the
liquid nitrogen boiling point. Here we report an interface engineering method
for dramatically raising the TC of superconducting films. We find that one
unit-cell (UC) thick films of FeSe grown on SrTiO3 (STO) substrates by
molecular beam epitaxy (MBE) show signatures of superconducting transition
above 50 K by transport measurement. A superconducting gap as large as 20 meV
of the 1 UC films observed by scanning tunneling microcopy (STM) suggests that
the superconductivity could occur above 77 K. The occurrence of
superconductivity is further supported by the presence of superconducting
vortices under magnetic field. Our work not only demonstrates a powerful way
for finding new superconductors and for raising TC, but also provides a
well-defined platform for systematic study of the mechanism of unconventional
superconductivity by using different superconducting materials and substrates.


ImageNet Large Scale Visual Recognition Challenge

  The ImageNet Large Scale Visual Recognition Challenge is a benchmark in
object category classification and detection on hundreds of object categories
and millions of images. The challenge has been run annually from 2010 to
present, attracting participation from more than fifty institutions.
  This paper describes the creation of this benchmark dataset and the advances
in object recognition that have been possible as a result. We discuss the
challenges of collecting large-scale ground truth annotation, highlight key
breakthroughs in categorical object recognition, provide a detailed analysis of
the current state of the field of large-scale image classification and object
detection, and compare the state-of-the-art computer vision accuracy with human
accuracy. We conclude with lessons learned in the five years of the challenge,
and propose future directions and improvements.


Site-wise manipulations and Mott insulator-superfluid transition of
  interacting photons using superconducting circuit simulators

  The Bose Hubbard model (BHM) of interacting bosons in a lattice has been a
paradigm in many-body physics, and it exhibits a Mott insulator (MI)-superfluid
(SF) transition at integer filling. Here a quantum simulator of the BHM using a
superconducting circuit is proposed. Specifically, a superconducting
transmission line resonator supporting microwave photons is coupled to a charge
qubit to form one site of the BHM, and adjacent sites are connected by a
tunable coupler. To obtain a mapping from the superconducting circuit to the
BHM, we focus on the dispersive regime where the excitations remain
photon-like. Standard perturbation theory is implemented to locate the
parameter range where the MI-SF transition may be simulated. This simulator
allows single-site manipulations and we illustrate this feature by considering
two scenarios where a single-site manipulation can drive a MI-SF transition.
The transition can be analyzed by mean-field analyses, and the exact
diagonalization was implemented to provide accurate results. The variance of
the photon density and the fidelity metric clearly show signatures of the
transition. Experimental realizations and other possible applications of this
simulator are also discussed.


Probabilistic Label Relation Graphs with Ising Models

  We consider classification problems in which the label space has structure. A
common example is hierarchical label spaces, corresponding to the case where
one label subsumes another (e.g., animal subsumes dog). But labels can also be
mutually exclusive (e.g., dog vs cat) or unrelated (e.g., furry, carnivore). To
jointly model hierarchy and exclusion relations, the notion of a HEX (hierarchy
and exclusion) graph was introduced in [7]. This combined a conditional random
field (CRF) with a deep neural network (DNN), resulting in state of the art
results when applied to visual object classification problems where the
training labels were drawn from different levels of the ImageNet hierarchy
(e.g., an image might be labeled with the basic level category "dog", rather
than the more specific label "husky"). In this paper, we extend the HEX model
to allow for soft or probabilistic relations between labels, which is useful
when there is uncertainty about the relationship between two labels (e.g., an
antelope is "sort of" furry, but not to the same degree as a grizzly bear). We
call our new model pHEX, for probabilistic HEX. We show that the pHEX graph can
be converted to an Ising model, which allows us to use existing off-the-shelf
inference methods (in contrast to the HEX method, which needed specialized
inference algorithms). Experimental results show significant improvements in a
number of large-scale visual object classification tasks, outperforming the
previous HEX model.


Direct evidences for inner-shell electron-excitation by laser induced
  electron recollision

  Extreme ultraviolet (XUV) attosecond pulses, generated by a process known as
laser-induced electron recollision, are a key ingredient for attosecond
metrology, providing a tool to precisely initiate and probe sub-femtosecond
dynamics in the microcosms of atoms, molecules and solids[1]. However, with the
current technology, extending attosecond metrology to scrutinize the dynamics
of the inner-shell electrons is a challenge, that is because of the lower
efficiency in generating the required soft x-ray \hbar\omega>300 eV attosecond
bursts and the lower absorption cross-sections in this spectral range. A way
around this problem is to use the recolliding electron to directly initiate the
desired inner-shell process, instead of using the currently low flux x-ray
attosecond sources.Such an excitation process occurs in a sub-femtosecond
timescale, and may provide the necessary "pump" step in a pump-probe
experiment[2]. Here we used a few cycle infrared \lambda_{0}~1800nm source[3]
and observed direct evidences for inner-shell excitations through the
laser-induced electron recollision process. It is the first step toward
time-resolved core-hole studies in the keV energy range with sub-femtosecond
time resolution.


Monolayer charge-neutral graphene on platinum with extremely weak
  electron-phonon coupling

  Epitaxial growth of graphene on transition metal substrates is an important
route for obtaining large scale graphene. However, the interaction between
graphene and the substrate often leads to multiple orientations, distorted
graphene band structure, large doping and strong electron-phonon coupling. Here
we report the growth of monolayer graphene with high crystalline quality on
Pt(111) substrate by using a very low concentration of an internal carbon
source with high annealing temperature. The controlled growth leads to
electronically decoupled graphene: it is nearly charge neutral and has
extremely weak electron-phonon coupling (coupling strength $\lambda$ $\approx$
0.056) as revealed by angle-resolved photoemission spectroscopic measurements.
The thermodynamics and kinetics of the carbon diffusion process is investigated
by DFT calculation. Such graphene with negligible graphene-substrate
interaction provides an important platform for fundamental research as well as
device applications when combined with a nondestructive sample transfer
technique.


Chromatic Effect for THz Generation in a Novel Wave-front Tilt Scheme

  Deriving single or few cycle terahertz pulse (THz) by intense femtosecond
laser through cascaded optical rectification in electro-optic crystals is a
crucial technique in cutting-edge time-resolved spectroscopy to characterize
micro-scale structures and ultrafast dynamics. In the past decade, lithium
niobate (LN) crystal implementation of wave-front tilt scheme has been
prevalently used, while painstaking efforts have been invested in order to
achieve higher THz conversion efficiency. In this research we developed a brand
new type of LN crystal possessing dual-face-cut and Brewster coupling, and
conducted experimental and simulative investigation systematically to optimize
the multi-dimensionally entangled parameters in THz generation, predicting the
extreme conversion efficiency of 10% is potentially promising at the THz
absorption coefficient of 0.5cm-1. More remarkably, we first discovered that
the chirp of the driving laser pulse plays a decisive role in the wave-front
tilt scheme, and the THz generation efficiency could be enhanced tremendously
by applying an appropriate chirp.


Highly responsive ground state of PbTaSe$_2$: structural phase
  transition and evolution of superconductivity under pressure

  Transport and magnetic studies of PbTaSe$_2$ under pressure suggest existence
of two superconducting phases with the low temperature phase boundary at $\sim
0.25$ GPa that is defined by a very sharp, first order, phase transition. The
first order phase transition line can be followed via pressure dependent
resistivity measurements, and is found to be near 0.12 GPa near room
temperature. Transmission electron microscopy and x-ray diffraction at elevated
temperatures confirm that this first order phase transition is structural and
occurs at ambient pressure near $\sim 425$ K. The new, high temperature / high
pressure phase has a similar crystal structure and slightly lower unit cell
volume relative to the ambient pressure, room temperature structure. Based on
first-principles calculations this structure is suggested to be obtained by
shifting the Pb atoms from the $1a$ to $1e$ Wyckoff position without changing
the positions of Ta and Se atoms. PbTaSe$_2$ has an exceptionally pressure
sensitive, structural phase transition with $\Delta T_s/\Delta P \approx -
1700$ K/GPa near 4 K, this first order transition causes an $\sim 1$ K ($\sim
25 \%$) step - like decrease in $T_c$ as pressure is increased through 0.25
GPa.


Leveraging local h-index to identify and rank influential spreaders in
  networks

  Identifying influential nodes in complex networks has received increasing
attention for its great theoretical and practical applications in many fields.
Traditional methods, such as degree centrality, betweenness centrality,
closeness centrality, and coreness centrality, have more or less disadvantages
in detecting influential nodes, which have been illustrated in related
literatures. Recently, the h-index, which is utilized to measure both the
productivity and citation impact of the publications of a scientist or scholar,
has been introduced to the network world to evaluate a node's spreading
ability. However, this method assigns too many nodes with the same value, which
leads to a resolution limit problem in distinguishing the real influence of
these nodes. In this paper, we propose a local h-index centrality (LH-index)
method for identifying and ranking influential nodes in networks. The LH-index
method simultaneously takes into account of h-index values of the node itself
and its neighbors, which is based on the idea that a node connects to more
influential nodes will also be influential. According to the simulation results
with the stochastic Susceptible-Infected-Recovered (SIR) model in four real
world networks and several simulated networks, we demonstrate the effectivity
of the LH-index method in identifying influential nodes in networks.


Fine-Grained Car Detection for Visual Census Estimation

  Targeted socioeconomic policies require an accurate understanding of a
country's demographic makeup. To that end, the United States spends more than 1
billion dollars a year gathering census data such as race, gender, education,
occupation and unemployment rates. Compared to the traditional method of
collecting surveys across many years which is costly and labor intensive,
data-driven, machine learning driven approaches are cheaper and faster--with
the potential ability to detect trends in close to real time. In this work, we
leverage the ubiquity of Google Street View images and develop a computer
vision pipeline to predict income, per capita carbon emission, crime rates and
other city attributes from a single source of publicly available visual data.
We first detect cars in 50 million images across 200 of the largest US cities
and train a model to predict demographic attributes using the detected cars. To
facilitate our work, we have collected the largest and most challenging
fine-grained dataset reported to date consisting of over 2600 classes of cars
comprised of images from Google Street View and other web sources, classified
by car experts to account for even the most subtle of visual differences. We
use this data to construct the largest scale fine-grained detection system
reported to date. Our prediction results correlate well with ground truth
income data (r=0.82), Massachusetts department of vehicle registration, and
sources investigating crime rates, income segregation, per capita carbon
emission, and other market research. Finally, we learn interesting
relationships between cars and neighborhoods allowing us to perform the first
large scale sociological analysis of cities using computer vision techniques.


Inferring users' preferences through leveraging their social
  relationships

  Recommender systems, inferring users' preferences from their historical
activities and personal profiles, have been an enormous success in the last
several years. Most of the existing works are based on the similarities of
users, objects or both that derived from their purchases records in the online
shopping platforms. Such approaches, however, are facing bottlenecks when the
known information is limited. The extreme case is how to recommend products to
new users, namely the so-called cold-start problem. The rise of the online
social networks gives us a chance to break the glass ceiling. Birds of a
feather flock together. Close friends may have similar hidden pattern of
selecting products and the advices from friends are more trustworthy.
  In this paper, we integrate the individual's social relationships into
recommender systems and propose a new method, called Social Mass Diffusion
(SMD), based on a mass diffusion process in the combined network of users'
social network and user-item bipartite network. The results show that the SMD
algorithm can achieve higher recommendation accuracy than the Mass Diffusion
(MD) purely on the bipartite network. Especially, the improvement is striking
for small degree users. Moreover, SMD provides a good solution to the
cold-start problem. The recommendation accuracy for new users significantly
higher than that of the conventional popularity-based algorithm. These results
may shed some light on the new designs of better personalized recommender
systems and information services.


