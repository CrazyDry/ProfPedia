Learning Models for Following Natural Language Directions in Unknown  Environments

  Natural language offers an intuitive and flexible means for humans tocommunicate with the robots that we will increasingly work alongside in ourhomes and workplaces. Recent advancements have given rise to robots that areable to interpret natural language manipulation and navigation commands, butthese methods require a prior map of the robot's environment. In this paper, wepropose a novel learning framework that enables robots to successfully follownatural language route directions without any previous knowledge of theenvironment. The algorithm utilizes spatial and semantic information that thehuman conveys through the command to learn a distribution over the metric andsemantic properties of spatially extended environments. Our method uses thisdistribution in place of the latent world model and interprets the naturallanguage instruction as a distribution over the intended behavior. A novelbelief space planner reasons directly over the map and behavior distributionsto solve for a policy using imitation learning. We evaluate our framework on avoice-commandable wheelchair. The results demonstrate that by learning andperforming inference over a latent environment model, the algorithm is able tosuccessfully follow natural language route directions within novel, extendedenvironments.

Inferring Compact Representations for Efficient Natural Language  Understanding of Robot Instructions

  The speed and accuracy with which robots are able to interpret naturallanguage is fundamental to realizing effective human-robot interaction. A greatdeal of attention has been paid to developing models and approximate inferencealgorithms that improve the efficiency of language understanding. However,existing methods still attempt to reason over a representation of theenvironment that is flat and unnecessarily detailed, which limits scalability.An open problem is then to develop methods capable of producing the mostcompact environment model sufficient for accurate and efficient naturallanguage understanding. We propose a model that leverages environment-relatedinformation encoded within instructions to identify the subset of observationsand perceptual classifiers necessary to perceive a succinct,instruction-specific environment representation. The framework uses threeprobabilistic graphical models trained from a corpus of annotated instructionsto infer salient scene semantics, perceptual classifiers, and grounded symbols.Experimental results on two robots operating in different environmentsdemonstrate that by exploiting the content and the structure of theinstructions, our method learns compact environment representations thatsignificantly improve the efficiency of natural language symbol grounding.

Learning Articulated Motion Models from Visual and Lingual Signals

  In order for robots to operate effectively in homes and workplaces, they mustbe able to manipulate the articulated objects common within environments builtfor and by humans. Previous work learns kinematic models that prescribe thismanipulation from visual demonstrations. Lingual signals, such as naturallanguage descriptions and instructions, offer a complementary means ofconveying knowledge of such manipulation models and are suitable to a widerange of interactions (e.g., remote manipulation). In this paper, we present amultimodal learning framework that incorporates both visual and lingualinformation to estimate the structure and parameters that define kinematicmodels of articulated objects. The visual signal takes the form of an RGB-Dimage stream that opportunistically captures object motion in an unpreparedscene. Accompanying natural language descriptions of the motion constitute thelingual signal. We present a probabilistic language model that uses wordembeddings to associate lingual verbs with their corresponding kinematicstructures. By exploiting the complementary nature of the visual and lingualinput, our method infers correct kinematic structures for various multiple-partobjects on which the previous state-of-the-art, visual-only system fails. Weevaluate our multimodal learning framework on a dataset comprised of a varietyof household objects, and demonstrate a 36% improvement in model accuracy overthe vision-only baseline.

Atom chips on direct bonded copper substrates

  We present the use of direct bonded copper (DBC) for the straightforwardfabrication of high power atom chips. Atom chips using DBC have severalbenefits: excellent copper/substrate adhesion, high purity, thick (> 100microns) copper layers, high substrate thermal conductivity, high aspect ratiowires, the potential for rapid (< 8 hr) fabrication, and three dimensional atomchip structures. Two mask options for DBC atom chip fabrication are presented,as well as two methods for etching wire patterns into the copper layer. Thewire aspect ratio that optimizes the magnetic field gradient as a function ofpower dissipation is determined to be 0.84:1 (height:width). The optimal wirethickness as a function of magnetic trapping height is also determined. A testchip, able to support 100 A of current for 2 s without failing, is used todetermine the thermal impedance of the DBC. An assembly using two DBC atomchips to provide magnetic confinement is also shown.

Adjustable microchip ring trap for cold atoms and molecules

  We describe the design and function of a circular magnetic waveguide producedfrom wires on a microchip for atom interferometry using deBroglie waves. Theguide is a two-dimensional magnetic minimum for trapping weak-field seekingstates of atoms or molecules with a magnetic dipole moment. The design consistsof seven circular wires sharing a common radius. We describe the design, thetime-dependent currents of the wires and show that it is possible to form acircular waveguide with adjustable height and gradient while minimizingperturbation resulting from leads or wire crossings. This maximal area geometryis suited for rotation sensing with atom interferometry via the Sagnac effectusing either cold atoms, molecules and Bose-condensed systems.

Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to  Action Sequences

  We propose a neural sequence-to-sequence model for direction following, atask that is essential to realizing effective autonomous agents. Ouralignment-based encoder-decoder model with long short-term memory recurrentneural networks (LSTM-RNN) translates natural language instructions to actionsequences based upon a representation of the observable world state. Weintroduce a multi-level aligner that empowers our model to focus on sentence"regions" salient to the current world state by using multiple abstractions ofthe input sentence. In contrast to existing methods, our model uses nospecialized linguistic resources (e.g., parsers) or task-specific annotations(e.g., seed lexicons). It is therefore generalizable, yet still achieves thebest results reported to-date on a benchmark single-sentence dataset andcompetitive results for the limited-training multi-sentence setting. We analyzeour model through a series of ablations that elucidate the contributions of theprimary components of our model.

What to talk about and how? Selective Generation using LSTMs with  Coarse-to-Fine Alignment

  We propose an end-to-end, domain-independent neural encoder-aligner-decodermodel for selective generation, i.e., the joint task of content selection andsurface realization. Our model first encodes a full set of over-determineddatabase event records via an LSTM-based recurrent neural network, thenutilizes a novel coarse-to-fine aligner to identify the small subset of salientrecords to talk about, and finally employs a decoder to generate free-formdescriptions of the aligned, selected records. Our model achieves the bestselection and generation results reported to-date (with 59% relativeimprovement in generation) on the benchmark WeatherGov dataset, despite usingno specialized features or linguistic resources. Using an improved k-nearestneighbor beam filter helps further. We also perform a series of ablations andvisualizations to elucidate the contributions of our key model components.Lastly, we evaluate the generalizability of our model on the RoboCup dataset,and get results that are competitive with or better than the state-of-the-art,despite being severely data-starved.

Accurate Vision-based Vehicle Localization using Satellite Imagery

  We propose a method for accurately localizing ground vehicles with the aid ofsatellite imagery. Our approach takes a ground image as input, and outputs thelocation from which it was taken on a georeferenced satellite image. We performvisual localization by estimating the co-occurrence probabilities between theground and satellite images based on a ground-satellite feature dictionary. Themethod is able to estimate likelihoods over arbitrary locations without theneed for a dense ground image database. We present a ranking-loss basedalgorithm that learns location-discriminative feature projection matrices thatresult in further improvements in accuracy. We evaluate our method on theMalaga and KITTI public datasets and demonstrate significant improvements overa baseline that performs exhaustive search.

Search for Optical Pulsations in PSR J0337+1715

  We report on a search for optical pulsations from PSR J0337+1715 at itsobserved radio pulse period. PSR J0337+1715 is a millisecond pulsar (2.7 msspin period) in a triple hierarchical system with two white dwarfs, and has aknown optical counterpart with g-band magnitude 18. The observations were donewith the Array Camera for Optical to Near-IR Spectrophotometry (ARCONS) at the200" Hale telescope at Palomar Observatory. No significant pulsations werefound in the range 4000-11000 angstroms, and we can limit pulsed emission ing-band to be fainter than 25 mag.

Navigational Instruction Generation as Inverse Reinforcement Learning  with Neural Machine Translation

  Modern robotics applications that involve human-robot interaction requirerobots to be able to communicate with humans seamlessly and effectively.Natural language provides a flexible and efficient medium through which robotscan exchange information with their human partners. Significant advancementshave been made in developing robots capable of interpreting free-forminstructions, but less attention has been devoted to endowing robots with theability to generate natural language. We propose a navigational guide modelthat enables robots to generate natural language instructions that allow humansto navigate a priori unknown environments. We first decide which information toshare with the user according to their preferences, using a policy trained fromhuman demonstrations via inverse reinforcement learning. We then "translate"this information into a natural language instruction using a neuralsequence-to-sequence model that learns to generate free-form instructions fromnatural language corpora. We evaluate our method on a benchmark routeinstruction dataset and achieve a BLEU score of 72.18% when compared tohuman-generated reference instructions. We additionally conduct navigationexperiments with human participants that demonstrate that our method generatesinstructions that people follow as accurately and easily as those produced byhumans.

Coherent Dialogue with Attention-based Language Models

  We model coherent conversation continuation via RNN-based dialogue modelsequipped with a dynamic attention mechanism. Our attention-RNN language modeldynamically increases the scope of attention on the history as the conversationcontinues, as opposed to standard attention (or alignment) models with a fixedinput scope in a sequence-to-sequence model. This allows each generated word tobe associated with the most relevant words in its corresponding conversationhistory. We evaluate the model on two popular dialogue datasets, theopen-domain MovieTriples dataset and the closed-domain Ubuntu Troubleshootdataset, and achieve significant improvements over the state-of-the-art andbaselines on several metrics, including complementary diversity-based metrics,human evaluation, and qualitative visualizations. We also show that a vanillaRNN with dynamic attention outperforms more complex memory models (e.g., LSTMand GRU) by allowing for flexible, long-distance memory. We promote furthercoherence via topic modeling-based reranking.

Jointly Optimizing Placement and Inference for Beacon-based Localization

  The ability of robots to estimate their location is crucial for a widevariety of autonomous operations. In settings where GPS is unavailable,measurements of transmissions from fixed beacons provide an effective means ofestimating a robot's location as it navigates. The accuracy of such abeacon-based localization system depends both on how beacons are distributed inthe environment, and how the robot's location is inferred based on noisy andpotentially ambiguous measurements. We propose an approach for making thesedesign decisions automatically and without expert supervision, by explicitlysearching for the placement and inference strategies that, together, areoptimal for a given environment. Since this search is computationallyexpensive, our approach encodes beacon placement as a differential neural layerthat interfaces with a neural network for inference. This formulation allows usto employ standard techniques for training neural networks to carry out thejoint optimization. We evaluate this approach on a variety of environments andsettings, and find that it is able to discover designs that enable highlocalization accuracy.

Satellite Image-based Localization via Learned Embeddings

  We propose a vision-based method that localizes a ground vehicle usingpublicly available satellite imagery as the only prior knowledge of theenvironment. Our approach takes as input a sequence of ground-level imagesacquired by the vehicle as it navigates, and outputs an estimate of thevehicle's pose relative to a georeferenced satellite image. We overcome thesignificant viewpoint and appearance variations between the images through aneural multi-view model that learns location-discriminative embeddings in whichground-level images are matched with their corresponding satellite view of thescene. We use this learned function as an observation model in a filteringframework to maintain a distribution over the vehicle's pose. We evaluate ourmethod on different benchmark datasets and demonstrate its ability localizeground-level images in environments novel relative to training, despite thechallenges of significant viewpoint and appearance variations.

Processing Images from the Zwicky Transient Facility

  The Zwicky Transient Facility is a new robotic-observing program, in which anewly engineered 600-MP digital camera with a pioneeringly large field of view,47~square degrees, will be installed into the 48-inch Samuel Oschin Telescopeat the Palomar Observatory. The camera will generate $\sim 1$~petabyte of rawimage data over three years of operations. In parallel related work, newhardware and software systems are being developed to process these data in realtime and build a long-term archive for the processed products. The first publicrelease of archived products is planned for early 2019, which will includeprocessed images and astronomical-source catalogs of the northern sky in the$g$ and $r$ bands. Source catalogs based on two different methods will begenerated for the archive: aperture photometry and point-spread-functionfitting.

Learning Articulated Motions From Visual Demonstration

  Many functional elements of human homes and workplaces consist of rigidcomponents which are connected through one or more sliding or rotatinglinkages. Examples include doors and drawers of cabinets and appliances;laptops; and swivel office chairs. A robotic mobile manipulator would benefitfrom the ability to acquire kinematic models of such objects from observation.This paper describes a method by which a robot can acquire an object model bycapturing depth imagery of the object as a human moves it through its range ofmotion. We envision that in future, a machine newly introduced to anenvironment could be shown by its human user the articulated objects particularto that environment, inferring from these "visual demonstrations" enoughinformation to actuate each object independently of the user.  Our method employs sparse (markerless) feature tracking, motion segmentation,component pose estimation, and articulation learning; it does not require priorobject models. Using the method, a robot can observe an object being exercised,infer a kinematic model incorporating rigid, prismatic and revolute joints,then use the model to predict the object's motion from a novel vantage point.We evaluate the method's performance, and compare it to that of a previouslypublished technique, for a variety of household objects.

Key Science Goals for the Next Generation Very Large Array (ngVLA):  Report from the ngVLA Science Advisory Council

  This document describes some of the fundamental astrophysical problems thatrequire observing capabilities at millimeter- and centimeter wavelengths wellbeyond those of existing, or already planned, telescopes. The resultssummarized in this report follow a solicitation from the National RadioAstronomy Observatory to develop key science cases for a future U. S.-led radiotelescope, the "next generation Very Large Array" (ngVLA). The ngVLA will haveroughly 10 times the collecting area of the Jansky VLA, operate at frequenciesfrom 1 GHz to 116 GHz with up to 20 GHz of bandwidth, possess a compact corefor high surface-brightness sensitivity, and extended baselines of at leasthundreds of kilometers and ultimately across the continent to providehigh-resolution imaging. The ngVLA builds on the scientific and technicallegacy of the Jansky VLA and ALMA, and will be designed to provide the nextleap forward in our understanding of planets, galaxies, and black holes.

Jointly Learning to Construct and Control Agents using Deep  Reinforcement Learning

  The physical design of a robot and the policy that controls its motion areinherently coupled, and should be determined according to the task andenvironment. In an increasing number of applications, data-driven andlearning-based approaches, such as deep reinforcement learning, have proveneffective at designing control policies. For most tasks, the only way toevaluate a physical design with respect to such control policies isempirical--i.e., by picking a design and training a control policy for it.Since training these policies is time-consuming, it is computationallyinfeasible to train separate policies for all possible designs as a means toidentify the best one. In this work, we address this limitation by introducinga method that performs simultaneous joint optimization of the physical designand control network. Our approach maintains a distribution over designs anduses reinforcement learning to optimize a control policy to maximize expectedreward over the design distribution. We give the controller access to designparameters to allow it to tailor its policy to each design in the distribution.Throughout training, we shift the distribution towards higher-performingdesigns, eventually converging to a design and control policy that are jointlyoptimal. We evaluate our approach in the context of legged locomotion, anddemonstrate that it discovers novel designs and walking gaits, outperformingbaselines in both performance and efficiency.

The AI Driving Olympics at NeurIPS 2018

  Despite recent breakthroughs, the ability of deep learning and reinforcementlearning to outperform traditional approaches to control physically embodiedrobotic agents remains largely unproven. To help bridge this gap, we createdthe 'AI Driving Olympics' (AI-DO), a competition with the objective ofevaluating the state of the art in machine learning and artificial intelligencefor mobile robotics. Based on the simple and well specified autonomous drivingand navigation environment called 'Duckietown', AI-DO includes a series oftasks of increasing complexity -- from simple lane-following to fleetmanagement. For each task, we provide tools for competitors to use in the formof simulators, logs, code templates, baseline implementations and low-costaccess to robotic hardware. We evaluate submissions in simulation online, onstandardized hardware environments, and finally at the competition event. Thefirst AI-DO, AI-DO 1, occurred at the Neural Information Processing Systems(NeurIPS) conference in December 2018. The results of AI-DO 1 highlight theneed for better benchmarks, which are lacking in robotics, as well as improvedmechanisms to bridge the gap between simulation and reality.

The case for a 'sub-millimeter SDSS': a 3D map of galaxy evolution to  z~10

  The Sloan Digital Sky Survey (SDSS) was revolutionary because of theextraordinary breadth and ambition of its optical imaging and spectroscopy. Weargue that a 'sub-millimeter SDSS' - a sensitive large-areaimaging+spectroscopic survey in the sub-mm window - will revolutionize ourunderstanding of galaxy evolution in the early Universe. By detecting thethermal dust continuum emission and atomic and molecular line emission ofgalaxies out to z~10 it will be possible to measure the redshifts, starformation rates, dust and gas content of hundreds of thousands of high-zgalaxies down to ~L*. Many of these galaxies will have counterparts visible inthe deep optical imaging of the Large Synoptic Survey Telescope. This 3D map ofgalaxy evolution will span the peak epoch of galaxy formation all the way backto cosmic dawn, measuring the co-evolution of the star formation rate densityand molecular gas content of galaxies, tracking the production of metals andcharting the growth of large-scale structure.

The LUVOIR Ultraviolet Multi-Object Spectrograph (LUMOS): Instrument  Definition and Design

  The Large Ultraviolet / Optical / Infrared Surveyor (LUVOIR) is one of fourlarge mission concepts currently undergoing community study for considerationby the 2020 Astronomy and Astrophysics Decadal Survey. The LUVOIR UltravioletMulti-Object Spectrograph, LUMOS, is being designed to support all of the UVscience requirements of LUVOIR, from exoplanet host star characterization totomography of circumgalactic halos to water plumes on outer solar systemsatellites. LUMOS offers point source and multi-object spectroscopy across theUV bandpass, with multiple resolution modes to support different science goals.The instrument will provide low (R = 8,000-18,000) and medium (R =30,000-65,000) resolution modes across the far-ultraviolet (FUV: 100-200 nm)and near-ultraviolet (NUV: 200-400 nm) windows, and a very low resolution mode(R = 500) for spectroscopic investigations of extremely faint objects in theFUV. Imaging spectroscopy will be accomplished over a 3 x 1.6 arcminutefield-of-view by employing holographically-ruled diffraction gratings tocontrol optical aberrations, microshutter arrays (MSA), advanced opticalcoatings for high-throughput in the FUV, and next generation large-formatphoton-counting detectors. The spectroscopic capabilities of LUMOS areaugmented by an FUV imaging channel (100-200nm, 13 milliarcsecond angularresolution, 2 x 2 arcminute field-of-view) that will employ a complement ofnarrow and medium-band filters. We present an overview of LUMOS' observingmodes and estimated performance curves for effective area, spectral resolution,and imaging performance. Example "LUMOS 100-hour Highlights" observing programsare presented to demonstrate the potential power of LUVOIR's ultravioletspectroscopic capabilities.

Instrumentation for the Citizen CATE Experiment: Faroe Islands and  Indonesia

  The inner regions of the solar corona from 1-2.5 Rsun are poorly sampled bothfrom the ground and space telescopes. A solar eclipse reduces the sky scatteredbackground intensity by a factor of about 10,000 and opens a window to viewthis region directly. The goal of the Citizen {\it Continental-AmericaTelescopic Eclipse} (CATE) Experiment is to take a 90-minute time sequence ofcalibrated white light images of this coronal region using 60 identicaltelescopes spread from Oregon to South Carolina during the 21 August 2017 totalsolar eclipse. Observations that can address questions of coronal dynamics inthis region can be collected with rather modest telescope equipment, but thelarge dynamic range of the coronal brightness requires careful camera control.The instruments used for test runs on the Faroe Islands in 2015 and at fivesites in Indonesia in 2016 are described. Intensity calibration of the coronalimages is done and compared with previous eclipse measurements from November \&Koutchmy (1996) and Bazin et al. (2015). The change of coronal brightness withdistance from the Sun seen in the 2016 eclipse agrees with observations fromthe 1991 eclipse but differ substantially from the 2010 eclipse. The 2015observations agree with 2016 and 1991 solar radii near the Sun, but are fainterat larger distances. Problems encountered during these test runs are discussedas well the solutions which will be implemented for the 2017 eclipseexperiment.

The Zwicky Transient Facility: Data Processing, Products, and Archive

  The Zwicky Transient Facility (ZTF) is a new robotic time-domain surveycurrently in progress using the Palomar 48-inch Schmidt Telescope. ZTF uses a47 square degree field with a 600 megapixel camera to scan the entire northernvisible sky at rates of ~3760 square degrees/hour to median depths of g ~ 20.8and r ~ 20.6 mag (AB, 5sigma in 30 sec). We describe the Science Data Systemthat is housed at IPAC, Caltech. This comprises the data-processing pipelines,alert production system, data archive, and user interfaces for accessing andanalyzing the products. The realtime pipeline employs a novelimage-differencing algorithm, optimized for the detection of point sourcetransient events. These events are vetted for reliability using amachine-learned classifier and combined with contextual information to generatedata-rich alert packets. The packets become available for distributiontypically within 13 minutes (95th percentile) of observation. Detected eventsare also linked to generate candidate moving-object tracks using a novelalgorithm. Objects that move fast enough to streak in the individual exposuresare also extracted and vetted. The reconstructed astrometric accuracy perscience image with respect to Gaia is typically 45 to 85 milliarcsec. This isthe RMS per axis on the sky for sources extracted with photometric S/N >= 10.The derived photometric precision (repeatability) at bright unsaturated fluxesvaries between 8 and 25 millimag. Photometric calibration accuracy with respectto Pan-STARRS1 is generally better than 2%. The products support a broad rangeof scientific applications: fast and young supernovae, rare flux transients,variable stars, eclipsing binaries, variability from active galactic nuclei,counterparts to gravitational wave sources, a more complete census of Type Iasupernovae, and Solar System objects.

Excess Optical Enhancement Observed with ARCONS for Early Crab Giant  Pulses

  We observe an extraordinary link in the Crab pulsar between the enhancementof an optical pulse and the timing of the corresponding giant radio pulse. Atoptical through infrared wavelengths, our observations use the high timeresolution of ARCONS, a unique superconducting energy-resolving photon-countingarray at the Palomar 200-inch telescope. At radio wavelengths, we observe withthe Robert C. Byrd Green Bank Telescope and the GUPPI backend. We see an$11.3\pm2.5\%$ increase in peak optical flux for pulses that have anaccompanying giant radio pulse arriving near the peak of the optical mainpulse, in contrast to a $3.2\pm0.5\%$ increase when an accompanying giant radiopulse arrives soon after the optical peak. We also observe that the peak of theoptical main pulse is $2.8\pm0.8\%$ enhanced when there is a giant radio pulseaccompanying the optical interpulse. We observe no statistically significantspectral differences between optical pulses accompanied by and not accompaniedby giant radio pulses. Our results extend previous observations ofoptical-radio correlation to the time and spectral domains. Our refinedtemporal correlation suggests that optical and radio emission are indeedcausally linked, and the lack of spectral differences suggests that the samemechanism is responsible for all optical emission.

A Brief Technical History of the Large-Area Picosecond Photodetector  (LAPPD) Collaboration

  The Large Area Picosecond PhotoDetector (LAPPD) Collaboration was formed in2009 to develop large-area photodetectors capable of time resolutions measuredin pico-seconds, with accompanying sub-millimeter spatial resolution. Duringthe next three and one-half years the Collaboration developed the LAPPD designof 20 x 20 cm modules with gains greater than $10^7$ and non-uniformity lessthan $15\%$, time resolution less than 50 psec for single photons and spatialresolution of 700~microns in both lateral dimensions. We describe the R\&Dperformed to develop large-area micro-channel plate glass substrates, resistiveand secondary-emitting coatings, large-area bialkali photocathodes, andRF-capable hermetic packaging. In addition, the Collaboration developed thenecessary electronics for large systems capable of precise timing, built upfrom a custom low-power 15-GigaSample/sec waveform sampling 6-channelintegrated circuit and supported by a two-level modular data acquisition systembased on Field-Programmable Gate Arrays for local control, data-sparcification,and triggering. We discuss the formation, organization, and technical successesand short-comings of the Collaboration. The Collaboration ended in December2012 with a transition from R\&D to commercialization.

2900 square degree search for the optical counterpart of short gamma-ray  burst GRB 180523B with the Zwicky Transient Facility

  There is significant interest in the models for production of short gamma-raybursts. Until now, the number of known short gamma-ray bursts withmulti-wavelength afterglows has been small. While the {\it Fermi} Gamma-RayBurst Monitor detects many gamma-ray bursts relative to the Neil Gehrels {\itSwift} Observatory, the large localization regions makes the search forcounterparts difficult. With the Zwicky Transient Facility recently achievingfirst light, it is now fruitful to use its combination of depth ($m_\textrm{AB}\sim 20.6$), field of view ($\approx$ 47 square degrees), and survey cadence(every $\sim 3$ days) to perform Target of Opportunity observations. Wedemonstrate this capability on GRB 180523B, which was recently announced by the{\it Fermi} Gamma-Ray Burst Monitor as a short gamma-ray burst. ZTF imaged$\approx$ 2900\,square degrees of the localization region, resulting in thecoverage of 61.6\,\% of the enclosed probability over 2 nights to a depth of$m_\textrm{AB} \sim 20.5$. We characterized 14 previously unidentifiedtransients, and none were found to be consistent with a short gamma-ray burstcounterpart. This search with the Zwicky Transient Facility shows it is anefficient camera for searching for coarsely-localized short gamma-ray burst andgravitational-wave counterparts, allowing for a sensitive search with minimalinterruption to its nominal cadence.

Key $^{19}$Ne states identified affecting $γ$-ray emission from  $^{18}$F in novae

  Detection of nuclear-decay $\gamma$ rays provides a sensitive thermometer ofnova nucleosynthesis. The most intense $\gamma$-ray flux is thought to beannihilation radiation from the $\beta^+$ decay of $^{18}$F, which is destroyedprior to decay by the $^{18}$F($p$,$\alpha$)$^{15}$O reaction. Estimates of$^{18}$F production had been uncertain, however, because key near-thresholdlevels in the compound nucleus, $^{19}$Ne, had yet to be identified. ThisLetter reports the first measurement of the$^{19}$F($^{3}$He,$t\gamma$)$^{19}$Ne reaction, in which the placement of twolong-sought 3/2$^+$ levels is suggested via triton-$\gamma$-$\gamma$coincidences. The precise determination of their resonance energies reduces theupper limit of the rate by a factor of $1.5-17$ at nova temperatures andreduces the average uncertainty on the nova detection probability by a factorof 2.1.

New $γ$-ray Transitions Observed in $^{19}$Ne with Implications for  the $^{15}$O($α$,$γ$)$^{19}$Ne Reaction Rate

  The $^{15}$O($\alpha$,$\gamma$)$^{19}$Ne reaction is responsible for breakoutfrom the hot CNO cycle in Type I x-ray bursts. Understanding the properties ofresonances between $E_x = 4$ and 5 MeV in $^{19}$Ne is crucial in thecalculation of this reaction rate. The spins and parities of these states arewell known, with the exception of the 4.14- and 4.20-MeV states, which haveadopted spin-parities of 9/2$^-$ and 7/2$^-$, respectively. Gamma-raytransitions from these states were studied using triton-$\gamma$-$\gamma$coincidences from the $^{19}$F($^{3}$He,$t\gamma$)$^{19}$Ne reaction measuredwith GODDESS (Gammasphere ORRUBA Dual Detectors for Experimental StructureStudies) at Argonne National Laboratory. The observed transitions from the4.14- and 4.20-MeV states provide strong evidence that the $J^\pi$ values areactually 7/2$^-$ and 9/2$^-$, respectively. These assignments are consistentwith the values in the $^{19}$F mirror nucleus and in contrast to previouslyaccepted assignments.

The Zwicky Transient Facility: Science Objectives

  The Zwicky Transient Facility (ZTF), a public-private enterprise, is a newtime domain survey employing a dedicated camera on the Palomar 48-inch Schmidttelescope with a 47 deg$^2$ field of view and 8 second readout time. It is wellpositioned in the development of time domain astronomy, offering operations at10% of the scale and style of the Large Synoptic Survey Telescope (LSST) with asingle 1-m class survey telescope. The public surveys will cover the observablenorthern sky every three nights in g and r filters and the visible Galacticplane every night in g and r. Alerts generated by these surveys are sent inreal time to brokers. A consortium of universities which provided funding("partnership") are undertaking several boutique surveys. The combination ofthese surveys producing one million alerts per night allows for exploration oftransient and variable astrophysical phenomena brighter than r $\sim$ 20.5 ontimescales of minutes to years. We describe the primary science objectivesdriving ZTF including the physics of supernovae and relativistic explosions,multi-messenger astrophysics, supernova cosmology, active galactic nuclei andtidal disruption events, stellar variability, and Solar System objects.

Machine Learning for Large-Scale Quality Control of 3D Shape Models in  Neuroimaging

  As very large studies of complex neuroimaging phenotypes become more common,human quality assessment of MRI-derived data remains one of the last majorbottlenecks. Few attempts have so far been made to address this issue withmachine learning. In this work, we optimize predictive models of quality formeshes representing deep brain structure shapes. We use standard vertex-wiseand global shape features computed homologously across 19 cohorts and over 7500human-rated subjects, training kernelized Support Vector Machine and GradientBoosted Decision Trees classifiers to detect meshes of failing quality. Ourmodels generalize across datasets and diseases, reducing human workload by30-70\%, or equivalently hundreds of human rater hours for datasets ofcomparable size, with recall rates approaching inter-rater reliability.

Deep Learning for Quality Control of Subcortical Brain 3D Shape Models

  We present several deep learning models for assessing the morphometricfidelity of deep grey matter region models extracted from brain MRI. We testthree different convolutional neural net architectures (VGGNet, ResNet andInception) over 2D maps of geometric features. Further, we present a novelgeometry feature augmentation technique based on a parametric sphericalmapping. Finally, we present an approach for model decision visualization,allowing human raters to see the areas of subcortical shapes most likely to bedeemed of failing quality by the machine. Our training data is comprised of5200 subjects from the ENIGMA Schizophrenia MRI cohorts, and our test datasetcontains 1500 subjects from the ENIGMA Major Depressive Disorder cohorts. Ourfinal models reduce human rater time by 46-70%. ResNet outperforms VGGNet andInception for all of our predictive tasks.

Polarimetric Observations of 15 Active Galactic Nuclei at High  Frequencies: Jet Kinematics from Bimonthly Monitoring with the Very Long  Baseline Array

  We present total and polarized intensity images of 15 active galactic nucleiobtained with the Very Long Baseline Array at 7 mm at 17 epochs from 1998 Marchto 2001 April. At some epochs the images are accompanied by nearly simultaneouspolarization measurements at 3 mm, 1.35/0.85 mm, and optical wavelengths. Herewe analyze the 7 mm images to define the properties of the jets of two radiogalaxies, five BL Lac objects, and eight quasars on angular scales $\gtrsim0.1$ milliarcseconds. We determine the apparent velocities of 106 features inthe jets; for many of the features we derive Doppler factors using a new methodbased on comparison of timescale of decline in flux density with thelight-travel time across the emitting region. This allows us to estimate theLorentz factors, intrinsic brightness temperatures, and viewing angles of 73superluminal knots, as well as the opening angle of the jet for each source. Weanalyze the derived physical parameters of the jets. In nine sources we detectstatistically meaningful deviations from ballistic motion, with the majority ofcomponents accelerating with distance from the core. In six sources we identifyjet features with characteristics of trailing shocks that form behind theprimary strong perturbations in jet simulations. The apparent speeds of thesecomponents increase with distance from the core suggesting an acceleration ofthe underlying jet.

Multiwaveband Polarimetric Observations of 15 Active Galactic Nuclei at  High Frequencies: Correlated Polarization Behavior

  We report on multi-frequency linear polarization monitoring of 15 activegalactic nuclei containing highly relativistic jets with apparent speeds from$\sim$4 $c$ to $>40c$. The measurements were obtained at optical, 1 mm, and 3mm wavelengths, and at 7 mm with the Very Long Baseline Array. The data show awide range in degree of linear polarization among the sources, from $<$1% to$>$30%, and interday polarization variability in individual sources. Thepolarization properties suggest separation of the sample into three groups withlow, intermediate, and high variability of polarization in the core at 7 mm :LVP, IVP, and HVP, respectively. The groups are partially associated with thecommon classification of active galactic nuclei as radio galaxies and quasarswith low optical polarization (LVP), BL Lacertae objects (IVP), and highlyoptically polarized quasars (HVP). Our study investigates correlations betweentotal flux, fractional polarization, and polarization position angle at thedifferent wavelengths. We interpret the polarization properties of the sourcesin the sample through models in which weak shocks compress turbulent plasma inthe jet. The differences in the orientation of sources with respect to theobserver, jet kinematics, and abundance of thermal matter external to the jetnear the core can account for the diversity in the polarization properties. Theresults provide strong evidence that the optical polarized emission originatesin shocks, most likely situated between the 3 mm and 7 mm VLBI cores. They alsosupport the idea that the 1 mm core lies at the edge of the transition zonebetween electromagnetically dominated and turbulent hydrodynamical sections ofthe jet.

The Pluto Energetic Particle Spectrometer Science Investigation (PEPSSI)  on the New Horizons Mission

  The Pluto Energetic Particle Spectrometer Science Investigation (PEPSSI)comprises the hardware and accompanying science investigation on the NewHorizons spacecraft to measure pick-up ions from Pluto's outgassing atmosphere.To the extent that Pluto retains its characteristics similar to those of a"heavy comet" as detected in stellar occultations since the early 1980s, thesemeasurements will characterize the neutral atmosphere of Pluto while providinga consistency check on the atmospheric escape rate at the encounter epoch withthat deduced from the atmospheric structure at lower altitudes by the ALICE,REX, and SWAP experiments on New Horizons. In addition, PEPSSI willcharacterize any extended ionosphere and solar wind interaction while alsocharacterizing the energetic particle environment of Pluto, Charon, and theirassociated system. First proposed for development for the Pluto Express missionin September 1993, what became the PEPSSI instrument went through a number ofdevelopment stages to meet the requirements of such an instrument for a missionto Pluto while minimizing the required spacecraft resources. The PEPSSIinstrument provides for measurements of ions (with compositional information)and electrons from 10s of keV to ~1 MeV in a 120 deg x 12 deg fan-shaped beamin six sectors for 1.5 kg and ~2.5 W.

Herschel Exploitation of Local Galaxy Andromeda (HELGA) III: The Star  Formation Law in M31

  We present a detailed study of how the Star Formation Rate (SFR) relates tothe interstellar medium (ISM) of M31 at ~140pc scales. The SFR is calculatedusing the far-ultraviolet and 24um emission, corrected for the old stellarpopulation in M31. We find a global value for the SFR of 0.25+/-0.05Msun/yr andcompare this with the SFR found using the total far-infrared (FIR) luminosity.There is general agreement in regions where young stars dominate the dustheating. Atomic hydrogen (HI) and molecular gas (traced by carbon monoxide, CO)or the dust mass is used to trace the total gas in the ISM. We show that theglobal surface densities of SFR and gas mass place M31 amongst a set of low-SFRgalaxies in the plot of Kennicutt (1998b). The relationship between SFR and gassurface density is tested in six radial annuli across M31, assuming a power lawrelationship with index, N. The star formation law using total gas traced by HIand CO gives a global index of N=2.03+/-0.04, with a significant variation withradius; the highest values are observed in the 10kpc ring. We suggest that thisslope is due to HI turning molecular at ~10Msun/pc2. When looking at H2regions, we measure a higher mean SFR suggesting a better spatial correlationbetween H2 and SF. We find N~0.6 with consistent results throughout the disk -this is at the low end of values found in previous work and argues against asuperlinear SF law on small scales.

The Atacama Cosmology Telescope: Cross Correlation with Planck maps

  We present the temperature power spectrum of the Cosmic Microwave Backgroundobtained by cross-correlating maps from the Atacama Cosmology Telescope (ACT)at 148 and 218 GHz with maps from the Planck satellite at 143 and 217 GHz, intwo overlapping regions covering 592 square degrees. We find excellentagreement between the two datasets at both frequencies, quantified using thevariance of the residuals between the ACT power spectra and the ACTxPlanckcross-spectra. We use these cross-correlations to calibrate the ACT data at 148and 218 GHz, to 0.7% and 2% precision respectively. We find no evidence foranisotropy in the calibration parameter. We compare the Planck 353 GHz powerspectrum with the measured amplitudes of dust and cosmic infrared background(CIB) of ACT data at 148 and 218 GHz. We also compare planet and point sourcemeasurements from the two experiments.

Science with an ngVLA: The ngVLA Science Case and Associated Science  Requirements

  The science case and associated science requirements for a next-generationVery Large Array (ngVLA) are described, highlighting the five key science goalsdeveloped out of a community-driven vision of the highest scientific prioritiesin the next decade. Building on the superb cm observing conditions and existinginfrastructure of the VLA site in the U.S. Southwest, the ngVLA is envisaged tobe an interferometric array with more than 10 times the sensitivity and spatialresolution of the current VLA and ALMA, operating at frequencies spanning$\sim1.2 - 116$\,GHz with extended baselines reaching across North America. ThengVLA will be optimized for observations at wavelengths between the exquisiteperformance of ALMA at submm wavelengths, and the future SKA-1 at decimeter tometer wavelengths, thus lending itself to be highly complementary with thesefacilities. The ngVLA will be the only facility in the world that can tackle abroad range of outstanding scientific questions in modern astronomy bysimultaneously delivering the capability to: (1) unveil the formation of SolarSystem analogues; (2) probe the initial conditions for planetary systems andlife with astrochemistry; (3) characterize the assembly, structure, andevolution of galaxies from the first billion years to the present; (4) usepulsars in the Galactic center as fundamental tests of gravity; and (5)understand the formation and evolution of stellar and supermassive blackholesin the era of multi-messenger astronomy.

BLAST: the far-infrared/radio correlation in distant galaxies

  We investigate the correlation between far-infrared (FIR) and radioluminosities in distant galaxies, a lynchpin of modern astronomy. We use datafrom the Balloon-borne Large Aperture Submillimetre Telescope (BLAST), Spitzer,the Large Apex BOlometer CamerA (LABOCA), the Very Large Array (VLA) and theGiant Metre-wave Radio Telescope (GMRT) in the Extended Chandra Deep FieldSouth (ECDFS). For a catalogue of BLAST 250-micron-selected galaxies, were-measure the 70--870-micron flux densities at the positions of their mostlikely 24-micron counterparts, which have a median [interquartile] redshift of0.74 [0.25, 1.57]. From these, we determine the monochromatic flux densityratio, q_250 = log_10 (S_250micron / S_1400MHz), and the bolometric equivalent,q_IR. At z ~= 0.6, where our 250-micron filter probes rest-frame 160-micronemission, we find no evolution relative to q_160 for local galaxies. We alsostack the FIR and submm images at the positions of 24-micron- andradio-selected galaxies. The difference between q_IR seen for 250-micron- andradio-selected galaxies suggests star formation provides most of the IRluminosity in ~< 100-uJy radio galaxies, but rather less for those in the mJyregime. For the 24-micron sample, the radio spectral index is constant across 0< z < 3, but q_IR exhibits tentative evidence of a steady decline such thatq_IR is proportional to (1+z)^(-0.15 +/- 0.03) - significant evolution,spanning the epoch of galaxy formation, with major implications for techniquesthat rely on the FIR/radio correlation. We compare with model predictions andspeculate that we may be seeing the increase in radio activity that gives riseto the radio background.

Learning from FITS: Limitations in use in modern astronomical research

  The Flexible Image Transport System (FITS) standard has been a great boon toastronomy, allowing observatories, scientists and the public to exchangeastronomical information easily. The FITS standard, however, is showing itsage. Developed in the late 1970s, the FITS authors made a number ofimplementation choices that, while common at the time, are now seen to limitits utility with modern data. The authors of the FITS standard could notanticipate the challenges which we are facing today in astronomical computing.Difficulties we now face include, but are not limited to, addressing the needto handle an expanded range of specialized data product types (data models),being more conducive to the networked exchange and storage of data, handlingvery large datasets, and capturing significantly more complex metadata and datarelationships.  There are members of the community today who find some or all of theselimitations unworkable, and have decided to move ahead with storing data inother formats. If this fragmentation continues, we risk abandoning theadvantages of broad interoperability, and ready archivability, that the FITSformat provides for astronomy. In this paper we detail some selected importantproblems which exist within the FITS standard today. These problems may provideinsight into deeper underlying issues which reside in the format and we providea discussion of some lessons learned. It is not our intention here to prescribespecific remedies to these issues; rather, it is to call attention of the FITSand greater astronomical computing communities to these problems in the hopethat it will spur action to address them.

US Cosmic Visions: New Ideas in Dark Matter 2017: Community Report

  This white paper summarizes the workshop "U.S. Cosmic Visions: New Ideas inDark Matter" held at University of Maryland on March 23-25, 2017.

The Time Domain Spectroscopic Survey: Variable Object Selection and  Anticipated Results

  We present the selection algorithm and anticipated results for the TimeDomain Spectroscopic Survey (TDSS). TDSS is an SDSS-IV eBOSS subproject thatwill provide initial identification spectra of approximately 220,000luminosity-variable objects (variable stars and AGN) across 7,500 squaredegrees selected from a combination of SDSS and multi-epoch Pan-STARRS1photometry. TDSS will be the largest spectroscopic survey to explicitly targetvariable objects, avoiding pre-selection on the basis of colors or detailedmodeling of specific variability characteristics. Kernel Density Estimate (KDE)analysis of our target population performed on SDSS Stripe 82 data suggests ourtarget sample will be 95% pure (meaning 95% of objects we select have genuineluminosity variability of a few magnitudes or more). Our final spectroscopicsample will contain roughly 135,000 quasars and 85,000 stellar variables,approximately 4,000 of which will be RR Lyrae stars which may be used as outerMilky Way probes. The variability-selected quasar population has a smootherredshift distribution than a color-selected sample, and variabilitymeasurements similar to those we develop here may be used to make more uniformquasar samples in large surveys. The stellar variable targets are distributedfairly uniformly across color space, indicating that TDSS will obtain spectrafor a wide variety of stellar variables including pulsating variables, starswith significant chromospheric activity, cataclysmic variables and eclipsingbinaries. TDSS will serve as a pathfinder mission to identify and characterizethe multitude of variable objects that will be detected photometrically in evenlarger variability surveys such as LSST.

Determining the neutrino mass with Cyclotron Radiation Emission  Spectroscopy - Project 8

  The most sensitive direct method to establish the absolute neutrino mass isobservation of the endpoint of the tritium beta-decay spectrum. CyclotronRadiation Emission Spectroscopy (CRES) is a precision spectrographic techniquethat can probe much of the unexplored neutrino mass range with$\mathcal{O}({\rm eV})$ resolution. A lower bound of $m(\nu_e) \gtrsim 9(0.1)\,{\rm meV}$ is set by observations of neutrino oscillations, while the KATRINExperiment - the current-generation tritium beta-decay experiment that is basedon Magnetic Adiabatic Collimation with an Electrostatic (MAC-E) filter - willachieve a sensitivity of $m(\nu_e) \lesssim 0.2\,{\rm eV}$. The CRES techniqueaims to avoid the difficulties in scaling up a MAC-E filter-based experiment toachieve a lower mass sensitivity. In this paper we review the current status ofthe CRES technique and describe Project 8, a phased absolute neutrino massexperiment that has the potential to reach sensitivities down to $m(\nu_e)\lesssim 40\,{\rm meV}$ using an atomic tritium source.

The Zwicky Transient Facility: System Overview, Performance, and First  Results

  The Zwicky Transient Facility (ZTF) is a new optical time-domain survey thatuses the Palomar 48-inch Schmidt telescope. A custom-built wide-field cameraprovides a 47 deg$^2$ field of view and 8 second readout time, yielding morethan an order of magnitude improvement in survey speed relative to itspredecessor survey, the Palomar Transient Factory (PTF). We describe the designand implementation of the camera and observing system. The ZTF data system atthe Infrared Processing and Analysis Center provides near-real-time reductionto identify moving and varying objects. We outline the analysis pipelines, dataproducts, and associated archive. Finally, we present on-sky performanceanalysis and first scientific results from commissioning and the early survey.ZTF's public alert stream will serve as a useful precursor for that of theLarge Synoptic Survey Telescope.

A joint analysis of BLAST 250--500um and LABOCA 870um observations in  the Extended Chandra Deep Field South

  We present a joint analysis of the overlapping BLAST 250, 350, 500um, andLABOCA 870um observations (from the LESS survey) of the ECDF-S. Out to z~3, theBLAST filters sample near the peak wavelength of far-infrared (FIR) emissionfrom galaxies (rest-frame wavelengths ~60--200um), primarily produced by dustheated through absorption in star-forming clouds. However, identifyingcounterparts to individual BLAST peaks is very challenging, given the largebeams (FWHM 36--60"). In contrast, the 870um observations have a significantlysmaller 19" FWHM beam, and are sensitive to higher redshifts (z~1--5, andpotentially beyond) due to the more favourable negative K-correction. We usethe LESS data, as well as deep Spitzer and VLA imaging, to identify 118individual sources that produce significant emission in the BLAST bands. Wecharacterize the temperatures and FIR luminosities for a subset of 69 sourceswhich have well-measured submm SEDs and redshift measurements out to z~3. Forflux-limited sub-samples in each BLAST band, and a dust emissivity index\beta=2.0, we find a median temperature T=30K (all bands) as well as medianredshifts: z=1.1 (interquartile range 0.2--1.9) for S250 > 40mJy; z=1.3(interquartile range 0.6--2.1) for S350 > 30mJy; and z=1.6 (interquartile range1.3--2.3) for S500 > 20mJy. Taking into account selection effects for oursurvey (a bias toward detecting lower-temperature galaxies), we find noevidence for evolution in the local FIR-temperature correlation out to z~2.5.Comparing with star-forming galaxy SED templates, about 8% of our sampleappears to exhibit significant excesses in the radio and/or mid-IR, consistentwith those sources harbouring an AGN. We describe the following techniques intwo appendices: our `matched filter' for identifying sources in the presence ofpoint-source confusion; and our approach for identifying counterparts usinglikelihood ratios.

High-Angular-Resolution and High-Sensitivity Science Enabled by  Beamformed ALMA

  An international consortium is presently constructing a beamformer for theAtacama Large Millimeter/submillimeter Array (ALMA) in Chile that will beavailable as a facility instrument. The beamformer will aggregate the entirecollecting area of the array into a single, very large aperture. Theextraordinary sensitivity of phased ALMA, combined with the extremely fineangular resolution available on baselines to the Northern Hemisphere, willenable transformational new very long baseline interferometry (VLBI)observations in Bands 6 and 7 (1.3 and 0.8 mm) and provide substantialimprovements to existing VLBI arrays in Bands 1 and 3 (7 and 3 mm). The ALMAbeamformer will have impact on a variety of scientific topics, includingaccretion and outflow processes around black holes in active galactic nuclei(AGN), tests of general relativity near black holes, jet launch and collimationfrom AGN and microquasars, pulsar and magnetar emission processes, the chemicalhistory of the universe and the evolution of fundamental constants acrosscosmic time, maser science, and astrometry.

Characterizing K2 Planet Discoveries: A super-Earth transiting the  bright K-dwarf HIP 116454

  We report the first planet discovery from the two-wheeled Kepler (K2)mission: HIP 116454 b. The host star HIP 116454 is a bright (V = 10.1, K = 8.0)K1-dwarf with high proper motion, and a parallax-based distance of 55.2 +/- 5.4pc. Based on high-resolution optical spectroscopy, we find that the host staris metal-poor with [Fe/H] = -.16 +/- .18, and has a radius R = 0.716 +/- .0024R_sun and mass M = .775 +/- .027 Msun. The star was observed by the Keplerspacecraft during its Two-Wheeled Concept Engineering Test in February 2014.During the 9 days of observations, K2 observed a single transit event. Using anew K2 photometric analysis technique we are able to correct small telescopedrifts and recover the observed transit at high confidence, corresponding to aplanetary radius of Rp = 2.53 +/- 0.18 Rearth. Radial velocity observationswith the HARPS-N spectrograph reveal a 11.82 +/- 1.33 Mearth planet in a 9.1day orbit, consistent with the transit depth, duration, and ephemeris.Follow-up photometric measurements from the MOST satellite confirm the transitobserved in the K2 photometry and provide a refined ephemeris, making HIP116454 b amenable for future follow-up observations of this latest addition tothe growing population of transiting super-Earths around nearby, bright stars.

The Survey of Water and Ammonia in the Galactic Center (SWAG): Molecular  Cloud Evolution in the Central Molecular Zone

  The Survey of Water and Ammonia in the Galactic Center (SWAG) covers theCentral Molecular Zone (CMZ) of the Milky Way at frequencies between 21.2 and25.4 GHz obtained at the Australia Telescope Compact Array at $\sim 0.9$ pcspatial and $\sim 2.0$ km s$^{-1}$ spectral resolution. In this paper, wepresent data on the inner $\sim 250$ pc ($1.4^\circ$) between Sgr C and Sgr B2.We focus on the hyperfine structure of the metastable ammonia inversion lines(J,K) = (1,1) - (6,6) to derive column density, kinematics, opacity and kineticgas temperature. In the CMZ molecular clouds, we find typical line widths of$8-16$ km s$^{-1}$ and extended regions of optically thick ($\tau > 1$)emission. Two components in kinetic temperature are detected at $25-50$ K and$60-100$ K, both being significantly hotter than dust temperatures throughoutthe CMZ. We discuss the physical state of the CMZ gas as traced by ammonia inthe context of the orbital model by Kruijssen et al. (2015) that interprets theobserved distribution as a stream of molecular clouds following an openeccentric orbit. This allows us to statistically investigate the timedependencies of gas temperature, column density and line width. We find heatingrates between $\sim 50$ and $\sim 100$ K Myr$^{-1}$ along the stream orbit. Nostrong signs of time dependence are found for column density or line width.These quantities are likely dominated by cloud-to-cloud variations. Our resultsqualitatively match the predictions of the current model of tidal triggering ofcloud collapse, orbital kinematics and the observation of an evolutionarysequence of increasing star formation activity with orbital phase.

The MALATANG Survey: the L_gas-L_IR correlation on sub-kiloparsec scale  in six nearby star-forming galaxies as traced by HCN J=4-3 and HCO^+ J=4-3

  We present HCN J=4-3 and HCO^+ J=4-3 maps of six nearby star-forminggalaxies, NGC 253, NGC 1068, IC 342, M82, M83, and NGC 6946, obtained with theJames Clerk Maxwell Telescope as part of the MALATANG survey. All galaxies weremapped in the central 2 arcmin $\times$ 2 arcmin region at 14 arcsec (FWHM)resolution (corresponding to linear scales of ~ 0.2-1.0 kpc). The L_IR-L'_denserelation, where the dense gas is traced by the HCN J=4-3 and the HCO^+ J=4-3emission, measured in our sample of spatially-resolved galaxies is found tofollow the linear correlation established globally in galaxies within thescatter. We find that the luminosity ratio, L_IR/L'_dense, shows systematicvariations with L_IR within individual spatially resolved galaxies, whereas thegalaxy-integrated ratios vary little. A rising trend is also found betweenL_IR/L'_dense ratio and the warm-dust temperature gauged by the 70 \mu m/100\mu m flux ratio. We find the luminosity ratios of IR/HCN(4-3) andIR/HCO^+(4-3), which can be taken as a proxy for the efficiency of starformation in the dense molecular gas (SFE_dense), appears to be nearlyindependent of the dense-gas fraction (f_dense) for our sample of galaxies. TheSFE of the total molecular gas (SFE_mol) is found to increase substantiallywith f_dense when combining our data with that on local (ultra)luminousinfrared galaxies and high-z quasars. The mean L'_HCN(4-3)/L'_HCO^+(4-3) lineratio measured for the six targeted galaxies is 0.9+/-0.6. No significantcorrelation is found for the L'_HCN(4-3)/L'_HCO^+(4-3) ratio with the SFR astraced by L_IR, nor with the warm-dust temperature, for the differentpopulations of galaxies.

On the sensitivity of the HAWC observatory to gamma-ray bursts

  We present the sensitivity of HAWC to Gamma Ray Bursts (GRBs). HAWC is a veryhigh-energy gamma-ray observatory currently under construction in Mexico at analtitude of 4100 m. It will observe atmospheric air showers via the waterCherenkov method. HAWC will consist of 300 large water tanks instrumented with4 photomultipliers each. HAWC has two data acquisition (DAQ) systems. The mainDAQ system reads out coincident signals in the tanks and reconstructs thedirection and energy of individual atmospheric showers. The scaler DAQ countsthe hits in each photomultiplier tube (PMT) in the detector and searches for astatistical excess over the noise of all PMTs. We show that HAWC has arealistic opportunity to observe the high-energy power law components of GRBsthat extend at least up to 30 GeV, as it has been observed by Fermi LAT. Thetwo DAQ systems have an energy threshold that is low enough to observe eventssimilar to GRB 090510 and GRB 090902b with the characteristics observed byFermi LAT. HAWC will provide information about the high-energy spectra of GRBswhich in turn could help to understanding about e-pair attenuation in GRB jets,extragalactic background light absorption, as well as establishing the highestenergy to which GRBs accelerate particles.

Probing the Fundamental Nature of Dark Matter with the Large Synoptic  Survey Telescope

  Astrophysical and cosmological observations currently provide the onlyrobust, empirical measurements of dark matter. Future observations with LargeSynoptic Survey Telescope (LSST) will provide necessary guidance for theexperimental dark matter program. This white paper represents a communityeffort to summarize the science case for studying the fundamental physics ofdark matter with LSST. We discuss how LSST will inform our understanding of thefundamental properties of dark matter, such as particle mass, self-interactionstrength, non-gravitational couplings to the Standard Model, and compact objectabundances. Additionally, we discuss the ways that LSST will complement otherexperiments to strengthen our understanding of the fundamental characteristicsof dark matter. More information on the LSST dark matter effort can be found athttps://lsstdarkmatter.github.io/ .

The Multi-Object, Fiber-Fed Spectrographs for SDSS and the Baryon  Oscillation Spectroscopic Survey

  We present the design and performance of the multi-object fiber spectrographsfor the Sloan Digital Sky Survey (SDSS) and their upgrade for the BaryonOscillation Spectroscopic Survey (BOSS). Originally commissioned in Fall 1999on the 2.5-m aperture Sloan Telescope at Apache Point Observatory, thespectrographs produced more than 1.5 million spectra for the SDSS and SDSS-IIsurveys, enabling a wide variety of Galactic and extra-galactic scienceincluding the first observation of baryon acoustic oscillations in 2005. Thespectrographs were upgraded in 2009 and are currently in use for BOSS, theflagship survey of the third-generation SDSS-III project. BOSS will measureredshifts of 1.35 million massive galaxies to redshift 0.7 and Lyman-alphaabsorption of 160,000 high redshift quasars over 10,000 square degrees of sky,making percent level measurements of the absolute cosmic distance scale of theUniverse and placing tight constraints on the equation of state of dark energy.  The twin multi-object fiber spectrographs utilize a simple optical layoutwith reflective collimators, gratings, all-refractive cameras, andstate-of-the-art CCD detectors to produce hundreds of spectra simultaneously intwo channels over a bandpass covering the near ultraviolet to the nearinfrared, with a resolving power R = \lambda/FWHM ~ 2000. Building on provenheritage, the spectrographs were upgraded for BOSS with volume-phaseholographic gratings and modern CCD detectors, improving the peak throughput bynearly a factor of two, extending the bandpass to cover 360 < \lambda < 1000nm, and increasing the number of fibers from 640 to 1000 per exposure. In thispaper we describe the original SDSS spectrograph design and the upgradesimplemented for BOSS, and document the predicted and measured performances.

