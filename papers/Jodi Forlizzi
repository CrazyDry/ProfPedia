Planning with Verbal Communication for Human-Robot Collaboration

  Human collaborators coordinate effectively their actions through both verbaland non-verbal communication. We believe that the the same should hold forhuman-robot teams. We propose a formalism that enables a robot to decideoptimally between doing a task and issuing an utterance. We focus on two typesof utterances: verbal commands, where the robot expresses how it wants itshuman teammate to behave, and state-conveying actions, where the robot explainswhy it is behaving this way. Human subject experiments show that enabling therobot to issue verbal commands is the most effective form of communicatingobjectives, while retaining user trust in the robot. Communicating whyinformation should be done judiciously, since many participants questioned thetruthfulness of the robot statements.

Mathematical Models of Adaptation in Human-Robot Collaboration

  A robot operating in isolation needs to reason over the uncertainty in itsmodel of the world and adapt its own actions to account for this uncertainty.Similarly, a robot interacting with people needs to reason over its uncertaintyover the human internal state, as well as over how this state may change, ashumans adapt to the robot. This paper summarizes our own work in this area,which depicts the different ways that probabilistic planning and game-theoreticalgorithms can enable such reasoning in robotic systems that collaborate withpeople. We start with a general formulation of the problem as a two-player gamewith incomplete information. We then articulate the different assumptionswithin this general formulation, and we explain how these lead to exciting anddiverse robot behaviors in real-time interactions with actual human subjects,in a variety of manufacturing, personal robotics and assistive care settings.

