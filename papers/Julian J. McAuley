Robust Near-Isometric Matching via Structured Learning of Graphical  Models

  Models for near-rigid shape matching are typically based on distance-relatedfeatures, in order to infer matches that are consistent with the isometricassumption. However, real shapes from image datasets, even when expected to berelated by "almost isometric" transformations, are actually subject not only tonoise but also, to some limited degree, to variations in appearance and scale.In this paper, we introduce a graphical model that parameterises appearance,distance, and angle features and we learn all of the involved parameters viastructured prediction. The outcome is a model for near-rigid shape matchingwhich is robust in the sense that it is able to capture the possibly limitedbut still important scale and appearance variations. Our experimental resultsreveal substantial improvements upon recent successful models, whilemaintaining similar running times.

Graph rigidity, Cyclic Belief Propagation and Point Pattern Matching

  A recent paper \cite{CaeCaeSchBar06} proposed a provably optimal, polynomialtime method for performing near-isometric point pattern matching by means ofexact probabilistic inference in a chordal graphical model. Their fundamentalresult is that the chordal graph in question is shown to be globally rigid,implying that exact inference provides the same matching solution as exactinference in a complete graphical model. This implies that the algorithm isoptimal when there is no noise in the point patterns. In this paper, we presenta new graph which is also globally rigid but has an advantage over the graphproposed in \cite{CaeCaeSchBar06}: its maximal clique size is smaller,rendering inference significantly more efficient. However, our graph is notchordal and thus standard Junction Tree algorithms cannot be directly applied.Nevertheless, we show that loopy belief propagation in such a graph convergesto the optimal solution. This allows us to retain the optimality guarantee inthe noiseless case, while substantially reducing both memory requirements andprocessing time. Our experimental results show that the accuracy of theproposed solution is indistinguishable from that of \cite{CaeCaeSchBar06} whenthere is noise in the point patterns.

Faster Algorithms for Max-Product Message-Passing

  Maximum A Posteriori inference in graphical models is often solved viamessage-passing algorithms, such as the junction-tree algorithm, or loopybelief-propagation. The exact solution to this problem is well known to beexponential in the size of the model's maximal cliques after it istriangulated, while approximate inference is typically exponential in the sizeof the model's factors. In this paper, we take advantage of the fact that manymodels have maximal cliques that are larger than their constituent factors, andalso of the fact that many factors consist entirely of latent variables (i.e.,they do not depend on an observation). This is a common case in a wide varietyof applications, including grids, trees, and ring-structured models. In suchcases, we are able to decrease the exponent of complexity for message-passingby 0.5 for both exact and approximate inference.

An expected-case sub-cubic solution to the all-pairs shortest path  problem in R

  It has been shown by Alon et al. that the so-called 'all-pairs shortest-path'problem can be solved in O((MV)^2.688 * log^3(V)) for graphs with V vertices,with integer distances bounded by M. We solve the more general problem forgraphs in R (assuming no negative cycles), with expected-case running timeO(V^2.5 * log(V)). While our result appears to violate the Omega(V^3)requirement of "Funny Matrix Multiplication" (due to Kerr), we find that it hasa sub-cubic expected time solution subject to reasonable conditions on the datadistribution. The expected time solution arises when certain sub-problems areuncorrelated, though we can do better/worse than the expected-case underpositive/negative correlation (respectively). Whether we observepositive/negative correlation depends on the statistics of the graph inquestion. In practice, our algorithm is significantly faster thanFloyd-Warshall, even for dense graphs.

Learning Graph Matching

  As a fundamental problem in pattern recognition, graph matching hasapplications in a variety of fields, from computer vision to computationalbiology. In graph matching, patterns are modeled as graphs and patternrecognition amounts to finding a correspondence between the nodes of differentgraphs. Many formulations of this problem can be cast in general as a quadraticassignment problem, where a linear term in the objective function encodes nodecompatibility and a quadratic term encodes edge compatibility. The mainresearch focus in this theme is about designing efficient algorithms forapproximately solving the quadratic assignment problem, since it is NP-hard. Inthis paper we turn our attention to a different question: how to estimatecompatibility functions such that the solution of the resulting graph matchingproblem best matches the expected solution that a human would manually provide.We present a method for learning graph matching: the training examples arepairs of graphs and the `labels' are matches between them. Our experimentalresults reveal that learning can substantially improve the performance ofstandard graph matching algorithms. In particular, we find that simple linearassignment with such a learning scheme outperforms Graduated Assignment withbistochastic normalisation, a state-of-the-art quadratic assignment relaxationalgorithm.

The rich-club phenomenon across complex network hierarchies

  The so-called rich-club phenomenon in a complex network is characterized whennodes of higher degree (hubs) are better connected among themselves than arenodes with smaller degree. The presence of the rich-club phenomenon may be anindicator of several interesting high-level network properties, such astolerance to hub failures. Here we investigate the existence of the rich-clubphenomenon across the hierarchical degrees of a number of real-world networks.Our simulations reveal that the phenomenon may appear in some hierarchies butnot in others and, moreover, that it may appear and disappear as we move acrosshierarchies. This reveals the interesting possibility of non-monotonic behaviorof the phenomenon; the possible implications of our findings are discussed.

