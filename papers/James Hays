Identifying Near Earth Object Families

  The study of asteroid families has provided tremendous insight into theforces that sculpted the main belt and continue to drive the collisional anddynamical evolution of asteroids. The identification of asteroid familieswithin the NEO population could provide a similar boon to studies of theirformation and interiors. In this study we examine the purported identificationof NEO families by Drummond (2000) and conclude that it is unlikely that theyare anything more than random fluctuations in the distribution of NEOosculating orbital elements. We arrive at this conclusion after examining theexpected formation rate of NEO families, the identification of NEO groups insynthetic populations that contain no genetically related NEOs, the orbitalevolution of the largest association identified by Drummond (2000), and thedecoherence of synthetic NEO families intended to reproduce the observedmembers of the same association. These studies allowed us to identify a newcriterion that can be used to select real NEO families for further study infuture analyses, based on the ratio of the number of pairs and the size ofstrings to the number of objects in an identified association.

Super-resolution Using Constrained Deep Texture Synthesis

  Hallucinating high frequency image details in single image super-resolutionis a challenging task. Traditional super-resolution methods tend to produceoversmoothed output images due to the ambiguity in mapping between low and highresolution patches. We build on recent success in deep learning based texturesynthesis and show that this rich feature space can facilitate successfultransfer and synthesis of high frequency image details to improve the visualquality of super-resolution results on a wide variety of natural textures andimages.

Defect Structures in the Growth Kinetics of the Swift-Hohenberg Model

  The growth of striped order resulting from a quench of the two-dimensionalSwift-Hohenberg model is studied in the regime of a small control parameter andquenches to zero temperature. We introduce an algorithm for finding andidentifying the disordering defects (dislocations, disclinations and grainboundaries) at a given time. We can track their trajectories separately. Wefind that the coarsening of the defects and lowering of the effective freeenergy in the system are governed by a growth law $L(t)\approx t^{x}$ with anexponent x near 1/3. We obtain scaling for the correlations of the nematicorder parameter with the same growth law. The scaling for the order parameterstructure factor is governed, as found by others, by a growth law with anexponent smaller than x and near to 1/4. By comparing two systems withdifferent sizes, we clarify the finite size effect. We find that the system hasa very low density of disclinations compared to that for dislocations andfraction of points in grain boundaries. We also measure the speed distributionsof the defects at different times and find that they all have power-law tailsand the average speed decreases as a power law.

Same-sign W pair production as a probe of double parton scattering at  the LHC

  We study the production of same-sign W boson pairs at the LHC in doubleparton interactions. Compared with simple factorised double partondistributions (dPDFs), we show that the recently developed dPDFs, GS09, lead tonon-trivial kinematic correlations between the W bosons. A numerical study ofthe prospects for observing this process using same-sign dilepton signatures,including same-sign WWjj, di-boson and heavy flavour backgrounds, at 14 TeVcentre-of-mass energy is then performed. It is shown that a small excess ofsame-sign dilepton events from double parton scattering over a backgrounddominated by single scattering WZ(gamma*) production could be observed at theLHC.

Computational Nuclear Quantum Many-Body Problem: The UNEDF Project

  The UNEDF project was a large-scale collaborative effort that appliedhigh-performance computing to the nuclear quantum many-body problem. UNEDFdemonstrated that close associations among nuclear physicists, mathematicians,and computer scientists can lead to novel physics outcomes built on algorithmicinnovations and computational developments. This review showcases a wide rangeof UNEDF science results to illustrate this interplay.

Lens Factory: Automatic Lens Generation Using Off-the-shelf Components

  Custom optics is a necessity for many imaging applications. Unfortunately,custom lens design is costly (thousands to tens of thousands of dollars), timeconsuming (10-12 weeks typical lead time), and requires specialized opticsdesign expertise. By using only inexpensive, off-the-shelf lens components theLens Factory automatic design system greatly reduces cost and time. Design,ordering of parts, delivery, and assembly can be completed in a few days, at acost in the low hundreds of dollars. Lens design constraints, such as focallength and field of view, are specified in terms familiar to the graphicscommunity so no optics expertise is necessary. Unlike conventional lens designsystems, which only use continuous optimization methods, Lens Factory adds adiscrete optimization stage. This stage searches the combinatorial space ofpossible combinations of lens elements to find novel designs, evolving simplecanonical lens designs into more complex, better designs. Intelligent pruningrules make the combinatorial search feasible. We have designed and builtseveral high performance optical systems which demonstrate the practicality ofthe system.

StuffNet: Using 'Stuff' to Improve Object Detection

  We propose a Convolutional Neural Network (CNN) based algorithm - StuffNet -for object detection. In addition to the standard convolutional featurestrained for region proposal and object detection [31], StuffNet usesconvolutional features trained for segmentation of objects and 'stuff'(amorphous categories such as ground and water). Through experiments on PascalVOC 2010, we show the importance of features learnt from stuff segmentation forimproving object detection performance. StuffNet improves performance from18.8% mAP to 23.9% mAP for small objects. We also devise a method to trainStuffNet on datasets that do not have stuff segmentation labels. Throughexperiments on Pascal VOC 2007 and 2012, we demonstrate the effectiveness ofthis method and show that StuffNet also significantly improves object detectionperformance on such datasets.

Scribbler: Controlling Deep Image Synthesis with Sketch and Color

  Recently, there have been several promising methods to generate realisticimagery from deep convolutional networks. These methods sidestep thetraditional computer graphics rendering pipeline and instead generate imageryat the pixel level by learning from large collections of photos (e.g. faces orbedrooms). However, these methods are of limited utility because it isdifficult for a user to control what the network produces. In this paper, wepropose a deep adversarial image synthesis architecture that is conditioned onsketched boundaries and sparse color strokes to generate realistic cars,bedrooms, or faces. We demonstrate a sketch based image synthesis system whichallows users to 'scribble' over the sketch to indicate preferred color forobjects. Our network can then generate convincing images that satisfy both thecolor and the sketch constraints of user. The network is feed-forward whichallows users to see the effect of their edits in real time. We compare torecent work on sketch to image synthesis and show that our approach cangenerate more realistic, more diverse, and more controllable outputs. Thearchitecture is also effective at user-guided colorization of grayscale images.

Complex Event Recognition from Images with Few Training Examples

  We propose to leverage concept-level representations for complex eventrecognition in photographs given limited training examples. We introduce anovel framework to discover event concept attributes from the web and use thatto extract semantic features from images and classify them into social eventcategories with few training examples. Discovered concepts include a variety ofobjects, scenes, actions and event sub-types, leading to a discriminative andcompact representation for event images. Web images are obtained for eachdiscovered event concept and we use (pretrained) CNN features to train conceptclassifiers. Extensive experiments on challenging event datasets demonstratethat our proposed method outperforms several baselines using deep CNN featuresdirectly in classifying images into events with limited training examples. Wealso demonstrate that our method achieves the best overall accuracy on adataset with unseen event categories using a single training example.

DeepNav: Learning to Navigate Large Cities

  We present DeepNav, a Convolutional Neural Network (CNN) based algorithm fornavigating large cities using locally visible street-view images. The DeepNavagent learns to reach its destination quickly by making the correct navigationdecisions at intersections. We collect a large-scale dataset of street-viewimages organized in a graph where nodes are connected by roads. This datasetcontains 10 city graphs and more than 1 million street-view images. We propose3 supervised learning approaches for the navigation task and show how A* searchin the city graph can be used to generate supervision for the learning. Ourannotation process is fully automated using publicly available mapping servicesand requires no human input. We evaluate the proposed DeepNav models on 4held-out cities for navigating to 5 different types of destinations. Ouralgorithms outperform previous work that uses hand-crafted features and SupportVector Regression (SVR)[19].

Revisiting IM2GPS in the Deep Learning Era

  Image geolocalization, inferring the geographic location of an image, is achallenging computer vision problem with many potential applications. Therecent state-of-the-art approach to this problem is a deep image classificationapproach in which the world is spatially divided into cells and a deep networkis trained to predict the correct cell for a given image. We propose to combinethis approach with the original Im2GPS approach in which a query image ismatched against a database of geotagged images and the location is inferredfrom the retrieved set. We estimate the geographic location of a query image byapplying kernel density estimation to the locations of its nearest neighbors inthe reference database. Interestingly, we find that the best features for ourretrieval task are derived from networks trained with classification loss eventhough we do not use a classification approach at test time. Training withclassification loss outperforms several deep feature learning methods (e.g.Siamese networks with contrastive of triplet loss) more typical for retrievalapplications. Our simple approach achieves state-of-the-art geolocalizationaccuracy while also requiring significantly less training data.

On Convergence and Stability of GANs

  We propose studying GAN training dynamics as regret minimization, which is incontrast to the popular view that there is consistent minimization of adivergence between real and generated distributions. We analyze the convergenceof GAN training from this new point of view to understand why mode collapsehappens. We hypothesize the existence of undesirable local equilibria in thisnon-convex game to be responsible for mode collapse. We observe that theselocal equilibria often exhibit sharp gradients of the discriminator functionaround some real data points. We demonstrate that these degenerate localequilibria can be avoided with a gradient penalty scheme called DRAGAN. We showthat DRAGAN enables faster training, achieves improved stability with fewermode collapses, and leads to generator networks with better modelingperformance across a variety of architectures and objective functions.

TextureGAN: Controlling Deep Image Synthesis with Texture Patches

  In this paper, we investigate deep image synthesis guided by sketch, color,and texture. Previous image synthesis methods can be controlled by sketch andcolor strokes but we are the first to examine texture control. We allow a userto place a texture patch on a sketch at arbitrary locations and scales tocontrol the desired output texture. Our generative network learns to synthesizeobjects consistent with these texture suggestions. To achieve this, we developa local texture loss in addition to adversarial and content loss to train thegenerative network. We conduct experiments using sketches generated from realimages and textures sampled from a separate texture database and results showthat our proposed algorithm is able to generate plausible images that arefaithful to user controls. Ablation studies show that our proposed pipeline cangenerate more realistic images than adapting existing methods directly.

SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis

  Synthesizing realistic images from human drawn sketches is a challengingproblem in computer graphics and vision. Existing approaches either need exactedge maps, or rely on retrieval of existing photographs. In this work, wepropose a novel Generative Adversarial Network (GAN) approach that synthesizesplausible images from 50 categories including motorcycles, horses and couches.We demonstrate a data augmentation technique for sketches which is fullyautomatic, and we show that the augmented data is helpful to our task. Weintroduce a new network building block suitable for both the generator anddiscriminator which improves the information flow by injecting the input imageat multiple scales. Compared to state-of-the-art image translation methods, ourapproach generates more realistic images and achieves significantly higherInception Scores.

Generalization in Metric Learning: Should the Embedding Layer be the  Embedding Layer?

  This work studies deep metric learning under small to medium scale data as webelieve that better generalization could be a contributing factor to theimprovement of previous fine-grained image retrieval methods; it should beconsidered when designing future techniques. In particular, we investigateusing other layers in a deep metric learning system (besides the embeddinglayer) for feature extraction and analyze how well they perform on trainingdata and generalize to testing data. From this study, we suggest a newregularization practice where one can add or choose a more optimal layer forfeature extraction. State-of-the-art performance is demonstrated on 3fine-grained image retrieval benchmarks: Cars-196, CUB-200-2011, and StanfordOnline Product.

Informative Features for Model Comparison

  Given two candidate models, and a set of target observations, we address theproblem of measuring the relative goodness of fit of the two models. We proposetwo new statistical tests which are nonparametric, computationally efficient(runtime complexity is linear in the sample size), and interpretable. As aunique advantage, our tests can produce a set of examples (informativefeatures) indicating the regions in the data domain where one model fitssignificantly better than the other. In a real-world problem of comparing GANmodels, the test power of our new test matches that of the state-of-the-arttest of relative goodness of fit, while being one order of magnitude faster.

Composing Text and Image for Image Retrieval - An Empirical Odyssey

  In this paper, we study the task of image retrieval, where the input query isspecified in the form of an image plus some text that describes desiredmodifications to the input image. For example, we may present an image of theEiffel tower, and ask the system to find images which are visually similar butare modified in small ways, such as being taken at nighttime instead of duringthe day. To tackle this task, we learn a similarity metric between a targetimage and a source image plus source text, an embedding and composing functionsuch that target image feature is close to the source image plus textcomposition feature. We propose a new way to combine image and text using suchfunction that is designed for the retrieval task. We show this outperformsexisting approaches on 3 different datasets, namely Fashion-200k, MIT-Statesand a new synthetic dataset we create based on CLEVR. We also show that ourapproach can be used to classify input queries, in addition to image retrieval.

Let's Transfer Transformations of Shared Semantic Representations

  With a good image understanding capability, can we manipulate the images highlevel semantic representation? Such transformation operation can be used togenerate or retrieve similar images but with a desired modification (forexample changing beach background to street background); similar ability hasbeen demonstrated in zero shot learning, attribute composition and attributemanipulation image search. In this work we show how one can learntransformations with no training examples by learning them on another domainand then transfer to the target domain. This is feasible if: first,transformation training data is more accessible in the other domain and second,both domains share similar semantics such that one can learn transformations ina shared embedding space. We demonstrate this on an image retrieval task wheresearch query is an image, plus an additional transformation specification (forexample: search for images similar to this one but background is a streetinstead of a beach). In one experiment, we transfer transformation fromsynthesized 2D blobs image to 3D rendered image, and in the other, we transferfrom text domain to natural image domain.

ContactGrasp: Functional Multi-finger Grasp Synthesis from Contact

  Grasping and manipulating objects is an important human skill. Since mostobjects are designed to be manipulated by human hands, anthropomorphic handscan enable richer human-robot interaction. Desirable grasps are not onlystable, but also functional: they enable post-grasp actions with the object.However, functional grasp synthesis for high-dof anthropomorphic hands fromobject shape alone is challenging. We present ContactGrasp, a framework thatallows functional grasp synthesis from object shape and contact on the objectsurface. Contact can be manually specified or obtained through demonstrations.Our contact representation is object-centric and allows functional graspsynthesis even for hand models different than the one used for demonstration.Using a dataset of contact demonstrations from humans grasping diversehousehold objects, we synthesize functional grasps for three hand models andtwo functional intents. The project webpage ishttps://contactdb.cc.gatech.edu/contactgrasp.html.

Identifying the genetic basis of antigenic change in influenza A(H1N1)

  Determining phenotype from genetic data is a fundamental challenge. InfluenzaA viruses undergo rapid antigenic drift and identification of emergingantigenic variants is critical to the vaccine selection process. Using formerseasonal influenza A(H1N1) viruses, hemagglutinin sequence and correspondingantigenic data were analyzed in combination with 3-D structural information. Weattributed variation in hemagglutination inhibition to individual amino acidsubstitutions and quantified their antigenic impact, validating a subsetexperimentally using reverse genetics. Substitutions identified as low-impactwere shown to be a critical component of influenza antigenic evolution and byincluding these, as well as the high-impact substitutions often focused on, theaccuracy of predicting antigenic phenotypes of emerging viruses from genotypewas doubled. The ability to quantify the phenotypic impact of specific aminoacid substitutions should help refine techniques that predict the fitness andevolutionary success of variant viruses, leading to stronger theoreticalfoundations for selection of candidate vaccine viruses.

Microsoft COCO: Common Objects in Context

  We present a new dataset with the goal of advancing the state-of-the-art inobject recognition by placing the question of object recognition in the contextof the broader question of scene understanding. This is achieved by gatheringimages of complex everyday scenes containing common objects in their naturalcontext. Objects are labeled using per-instance segmentations to aid in preciseobject localization. Our dataset contains photos of 91 objects types that wouldbe easily recognizable by a 4 year old. With a total of 2.5 million labeledinstances in 328k images, the creation of our dataset drew upon extensive crowdworker involvement via novel user interfaces for category detection, instancespotting and instance segmentation. We present a detailed statistical analysisof the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we providebaseline performance analysis for bounding box and segmentation detectionresults using a Deformable Parts Model.

Localizing and Orienting Street Views Using Overhead Imagery

  In this paper we aim to determine the location and orientation of aground-level query image by matching to a reference database of overhead (e.g.satellite) images. For this task we collect a new dataset with one millionpairs of street view and overhead images sampled from eleven U.S. cities. Weexplore several deep CNN architectures for cross-domain matching --Classification, Hybrid, Siamese, and Triplet networks. Classification andHybrid architectures are accurate but slow since they allow only partialfeature precomputation. We propose a new loss function which significantlyimproves the accuracy of Siamese and Triplet embedding networks whilemaintaining their applicability to large-scale retrieval tasks like imagegeolocalization. This image matching task is challenging not just because ofthe dramatic viewpoint difference between ground-level and overhead imagery butbecause the orientation (i.e. azimuth) of the street views is unknown makingcorrespondence even more difficult. We examine several mechanisms to match inspite of this -- training for rotation invariance, sampling possible rotationsat query time, and explicitly predicting relative rotation of ground andoverhead images with our deep networks. It turns out that explicit orientationsupervision also improves location prediction accuracy. Our best performingarchitectures are roughly 2.5 times as accurate as the commonly used Siamesenetwork baseline.

Geometry-Aware Learning of Maps for Camera Localization

  Maps are a key component in image-based camera localization and visual SLAMsystems: they are used to establish geometric constraints between images,correct drift in relative pose estimation, and relocalize cameras after losttracking. The exact definitions of maps, however, are oftenapplication-specific and hand-crafted for different scenarios (e.g. 3Dlandmarks, lines, planes, bags of visual words). We propose to represent mapsas a deep neural net called MapNet, which enables learning a data-driven maprepresentation. Unlike prior work on learning maps, MapNet exploits cheap andubiquitous sensory inputs like visual odometry and GPS in addition to imagesand fuses them together for camera localization. Geometric constraintsexpressed by these inputs, which have traditionally been used in bundleadjustment or pose-graph optimization, are formulated as loss terms in MapNettraining and also used during inference. In addition to directly improvinglocalization accuracy, this allows us to update the MapNet (i.e., maps) in aself-supervised manner using additional unlabeled video sequences from thescene. We also propose a novel parameterization for camera rotation which isbetter suited for deep-learning based camera pose regression. Experimentalresults on both the indoor 7-Scenes dataset and the outdoor Oxford RobotCardataset show significant performance improvement over prior work. The MapNetproject webpage is https://goo.gl/mRB3Au.

Let's Dance: Learning From Online Dance Videos

  In recent years, deep neural network approaches have naturally extended tothe video domain, in their simplest case by aggregating per-frameclassifications as a baseline for action recognition. A majority of the work inthis area extends from the imaging domain, leading to visual-feature heavyapproaches on temporal data. To address this issue we introduce "Let's Dance",a 1000 video dataset (and growing) comprised of 10 visually overlapping dancecategories that require motion for their classification. We stress theimportant of human motion as a key distinguisher in our work given that, as weshow in this work, visual information is not sufficient to classifymotion-heavy categories. We compare our datasets' performance using imagingtechniques with UCF-101 and demonstrate this inherent difficulty. We present acomparison of numerous state-of-the-art techniques on our dataset using threedifferent representations (video, optical flow and multi-person pose data) inorder to analyze these approaches. We discuss the motion parameterization ofeach of them and their value in learning to categorize online dance videos.Lastly, we release this dataset (and its three representations) for theresearch community to use.

Bubbling AdS and droplet descriptions of BPS geometries in IIB  supergravity

  This paper focuses on supergravity duals of BPS states in N=4 superYang-Mills. In order to describe these duals, we begin with a sequence ofbreathing mode reductions of IIB supergravity: first on S^3, then S^3 x S^1,and finally on S^3 x S^1 x CP^1. We then follow with a complete supersymmetryanalysis, yielding 1/8, 1/4 and 1/2 BPS configurations, respectively (where inthe last step we take the Hopf fibration of S^3). The 1/8 BPS geometries, whichhave an S^3 isometry and are time-fibered over a six-dimensional base, aredetermined by solving a non-linear equation for the Kahler metric on the base.Similarly, the 1/4 BPS configurations have an S^3 x S^1 isometry and afour-dimensional base, whose Kahler metric obeys another non-linear,Monge-Ampere type equation.  Despite the non-linearity of the problem, we develop a universal bubbling AdSdescription of these geometries by focusing on the boundary conditions whichensure their regularity. In the 1/8 BPS case, we find that the S^3 cycleshrinks to zero size on a five-dimensional locus inside the six-dimensionalbase. Enforcing regularity of the full solution requires that the interior of asmooth, generally disconnected five-dimensional surface be removed from thebase. The AdS_5 x S^5 ground state corresponds to excising the interior of anS^5, while the 1/8 BPS excitations correspond to deformations (includingtopology change) of the S^5 and/or the excision of additional droplets from thebase. In the case of 1/4 BPS configurations, by enforcing regularityconditions, we identify three-dimensional surfaces inside the four-dimensionalbase which separate the regions where the S^3 shrinks to zero size from thosewhere the S^1 shrinks.

About AGN ionization echoes, thermal echoes, and ionization deficits in  low redshift Lyman-alpha blobs

  We report the discovery of 14 Lyman-alpha blobs (LABs) at z~0.3, existing atleast 4-7 billion years later in the Universe than all other LABs known. Theiroptical diameters are 20-70 kpc, and GALEX data imply Ly-alpha luminosities of(0.4-6.3)x10^43 erg/s. Contrary to high-z LABs, they live in low-density areas.They are ionized by AGN, suggesting that cold accretion streams as a powersource must deplete between z=2 and z=0.3. We also show that transient AGNnaturally explain the ionization deficits observed in many LABs: Their Ly-alphaand X-ray fluxes decorrelate below 10^6 years because of the delayed escape ofresonantly scattering Ly-alpha photons. High Ly-alpha luminosities do notrequire currently powerful AGN, independent of obscuration. Chandra X-ray datareveal intrinsically weak AGN, confirming the luminous optical nebulae asimpressive ionization echoes. For the first time, we also report mid-infraredthermal echoes from the dusty tori. We conclude that the AGN have faded by 3-4orders of magnitude within the last 10^(4-5) years, leaving fossil UV, opticaland thermal radiation behind. The host galaxies belong to the group ofpreviously discovered Green Bean galaxies (GBs). Gemini optical imaging revealssmooth spheres, mergers, spectacular outflows and ionization cones. Because oftheir proximity and high flux densities, GBs are perfect targets to study AGNfeedback, mode switching and the Ly-alpha escape. The fully calibrated, coaddedoptical FITS images are publicly available.

The disappearing act: A dusty wind eclipsing RW Aur

  RW Aur is a young binary star that experienced a deep dimming in 2010-11 incomponent A and a second even deeper dimming from summer 2014 to summer 2016.We present new unresolved multi-band photometry during the 2014-16 eclipse, newemission line spectroscopy before and during the dimming, archive infraredphotometry between 2014-15, as well as an overview of literature data.  Spectral observations were carried out with the Fibre-fed RObotic Dual-beamOptical Spectrograph on the Liverpool Telescope. Photometric monitoring wasdone with the Las Cumbres Observatory Global Telescope Network and JamesGregory Telescope. Our photometry shows that RW Aur dropped in brightness to R= 12.5 in March 2016. In addition to the long-term dimming trend, RW Aur isvariable on time scales as short as hours. The short-term variation is mostlikely due to an unstable accretion flow. This, combined with the presence ofaccretion-related emission lines in the spectra suggest that accretion flows inthe binary system are at least partially visible during the eclipse.  The equivalent width of [O I] increases by a factor of ten in 2014,coinciding with the dimming event, confirming previous reports. Theblue-shifted part of the $H\alpha$ profile is suppressed during the eclipse. Incombination with the increase in mid-infrared brightness during the eclipsereported in the literature and seen in WISE archival data, and constraints onthe geometry of the disk around RW Aur A we arrive at the conclusion that theobscuring screen is part of a wind emanating from the inner disk.

The detection of an extremely bright fast radio burst in a phased array  feed survey

  We report the detection of an ultra-bright fast radio burst (FRB) from amodest, 3.4-day pilot survey with the Australian Square Kilometre ArrayPathfinder. The survey was conducted in a wide-field fly's-eye configurationusing the phased-array-feed technology deployed on the array to instantaneouslyobserve an effective area of $160$ deg$^2$, and achieve an exposure totaling$13200$ deg$^2$ hr. We constrain the position of FRB 170107 to a region$8'\times8'$ in size (90% containment) and its fluence to be $58\pm6$ Jy ms.The spectrum of the burst shows a sharp cutoff above $1400$ MHz, which could beeither due to scintillation or an intrinsic feature of the burst. This confirmsthe existence of an ultra-bright ($>20$ Jy ms) population of FRBs.

SDSS-IV MaNGA IFS Galaxy Survey --- Survey Design, Execution, and  Initial Data Quality

  The MaNGA Survey (Mapping Nearby Galaxies at Apache Point Observatory) is oneof three core programs in the Sloan Digital Sky Survey IV. It is obtainingintegral field spectroscopy (IFS) for 10K nearby galaxies at a spectralresolution of R~2000 from 3,622-10,354A. The design of the survey is driven bya set of science requirements on the precision of estimates of the followingproperties: star formation rate surface density, gas metallicity, stellarpopulation age, metallicity, and abundance ratio, and their gradients; stellarand gas kinematics; and enclosed gravitational mass as a function of radius. Wedescribe how these science requirements set the depth of the observations anddictate sample selection. The majority of targeted galaxies are selected toensure uniform spatial coverage in units of effective radius (Re) whilemaximizing spatial resolution. About 2/3 of the sample is covered out to 1.5Re(Primary sample), and 1/3 of the sample is covered to 2.5Re (Secondary sample).We describe the survey execution with details that would be useful in thedesign of similar future surveys. We also present statistics on the achieveddata quality, specifically, the point spread function, sampling uniformity,spectral resolution, sky subtraction, and flux calibration. For our Primarysample, the median r-band signal-to-noise ratio is ~73 per 1.4A pixel forspectra stacked between 1-1.5 Re. Measurements of various galaxy propertiesfrom the first year data show that we are meeting or exceeding the definedrequirements for the majority of our science goals.

Overview of the SDSS-IV MaNGA Survey: Mapping Nearby Galaxies at Apache  Point Observatory

  We present an overview of a new integral field spectroscopic survey calledMaNGA (Mapping Nearby Galaxies at Apache Point Observatory), one of three coreprograms in the fourth-generation Sloan Digital Sky Survey (SDSS-IV) that beganon 2014 July 1. MaNGA will investigate the internal kinematic structure andcomposition of gas and stars in an unprecedented sample of 10,000 nearbygalaxies. We summarize essential characteristics of the instrument and surveydesign in the context of MaNGA's key science goals and present prototypeobservations to demonstrate MaNGA's scientific potential. MaNGA employsdithered observations with 17 fiber-bundle integral field units that vary indiameter from 12" (19 fibers) to 32" (127 fibers). Two dual-channelspectrographs provide simultaneous wavelength coverage over 3600-10300 A atR~2000. With a typical integration time of 3 hr, MaNGA reaches a target r-bandsignal-to-noise ratio of 4-8 (per A, per 2" fiber) at 23 AB mag per sq. arcsec,which is typical for the outskirts of MaNGA galaxies. Targets are selected withstellar mass greater than 1e9 Msun using SDSS-I redshifts and i-band luminosityto achieve uniform radial coverage in terms of the effective radius, anapproximately flat distribution in stellar mass, and a sample spanning a widerange of environments. Analysis of our prototype observations demonstratesMaNGA's ability to probe gas ionization, shed light on recent star formationand quenching, enable dynamical modeling, decompose constituent components, andmap the composition of stellar populations. MaNGA's spatially resolved spectrawill enable an unprecedented study of the astrophysics of nearby galaxies inthe coming 6 yr.

Observations of Milky Way Dwarf Spheroidal galaxies with the Fermi-LAT  detector and constraints on Dark Matter models

  We report on the observations of 14 dwarf spheroidal galaxies with the FermiGamma-Ray Space Telescope taken during the first 11 months of survey modeoperations. The Fermi telescope provides a new opportunity to test particledark matter models through the expected gamma-ray emission produced by pairannihilation of weakly interacting massive particles (WIMPs). Local Group dwarfspheroidal galaxies, the largest galactic substructures predicted by the colddark matter scenario, are attractive targets for such indirect searches fordark matter because they are nearby and among the most extreme dark matterdominated environments. No significant gamma-ray emission was detected above100 MeV from the candidate dwarf galaxies. We determine upper limits to thegamma-ray flux assuming both power-law spectra and representative spectra fromWIMP annihilation. The resulting integral flux above 100 MeV is constrained tobe at a level below around 10^-9 photons cm^-2 s^-1. Using recent stellarkinematic data, the gamma-ray flux limits are combined with improveddeterminations of the dark matter density profile in 8 of the 14 candidatedwarfs to place limits on the pair annihilation cross-section of WIMPs inseveral widely studied extensions of the standard model. With the present data,we are able to rule out large parts of the parameter space where the thermalrelic density is below the observed cosmological dark matter density and WIMPs(neutralinos here) are dominantly produced non-thermally, e.g. in models wheresupersymmetry breaking occurs via anomaly mediation. The gamma-ray limitspresented here also constrain some WIMP models proposed to explain the Fermiand PAMELA e^+e^- data, including low-mass wino-like neutralinos and modelswith TeV masses pair-annihilating into muon-antimuon pairs. (Abridged)

Discovery of HI gas in a young radio galaxy at $z = 0.44$ using the  Australian Square Kilometre Array Pathfinder

  We report the discovery of a new 21-cm HI absorption system usingcommissioning data from the Boolardy Engineering Test Array of the AustralianSquare Kilometre Array Pathfinder (ASKAP). Using the 711.5 - 1015.5 MHz band ofASKAP we were able to conduct a blind search for the 21-cm line in a continuousredshift range between $z = 0.4$ and 1.0, which has, until now, remainedlargely unexplored. The absorption line is detected at $z = 0.44$ towards theGHz-peaked spectrum radio source PKS B1740$-$517 and demonstrates ASKAP'sexcellent capability for performing a future wide-field survey for HIabsorption at these redshifts. Optical spectroscopy and imaging using theGemini-South telescope indicates that the HI gas is intrinsic to the hostgalaxy of the radio source. The narrow OIII emission lines show cleardouble-peaked structure, indicating either large-scale outflow or rotation ofthe ionized gas. Archival data from the \emph{XMM-Newton} satellite exhibit anabsorbed X-ray spectrum that is consistent with a high column density obscuringmedium around the active galactic nucleus. The HI absorption profile iscomplex, with four distinct components ranging in width from 5 to 300 kms$^{-1}$ and fractional depths from 0.2 to 20 per cent. In addition to systemicHI gas, in a circumnuclear disc or ring structure aligned with the radio jet,we find evidence for a possible broad outflow of neutral gas moving at a radialvelocity of $v \sim 300$ km s$^{-1}$. We infer that the expanding young radiosource ($t_{\rm age} \approx 2500$ yr) is cocooned within a dense medium andmay be driving circumnuclear neutral gas in an outflow of $\sim$ 1$\mathrm{M}_{\odot}$ yr$^{-1}$.

The NuMI Neutrino Beam

  This paper describes the hardware and operations of the Neutrinos at the MainInjector (NuMI) beam at Fermilab. It elaborates on the design considerationsfor the beam as a whole and for individual elements. The most important designdetails of individual components are described. Beam monitoring systems andprocedures, including the tuning and alignment of the beam and NuMI long-termperformance, are also discussed.

The 2010 Interim Report of the Long-Baseline Neutrino Experiment  Collaboration Physics Working Groups

  In early 2010, the Long-Baseline Neutrino Experiment (LBNE) sciencecollaboration initiated a study to investigate the physics potential of theexperiment with a broad set of different beam, near- and far-detectorconfigurations. Nine initial topics were identified as scientific areas thatmotivate construction of a long-baseline neutrino experiment with a very largefar detector. We summarize the scientific justification for each topic and theestimated performance for a set of far detector reference configurations. Wereport also on a study of optimized beam parameters and the physics capabilityof proposed Near Detector configurations. This document was presented to thecollaboration in fall 2010 and updated with minor modifications in early 2011.

Searches for the Higgs boson decaying to W^{+} W^{-} -> l^{+}nu  l^{-}nubar with the CDF II detector

  We present a search for a standard model Higgs boson decaying to two $W$bosons that decay to leptons using the full data set collected with the CDF IIdetector in $\sqrt{s}=1.96$ TeV $p\bar{p}$ collisions at the Fermilab Tevatron,corresponding to an integrated luminosity of 9.7 fb${}^{-1}$. We obtain noevidence for production of a standard model Higgs boson with mass between 110and 200 GeV/$c^2$, and place upper limits on the production cross sectionwithin this range. We exclude standard model Higgs boson production at the 95%confidence level in the mass range between 149 and 172 GeV/$c^2$, whileexpecting to exclude, in the absence of signal, the range between 155 and 175GeV/$c^2$. We also interpret the search in terms of standard model Higgs bosonproduction in the presence of a fourth generation of fermions and within thecontext of a fermiophobic Higgs boson model. For the specific case of astandard model-like Higgs boson in the presence of fourth-generation fermions,we exclude at the 95% confidence level Higgs boson production in the mass rangebetween 124 and 200 GeV/$c^2$, while expecting to exclude, in the absence ofsignal, the range between 124 and 221 GeV/$c^2$.

Identifying the Best Machine Learning Algorithms for Brain Tumor  Segmentation, Progression Assessment, and Overall Survival Prediction in the  BRATS Challenge

  Gliomas are the most common primary brain malignancies, with differentdegrees of aggressiveness, variable prognosis and various heterogeneoushistologic sub-regions, i.e., peritumoral edematous/invaded tissue, necroticcore, active and non-enhancing core. This intrinsic heterogeneity is alsoportrayed in their radio-phenotype, as their sub-regions are depicted byvarying intensity profiles disseminated across multi-parametric magneticresonance imaging (mpMRI) scans, reflecting varying biological properties.Their heterogeneous shape, extent, and location are some of the factors thatmake these tumors difficult to resect, and in some cases inoperable. The amountof resected tumor is a factor also considered in longitudinal scans, whenevaluating the apparent tumor for potential diagnosis of progression.Furthermore, there is mounting evidence that accurate segmentation of thevarious tumor sub-regions can offer the basis for quantitative image analysistowards prediction of patient overall survival. This study assesses thestate-of-the-art machine learning (ML) methods used for brain tumor imageanalysis in mpMRI scans, during the last seven instances of the InternationalBrain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, wefocus on i) evaluating segmentations of the various glioma sub-regions inpre-operative mpMRI scans, ii) assessing potential tumor progression by virtueof longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANOcriteria, and iii) predicting the overall survival from pre-operative mpMRIscans of patients that underwent gross total resection. Finally, we investigatethe challenge of identifying the best ML algorithms for each of these tasks,considering that apart from being diverse on each instance of the challenge,the multi-institutional mpMRI BraTS dataset has also been a continuouslyevolving/growing dataset.

Search for high-mass resonances decaying into ZZ in p$\bar{p}$  collisions at $\sqrt{s}=1.96$\,TeV

  We search for high-mass resonances decaying into Z boson pairs using datacorresponding to 6 fb^-1 collected by the CDF experiment in p\bar{p} collisionsat sqrt{s}=1.96 TeV. The search is performed in three distinct final states: ZZ--> l^+l^-l^+l^-, ZZ --> l^+l^-\nu\nu, and ZZ --> l^+l^-jj. For aRandall-Sundrum graviton G*, the 95% CL upper limits on the production crosssection times branching ratio to ZZ, sigma(p\bar{p} --> G^* --> ZZ), varybetween 0.26 pb and 0.045 pb in the mass range 300 < M_{G*} < 1000 GeV/c^2.

Measurements of Angular Distributions of Muons From Upsilon Meson Decays  in p p-bar Collisions at sqrt(s)=1.96 TeV

  The angular distributions of muons from Upsilon(1S,2S,3S) to mu+mu- decaysare measured using data from proton anti-proton collisions at sqrt(s)=1.96 TeVcorresponding to an integrated luminosity of 6.7 /fb and collected with the CDFII detector at the Fermilab Tevatron. This analysis is the first to report thefull angular distributions as functions of transverse momentum pT for theUpsilon mesons in both the Collins-Soper and s-channel helicity frames. This isalso the first measurement of spin alignment of Upsilon(3S) mesons. Within thekinematic range of Upsilon rapidity |y|<0.6 and pT up to 40 GeV/c, the angulardistributions are found to be nearly isotropic.

Measurement of the Top Quark Mass in the All-Hadronic Mode at CDF

  We present a measurement of the top quark mass (Mtop) in the all-hadronicdecay channel using 5.8 fb^{-1} of proton-antiproton data collected with theCDF II detector at the Fermilab Tevatron Collider. Events with 6 to 8 jets areselected by a neural network algorithm and by the requirement that at least oneof the jets is tagged as a b quark jet. The measurement is performed by alikelihood fit technique, which determines simultaneously Mtop and the jetenergy scale (JES) calibration. The fit yields a value of 172.5 +- 1.4(stat)+-1.0(JES) +-1.1(syst) GeV/c^2.

A search for dark matter in events with one jet and missing transverse  energy in pp-bar collisions at sqrt(s) = 1.96 TeV

  We present the results of a search for dark matter production in the monojetsignature. We analyze a sample of Tevatron pp-bar collisions at sqrt(s)=1.96TeV corresponding to an integrated luminosity of 6.7/fb recorded by the CDF IIdetector. In events with large missing transverse energy and one energetic jet,we find good agreement between the standard model prediction and the observeddata. We set 90% confidence level upper limits on the dark matter productionrate. The limits are translated into bounds on nucleon-dark matter scatteringrates which are competitive with current direct detection bounds onspin-independent interaction below a dark matter candidate mass of 5 GeV/c^2,and on spin-dependent interactions up to masses of 200 GeV/c^2.

Search for the Standard Model Higgs Boson Produced in Association with a  $Z$ Boson in $p\bar{p}$ Collisions at $\sqrt{s} = 1.96$ TeV

  We present a search for the standard model Higgs boson produced inassociation with a $Z$ boson, using up to 7.9 fb$^{-1}$ of integratedluminosity from $p\bar{p}$ collisions collected with the CDF II detector. Weutilize several novel techniques, including multivariate lepton selection,multivariate trigger parametrization, and a multi-stage signal discriminantconsisting of specialized functions trained to distinguish individualbackgrounds. By increasing acceptance and enhancing signal discrimination,these techniques have significantly improved the sensitivity of the analysisabove what was expected from a larger dataset alone. We observe no significantevidence for a signal, and we set limits on the $ZH$ production cross section.For a Higgs boson with mass 115 GeV/$c^2$, we expect (observe) a limit of 3.9(4.8) times the standard model predicted value, at the 95% credibility level.

Measurement of the top quark forward-backward production asymmetry and  its dependence on event kinematic properties

  We present new measurements of the inclusive forward-backward ttbarproduction asymmetry, AFB, and its dependence on several properties of thettbar system. The measurements are performed with the full Tevatron data setrecorded with the CDF II detector during ppbar collisions at sqrt(s) = 1.96TeV, corresponding to an integrated luminosity of 9.4 fb^(-1). We measure theasymmetry using the rapidity difference Delta-y=y_(t)-y_(tbar). Parton-levelresults are derived, yielding an inclusive asymmetry of 0.164+/-0.047 (stat +syst). We observe a linear dependence of AFB on the top-quark pair massM(ttbar) and the rapidity difference |Delta-y| at detector and parton levels.Assuming the standard model, the probabilities to observe the measured valuesor larger for the detector-level dependencies are 7.4*10^(-3) and 2.2*10^(-3)for M(ttbar) and |Delta-y| respectively. Lastly, we study the dependence of theasymmetry on the transverse momentum of the ttbar system at the detector level.These results are consistent with previous lower-precision measurements andprovide additional quantification of the functional dependencies of theasymmetry.

Updated search for the standard model Higgs boson in events with jets  and missing transverse energy using the full CDF data set

  We present an updated search for the Higgs boson produced in association witha vector boson in the final state with missing transverse energy and two jets.We use the full CDF data set corresponding to an integrated luminosity of 9.45fb${}^{-1}$ at a proton-antiproton center-of-mass energy of $\sqrt{s}=1.96$TeV. New to this analysis is the inclusion of a $b$-jet identificationalgorithm specifically optimized for $H\to b\bar{b}$ searches. Across the Higgsboson mass range $90 \le m_H \le 150$ GeV$/c^2$, the expected 95% credibilitylevel upper limits on the $V H$ production cross section times the $H\tob\bar{b}$ branching fraction are improved by an average of 14% relative to theprevious analysis. At a Higgs boson mass of 125 GeV$/c^2$, the observed(expected) limit is 3.06 (3.33) times the standard model prediction,corresponding to one of the most sensitive searches to date in this finalstate.

Exclusion of exotic top-like quarks with -4/3 electric charge using  jet-charge tagging in single-lepton ttbar events at CDF

  We report on a measurement of the top-quark electric charge in ttbar eventsin which one W boson originating from the top-quark pair decays into leptonsand the other into hadrons. The event sample was collected by the CDF IIdetector in sqrt(s)=1.96 TeV proton-antiproton collisions and corresponds to5.6 fb^(-1). We find the data to be consistent with the standard model andexclude the existence of an exotic quark with -4/3 electric charge and mass ofthe conventional top quark at the 99% confidence level.

Measurement of the Differential Cross Section dσ/d(cos θt)  for Top-Quark Pair Production in p-pbar Collisions at sqrt{s} = 1.96 TeV

  We report a measurement of the differential cross section, d{\sigma}/d(cos{\theta}t), for top-quark-pair production as a function of the top-quarkproduction angle in proton-antiproton collisions at sqrt{s} = 1.96 TeV. Thismeasurement is performed using data collected with the CDF II detector at theTevatron, corresponding to an integrated luminosity of 9.4/fb. We employ theLegendre polynomials to characterize the shape of the differential crosssection at the parton level. The observed Legendre coefficients are in goodagreement with the prediction of the next-to-leading-order standard-modelcalculation, with the exception of an excess linear-term coefficient, a1 = 0.40+- 0.12, compared to the standard-model prediction of a1 =0.15^{+0.07}_{-0.03}.

A signature-based search for delayed photons in exclusive photon plus  missing transverse energy events from $p \bar{p}$ collisions with $\sqrt{s} =  1.96$ TeV

  We present the first signature-based search for delayed photons using anexclusive photon plus missing transverse energy final state. Events arereconstructed in a data sample from the CDF II detector corresponding to $6.3\text{fb}^{-1}$ of integrated luminosity from $\sqrt{s}=1.96$ TeVproton-antiproton collisions. Candidate events are selected if they contain aphoton with an arrival time in the detector larger than expected from apromptly-produced photon. The mean number of events from standard model sourcespredicted by the data-driven background model based on the photon timingdistribution is $286 \pm 24$. A total of 322 events are observed. A $p$-valueof 12% is obtained, showing consistency of the data with standard modelpredictions.

Measurement of the leptonic asymmetry in ttbar events produced in ppbar  collisions at sqrt(s)=1.96 TeV

  We measure the asymmetry in the charge-weighted rapidity of the lepton insemileptonic ttbar decays recorded with the CDF II detector using the fullTevatron Run II sample, corresponding to an integrated luminosity of 9.4/fb. Aparametrization of the asymmetry as a function of the charge-weighted rapidityis used to correct for the finite acceptance of the detector and recover theproduction-level asymmetry. The result of afb(lep) = 0.094 +0.032 -0.029 is tobe compared to the standard model next-to-leading-order prediction of afb(lep)= 0.038 +-0.003.

Evidence for a bottom baryon resonance Lambda_b* in CDF data

  Using data from proton-antiproton collisions at Ecms=1.96 TeV recorded by theCDF II detector at the Fermilab Tevatron, evidence for the excited resonancestate Lambda_b* is presented in its Lambda_b0 pi+ pi- decay, followed by theLambda_b0 -->Lambda_c+ (-->proton K- pi+) pi- decays. The analysis is based ona data sample corresponding to an integrated luminosity of 9.6/fb collected byan online event selection based on charged-particle tracks displaced from theproton-antiproton interaction point. The significance of the observed signal is3.5 Gaussian sigmas. The mass of the observed state is found to be 5919.22 +-0.76 MeV in agreement with similar findings in proton-proton collisionexperiments.

A Direct Measurement of the Total Decay Width of the Top Quark

  We present a measurement of the total decay width of the top quark usingevents with top-antitop-quark pair candidates reconstructed in the final statewith one charged lepton and four or more hadronic jets. We use the fullTevatron Run II data set of $\sqrt{s} = 1.96$ TeV proton-antiproton collisionsrecorded by the CDF II detector. The top-quark mass and the mass of thehadronically-decaying $W$ boson are reconstructed for each event and comparedwith distributions derived from simulated signal and background samples toextract the top-quark width (\gmt) and the energy scale of the calorimeter jetswith {\it in-situ} calibration. For a top-quark mass $\mtop = \gevcc{172.5}$,we find $1.10<\gmt<\gev{4.05}$ at 68% confidence level, which is in agreementwith the standard-model expectation of \gev{1.3} and is the most precise directmeasurement of the top-quark width to date.

Observation of D0-D0bar Mixing using the CDF II Detector

  We measure the time dependence of the ratio of decay rates for D0 -> K+ pi-to the Cabibbo-favored decay D0 -> K- pi+. The charge conjugate decays areincluded. A signal of 3.3 x 10^4 D*+ -> pi+ D0, D0 -> K+ pi- decays is obtainedwith D0 proper decay times between 0.75 and 10 mean D0 lifetimes. The data wererecorded with the CDF II detector at the Fermilab Tevatron and correspond to anintegrated luminosity of 9.6 fb-1 for p-pbar collisions at sqrt(s) = 1.96 TeV.Assuming CP conservation, we search for D0-D0bar mixing and measure the mixingparameters to be R_D = (3.51 +/- 0.35) x 10^{-3}, y' = (4.3 +/- 4.3) x 10^{-3},and x'^2 = (0.08 +/- 0.18) x 10^{-3}. We report Bayesian probability intervalsin the x'^2 - y' plane and find that the significance of excluding theno-mixing hypothesis is equivalent to 6.1 Gaussian standard deviations,providing the second observation of D0-D0bar mixing from a single experiment.

