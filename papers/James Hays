Identifying Near Earth Object Families

  The study of asteroid families has provided tremendous insight into the
forces that sculpted the main belt and continue to drive the collisional and
dynamical evolution of asteroids. The identification of asteroid families
within the NEO population could provide a similar boon to studies of their
formation and interiors. In this study we examine the purported identification
of NEO families by Drummond (2000) and conclude that it is unlikely that they
are anything more than random fluctuations in the distribution of NEO
osculating orbital elements. We arrive at this conclusion after examining the
expected formation rate of NEO families, the identification of NEO groups in
synthetic populations that contain no genetically related NEOs, the orbital
evolution of the largest association identified by Drummond (2000), and the
decoherence of synthetic NEO families intended to reproduce the observed
members of the same association. These studies allowed us to identify a new
criterion that can be used to select real NEO families for further study in
future analyses, based on the ratio of the number of pairs and the size of
strings to the number of objects in an identified association.


Super-resolution Using Constrained Deep Texture Synthesis

  Hallucinating high frequency image details in single image super-resolution
is a challenging task. Traditional super-resolution methods tend to produce
oversmoothed output images due to the ambiguity in mapping between low and high
resolution patches. We build on recent success in deep learning based texture
synthesis and show that this rich feature space can facilitate successful
transfer and synthesis of high frequency image details to improve the visual
quality of super-resolution results on a wide variety of natural textures and
images.


Defect Structures in the Growth Kinetics of the Swift-Hohenberg Model

  The growth of striped order resulting from a quench of the two-dimensional
Swift-Hohenberg model is studied in the regime of a small control parameter and
quenches to zero temperature. We introduce an algorithm for finding and
identifying the disordering defects (dislocations, disclinations and grain
boundaries) at a given time. We can track their trajectories separately. We
find that the coarsening of the defects and lowering of the effective free
energy in the system are governed by a growth law $L(t)\approx t^{x}$ with an
exponent x near 1/3. We obtain scaling for the correlations of the nematic
order parameter with the same growth law. The scaling for the order parameter
structure factor is governed, as found by others, by a growth law with an
exponent smaller than x and near to 1/4. By comparing two systems with
different sizes, we clarify the finite size effect. We find that the system has
a very low density of disclinations compared to that for dislocations and
fraction of points in grain boundaries. We also measure the speed distributions
of the defects at different times and find that they all have power-law tails
and the average speed decreases as a power law.


Computational Nuclear Quantum Many-Body Problem: The UNEDF Project

  The UNEDF project was a large-scale collaborative effort that applied
high-performance computing to the nuclear quantum many-body problem. UNEDF
demonstrated that close associations among nuclear physicists, mathematicians,
and computer scientists can lead to novel physics outcomes built on algorithmic
innovations and computational developments. This review showcases a wide range
of UNEDF science results to illustrate this interplay.


Same-sign W pair production as a probe of double parton scattering at
  the LHC

  We study the production of same-sign W boson pairs at the LHC in double
parton interactions. Compared with simple factorised double parton
distributions (dPDFs), we show that the recently developed dPDFs, GS09, lead to
non-trivial kinematic correlations between the W bosons. A numerical study of
the prospects for observing this process using same-sign dilepton signatures,
including same-sign WWjj, di-boson and heavy flavour backgrounds, at 14 TeV
centre-of-mass energy is then performed. It is shown that a small excess of
same-sign dilepton events from double parton scattering over a background
dominated by single scattering WZ(gamma*) production could be observed at the
LHC.


Lens Factory: Automatic Lens Generation Using Off-the-shelf Components

  Custom optics is a necessity for many imaging applications. Unfortunately,
custom lens design is costly (thousands to tens of thousands of dollars), time
consuming (10-12 weeks typical lead time), and requires specialized optics
design expertise. By using only inexpensive, off-the-shelf lens components the
Lens Factory automatic design system greatly reduces cost and time. Design,
ordering of parts, delivery, and assembly can be completed in a few days, at a
cost in the low hundreds of dollars. Lens design constraints, such as focal
length and field of view, are specified in terms familiar to the graphics
community so no optics expertise is necessary. Unlike conventional lens design
systems, which only use continuous optimization methods, Lens Factory adds a
discrete optimization stage. This stage searches the combinatorial space of
possible combinations of lens elements to find novel designs, evolving simple
canonical lens designs into more complex, better designs. Intelligent pruning
rules make the combinatorial search feasible. We have designed and built
several high performance optical systems which demonstrate the practicality of
the system.


StuffNet: Using 'Stuff' to Improve Object Detection

  We propose a Convolutional Neural Network (CNN) based algorithm - StuffNet -
for object detection. In addition to the standard convolutional features
trained for region proposal and object detection [31], StuffNet uses
convolutional features trained for segmentation of objects and 'stuff'
(amorphous categories such as ground and water). Through experiments on Pascal
VOC 2010, we show the importance of features learnt from stuff segmentation for
improving object detection performance. StuffNet improves performance from
18.8% mAP to 23.9% mAP for small objects. We also devise a method to train
StuffNet on datasets that do not have stuff segmentation labels. Through
experiments on Pascal VOC 2007 and 2012, we demonstrate the effectiveness of
this method and show that StuffNet also significantly improves object detection
performance on such datasets.


Scribbler: Controlling Deep Image Synthesis with Sketch and Color

  Recently, there have been several promising methods to generate realistic
imagery from deep convolutional networks. These methods sidestep the
traditional computer graphics rendering pipeline and instead generate imagery
at the pixel level by learning from large collections of photos (e.g. faces or
bedrooms). However, these methods are of limited utility because it is
difficult for a user to control what the network produces. In this paper, we
propose a deep adversarial image synthesis architecture that is conditioned on
sketched boundaries and sparse color strokes to generate realistic cars,
bedrooms, or faces. We demonstrate a sketch based image synthesis system which
allows users to 'scribble' over the sketch to indicate preferred color for
objects. Our network can then generate convincing images that satisfy both the
color and the sketch constraints of user. The network is feed-forward which
allows users to see the effect of their edits in real time. We compare to
recent work on sketch to image synthesis and show that our approach can
generate more realistic, more diverse, and more controllable outputs. The
architecture is also effective at user-guided colorization of grayscale images.


Complex Event Recognition from Images with Few Training Examples

  We propose to leverage concept-level representations for complex event
recognition in photographs given limited training examples. We introduce a
novel framework to discover event concept attributes from the web and use that
to extract semantic features from images and classify them into social event
categories with few training examples. Discovered concepts include a variety of
objects, scenes, actions and event sub-types, leading to a discriminative and
compact representation for event images. Web images are obtained for each
discovered event concept and we use (pretrained) CNN features to train concept
classifiers. Extensive experiments on challenging event datasets demonstrate
that our proposed method outperforms several baselines using deep CNN features
directly in classifying images into events with limited training examples. We
also demonstrate that our method achieves the best overall accuracy on a
dataset with unseen event categories using a single training example.


DeepNav: Learning to Navigate Large Cities

  We present DeepNav, a Convolutional Neural Network (CNN) based algorithm for
navigating large cities using locally visible street-view images. The DeepNav
agent learns to reach its destination quickly by making the correct navigation
decisions at intersections. We collect a large-scale dataset of street-view
images organized in a graph where nodes are connected by roads. This dataset
contains 10 city graphs and more than 1 million street-view images. We propose
3 supervised learning approaches for the navigation task and show how A* search
in the city graph can be used to generate supervision for the learning. Our
annotation process is fully automated using publicly available mapping services
and requires no human input. We evaluate the proposed DeepNav models on 4
held-out cities for navigating to 5 different types of destinations. Our
algorithms outperform previous work that uses hand-crafted features and Support
Vector Regression (SVR)[19].


Revisiting IM2GPS in the Deep Learning Era

  Image geolocalization, inferring the geographic location of an image, is a
challenging computer vision problem with many potential applications. The
recent state-of-the-art approach to this problem is a deep image classification
approach in which the world is spatially divided into cells and a deep network
is trained to predict the correct cell for a given image. We propose to combine
this approach with the original Im2GPS approach in which a query image is
matched against a database of geotagged images and the location is inferred
from the retrieved set. We estimate the geographic location of a query image by
applying kernel density estimation to the locations of its nearest neighbors in
the reference database. Interestingly, we find that the best features for our
retrieval task are derived from networks trained with classification loss even
though we do not use a classification approach at test time. Training with
classification loss outperforms several deep feature learning methods (e.g.
Siamese networks with contrastive of triplet loss) more typical for retrieval
applications. Our simple approach achieves state-of-the-art geolocalization
accuracy while also requiring significantly less training data.


On Convergence and Stability of GANs

  We propose studying GAN training dynamics as regret minimization, which is in
contrast to the popular view that there is consistent minimization of a
divergence between real and generated distributions. We analyze the convergence
of GAN training from this new point of view to understand why mode collapse
happens. We hypothesize the existence of undesirable local equilibria in this
non-convex game to be responsible for mode collapse. We observe that these
local equilibria often exhibit sharp gradients of the discriminator function
around some real data points. We demonstrate that these degenerate local
equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show
that DRAGAN enables faster training, achieves improved stability with fewer
mode collapses, and leads to generator networks with better modeling
performance across a variety of architectures and objective functions.


TextureGAN: Controlling Deep Image Synthesis with Texture Patches

  In this paper, we investigate deep image synthesis guided by sketch, color,
and texture. Previous image synthesis methods can be controlled by sketch and
color strokes but we are the first to examine texture control. We allow a user
to place a texture patch on a sketch at arbitrary locations and scales to
control the desired output texture. Our generative network learns to synthesize
objects consistent with these texture suggestions. To achieve this, we develop
a local texture loss in addition to adversarial and content loss to train the
generative network. We conduct experiments using sketches generated from real
images and textures sampled from a separate texture database and results show
that our proposed algorithm is able to generate plausible images that are
faithful to user controls. Ablation studies show that our proposed pipeline can
generate more realistic images than adapting existing methods directly.


SketchyGAN: Towards Diverse and Realistic Sketch to Image Synthesis

  Synthesizing realistic images from human drawn sketches is a challenging
problem in computer graphics and vision. Existing approaches either need exact
edge maps, or rely on retrieval of existing photographs. In this work, we
propose a novel Generative Adversarial Network (GAN) approach that synthesizes
plausible images from 50 categories including motorcycles, horses and couches.
We demonstrate a data augmentation technique for sketches which is fully
automatic, and we show that the augmented data is helpful to our task. We
introduce a new network building block suitable for both the generator and
discriminator which improves the information flow by injecting the input image
at multiple scales. Compared to state-of-the-art image translation methods, our
approach generates more realistic images and achieves significantly higher
Inception Scores.


Generalization in Metric Learning: Should the Embedding Layer be the
  Embedding Layer?

  This work studies deep metric learning under small to medium scale data as we
believe that better generalization could be a contributing factor to the
improvement of previous fine-grained image retrieval methods; it should be
considered when designing future techniques. In particular, we investigate
using other layers in a deep metric learning system (besides the embedding
layer) for feature extraction and analyze how well they perform on training
data and generalize to testing data. From this study, we suggest a new
regularization practice where one can add or choose a more optimal layer for
feature extraction. State-of-the-art performance is demonstrated on 3
fine-grained image retrieval benchmarks: Cars-196, CUB-200-2011, and Stanford
Online Product.


Informative Features for Model Comparison

  Given two candidate models, and a set of target observations, we address the
problem of measuring the relative goodness of fit of the two models. We propose
two new statistical tests which are nonparametric, computationally efficient
(runtime complexity is linear in the sample size), and interpretable. As a
unique advantage, our tests can produce a set of examples (informative
features) indicating the regions in the data domain where one model fits
significantly better than the other. In a real-world problem of comparing GAN
models, the test power of our new test matches that of the state-of-the-art
test of relative goodness of fit, while being one order of magnitude faster.


Composing Text and Image for Image Retrieval - An Empirical Odyssey

  In this paper, we study the task of image retrieval, where the input query is
specified in the form of an image plus some text that describes desired
modifications to the input image. For example, we may present an image of the
Eiffel tower, and ask the system to find images which are visually similar but
are modified in small ways, such as being taken at nighttime instead of during
the day. To tackle this task, we learn a similarity metric between a target
image and a source image plus source text, an embedding and composing function
such that target image feature is close to the source image plus text
composition feature. We propose a new way to combine image and text using such
function that is designed for the retrieval task. We show this outperforms
existing approaches on 3 different datasets, namely Fashion-200k, MIT-States
and a new synthetic dataset we create based on CLEVR. We also show that our
approach can be used to classify input queries, in addition to image retrieval.


Let's Transfer Transformations of Shared Semantic Representations

  With a good image understanding capability, can we manipulate the images high
level semantic representation? Such transformation operation can be used to
generate or retrieve similar images but with a desired modification (for
example changing beach background to street background); similar ability has
been demonstrated in zero shot learning, attribute composition and attribute
manipulation image search. In this work we show how one can learn
transformations with no training examples by learning them on another domain
and then transfer to the target domain. This is feasible if: first,
transformation training data is more accessible in the other domain and second,
both domains share similar semantics such that one can learn transformations in
a shared embedding space. We demonstrate this on an image retrieval task where
search query is an image, plus an additional transformation specification (for
example: search for images similar to this one but background is a street
instead of a beach). In one experiment, we transfer transformation from
synthesized 2D blobs image to 3D rendered image, and in the other, we transfer
from text domain to natural image domain.


ContactGrasp: Functional Multi-finger Grasp Synthesis from Contact

  Grasping and manipulating objects is an important human skill. Since most
objects are designed to be manipulated by human hands, anthropomorphic hands
can enable richer human-robot interaction. Desirable grasps are not only
stable, but also functional: they enable post-grasp actions with the object.
However, functional grasp synthesis for high-dof anthropomorphic hands from
object shape alone is challenging. We present ContactGrasp, a framework that
allows functional grasp synthesis from object shape and contact on the object
surface. Contact can be manually specified or obtained through demonstrations.
Our contact representation is object-centric and allows functional grasp
synthesis even for hand models different than the one used for demonstration.
Using a dataset of contact demonstrations from humans grasping diverse
household objects, we synthesize functional grasps for three hand models and
two functional intents. The project webpage is
https://contactdb.cc.gatech.edu/contactgrasp.html.


Identifying the genetic basis of antigenic change in influenza A(H1N1)

  Determining phenotype from genetic data is a fundamental challenge. Influenza
A viruses undergo rapid antigenic drift and identification of emerging
antigenic variants is critical to the vaccine selection process. Using former
seasonal influenza A(H1N1) viruses, hemagglutinin sequence and corresponding
antigenic data were analyzed in combination with 3-D structural information. We
attributed variation in hemagglutination inhibition to individual amino acid
substitutions and quantified their antigenic impact, validating a subset
experimentally using reverse genetics. Substitutions identified as low-impact
were shown to be a critical component of influenza antigenic evolution and by
including these, as well as the high-impact substitutions often focused on, the
accuracy of predicting antigenic phenotypes of emerging viruses from genotype
was doubled. The ability to quantify the phenotypic impact of specific amino
acid substitutions should help refine techniques that predict the fitness and
evolutionary success of variant viruses, leading to stronger theoretical
foundations for selection of candidate vaccine viruses.


Microsoft COCO: Common Objects in Context

  We present a new dataset with the goal of advancing the state-of-the-art in
object recognition by placing the question of object recognition in the context
of the broader question of scene understanding. This is achieved by gathering
images of complex everyday scenes containing common objects in their natural
context. Objects are labeled using per-instance segmentations to aid in precise
object localization. Our dataset contains photos of 91 objects types that would
be easily recognizable by a 4 year old. With a total of 2.5 million labeled
instances in 328k images, the creation of our dataset drew upon extensive crowd
worker involvement via novel user interfaces for category detection, instance
spotting and instance segmentation. We present a detailed statistical analysis
of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide
baseline performance analysis for bounding box and segmentation detection
results using a Deformable Parts Model.


Localizing and Orienting Street Views Using Overhead Imagery

  In this paper we aim to determine the location and orientation of a
ground-level query image by matching to a reference database of overhead (e.g.
satellite) images. For this task we collect a new dataset with one million
pairs of street view and overhead images sampled from eleven U.S. cities. We
explore several deep CNN architectures for cross-domain matching --
Classification, Hybrid, Siamese, and Triplet networks. Classification and
Hybrid architectures are accurate but slow since they allow only partial
feature precomputation. We propose a new loss function which significantly
improves the accuracy of Siamese and Triplet embedding networks while
maintaining their applicability to large-scale retrieval tasks like image
geolocalization. This image matching task is challenging not just because of
the dramatic viewpoint difference between ground-level and overhead imagery but
because the orientation (i.e. azimuth) of the street views is unknown making
correspondence even more difficult. We examine several mechanisms to match in
spite of this -- training for rotation invariance, sampling possible rotations
at query time, and explicitly predicting relative rotation of ground and
overhead images with our deep networks. It turns out that explicit orientation
supervision also improves location prediction accuracy. Our best performing
architectures are roughly 2.5 times as accurate as the commonly used Siamese
network baseline.


Geometry-Aware Learning of Maps for Camera Localization

  Maps are a key component in image-based camera localization and visual SLAM
systems: they are used to establish geometric constraints between images,
correct drift in relative pose estimation, and relocalize cameras after lost
tracking. The exact definitions of maps, however, are often
application-specific and hand-crafted for different scenarios (e.g. 3D
landmarks, lines, planes, bags of visual words). We propose to represent maps
as a deep neural net called MapNet, which enables learning a data-driven map
representation. Unlike prior work on learning maps, MapNet exploits cheap and
ubiquitous sensory inputs like visual odometry and GPS in addition to images
and fuses them together for camera localization. Geometric constraints
expressed by these inputs, which have traditionally been used in bundle
adjustment or pose-graph optimization, are formulated as loss terms in MapNet
training and also used during inference. In addition to directly improving
localization accuracy, this allows us to update the MapNet (i.e., maps) in a
self-supervised manner using additional unlabeled video sequences from the
scene. We also propose a novel parameterization for camera rotation which is
better suited for deep-learning based camera pose regression. Experimental
results on both the indoor 7-Scenes dataset and the outdoor Oxford RobotCar
dataset show significant performance improvement over prior work. The MapNet
project webpage is https://goo.gl/mRB3Au.


Let's Dance: Learning From Online Dance Videos

  In recent years, deep neural network approaches have naturally extended to
the video domain, in their simplest case by aggregating per-frame
classifications as a baseline for action recognition. A majority of the work in
this area extends from the imaging domain, leading to visual-feature heavy
approaches on temporal data. To address this issue we introduce "Let's Dance",
a 1000 video dataset (and growing) comprised of 10 visually overlapping dance
categories that require motion for their classification. We stress the
important of human motion as a key distinguisher in our work given that, as we
show in this work, visual information is not sufficient to classify
motion-heavy categories. We compare our datasets' performance using imaging
techniques with UCF-101 and demonstrate this inherent difficulty. We present a
comparison of numerous state-of-the-art techniques on our dataset using three
different representations (video, optical flow and multi-person pose data) in
order to analyze these approaches. We discuss the motion parameterization of
each of them and their value in learning to categorize online dance videos.
Lastly, we release this dataset (and its three representations) for the
research community to use.


Bubbling AdS and droplet descriptions of BPS geometries in IIB
  supergravity

  This paper focuses on supergravity duals of BPS states in N=4 super
Yang-Mills. In order to describe these duals, we begin with a sequence of
breathing mode reductions of IIB supergravity: first on S^3, then S^3 x S^1,
and finally on S^3 x S^1 x CP^1. We then follow with a complete supersymmetry
analysis, yielding 1/8, 1/4 and 1/2 BPS configurations, respectively (where in
the last step we take the Hopf fibration of S^3). The 1/8 BPS geometries, which
have an S^3 isometry and are time-fibered over a six-dimensional base, are
determined by solving a non-linear equation for the Kahler metric on the base.
Similarly, the 1/4 BPS configurations have an S^3 x S^1 isometry and a
four-dimensional base, whose Kahler metric obeys another non-linear,
Monge-Ampere type equation.
  Despite the non-linearity of the problem, we develop a universal bubbling AdS
description of these geometries by focusing on the boundary conditions which
ensure their regularity. In the 1/8 BPS case, we find that the S^3 cycle
shrinks to zero size on a five-dimensional locus inside the six-dimensional
base. Enforcing regularity of the full solution requires that the interior of a
smooth, generally disconnected five-dimensional surface be removed from the
base. The AdS_5 x S^5 ground state corresponds to excising the interior of an
S^5, while the 1/8 BPS excitations correspond to deformations (including
topology change) of the S^5 and/or the excision of additional droplets from the
base. In the case of 1/4 BPS configurations, by enforcing regularity
conditions, we identify three-dimensional surfaces inside the four-dimensional
base which separate the regions where the S^3 shrinks to zero size from those
where the S^1 shrinks.


About AGN ionization echoes, thermal echoes, and ionization deficits in
  low redshift Lyman-alpha blobs

  We report the discovery of 14 Lyman-alpha blobs (LABs) at z~0.3, existing at
least 4-7 billion years later in the Universe than all other LABs known. Their
optical diameters are 20-70 kpc, and GALEX data imply Ly-alpha luminosities of
(0.4-6.3)x10^43 erg/s. Contrary to high-z LABs, they live in low-density areas.
They are ionized by AGN, suggesting that cold accretion streams as a power
source must deplete between z=2 and z=0.3. We also show that transient AGN
naturally explain the ionization deficits observed in many LABs: Their Ly-alpha
and X-ray fluxes decorrelate below 10^6 years because of the delayed escape of
resonantly scattering Ly-alpha photons. High Ly-alpha luminosities do not
require currently powerful AGN, independent of obscuration. Chandra X-ray data
reveal intrinsically weak AGN, confirming the luminous optical nebulae as
impressive ionization echoes. For the first time, we also report mid-infrared
thermal echoes from the dusty tori. We conclude that the AGN have faded by 3-4
orders of magnitude within the last 10^(4-5) years, leaving fossil UV, optical
and thermal radiation behind. The host galaxies belong to the group of
previously discovered Green Bean galaxies (GBs). Gemini optical imaging reveals
smooth spheres, mergers, spectacular outflows and ionization cones. Because of
their proximity and high flux densities, GBs are perfect targets to study AGN
feedback, mode switching and the Ly-alpha escape. The fully calibrated, coadded
optical FITS images are publicly available.


The disappearing act: A dusty wind eclipsing RW Aur

  RW Aur is a young binary star that experienced a deep dimming in 2010-11 in
component A and a second even deeper dimming from summer 2014 to summer 2016.
We present new unresolved multi-band photometry during the 2014-16 eclipse, new
emission line spectroscopy before and during the dimming, archive infrared
photometry between 2014-15, as well as an overview of literature data.
  Spectral observations were carried out with the Fibre-fed RObotic Dual-beam
Optical Spectrograph on the Liverpool Telescope. Photometric monitoring was
done with the Las Cumbres Observatory Global Telescope Network and James
Gregory Telescope. Our photometry shows that RW Aur dropped in brightness to R
= 12.5 in March 2016. In addition to the long-term dimming trend, RW Aur is
variable on time scales as short as hours. The short-term variation is most
likely due to an unstable accretion flow. This, combined with the presence of
accretion-related emission lines in the spectra suggest that accretion flows in
the binary system are at least partially visible during the eclipse.
  The equivalent width of [O I] increases by a factor of ten in 2014,
coinciding with the dimming event, confirming previous reports. The
blue-shifted part of the $H\alpha$ profile is suppressed during the eclipse. In
combination with the increase in mid-infrared brightness during the eclipse
reported in the literature and seen in WISE archival data, and constraints on
the geometry of the disk around RW Aur A we arrive at the conclusion that the
obscuring screen is part of a wind emanating from the inner disk.


The detection of an extremely bright fast radio burst in a phased array
  feed survey

  We report the detection of an ultra-bright fast radio burst (FRB) from a
modest, 3.4-day pilot survey with the Australian Square Kilometre Array
Pathfinder. The survey was conducted in a wide-field fly's-eye configuration
using the phased-array-feed technology deployed on the array to instantaneously
observe an effective area of $160$ deg$^2$, and achieve an exposure totaling
$13200$ deg$^2$ hr. We constrain the position of FRB 170107 to a region
$8'\times8'$ in size (90% containment) and its fluence to be $58\pm6$ Jy ms.
The spectrum of the burst shows a sharp cutoff above $1400$ MHz, which could be
either due to scintillation or an intrinsic feature of the burst. This confirms
the existence of an ultra-bright ($>20$ Jy ms) population of FRBs.


SDSS-IV MaNGA IFS Galaxy Survey --- Survey Design, Execution, and
  Initial Data Quality

  The MaNGA Survey (Mapping Nearby Galaxies at Apache Point Observatory) is one
of three core programs in the Sloan Digital Sky Survey IV. It is obtaining
integral field spectroscopy (IFS) for 10K nearby galaxies at a spectral
resolution of R~2000 from 3,622-10,354A. The design of the survey is driven by
a set of science requirements on the precision of estimates of the following
properties: star formation rate surface density, gas metallicity, stellar
population age, metallicity, and abundance ratio, and their gradients; stellar
and gas kinematics; and enclosed gravitational mass as a function of radius. We
describe how these science requirements set the depth of the observations and
dictate sample selection. The majority of targeted galaxies are selected to
ensure uniform spatial coverage in units of effective radius (Re) while
maximizing spatial resolution. About 2/3 of the sample is covered out to 1.5Re
(Primary sample), and 1/3 of the sample is covered to 2.5Re (Secondary sample).
We describe the survey execution with details that would be useful in the
design of similar future surveys. We also present statistics on the achieved
data quality, specifically, the point spread function, sampling uniformity,
spectral resolution, sky subtraction, and flux calibration. For our Primary
sample, the median r-band signal-to-noise ratio is ~73 per 1.4A pixel for
spectra stacked between 1-1.5 Re. Measurements of various galaxy properties
from the first year data show that we are meeting or exceeding the defined
requirements for the majority of our science goals.


Overview of the SDSS-IV MaNGA Survey: Mapping Nearby Galaxies at Apache
  Point Observatory

  We present an overview of a new integral field spectroscopic survey called
MaNGA (Mapping Nearby Galaxies at Apache Point Observatory), one of three core
programs in the fourth-generation Sloan Digital Sky Survey (SDSS-IV) that began
on 2014 July 1. MaNGA will investigate the internal kinematic structure and
composition of gas and stars in an unprecedented sample of 10,000 nearby
galaxies. We summarize essential characteristics of the instrument and survey
design in the context of MaNGA's key science goals and present prototype
observations to demonstrate MaNGA's scientific potential. MaNGA employs
dithered observations with 17 fiber-bundle integral field units that vary in
diameter from 12" (19 fibers) to 32" (127 fibers). Two dual-channel
spectrographs provide simultaneous wavelength coverage over 3600-10300 A at
R~2000. With a typical integration time of 3 hr, MaNGA reaches a target r-band
signal-to-noise ratio of 4-8 (per A, per 2" fiber) at 23 AB mag per sq. arcsec,
which is typical for the outskirts of MaNGA galaxies. Targets are selected with
stellar mass greater than 1e9 Msun using SDSS-I redshifts and i-band luminosity
to achieve uniform radial coverage in terms of the effective radius, an
approximately flat distribution in stellar mass, and a sample spanning a wide
range of environments. Analysis of our prototype observations demonstrates
MaNGA's ability to probe gas ionization, shed light on recent star formation
and quenching, enable dynamical modeling, decompose constituent components, and
map the composition of stellar populations. MaNGA's spatially resolved spectra
will enable an unprecedented study of the astrophysics of nearby galaxies in
the coming 6 yr.


Observations of Milky Way Dwarf Spheroidal galaxies with the Fermi-LAT
  detector and constraints on Dark Matter models

  We report on the observations of 14 dwarf spheroidal galaxies with the Fermi
Gamma-Ray Space Telescope taken during the first 11 months of survey mode
operations. The Fermi telescope provides a new opportunity to test particle
dark matter models through the expected gamma-ray emission produced by pair
annihilation of weakly interacting massive particles (WIMPs). Local Group dwarf
spheroidal galaxies, the largest galactic substructures predicted by the cold
dark matter scenario, are attractive targets for such indirect searches for
dark matter because they are nearby and among the most extreme dark matter
dominated environments. No significant gamma-ray emission was detected above
100 MeV from the candidate dwarf galaxies. We determine upper limits to the
gamma-ray flux assuming both power-law spectra and representative spectra from
WIMP annihilation. The resulting integral flux above 100 MeV is constrained to
be at a level below around 10^-9 photons cm^-2 s^-1. Using recent stellar
kinematic data, the gamma-ray flux limits are combined with improved
determinations of the dark matter density profile in 8 of the 14 candidate
dwarfs to place limits on the pair annihilation cross-section of WIMPs in
several widely studied extensions of the standard model. With the present data,
we are able to rule out large parts of the parameter space where the thermal
relic density is below the observed cosmological dark matter density and WIMPs
(neutralinos here) are dominantly produced non-thermally, e.g. in models where
supersymmetry breaking occurs via anomaly mediation. The gamma-ray limits
presented here also constrain some WIMP models proposed to explain the Fermi
and PAMELA e^+e^- data, including low-mass wino-like neutralinos and models
with TeV masses pair-annihilating into muon-antimuon pairs. (Abridged)


Discovery of HI gas in a young radio galaxy at $z = 0.44$ using the
  Australian Square Kilometre Array Pathfinder

  We report the discovery of a new 21-cm HI absorption system using
commissioning data from the Boolardy Engineering Test Array of the Australian
Square Kilometre Array Pathfinder (ASKAP). Using the 711.5 - 1015.5 MHz band of
ASKAP we were able to conduct a blind search for the 21-cm line in a continuous
redshift range between $z = 0.4$ and 1.0, which has, until now, remained
largely unexplored. The absorption line is detected at $z = 0.44$ towards the
GHz-peaked spectrum radio source PKS B1740$-$517 and demonstrates ASKAP's
excellent capability for performing a future wide-field survey for HI
absorption at these redshifts. Optical spectroscopy and imaging using the
Gemini-South telescope indicates that the HI gas is intrinsic to the host
galaxy of the radio source. The narrow OIII emission lines show clear
double-peaked structure, indicating either large-scale outflow or rotation of
the ionized gas. Archival data from the \emph{XMM-Newton} satellite exhibit an
absorbed X-ray spectrum that is consistent with a high column density obscuring
medium around the active galactic nucleus. The HI absorption profile is
complex, with four distinct components ranging in width from 5 to 300 km
s$^{-1}$ and fractional depths from 0.2 to 20 per cent. In addition to systemic
HI gas, in a circumnuclear disc or ring structure aligned with the radio jet,
we find evidence for a possible broad outflow of neutral gas moving at a radial
velocity of $v \sim 300$ km s$^{-1}$. We infer that the expanding young radio
source ($t_{\rm age} \approx 2500$ yr) is cocooned within a dense medium and
may be driving circumnuclear neutral gas in an outflow of $\sim$ 1
$\mathrm{M}_{\odot}$ yr$^{-1}$.


The NuMI Neutrino Beam

  This paper describes the hardware and operations of the Neutrinos at the Main
Injector (NuMI) beam at Fermilab. It elaborates on the design considerations
for the beam as a whole and for individual elements. The most important design
details of individual components are described. Beam monitoring systems and
procedures, including the tuning and alignment of the beam and NuMI long-term
performance, are also discussed.


The 2010 Interim Report of the Long-Baseline Neutrino Experiment
  Collaboration Physics Working Groups

  In early 2010, the Long-Baseline Neutrino Experiment (LBNE) science
collaboration initiated a study to investigate the physics potential of the
experiment with a broad set of different beam, near- and far-detector
configurations. Nine initial topics were identified as scientific areas that
motivate construction of a long-baseline neutrino experiment with a very large
far detector. We summarize the scientific justification for each topic and the
estimated performance for a set of far detector reference configurations. We
report also on a study of optimized beam parameters and the physics capability
of proposed Near Detector configurations. This document was presented to the
collaboration in fall 2010 and updated with minor modifications in early 2011.


Searches for the Higgs boson decaying to W^{+} W^{-} -> l^{+}nu
  l^{-}nubar with the CDF II detector

  We present a search for a standard model Higgs boson decaying to two $W$
bosons that decay to leptons using the full data set collected with the CDF II
detector in $\sqrt{s}=1.96$ TeV $p\bar{p}$ collisions at the Fermilab Tevatron,
corresponding to an integrated luminosity of 9.7 fb${}^{-1}$. We obtain no
evidence for production of a standard model Higgs boson with mass between 110
and 200 GeV/$c^2$, and place upper limits on the production cross section
within this range. We exclude standard model Higgs boson production at the 95%
confidence level in the mass range between 149 and 172 GeV/$c^2$, while
expecting to exclude, in the absence of signal, the range between 155 and 175
GeV/$c^2$. We also interpret the search in terms of standard model Higgs boson
production in the presence of a fourth generation of fermions and within the
context of a fermiophobic Higgs boson model. For the specific case of a
standard model-like Higgs boson in the presence of fourth-generation fermions,
we exclude at the 95% confidence level Higgs boson production in the mass range
between 124 and 200 GeV/$c^2$, while expecting to exclude, in the absence of
signal, the range between 124 and 221 GeV/$c^2$.


Identifying the Best Machine Learning Algorithms for Brain Tumor
  Segmentation, Progression Assessment, and Overall Survival Prediction in the
  BRATS Challenge

  Gliomas are the most common primary brain malignancies, with different
degrees of aggressiveness, variable prognosis and various heterogeneous
histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic
core, active and non-enhancing core. This intrinsic heterogeneity is also
portrayed in their radio-phenotype, as their sub-regions are depicted by
varying intensity profiles disseminated across multi-parametric magnetic
resonance imaging (mpMRI) scans, reflecting varying biological properties.
Their heterogeneous shape, extent, and location are some of the factors that
make these tumors difficult to resect, and in some cases inoperable. The amount
of resected tumor is a factor also considered in longitudinal scans, when
evaluating the apparent tumor for potential diagnosis of progression.
Furthermore, there is mounting evidence that accurate segmentation of the
various tumor sub-regions can offer the basis for quantitative image analysis
towards prediction of patient overall survival. This study assesses the
state-of-the-art machine learning (ML) methods used for brain tumor image
analysis in mpMRI scans, during the last seven instances of the International
Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we
focus on i) evaluating segmentations of the various glioma sub-regions in
pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue
of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO
criteria, and iii) predicting the overall survival from pre-operative mpMRI
scans of patients that underwent gross total resection. Finally, we investigate
the challenge of identifying the best ML algorithms for each of these tasks,
considering that apart from being diverse on each instance of the challenge,
the multi-institutional mpMRI BraTS dataset has also been a continuously
evolving/growing dataset.


Measurement of the top quark forward-backward production asymmetry and
  its dependence on event kinematic properties

  We present new measurements of the inclusive forward-backward ttbar
production asymmetry, AFB, and its dependence on several properties of the
ttbar system. The measurements are performed with the full Tevatron data set
recorded with the CDF II detector during ppbar collisions at sqrt(s) = 1.96
TeV, corresponding to an integrated luminosity of 9.4 fb^(-1). We measure the
asymmetry using the rapidity difference Delta-y=y_(t)-y_(tbar). Parton-level
results are derived, yielding an inclusive asymmetry of 0.164+/-0.047 (stat +
syst). We observe a linear dependence of AFB on the top-quark pair mass
M(ttbar) and the rapidity difference |Delta-y| at detector and parton levels.
Assuming the standard model, the probabilities to observe the measured values
or larger for the detector-level dependencies are 7.4*10^(-3) and 2.2*10^(-3)
for M(ttbar) and |Delta-y| respectively. Lastly, we study the dependence of the
asymmetry on the transverse momentum of the ttbar system at the detector level.
These results are consistent with previous lower-precision measurements and
provide additional quantification of the functional dependencies of the
asymmetry.


Exclusion of exotic top-like quarks with -4/3 electric charge using
  jet-charge tagging in single-lepton ttbar events at CDF

  We report on a measurement of the top-quark electric charge in ttbar events
in which one W boson originating from the top-quark pair decays into leptons
and the other into hadrons. The event sample was collected by the CDF II
detector in sqrt(s)=1.96 TeV proton-antiproton collisions and corresponds to
5.6 fb^(-1). We find the data to be consistent with the standard model and
exclude the existence of an exotic quark with -4/3 electric charge and mass of
the conventional top quark at the 99% confidence level.


Measurement of the Differential Cross Section dσ/d(cos θt)
  for Top-Quark Pair Production in p-pbar Collisions at sqrt{s} = 1.96 TeV

  We report a measurement of the differential cross section, d{\sigma}/d(cos
{\theta}t), for top-quark-pair production as a function of the top-quark
production angle in proton-antiproton collisions at sqrt{s} = 1.96 TeV. This
measurement is performed using data collected with the CDF II detector at the
Tevatron, corresponding to an integrated luminosity of 9.4/fb. We employ the
Legendre polynomials to characterize the shape of the differential cross
section at the parton level. The observed Legendre coefficients are in good
agreement with the prediction of the next-to-leading-order standard-model
calculation, with the exception of an excess linear-term coefficient, a1 = 0.40
+- 0.12, compared to the standard-model prediction of a1 =
0.15^{+0.07}_{-0.03}.


Measurement of the leptonic asymmetry in ttbar events produced in ppbar
  collisions at sqrt(s)=1.96 TeV

  We measure the asymmetry in the charge-weighted rapidity of the lepton in
semileptonic ttbar decays recorded with the CDF II detector using the full
Tevatron Run II sample, corresponding to an integrated luminosity of 9.4/fb. A
parametrization of the asymmetry as a function of the charge-weighted rapidity
is used to correct for the finite acceptance of the detector and recover the
production-level asymmetry. The result of afb(lep) = 0.094 +0.032 -0.029 is to
be compared to the standard model next-to-leading-order prediction of afb(lep)
= 0.038 +-0.003.


Evidence for a bottom baryon resonance Lambda_b* in CDF data

  Using data from proton-antiproton collisions at Ecms=1.96 TeV recorded by the
CDF II detector at the Fermilab Tevatron, evidence for the excited resonance
state Lambda_b* is presented in its Lambda_b0 pi+ pi- decay, followed by the
Lambda_b0 -->Lambda_c+ (-->proton K- pi+) pi- decays. The analysis is based on
a data sample corresponding to an integrated luminosity of 9.6/fb collected by
an online event selection based on charged-particle tracks displaced from the
proton-antiproton interaction point. The significance of the observed signal is
3.5 Gaussian sigmas. The mass of the observed state is found to be 5919.22 +-
0.76 MeV in agreement with similar findings in proton-proton collision
experiments.


A Direct Measurement of the Total Decay Width of the Top Quark

  We present a measurement of the total decay width of the top quark using
events with top-antitop-quark pair candidates reconstructed in the final state
with one charged lepton and four or more hadronic jets. We use the full
Tevatron Run II data set of $\sqrt{s} = 1.96$ TeV proton-antiproton collisions
recorded by the CDF II detector. The top-quark mass and the mass of the
hadronically-decaying $W$ boson are reconstructed for each event and compared
with distributions derived from simulated signal and background samples to
extract the top-quark width (\gmt) and the energy scale of the calorimeter jets
with {\it in-situ} calibration. For a top-quark mass $\mtop = \gevcc{172.5}$,
we find $1.10<\gmt<\gev{4.05}$ at 68% confidence level, which is in agreement
with the standard-model expectation of \gev{1.3} and is the most precise direct
measurement of the top-quark width to date.


Search for the production of ZW and ZZ boson pairs decaying into charged
  leptons and jets in proton-antiproton collisions at sqrt(s)=1.96 TeV

  We present a measurement of the production cross section for ZW and ZZ boson
pairs in final states with a pair of charged leptons, from the decay of a Z
boson, and at least two jets, from the decay of a W or Z boson, using the full
sample of proton-antiproton collisions recorded with the CDF II detector at the
Tevatron, corresponding to 8.9 fb^(-1) of integrated luminosity. We increase
the sensitivity to vector boson decays into pairs of quarks using a neural
network discriminant that exploits the differences between the spatial spread
of energy depositions and charged-particle momenta contained within the jet of
particles originating from quarks and gluons. Additionally, we employ new jet
energy corrections to Monte Carlo simulations that account for differences in
the observed energy scales for quark and gluon jets. The number of signal
events is extracted through a simultaneous fit to the dijet mass spectrum in
three classes of events: events likely to contain jets with a heavy-quark
decay, events likely to contain jets originating from light quarks, and events
that fail these identification criteria. We determine the production cross
section to be 2.5 +2.0 -1.0 pb (< 6.1 pb at the 95% confidence level),
consistent with the standard model prediction of 5.1 pb.


A search for dark matter in events with one jet and missing transverse
  energy in pp-bar collisions at sqrt(s) = 1.96 TeV

  We present the results of a search for dark matter production in the monojet
signature. We analyze a sample of Tevatron pp-bar collisions at sqrt(s)=1.96
TeV corresponding to an integrated luminosity of 6.7/fb recorded by the CDF II
detector. In events with large missing transverse energy and one energetic jet,
we find good agreement between the standard model prediction and the observed
data. We set 90% confidence level upper limits on the dark matter production
rate. The limits are translated into bounds on nucleon-dark matter scattering
rates which are competitive with current direct detection bounds on
spin-independent interaction below a dark matter candidate mass of 5 GeV/c^2,
and on spin-dependent interactions up to masses of 200 GeV/c^2.


Search for the Standard Model Higgs Boson Produced in Association with a
  $Z$ Boson in $p\bar{p}$ Collisions at $\sqrt{s} = 1.96$ TeV

  We present a search for the standard model Higgs boson produced in
association with a $Z$ boson, using up to 7.9 fb$^{-1}$ of integrated
luminosity from $p\bar{p}$ collisions collected with the CDF II detector. We
utilize several novel techniques, including multivariate lepton selection,
multivariate trigger parametrization, and a multi-stage signal discriminant
consisting of specialized functions trained to distinguish individual
backgrounds. By increasing acceptance and enhancing signal discrimination,
these techniques have significantly improved the sensitivity of the analysis
above what was expected from a larger dataset alone. We observe no significant
evidence for a signal, and we set limits on the $ZH$ production cross section.
For a Higgs boson with mass 115 GeV/$c^2$, we expect (observe) a limit of 3.9
(4.8) times the standard model predicted value, at the 95% credibility level.


Updated search for the standard model Higgs boson in events with jets
  and missing transverse energy using the full CDF data set

  We present an updated search for the Higgs boson produced in association with
a vector boson in the final state with missing transverse energy and two jets.
We use the full CDF data set corresponding to an integrated luminosity of 9.45
fb${}^{-1}$ at a proton-antiproton center-of-mass energy of $\sqrt{s}=1.96$
TeV. New to this analysis is the inclusion of a $b$-jet identification
algorithm specifically optimized for $H\to b\bar{b}$ searches. Across the Higgs
boson mass range $90 \le m_H \le 150$ GeV$/c^2$, the expected 95% credibility
level upper limits on the $V H$ production cross section times the $H\to
b\bar{b}$ branching fraction are improved by an average of 14% relative to the
previous analysis. At a Higgs boson mass of 125 GeV$/c^2$, the observed
(expected) limit is 3.06 (3.33) times the standard model prediction,
corresponding to one of the most sensitive searches to date in this final
state.


A signature-based search for delayed photons in exclusive photon plus
  missing transverse energy events from $p \bar{p}$ collisions with $\sqrt{s} =
  1.96$ TeV

  We present the first signature-based search for delayed photons using an
exclusive photon plus missing transverse energy final state. Events are
reconstructed in a data sample from the CDF II detector corresponding to $6.3
\text{fb}^{-1}$ of integrated luminosity from $\sqrt{s}=1.96$ TeV
proton-antiproton collisions. Candidate events are selected if they contain a
photon with an arrival time in the detector larger than expected from a
promptly-produced photon. The mean number of events from standard model sources
predicted by the data-driven background model based on the photon timing
distribution is $286 \pm 24$. A total of 322 events are observed. A $p$-value
of 12% is obtained, showing consistency of the data with standard model
predictions.


Measurement of \boldmath $R = {\mathcal{B}\left(t \rightarrow Wb
  \right)/\mathcal{B}\left(t \rightarrow Wq \right)} $ in Top--Quark--Pair
  Decays using Dilepton Events and the Full CDF Run II Data Set

  We present a measurement of the ratio of the top-quark branching fractions
$R=\mathcal{B}(t\rightarrow Wb)/\mathcal{B}(t\rightarrow $ $q$ represents
quarks of flavors $b$, $s$, or $d$, in the final state, in events with two
charged leptons, missing transverse energy and at least two jets. The
measurement uses $\sqrt{s}$ = 1.96 TeV proton--antiproton collision data
corresponding to an integrated luminosity of 8.7 fb$^{-1}$ and collected with
the Collider Detector at Fermilab during Run II of the Tevatron. We measure
$R=0.87 \pm 0.07$ (stat+syst), and extract the magnitude of the
Cabibbo-Kobayashi-Maskawa matrix element, $\left|V_{tb}\right| = 0.93 \pm 0.04$
(stat+syst) assuming three generations of quarks. Under these assumptions, a
lower limit of $|V_{tb}|>0.85$ at 95% credibility level is set.


Measurement of the inclusive leptonic asymmetry in top-quark pairs that
  decay to two charged leptons at CDF

  We measure the inclusive forward-backward asymmetry of the charged-lepton
pseudorapidities from top-quark pairs produced in proton-antiproton collisions,
and decaying to final states that contain two charged leptons (electrons or
muons), using data collected with the Collider Detector at Fermilab. With an
integrated luminosity of 9.1 $\rm{fb}^{-1}$, the leptonic forward-backward
asymmetry, $A_{\text{FB}}^{\ell}$, is measured to be $0.072 \pm 0.060$ and the
leptonic pair forward-backward asymmetry, $A_{\text{FB}}^{\ell\ell}$, is
measured to be $0.076 \pm 0.082$, compared with the standard model predictions
of $A_{\text{FB}}^{\ell} = 0.038 \pm 0.003$ and $A_{\text{FB}}^{\ell\ell} =
0.048 \pm 0.004$, respectively. Additionally, we combine the
$A_{\text{FB}}^{\ell}$ result with a previous determination from a final state
with a single lepton and hadronic jets and obtain $A_{\text{FB}}^{\ell} =
0.090^{+0.028}_{-0.026}$.


Measurement of differential production cross section for $Z/γ^*$
  bosons in association with jets in $p\bar{p}$ collisions at $\sqrt{s}=1.96$
  TeV

  Differential cross sections for the production of $Z$ bosons or off-shell
photons $\gamma^*$ in association with jets are measured in proton-antiproton
collisions at center-of-mass energy $\sqrt{s}=1.96$ TeV using the full data set
collected with the Collider Detector at Fermilab in Tevatron Run II, and
corresponding to 9.6 fb$^{-1}$ of integrated luminosity. Results include first
measurements at CDF of differential cross sections in events with a
$Z/\gamma^*$ boson and three or more jets, the inclusive cross section for
production of $Z/\gamma^*$ and four or more jets, and cross sections as
functions of various angular observables in lower jet-multiplicity final
states. Measured cross sections are compared to several theoretical
predictions.


