Quantitative complementarity between local and nonlocal character of  quantum states in a three-qubit system

  Local or nonlocal character of quantum states can be quantified and issubject to various bounds that can be formulated as complementarity relations.Here, we investigate the local vs. nonlocal character of pure three-qubitstates by a four-way interferometer. The complete entanglement in the systemcan be measured as the entanglement of a specific qubit with the subsystemconsisting of the other two qubits. The quantitative complementarity relationsare verified experimentally in an NMR quantum information processor.

3D Single-port Labyrinthine Acoustic Metamaterial

  In this paper, we report on the design, fabrication, and experimentalcharacterization of a 3D single-port labyrinthine acoustic metamaterial. Byusing curled perforations with one end closed and with appropriate loss inside,the proposed metamaterial can perfectly absorb airborne sounds in a lowfrequency band. Both the position and width of the band can be tuned flexibly.A tradeoff is uncovered between the relative absorption bandwidth and thicknessof the metamaterial. When the relative absorption bandwidth is as high as 51%,the requirement of deep subwavelength thickness (0.07{\lambda}) can still besatisfied.

Zero-energy proton dissociation of H$_2^+$ through stimulated Raman  scattering

  We show that (near-)zero energy proton emission from H$_2^+$ in strongtwo-color and broadband laser fields is dominated by a stimulated Ramanscattering process taking place on the electronic ground state. It isfurthermore shown that in the (near-)zero energy region the asymmetry in protonejection induced by asymmetric laser fields is due to the interplay of severalprocesses, rather than only pathway interferences, with vibrational trapping(or bond-hardening) taking a key role.

Regularized Risk Minimization by Nesterov's Accelerated Gradient  Methods: Algorithmic Extensions and Empirical Studies

  Nesterov's accelerated gradient methods (AGM) have been successfully appliedin many machine learning areas. However, their empirical performance ontraining max-margin models has been inferior to existing specialized solvers.In this paper, we first extend AGM to strongly convex and composite objectivefunctions with Bregman style prox-functions. Our unifying framework covers boththe $\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constantadaptively, and bounds the duality gap. Then we demonstrate various ways toapply this framework of methods to a wide range of machine learning problems.Emphasis will be given on their rate of convergence and how to efficientlycompute the gradient and optimize the models. The experimental results showthat with our extensions AGM outperforms state-of-the-art solvers on max-marginmodels.

Smoothing Multivariate Performance Measures

  A Support Vector Method for multivariate performance measures was recentlyintroduced by Joachims (2005). The underlying optimization problem is currentlysolved using cutting plane methods such as SVM-Perf and BMRM. One can show thatthese algorithms converge to an eta accurate solution in O(1/Lambda*e)iterations, where lambda is the trade-off parameter between the regularizer andthe loss function. We present a smoothing strategy for multivariate performancescores, in particular precision/recall break-even point and ROCArea. Whencombined with Nesterov's accelerated gradient algorithm our smoothing strategyyields an optimization algorithm which converges to an eta accurate solution inO(min{1/e,1/sqrt(lambda*e)}) iterations. Furthermore, the cost per iteration ofour scheme is the same as that of SVM-Perf and BMRM. Empirical evaluation on anumber of publicly available datasets shows that our method convergessignificantly faster than cutting plane methods without sacrificinggeneralization ability.

Regularizers versus Losses for Nonlinear Dimensionality Reduction: A  Factored View with New Convex Relaxations

  We demonstrate that almost all non-parametric dimensionality reductionmethods can be expressed by a simple procedure: regularized loss minimizationplus singular value truncation. By distinguishing the role of the loss andregularizer in such a process, we recover a factored perspective that revealssome gaps in the current literature. Beyond identifying a useful new loss formanifold unfolding, a key contribution is to derive new convex regularizersthat combine distance maximization with rank reduction. These regularizers canbe applied to any loss.

Quantum simulation of a system with competing two- and three-body  interactions

  Quantum phase transitions occur at zero temperature, when the ground state ofa Hamiltonian undergoes a qualitative change as a function of a controlparameter. We consider a particularly interesting system with competing one-,two- and three-body interactions. Depending on the relative strength of theseinteractions, the ground state of the system can be a product state, or it canexhibit genuine tripartite entanglement. We experimentally simulate such asystem in an NMR quantum simulator and observe the different ground states. Byadiabatically changing the strength of one coupling constant, we push thesystem from one ground state to a qualitatively different ground state. We showthat these ground states can be distinguished and the transitions between themobserved by measuring correlations between the spins or the expectation valuesof suitable entanglement witnesses.

Hybrid magic state distillation for universal fault-tolerant quantum  computation

  A set of stabilizer operations augmented by some special initial states knownas 'magic states', gives the possibility of universal fault-tolerant quantumcomputation. However, magic state preparation inevitably involves nonidealoperations that introduce noise. The most common method to eliminate the noiseis magic state distillation (MSD) by stabilizer operations. Here we propose ahybrid MSD protocol by connecting a four-qubit H-type MSD with a five-qubitT-type MSD, in order to overcome some disadvantages of the previous MSDprotocols. The hybrid MSD protocol further integrates distillable ranges ofdifferent existing MSD protocols and extends the T-type distillable range tothe stabilizer octahedron edges. And it provides considerable improvement inqubit cost for almost all of the distillable range. Moreover, we experimentallydemonstrate the four-qubit H-type MSD protocol using nuclear magnetic resonancetechnology, together with the previous five-qubit MSD experiment, to show thefeasibility of the hybrid MSD protocol.

Channel-resolved subcycle interferences of electron wave packets emitted  from H$_2$ in two-color laser fields

  We report on the observation of subcycle interferences of electron wavepackets released during the strong field ionization of H$_2$ with cycle-shapedtwo-color laser fields. With a reaction microscope, channel-resolvedphotoelectron momentum distribution are obtained for different final productsoriginating from single ionization of H$_2$. Our results show that the subcycleinterference structures of electron wave packet are very sensitive to thecycle-shape of the two-color laser field. The reason is that the ionizationtime within an optical cycle is determined by the cycle-shape of the laserfield. The subcycle interference structures can be further used to get thesubcycle dynamics of molecules during strong field interaction.

Knowledge-aided Two-dimensional Autofocus for Spotlight SAR Filtered  Backprojection Imagery

  Filtered backprojection (FBP) algorithm is a popular choice for complicatedtrajectory SAR image formation processing due to its inherent nonlinear motioncompensation capability. However, how to efficiently autofocus the defocusedFBP imagery when the motion measurement is not accurate enough is still achallenging problem. In this paper, a new interpretation of the FBP derivationis presented from the Fourier transform point of view. Based on this newviewpoint, the property of the residual 2-D phase error in FBP imagery isanalyzed in detail. Then, by incorporating the derived a priori knowledge onthe 2-D phase error, an accurate and efficient 2-D autofocus approach isproposed. The new approach performs the parameter estimation in adimension-reduced parameter subspace by exploiting the a priori analyticalstructure of the 2-D phase error, therefore possesses much higher accuracy andefficiency than conventional blind methods. Finally, experimental resultsclearly demonstrate the effectiveness and robustness of the proposed method.

Speedup of quantum state transfer by three- qubit interactions:  Implementation by nuclear magnetic resonance

  Universal quantum information processing requires single-qubit rotations andtwo-qubit interactions as minimal resources. A possible step beyond thisminimal scheme is the use of three-qubit interactions. We consider suchthree-qubit interactions and show how they can reduce the time required for aquantum state transfer in an XY spin chain. For the experimentalimplementation, we use liquid-state nuclear magnetic resonance (NMR), wherethree-qubit interactions can be implemented by sequences of radio-frequencypulses.

Localizing High-Lying Rydberg Wave Packets with Two-Color Laser Fields

  We demonstrate control over the localization of high-lying Rydberg wavepackets in argon atoms with phase-locked orthogonally polarized two-color (OTC)laser fields. With a reaction microscope, we measured ionization signals ofhigh-lying Rydberg states induced by a weak dc field and black-body radiationas a function of the relative phase between the two-color fields. We find thatthe dc-field ionization yields of high-lying Rydberg argon atoms oscillate withthe relative two-color phase with a period of $2\pi$ while the photoionizationsignal by black-body radiation shows a period of $\pi$. These observations area clear signature of the asymmetric localization of electrons recaptured intohigh-lying Rydberg states after conclusion of the laser pulse and are supportedby a semiclassical simulation of argon-OTC laser interaction. Our findings thusopen an effective pathway to control the localization of high-lying Rydbergwave packets.

Effect of system level structure and spectral distribution of the  environment on the decoherence rate

  Minimizing the effect of decoherence on a quantum register must be a centralpart of any strategy to realize scalable quantum information processing. Apartfrom the strength of the coupling to the environment, the decoherence rate isdetermined by the the system level structure and by the spectral composition ofthe noise trace that the environment generates. Here, we discuss a relativelysimple model that allows us to study these different effects quantitatively indetail. We evaluate the effect that the perturbation has on an NMR system whileit performs a Grover search algorithm.

Iterative quantum state transfer along a chain of nuclear spin qubits

  Transferring quantum information between two qubits is a basic requirementfor many applications in quantum communication and quantum informationprocessing. In the iterative quantum state transfer (IQST) proposed by D.Burgarth et al. [Phys. Rev. A 75, 062327 (2007)], this is achieved by a staticspin chain and a sequence of gate operations applied only to the receiving endof the chain. The only requirement on the spin chain is that it transfers afinite part of the input amplitude to the end of the chain, where the gateoperations accumulate the information. For an appropriate sequence ofevolutions and gate operations, the fidelity of the transfer can asymptoticallyapproach unity. We demonstrate the principle of operation of this transferscheme by implementing it in a nuclear magnetic resonance quantum informationprocessor.

Detection of quantum critical points by a probe qubit

  Quantum phase transitions occur when the ground state of a quantum systemundergoes a qualitative change when an external control parameter reaches acritical value. Here, we demonstrate a technique for studying quantum systemsundergoing a phase transition by coupling the system to a probe qubit. It usesdirectly the increased sensibility of the quantum system to perturbations whenit is close to a critical point. Using an NMR quantum simulator, we demonstratethis measurement technique for two different types of quantum phase transitionsin an Ising spin chain.

Lower Bounds for BMRM and Faster Rates for Training SVMs

  Regularized risk minimization with the binary hinge loss and its variantslies at the heart of many machine learning problems. Bundle methods forregularized risk minimization (BMRM) and the closely related SVMStruct areconsidered the best general purpose solvers to tackle this problem. It wasrecently shown that BMRM requires $O(1/\epsilon)$ iterations to converge to an$\epsilon$ accurate solution. In the first part of the paper we use theHadamard matrix to construct a regularized risk minimization problem and showthat these rates cannot be improved. We then show how one can exploit thestructure of the objective function to devise an algorithm for the binary hingeloss which converges to an $\epsilon$ accurate solution in$O(1/\sqrt{\epsilon})$ iterations.

Faster Rates for training Max-Margin Markov Networks

  Structured output prediction is an important machine learning problem both intheory and practice, and the max-margin Markov network (\mcn) is an effectiveapproach. All state-of-the-art algorithms for optimizing \mcn\ objectives takeat least $O(1/\epsilon)$ number of iterations to find an $\epsilon$ accuratesolution. Recent results in structured optimization suggest that faster ratesare possible by exploiting the structure of the objective function. Towardsthis end \citet{Nesterov05} proposed an excessive gap reduction technique basedon Euclidean projections which converges in $O(1/\sqrt{\epsilon})$ iterationson strongly convex functions. Unfortunately when applied to \mcn s, thisapproach does not admit graphical model factorization which, as in manyexisting algorithms, is crucial for keeping the cost per iteration tractable.In this paper, we present a new excessive gap reduction technique based onBregman projections which admits graphical model factorization naturally, andconverges in $O(1/\sqrt{\epsilon})$ iterations. Compared with existingalgorithms, the convergence rate of our method has better dependence on$\epsilon$ and other parameters of the problem, and can be easily kernelized.

Signature of multi-channel interference in high-order harmonic  generation from N2 driven by intense mid-infrared pulses

  We investigate the multi-electron dynamics in high-order harmonic generation(HHG) from N2 molecules. Clear spectral minima are observed in the cutoffregion at all three mid-infrared wavelengths (i.e., 1300, 1400 and 1500 nm)chosen in our experiment. It is found that the positions of the spectral minimado not depend on the alignment angles of molecules. In addition, the spectralminima shift almost linearly with the increasing laser intensity at all threewavelengths, which provides a strong evidence on the dynamic multi-channelinterference origin of these minima. The advantages of observation of dynamicmulti-channel interference based on HHG driven by long wavelength lasers arediscussed.

Convex Relaxations of Bregman Divergence Clustering

  Although many convex relaxations of clustering have been proposed in the pastdecade, current formulations remain restricted to spherical Gaussian ordiscriminative models and are susceptible to imbalanced clusters. To addressthese shortcomings, we propose a new class of convex relaxations that can beflexibly applied to more general forms of Bregman divergence clustering. Bybasing these new formulations on normalized equivalence relations we retainadditional control on relaxation quality, which allows improvement inclustering quality. We furthermore develop optimization methods that improvescalability by exploiting recent implicit matrix norm methods. In practice, wefind that the new formulations are able to efficiently produce tighterclusterings that improve the accuracy of state of the art methods.

Unfolding the fast neutron spectra of a BC501A liquid scintillation  detector using GRAVEL method

  Accurate knowledge of the neutron energy spectra is useful in basic researchand applications. The overall procedure of measuring and unfolding the fastneutron energy spectra with BC501A liquid scintillation detector is described.The recoil proton spectrum of Am-Be neutrons was obtained experimentally. Withthe NRESP7 code, the response matrix of detector was simulated. Combining therecoil proton spectrum and response matrix, the unfolding of neutron spectrawas performed by GRAVEL iterative algorithm. A MatLab program based on theGRAVEL method was developed. The continuous neutron spectrum of Am-Be sourceand monoenergetic neutron spectrum of D-T source have been unfoldedsuccessfully and are in good agreement with their standard reference spectra.The unfolded Am-Be spectrum are more accurate than the spectra unfolded byartificial neural networks in recent years.

Laser-sub-cycle two-dimensional electron momentum mapping using  orthogonal two-color fields

  The two-dimensional sub-cycle-time to electron momentum mapping provided byorthogonal two-color laser fields is applied to photoelectron spectroscopy.Using neon as the example we gain experimental access to the dynamics ofemitted electron wave packets in electron momenta spectra measured bycoincidence momentum imaging. We demonstrate the opportunities provided by thistime-to-momentum mapping by investigating the influence of the parent ion onthe emitted electrons on laser-sub-cycle times. It is found that depending ontheir sub-cycle birth time the trajectories of photoelectrons are affecteddifferently by the ion's Coulomb field.

Distributed Stochastic Optimization of the Regularized Risk

  Many machine learning algorithms minimize a regularized risk, and stochasticoptimization is widely used for this task. When working with massive data, itis desirable to perform stochastic optimization in parallel. Unfortunately,many existing stochastic optimization algorithms cannot be parallelizedefficiently. In this paper we show that one can rewrite the regularized riskminimization problem as an equivalent saddle-point problem, and propose anefficient distributed stochastic optimization (DSO) algorithm. We prove thealgorithm's rate of convergence; remarkably, our analysis shows that thealgorithm scales almost linearly with the number of processors. We also verifywith empirical evaluations that the proposed algorithm is competitive withother parallel, general purpose stochastic and batch optimization algorithmsfor regularized risk minimization.

Generalized Conditional Gradient for Sparse Estimation

  Structured sparsity is an important modeling tool that expands theapplicability of convex formulations for data analysis, however it also createssignificant challenges for efficient algorithm design. In this paper weinvestigate the generalized conditional gradient (GCG) algorithm for solvingstructured sparse optimization problems---demonstrating that, with someenhancements, it can provide a more efficient alternative to current state ofthe art approaches. After providing a comprehensive overview of the convergenceproperties of GCG, we develop efficient methods for evaluating polar operators,a subroutine that is required in each GCG iteration. In particular, we show howthe polar operator can be efficiently evaluated in two important scenarios:dictionary learning and structured sparse estimation. A further improvement isachieved by interleaving GCG with fixed-rank local subspace optimization. Aseries of experiments on matrix completion, multi-class classification,multi-view dictionary learning and overlapping group lasso shows that theproposed method can significantly reduce the training cost of currentalternatives.

Track segment finding with CGEM-IT and matching to tracks in ODC

  The relative differences in coordinates ofCylindrical-Gas-Electron-Multiplier-Detector-based Inner Tracker (CGEM-IT)clusters are studied to search for track segments in CGEM-IT. With the fullsimulation of single muon track samples, clear patterns are found andparameterized for the correct cluster combinations. The cluster combinationssatisfying the patterns are selected as track segment candidates in CGEM-ITwith an efficiency higher than 99%. The parameters of the track segments areobtained by a helix fitting. Some chi-squared quantities, evaluating thedifferences in track parameters between the track segments in CGEM-IT and thetracks found in Outer-Drift-Chamber (ODC), are calculated and used to matchthem. Proper chi-squared requirements are determined as a function oftransverse momentum and the matching efficiency is found reasonable.

Observation of Acoustic Valley Vortex States and Valley-Chirality Locked  Beam Splitting

  The Letter reports an experimental observation of the classical version ofvalley polarized states in a two-dimensional hexagonal sonic crystal, where theinversion-symmetry breaking of scatterers induces an omnidirectional frequencygap. The acoustic valley states, which carry specific linear momenta andorbital angular momenta, were selectively excited by external Gaussian beamsand conveniently confirmed by the pressure distribution outside the crystal,according to the criterion of momentum conservation. The vortex nature of suchintriguing crystal states was directly characterized by scanning the phaseprofile inside the crystal. In addition, we observed a peculiar beam splittingphenomenon, in which the separated beams are constructed by different valleysand locked to the opposite vortex chirality. The exceptional sound transport,encoded with valley-chirality locked information, may serve as the basis ofdesigning conceptually novel acoustic devices with unconventional functions.

Universal Quantum Control in Zero-field Nuclear Magnetic Resonance

  This paper describes a general method for manipulation of nuclear spins inzero magnetic field. In the absence of magnetic fields, the spins lose theindividual information on chemical shifts and inequivalent spins can only bedistinguished by nuclear gyromagnetic ratios and spin-spin couplings. Forspin-1/2 nuclei with different gyromagnetic ratios (i.e., different species) inzero magnetic field, we describe the scheme to realize a set of universalquantum logic gates, e.g., arbitrary single-qubit gates and two-qubitcontrolled-NOT gate. This method allows for universal quantum control insystems which might provide promising applications in materials science,chemistry, biology,quantum information processing and fundamental physics.

Observation of acoustic Landau quantization and quantum-Hall-like edge  states

  Many intriguing phenomena occur for electrons under strong magnetic fields.Recently, it was proposed that an appropriate strain texture in graphene caninduce a synthetic gauge field, in which the electrons behave like in a realmagnetic field. This opened the door to control quantum transport by mechanicalmeans and to explore unprecedented physics in high-field regime. Such studieshave been achieved in molecular and photonic lattices. Here we report the firstexperimental realization of giant uniform pseudomagnetic field in acoustics byintroducing a simple uniaxial deformation to acoustic graphene. Benefited fromthe controllability of our macroscopic platform, we observe the acoustic Landaulevels in frequency-resolved spectroscopy and their spatial localization inpressure-field distributions. We further visualize the quantum-Hall-like edgestates (connected to the zeroth Landau level), which have been elusive beforeowing to the challenge in creating large-area uniform pseudomagnetic fields.These results, highly consistent with our full-wave simulations, establish acomplete framework for artificial structures under constant pseudomagneticfields. Our findings, conceptually novel in acoustics, may offer newopportunities to manipulate sound.

Distributionally Robust Graphical Models

  In many structured prediction problems, complex relationships betweenvariables are compactly defined using graphical structures. The most prevalentgraphical prediction methods---probabilistic graphical models and large marginmethods---have their own distinct strengths but also possess significantdrawbacks. Conditional random fields (CRFs) are Fisher consistent, but they donot permit integration of customized loss metrics into their learning process.Large-margin models, such as structured support vector machines (SSVMs), havethe flexibility to incorporate customized loss metrics, but lack Fisherconsistency guarantees. We present adversarial graphical models (AGM), adistributionally robust approach for constructing a predictor that performsrobustly for a class of data distributions defined using a graphical structure.Our approach enjoys both the flexibility of incorporating customized lossmetrics into its design as well as the statistical guarantee of Fisherconsistency. We present exact learning and prediction algorithms for AGM withtime complexity similar to existing graphical models and show the practicalbenefits of our approach with experiments.

Consistent Robust Adversarial Prediction for General Multiclass  Classification

  We propose a robust adversarial prediction framework for general multiclassclassification. Our method seeks predictive distributions that robustlyoptimize non-convex and non-continuous multiclass loss metrics against theworst-case conditional label distributions (the adversarial distributions) that(approximately) match the statistics of the training data. Although theoptimized loss metrics are non-convex and non-continuous, the dual formulationof the framework is a convex optimization problem that can be recast as a riskminimization model with a prescribed convex surrogate loss we call theadversarial surrogate loss. We show that the adversarial surrogate losses fillan existing gap in surrogate loss construction for general multiclassclassification problems, by simultaneously aligning better with the originalmulticlass loss, guaranteeing Fisher consistency, enabling a way to incorporaterich feature spaces via the kernel trick, and providing competitive performancein practice.

New Approximation Algorithms for Minimum Enclosing Convex Shapes

  Given $n$ points in a $d$ dimensional Euclidean space, the Minimum EnclosingBall (MEB) problem is to find the ball with the smallest radius which containsall $n$ points. We give a $O(nd\Qcal/\sqrt{\epsilon})$ approximation algorithmfor producing an enclosing ball whose radius is at most $\epsilon$ away fromthe optimum (where $\Qcal$ is an upper bound on the norm of the points). Thisimproves existing results using \emph{coresets}, which yield a $O(nd/\epsilon)$greedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is arelated problem wherein a convex polytope of a fixed shape is given and the aimis to find the smallest magnification of the polytope which encloses the givenpoints. For this problem we present a $O(mnd\Qcal/\epsilon)$ approximationalgorithm, where $m$ is the number of faces of the polytope. Our algorithmsborrow heavily from convex duality and recently developed techniques innon-smooth optimization, and are in contrast with existing methods which relyon geometric arguments. In particular, we specialize the excessive gapframework of \citet{Nesterov05a} to obtain our results.

Study of n-γ discrimination in low energy range (above 40 keVee)  by charge comparison method with a BC501A liquid scintillation detector

  A VME-based experiment system for n-{\gamma} discrimination using the chargecomparison method was established. A data acquisition program for controllingthe programmable modules and processing data online via VME64X bus wasdeveloped through the use of LabVIEW. The two-dimensional (2D) scatter plots ofthe charge in the slow component vs. the total charge of recorded pulses fromAm-Be and Cf neutron sources were presented. The 2D scatter plots of the energyvs. the ratio of the charge in the slow component to the total charge of thepulses were presented at the meantime. The quality of n-{\gamma} discriminationwas checked by the figure-of-merit, and the results showed good performance ofn-{\gamma} discrimination at low energy range. Neutrons and {\gamma}-rays wereseparated above 50 keVee (electron-equivalent energy). The quality ofn-{\gamma} discrimination have been improved compared with others' results at 5energies (150, 250, 350, 450, 550 keVee).

DS-MLR: Exploiting Double Separability for Scaling up Distributed  Multinomial Logistic Regression

  Scaling multinomial logistic regression to datasets with very large number ofdata points and classes is challenging. This is primarily because one needs tocompute the log-partition function on every data point. This makes distributingthe computation hard. In this paper, we present a distributed stochasticgradient descent based optimization method (DS-MLR) for scaling up multinomiallogistic regression problems to massive scale datasets without hitting anystorage constraints on the data and model parameters. Our algorithm exploitsdouble-separability, an attractive property that allows us to achieve both dataas well as model parallelism simultaneously. In addition, we introduce anon-blocking and asynchronous variant of our algorithm that avoidsbulk-synchronization. We demonstrate the versatility of DS-MLR to variousscenarios in data and model parallelism, through an extensive empirical studyusing several real-world datasets. In particular, we demonstrate thescalability of DS-MLR by solving an extreme multi-class classification problemon the Reddit dataset (159 GB data, 358 GB parameters) where, to the best ofour knowledge, no other existing methods apply.

Expectation on Observation of Supernova Remnants with the LHAASO Project

  Supernova remnants (SNRs) are believed to be the most important accelerationsites for cosmic rays (CRs) below $\sim10^{15}$ eV in the Galaxy. High energyphotons, either directly from the shocks of the SNRs or indirectly from theinteraction between SNRs and the nearby clouds, are crucial probes for the CRacceleration. Big progresses on observations of SNRs have been achieved byspace- and ground-based $\gamma$-ray facilities. However, whether $\gamma$-rayscome from accelerated hadrons or not, as well as their connection with the CRsobserved at Earth, remains in debate. Large High Altitude Air ShowerObservatory (LHAASO), the next generation experiment, is designed to survey thenorthern part of the very high energy $\gamma$-ray sky from $\sim 0.3$ TeV toPeV with the sensitivity of $\lesssim1\%$ of the Crab nebula flux. In thispaper, we indicate that LHAASO will be dedicated to enlarging the $\gamma$-raySNR samples and improving the spectral and morphological measurements. Thesemeasurements, especially at energies above 30 TeV, will be important for us tofinally understand the CR acceleration in SNRs.

Global existence to a $3D$ chemotaxis-Navier-stokes system with  nonlinear diffusion and rotation

  This paper is concerned with the following quasilinearchemotaxis--Navier--Stokes system with nonlinear diffusion and rotation $$\left\{ \begin{array}{l} n_t+u\cdot\nabla n=\Deltan^m-\nabla\cdot(nS(x,n,c)\cdot\nabla c),\quad x\in \Omega, t>0,c_t+u\cdot\nabla c=\Delta c-nc,\quad x\in \Omega, t>0,\\ u_t+\kappa(u \cdot\nabla)u+\nabla P=\Delta u+n\nabla \phi ,\quad x\in \Omega, t>0,\\ \nabla\cdotu=0,\quad x\in \Omega, t>0 \end{array}\right.\eqno(CNF) $$ is considered underthe no-flux boundary conditions for $n, c$ and the Dirichlet boundary conditionfor $u$ in a three-dimensional convex domain $\Omega\subseteq \mathbb{R}^3$with smooth boundary, which describes the motion of oxygen-driven bacteria in afluid. Here % $\Omega\subseteq \mathbb{R}^3$ is a , $\kappa\in \mathbb{R}$ and$S$ denotes the strength of nonlinear fluid convection and a giventensor-valued function, respectively. Assume $m>\frac{10}{9}$ and $S$ fulfills$|S(x,n,c)| \leq S_0(c)$ for all $(x,n,c)\in \bar{\Omega} \times [0,\infty)\times[0, \infty)$ with $S_0(c)$ nondecreasing on $[0,\infty)$, then forany reasonably regular initial data, the corresponding initial-boundary problem$(CNF)$ admits at least one global weak solution.

Quantum Image Processing and Its Application to Edge Detection: Theory  and Experiment

  Processing of digital images is continuously gaining in volume and relevance,with concomitant demands on data storage, transmission and processing power.Encoding the image information in quantum-mechanical systems instead ofclassical ones and replacing classical with quantum information processing mayalleviate some of these challenges. By encoding and processing the imageinformation in quantum-mechanical systems, we here demonstrate the framework ofquantum image processing, where a pure quantum state encodes the imageinformation: we encode the pixel values in the probability amplitudes and thepixel positions in the computational basis states. Our quantum imagerepresentation reduces the required number of qubits compared to existingimplementations, and we present image processing algorithms that provideexponential speed-up over their classical counterparts. For the commonly usedtask of detecting the edge of an image, we propose and implement a quantumalgorithm that completes the task with only one single-qubit operation,independent of the size of the image. This demonstrates the potential ofquantum image processing for highly efficient image and video processing in thebig data era.

Exp-Concavity of Proper Composite Losses

  The goal of online prediction with expert advice is to find a decisionstrategy which will perform almost as well as the best expert in a given poolof experts, on any sequence of outcomes. This problem has been widely studiedand $O(\sqrt{T})$ and $O(\log{T})$ regret bounds can be achieved for convexlosses (\cite{zinkevich2003online}) and strictly convex losses with boundedfirst and second derivatives (\cite{hazan2007logarithmic}) respectively. Inspecial cases like the Aggregating Algorithm (\cite{vovk1995game}) with mixablelosses and the Weighted Average Algorithm (\cite{kivinen1999averaging}) withexp-concave losses, it is possible to achieve $O(1)$ regret bounds.\cite{van2012exp} has argued that mixability and exp-concavity are roughlyequivalent under certain conditions. Thus by understanding the underlyingrelationship between these two notions we can gain the best of both algorithms(strong theoretical performance guarantees of the Aggregating Algorithm and thecomputational efficiency of the Weighted Average Algorithm). In this paper weprovide a complete characterization of the exp-concavity of any propercomposite loss. Using this characterization and the mixability condition ofproper losses (\cite{van2012mixability}), we show that it is possible totransform (re-parameterize) any $\beta$-mixable binary proper loss into a$\beta$-exp-concave composite loss with the same $\beta$. In the multi-classcase, we propose an approximation approach for this transformation.

Detection of thermal neutrons with the PRISMA-YBJ array in Extensive Air  Showers selected by the ARGO-YBJ experiment

  We report on a measurement of thermal neutrons, generated by the hadroniccomponent of extensive air showers (EAS), by means of a small array ofEN-detectors developed for the PRISMA project (PRImary Spectrum MeasurementArray), novel devices based on a compound alloy of ZnS(Ag) and $^{6}$LiF. Thisarray has been operated within the ARGO-YBJ experiment at the high altitudeCosmic Ray Observatory in Yangbajing (Tibet, 4300 m a.s.l.). Due to the tightcorrelation between the air shower hadrons and thermal neutrons, this techniquecan be envisaged as a simple way to estimate the number of high energy hadronsin EAS. Coincident events generated by primary cosmic rays of energies greaterthan 100 TeV have been selected and analyzed. The EN-detectors have been usedto record simultaneously thermal neutrons and the air shower electromagneticcomponent. The density distributions of both components and the total number ofthermal neutrons have been measured. The correlation of these data with themeasurements carried out by ARGO-YBJ confirms the excellent performance of theEN-detector.

Exploring genetic variation in the tomato (Solanum section Lycopersicon)  clade by whole-genome sequencing

  Genetic variation in the tomato clade was explored by sequencing a selectionof 84 tomato accessions and related wild species representative for theLycopersicon, Arcanum, Eriopersicon, and Neolycopersicon groups. We present areconstruction of three new reference genomes in support of our comparativegenome analyses. Sequence diversity in commercial breeding lines appearsextremely low, indicating the dramatic genetic erosion of crop tomatoes. Thisis reflected by the SNP count in wild species which can exceed 10 million i.e.20 fold higher than in crop accessions. Comparative sequence alignment revealsgroup, species, and accession specific polymorphisms, which explaincharacteristic fruit traits and growth habits in tomato accessions. Using genemodels from the annotated Heinz reference genome, we observe a bias in dN/dSratio in fruit and growth diversification genes compared to a random set ofgenes, which probably is the result of a positive selection. We detected highlydivergent segments in wild S. lycopersicum species, and footprints ofintrogressions in crop accessions originating from a common donor accession.Phylogenetic relationships of fruit diversification and growth specific genesfrom crop accessions show incomplete resolution and are dependent on theintrogression donor. In contrast, whole genome SNP information has sufficientpower to resolve the phylogenetic placement of each accession in the four maingroups in the Lycopersicon clade using Maximum Likelihood analyses.Phylogenetic relationships appear correlated with habitat and mating type andpoint to the occurrence of geographical races within these groups and thus areof practical importance for introgressive hybridization breeding. Our studyillustrates the need for multiple reference genomes in support of tomatocomparative genomics and Solanum genome evolution studies.

The Long-Baseline Neutrino Experiment: Exploring Fundamental Symmetries  of the Universe

  The preponderance of matter over antimatter in the early Universe, thedynamics of the supernova bursts that produced the heavy elements necessary forlife and whether protons eventually decay --- these mysteries at the forefrontof particle physics and astrophysics are key to understanding the earlyevolution of our Universe, its current state and its eventual fate. TheLong-Baseline Neutrino Experiment (LBNE) represents an extensively developedplan for a world-class experiment dedicated to addressing these questions. LBNEis conceived around three central components: (1) a new, high-intensityneutrino source generated from a megawatt-class proton accelerator at FermiNational Accelerator Laboratory, (2) a near neutrino detector just downstreamof the source, and (3) a massive liquid argon time-projection chamber deployedas a far detector deep underground at the Sanford Underground ResearchFacility. This facility, located at the site of the former Homestake Mine inLead, South Dakota, is approximately 1,300 km from the neutrino source atFermilab -- a distance (baseline) that delivers optimal sensitivity to neutrinocharge-parity symmetry violation and mass ordering effects. This ambitious yetcost-effective design incorporates scalability and flexibility and canaccommodate a variety of upgrades and contributions. With its exceptionalcombination of experimental configuration, technical capabilities, andpotential for transformative discoveries, LBNE promises to be a vital facilityfor the field of particle physics worldwide, providing physicists from aroundthe globe with opportunities to collaborate in a twenty to thirty year programof exciting science. In this document we provide a comprehensive overview ofLBNE's scientific objectives, its place in the landscape of neutrino physicsworldwide, the technologies it will incorporate and the capabilities it willpossess.

