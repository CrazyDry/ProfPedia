Quantitative complementarity between local and nonlocal character of
  quantum states in a three-qubit system

  Local or nonlocal character of quantum states can be quantified and is
subject to various bounds that can be formulated as complementarity relations.
Here, we investigate the local vs. nonlocal character of pure three-qubit
states by a four-way interferometer. The complete entanglement in the system
can be measured as the entanglement of a specific qubit with the subsystem
consisting of the other two qubits. The quantitative complementarity relations
are verified experimentally in an NMR quantum information processor.


3D Single-port Labyrinthine Acoustic Metamaterial

  In this paper, we report on the design, fabrication, and experimental
characterization of a 3D single-port labyrinthine acoustic metamaterial. By
using curled perforations with one end closed and with appropriate loss inside,
the proposed metamaterial can perfectly absorb airborne sounds in a low
frequency band. Both the position and width of the band can be tuned flexibly.
A tradeoff is uncovered between the relative absorption bandwidth and thickness
of the metamaterial. When the relative absorption bandwidth is as high as 51%,
the requirement of deep subwavelength thickness (0.07{\lambda}) can still be
satisfied.


Zero-energy proton dissociation of H$_2^+$ through stimulated Raman
  scattering

  We show that (near-)zero energy proton emission from H$_2^+$ in strong
two-color and broadband laser fields is dominated by a stimulated Raman
scattering process taking place on the electronic ground state. It is
furthermore shown that in the (near-)zero energy region the asymmetry in proton
ejection induced by asymmetric laser fields is due to the interplay of several
processes, rather than only pathway interferences, with vibrational trapping
(or bond-hardening) taking a key role.


Regularized Risk Minimization by Nesterov's Accelerated Gradient
  Methods: Algorithmic Extensions and Empirical Studies

  Nesterov's accelerated gradient methods (AGM) have been successfully applied
in many machine learning areas. However, their empirical performance on
training max-margin models has been inferior to existing specialized solvers.
In this paper, we first extend AGM to strongly convex and composite objective
functions with Bregman style prox-functions. Our unifying framework covers both
the $\infty$-memory and 1-memory styles of AGM, tunes the Lipschiz constant
adaptively, and bounds the duality gap. Then we demonstrate various ways to
apply this framework of methods to a wide range of machine learning problems.
Emphasis will be given on their rate of convergence and how to efficiently
compute the gradient and optimize the models. The experimental results show
that with our extensions AGM outperforms state-of-the-art solvers on max-margin
models.


Smoothing Multivariate Performance Measures

  A Support Vector Method for multivariate performance measures was recently
introduced by Joachims (2005). The underlying optimization problem is currently
solved using cutting plane methods such as SVM-Perf and BMRM. One can show that
these algorithms converge to an eta accurate solution in O(1/Lambda*e)
iterations, where lambda is the trade-off parameter between the regularizer and
the loss function. We present a smoothing strategy for multivariate performance
scores, in particular precision/recall break-even point and ROCArea. When
combined with Nesterov's accelerated gradient algorithm our smoothing strategy
yields an optimization algorithm which converges to an eta accurate solution in
O(min{1/e,1/sqrt(lambda*e)}) iterations. Furthermore, the cost per iteration of
our scheme is the same as that of SVM-Perf and BMRM. Empirical evaluation on a
number of publicly available datasets shows that our method converges
significantly faster than cutting plane methods without sacrificing
generalization ability.


Regularizers versus Losses for Nonlinear Dimensionality Reduction: A
  Factored View with New Convex Relaxations

  We demonstrate that almost all non-parametric dimensionality reduction
methods can be expressed by a simple procedure: regularized loss minimization
plus singular value truncation. By distinguishing the role of the loss and
regularizer in such a process, we recover a factored perspective that reveals
some gaps in the current literature. Beyond identifying a useful new loss for
manifold unfolding, a key contribution is to derive new convex regularizers
that combine distance maximization with rank reduction. These regularizers can
be applied to any loss.


Quantum simulation of a system with competing two- and three-body
  interactions

  Quantum phase transitions occur at zero temperature, when the ground state of
a Hamiltonian undergoes a qualitative change as a function of a control
parameter. We consider a particularly interesting system with competing one-,
two- and three-body interactions. Depending on the relative strength of these
interactions, the ground state of the system can be a product state, or it can
exhibit genuine tripartite entanglement. We experimentally simulate such a
system in an NMR quantum simulator and observe the different ground states. By
adiabatically changing the strength of one coupling constant, we push the
system from one ground state to a qualitatively different ground state. We show
that these ground states can be distinguished and the transitions between them
observed by measuring correlations between the spins or the expectation values
of suitable entanglement witnesses.


Hybrid magic state distillation for universal fault-tolerant quantum
  computation

  A set of stabilizer operations augmented by some special initial states known
as 'magic states', gives the possibility of universal fault-tolerant quantum
computation. However, magic state preparation inevitably involves nonideal
operations that introduce noise. The most common method to eliminate the noise
is magic state distillation (MSD) by stabilizer operations. Here we propose a
hybrid MSD protocol by connecting a four-qubit H-type MSD with a five-qubit
T-type MSD, in order to overcome some disadvantages of the previous MSD
protocols. The hybrid MSD protocol further integrates distillable ranges of
different existing MSD protocols and extends the T-type distillable range to
the stabilizer octahedron edges. And it provides considerable improvement in
qubit cost for almost all of the distillable range. Moreover, we experimentally
demonstrate the four-qubit H-type MSD protocol using nuclear magnetic resonance
technology, together with the previous five-qubit MSD experiment, to show the
feasibility of the hybrid MSD protocol.


Channel-resolved subcycle interferences of electron wave packets emitted
  from H$_2$ in two-color laser fields

  We report on the observation of subcycle interferences of electron wave
packets released during the strong field ionization of H$_2$ with cycle-shaped
two-color laser fields. With a reaction microscope, channel-resolved
photoelectron momentum distribution are obtained for different final products
originating from single ionization of H$_2$. Our results show that the subcycle
interference structures of electron wave packet are very sensitive to the
cycle-shape of the two-color laser field. The reason is that the ionization
time within an optical cycle is determined by the cycle-shape of the laser
field. The subcycle interference structures can be further used to get the
subcycle dynamics of molecules during strong field interaction.


Knowledge-aided Two-dimensional Autofocus for Spotlight SAR Filtered
  Backprojection Imagery

  Filtered backprojection (FBP) algorithm is a popular choice for complicated
trajectory SAR image formation processing due to its inherent nonlinear motion
compensation capability. However, how to efficiently autofocus the defocused
FBP imagery when the motion measurement is not accurate enough is still a
challenging problem. In this paper, a new interpretation of the FBP derivation
is presented from the Fourier transform point of view. Based on this new
viewpoint, the property of the residual 2-D phase error in FBP imagery is
analyzed in detail. Then, by incorporating the derived a priori knowledge on
the 2-D phase error, an accurate and efficient 2-D autofocus approach is
proposed. The new approach performs the parameter estimation in a
dimension-reduced parameter subspace by exploiting the a priori analytical
structure of the 2-D phase error, therefore possesses much higher accuracy and
efficiency than conventional blind methods. Finally, experimental results
clearly demonstrate the effectiveness and robustness of the proposed method.


Speedup of quantum state transfer by three- qubit interactions:
  Implementation by nuclear magnetic resonance

  Universal quantum information processing requires single-qubit rotations and
two-qubit interactions as minimal resources. A possible step beyond this
minimal scheme is the use of three-qubit interactions. We consider such
three-qubit interactions and show how they can reduce the time required for a
quantum state transfer in an XY spin chain. For the experimental
implementation, we use liquid-state nuclear magnetic resonance (NMR), where
three-qubit interactions can be implemented by sequences of radio-frequency
pulses.


Localizing High-Lying Rydberg Wave Packets with Two-Color Laser Fields

  We demonstrate control over the localization of high-lying Rydberg wave
packets in argon atoms with phase-locked orthogonally polarized two-color (OTC)
laser fields. With a reaction microscope, we measured ionization signals of
high-lying Rydberg states induced by a weak dc field and black-body radiation
as a function of the relative phase between the two-color fields. We find that
the dc-field ionization yields of high-lying Rydberg argon atoms oscillate with
the relative two-color phase with a period of $2\pi$ while the photoionization
signal by black-body radiation shows a period of $\pi$. These observations are
a clear signature of the asymmetric localization of electrons recaptured into
high-lying Rydberg states after conclusion of the laser pulse and are supported
by a semiclassical simulation of argon-OTC laser interaction. Our findings thus
open an effective pathway to control the localization of high-lying Rydberg
wave packets.


Effect of system level structure and spectral distribution of the
  environment on the decoherence rate

  Minimizing the effect of decoherence on a quantum register must be a central
part of any strategy to realize scalable quantum information processing. Apart
from the strength of the coupling to the environment, the decoherence rate is
determined by the the system level structure and by the spectral composition of
the noise trace that the environment generates. Here, we discuss a relatively
simple model that allows us to study these different effects quantitatively in
detail. We evaluate the effect that the perturbation has on an NMR system while
it performs a Grover search algorithm.


Iterative quantum state transfer along a chain of nuclear spin qubits

  Transferring quantum information between two qubits is a basic requirement
for many applications in quantum communication and quantum information
processing. In the iterative quantum state transfer (IQST) proposed by D.
Burgarth et al. [Phys. Rev. A 75, 062327 (2007)], this is achieved by a static
spin chain and a sequence of gate operations applied only to the receiving end
of the chain. The only requirement on the spin chain is that it transfers a
finite part of the input amplitude to the end of the chain, where the gate
operations accumulate the information. For an appropriate sequence of
evolutions and gate operations, the fidelity of the transfer can asymptotically
approach unity. We demonstrate the principle of operation of this transfer
scheme by implementing it in a nuclear magnetic resonance quantum information
processor.


Detection of quantum critical points by a probe qubit

  Quantum phase transitions occur when the ground state of a quantum system
undergoes a qualitative change when an external control parameter reaches a
critical value. Here, we demonstrate a technique for studying quantum systems
undergoing a phase transition by coupling the system to a probe qubit. It uses
directly the increased sensibility of the quantum system to perturbations when
it is close to a critical point. Using an NMR quantum simulator, we demonstrate
this measurement technique for two different types of quantum phase transitions
in an Ising spin chain.


Signature of multi-channel interference in high-order harmonic
  generation from N2 driven by intense mid-infrared pulses

  We investigate the multi-electron dynamics in high-order harmonic generation
(HHG) from N2 molecules. Clear spectral minima are observed in the cutoff
region at all three mid-infrared wavelengths (i.e., 1300, 1400 and 1500 nm)
chosen in our experiment. It is found that the positions of the spectral minima
do not depend on the alignment angles of molecules. In addition, the spectral
minima shift almost linearly with the increasing laser intensity at all three
wavelengths, which provides a strong evidence on the dynamic multi-channel
interference origin of these minima. The advantages of observation of dynamic
multi-channel interference based on HHG driven by long wavelength lasers are
discussed.


Lower Bounds for BMRM and Faster Rates for Training SVMs

  Regularized risk minimization with the binary hinge loss and its variants
lies at the heart of many machine learning problems. Bundle methods for
regularized risk minimization (BMRM) and the closely related SVMStruct are
considered the best general purpose solvers to tackle this problem. It was
recently shown that BMRM requires $O(1/\epsilon)$ iterations to converge to an
$\epsilon$ accurate solution. In the first part of the paper we use the
Hadamard matrix to construct a regularized risk minimization problem and show
that these rates cannot be improved. We then show how one can exploit the
structure of the objective function to devise an algorithm for the binary hinge
loss which converges to an $\epsilon$ accurate solution in
$O(1/\sqrt{\epsilon})$ iterations.


Faster Rates for training Max-Margin Markov Networks

  Structured output prediction is an important machine learning problem both in
theory and practice, and the max-margin Markov network (\mcn) is an effective
approach. All state-of-the-art algorithms for optimizing \mcn\ objectives take
at least $O(1/\epsilon)$ number of iterations to find an $\epsilon$ accurate
solution. Recent results in structured optimization suggest that faster rates
are possible by exploiting the structure of the objective function. Towards
this end \citet{Nesterov05} proposed an excessive gap reduction technique based
on Euclidean projections which converges in $O(1/\sqrt{\epsilon})$ iterations
on strongly convex functions. Unfortunately when applied to \mcn s, this
approach does not admit graphical model factorization which, as in many
existing algorithms, is crucial for keeping the cost per iteration tractable.
In this paper, we present a new excessive gap reduction technique based on
Bregman projections which admits graphical model factorization naturally, and
converges in $O(1/\sqrt{\epsilon})$ iterations. Compared with existing
algorithms, the convergence rate of our method has better dependence on
$\epsilon$ and other parameters of the problem, and can be easily kernelized.


Laser-sub-cycle two-dimensional electron momentum mapping using
  orthogonal two-color fields

  The two-dimensional sub-cycle-time to electron momentum mapping provided by
orthogonal two-color laser fields is applied to photoelectron spectroscopy.
Using neon as the example we gain experimental access to the dynamics of
emitted electron wave packets in electron momenta spectra measured by
coincidence momentum imaging. We demonstrate the opportunities provided by this
time-to-momentum mapping by investigating the influence of the parent ion on
the emitted electrons on laser-sub-cycle times. It is found that depending on
their sub-cycle birth time the trajectories of photoelectrons are affected
differently by the ion's Coulomb field.


Generalized Conditional Gradient for Sparse Estimation

  Structured sparsity is an important modeling tool that expands the
applicability of convex formulations for data analysis, however it also creates
significant challenges for efficient algorithm design. In this paper we
investigate the generalized conditional gradient (GCG) algorithm for solving
structured sparse optimization problems---demonstrating that, with some
enhancements, it can provide a more efficient alternative to current state of
the art approaches. After providing a comprehensive overview of the convergence
properties of GCG, we develop efficient methods for evaluating polar operators,
a subroutine that is required in each GCG iteration. In particular, we show how
the polar operator can be efficiently evaluated in two important scenarios:
dictionary learning and structured sparse estimation. A further improvement is
achieved by interleaving GCG with fixed-rank local subspace optimization. A
series of experiments on matrix completion, multi-class classification,
multi-view dictionary learning and overlapping group lasso shows that the
proposed method can significantly reduce the training cost of current
alternatives.


Unfolding the fast neutron spectra of a BC501A liquid scintillation
  detector using GRAVEL method

  Accurate knowledge of the neutron energy spectra is useful in basic research
and applications. The overall procedure of measuring and unfolding the fast
neutron energy spectra with BC501A liquid scintillation detector is described.
The recoil proton spectrum of Am-Be neutrons was obtained experimentally. With
the NRESP7 code, the response matrix of detector was simulated. Combining the
recoil proton spectrum and response matrix, the unfolding of neutron spectra
was performed by GRAVEL iterative algorithm. A MatLab program based on the
GRAVEL method was developed. The continuous neutron spectrum of Am-Be source
and monoenergetic neutron spectrum of D-T source have been unfolded
successfully and are in good agreement with their standard reference spectra.
The unfolded Am-Be spectrum are more accurate than the spectra unfolded by
artificial neural networks in recent years.


Distributed Stochastic Optimization of the Regularized Risk

  Many machine learning algorithms minimize a regularized risk, and stochastic
optimization is widely used for this task. When working with massive data, it
is desirable to perform stochastic optimization in parallel. Unfortunately,
many existing stochastic optimization algorithms cannot be parallelized
efficiently. In this paper we show that one can rewrite the regularized risk
minimization problem as an equivalent saddle-point problem, and propose an
efficient distributed stochastic optimization (DSO) algorithm. We prove the
algorithm's rate of convergence; remarkably, our analysis shows that the
algorithm scales almost linearly with the number of processors. We also verify
with empirical evaluations that the proposed algorithm is competitive with
other parallel, general purpose stochastic and batch optimization algorithms
for regularized risk minimization.


Convex Relaxations of Bregman Divergence Clustering

  Although many convex relaxations of clustering have been proposed in the past
decade, current formulations remain restricted to spherical Gaussian or
discriminative models and are susceptible to imbalanced clusters. To address
these shortcomings, we propose a new class of convex relaxations that can be
flexibly applied to more general forms of Bregman divergence clustering. By
basing these new formulations on normalized equivalence relations we retain
additional control on relaxation quality, which allows improvement in
clustering quality. We furthermore develop optimization methods that improve
scalability by exploiting recent implicit matrix norm methods. In practice, we
find that the new formulations are able to efficiently produce tighter
clusterings that improve the accuracy of state of the art methods.


Track segment finding with CGEM-IT and matching to tracks in ODC

  The relative differences in coordinates of
Cylindrical-Gas-Electron-Multiplier-Detector-based Inner Tracker (CGEM-IT)
clusters are studied to search for track segments in CGEM-IT. With the full
simulation of single muon track samples, clear patterns are found and
parameterized for the correct cluster combinations. The cluster combinations
satisfying the patterns are selected as track segment candidates in CGEM-IT
with an efficiency higher than 99%. The parameters of the track segments are
obtained by a helix fitting. Some chi-squared quantities, evaluating the
differences in track parameters between the track segments in CGEM-IT and the
tracks found in Outer-Drift-Chamber (ODC), are calculated and used to match
them. Proper chi-squared requirements are determined as a function of
transverse momentum and the matching efficiency is found reasonable.


Observation of Acoustic Valley Vortex States and Valley-Chirality Locked
  Beam Splitting

  The Letter reports an experimental observation of the classical version of
valley polarized states in a two-dimensional hexagonal sonic crystal, where the
inversion-symmetry breaking of scatterers induces an omnidirectional frequency
gap. The acoustic valley states, which carry specific linear momenta and
orbital angular momenta, were selectively excited by external Gaussian beams
and conveniently confirmed by the pressure distribution outside the crystal,
according to the criterion of momentum conservation. The vortex nature of such
intriguing crystal states was directly characterized by scanning the phase
profile inside the crystal. In addition, we observed a peculiar beam splitting
phenomenon, in which the separated beams are constructed by different valleys
and locked to the opposite vortex chirality. The exceptional sound transport,
encoded with valley-chirality locked information, may serve as the basis of
designing conceptually novel acoustic devices with unconventional functions.


Universal Quantum Control in Zero-field Nuclear Magnetic Resonance

  This paper describes a general method for manipulation of nuclear spins in
zero magnetic field. In the absence of magnetic fields, the spins lose the
individual information on chemical shifts and inequivalent spins can only be
distinguished by nuclear gyromagnetic ratios and spin-spin couplings. For
spin-1/2 nuclei with different gyromagnetic ratios (i.e., different species) in
zero magnetic field, we describe the scheme to realize a set of universal
quantum logic gates, e.g., arbitrary single-qubit gates and two-qubit
controlled-NOT gate. This method allows for universal quantum control in
systems which might provide promising applications in materials science,
chemistry, biology,quantum information processing and fundamental physics.


Observation of acoustic Landau quantization and quantum-Hall-like edge
  states

  Many intriguing phenomena occur for electrons under strong magnetic fields.
Recently, it was proposed that an appropriate strain texture in graphene can
induce a synthetic gauge field, in which the electrons behave like in a real
magnetic field. This opened the door to control quantum transport by mechanical
means and to explore unprecedented physics in high-field regime. Such studies
have been achieved in molecular and photonic lattices. Here we report the first
experimental realization of giant uniform pseudomagnetic field in acoustics by
introducing a simple uniaxial deformation to acoustic graphene. Benefited from
the controllability of our macroscopic platform, we observe the acoustic Landau
levels in frequency-resolved spectroscopy and their spatial localization in
pressure-field distributions. We further visualize the quantum-Hall-like edge
states (connected to the zeroth Landau level), which have been elusive before
owing to the challenge in creating large-area uniform pseudomagnetic fields.
These results, highly consistent with our full-wave simulations, establish a
complete framework for artificial structures under constant pseudomagnetic
fields. Our findings, conceptually novel in acoustics, may offer new
opportunities to manipulate sound.


Distributionally Robust Graphical Models

  In many structured prediction problems, complex relationships between
variables are compactly defined using graphical structures. The most prevalent
graphical prediction methods---probabilistic graphical models and large margin
methods---have their own distinct strengths but also possess significant
drawbacks. Conditional random fields (CRFs) are Fisher consistent, but they do
not permit integration of customized loss metrics into their learning process.
Large-margin models, such as structured support vector machines (SSVMs), have
the flexibility to incorporate customized loss metrics, but lack Fisher
consistency guarantees. We present adversarial graphical models (AGM), a
distributionally robust approach for constructing a predictor that performs
robustly for a class of data distributions defined using a graphical structure.
Our approach enjoys both the flexibility of incorporating customized loss
metrics into its design as well as the statistical guarantee of Fisher
consistency. We present exact learning and prediction algorithms for AGM with
time complexity similar to existing graphical models and show the practical
benefits of our approach with experiments.


Consistent Robust Adversarial Prediction for General Multiclass
  Classification

  We propose a robust adversarial prediction framework for general multiclass
classification. Our method seeks predictive distributions that robustly
optimize non-convex and non-continuous multiclass loss metrics against the
worst-case conditional label distributions (the adversarial distributions) that
(approximately) match the statistics of the training data. Although the
optimized loss metrics are non-convex and non-continuous, the dual formulation
of the framework is a convex optimization problem that can be recast as a risk
minimization model with a prescribed convex surrogate loss we call the
adversarial surrogate loss. We show that the adversarial surrogate losses fill
an existing gap in surrogate loss construction for general multiclass
classification problems, by simultaneously aligning better with the original
multiclass loss, guaranteeing Fisher consistency, enabling a way to incorporate
rich feature spaces via the kernel trick, and providing competitive performance
in practice.


Study of n-γ discrimination in low energy range (above 40 keVee)
  by charge comparison method with a BC501A liquid scintillation detector

  A VME-based experiment system for n-{\gamma} discrimination using the charge
comparison method was established. A data acquisition program for controlling
the programmable modules and processing data online via VME64X bus was
developed through the use of LabVIEW. The two-dimensional (2D) scatter plots of
the charge in the slow component vs. the total charge of recorded pulses from
Am-Be and Cf neutron sources were presented. The 2D scatter plots of the energy
vs. the ratio of the charge in the slow component to the total charge of the
pulses were presented at the meantime. The quality of n-{\gamma} discrimination
was checked by the figure-of-merit, and the results showed good performance of
n-{\gamma} discrimination at low energy range. Neutrons and {\gamma}-rays were
separated above 50 keVee (electron-equivalent energy). The quality of
n-{\gamma} discrimination have been improved compared with others' results at 5
energies (150, 250, 350, 450, 550 keVee).


New Approximation Algorithms for Minimum Enclosing Convex Shapes

  Given $n$ points in a $d$ dimensional Euclidean space, the Minimum Enclosing
Ball (MEB) problem is to find the ball with the smallest radius which contains
all $n$ points. We give a $O(nd\Qcal/\sqrt{\epsilon})$ approximation algorithm
for producing an enclosing ball whose radius is at most $\epsilon$ away from
the optimum (where $\Qcal$ is an upper bound on the norm of the points). This
improves existing results using \emph{coresets}, which yield a $O(nd/\epsilon)$
greedy algorithm. Finding the Minimum Enclosing Convex Polytope (MECP) is a
related problem wherein a convex polytope of a fixed shape is given and the aim
is to find the smallest magnification of the polytope which encloses the given
points. For this problem we present a $O(mnd\Qcal/\epsilon)$ approximation
algorithm, where $m$ is the number of faces of the polytope. Our algorithms
borrow heavily from convex duality and recently developed techniques in
non-smooth optimization, and are in contrast with existing methods which rely
on geometric arguments. In particular, we specialize the excessive gap
framework of \citet{Nesterov05a} to obtain our results.


DS-MLR: Exploiting Double Separability for Scaling up Distributed
  Multinomial Logistic Regression

  Scaling multinomial logistic regression to datasets with very large number of
data points and classes is challenging. This is primarily because one needs to
compute the log-partition function on every data point. This makes distributing
the computation hard. In this paper, we present a distributed stochastic
gradient descent based optimization method (DS-MLR) for scaling up multinomial
logistic regression problems to massive scale datasets without hitting any
storage constraints on the data and model parameters. Our algorithm exploits
double-separability, an attractive property that allows us to achieve both data
as well as model parallelism simultaneously. In addition, we introduce a
non-blocking and asynchronous variant of our algorithm that avoids
bulk-synchronization. We demonstrate the versatility of DS-MLR to various
scenarios in data and model parallelism, through an extensive empirical study
using several real-world datasets. In particular, we demonstrate the
scalability of DS-MLR by solving an extreme multi-class classification problem
on the Reddit dataset (159 GB data, 358 GB parameters) where, to the best of
our knowledge, no other existing methods apply.


Expectation on Observation of Supernova Remnants with the LHAASO Project

  Supernova remnants (SNRs) are believed to be the most important acceleration
sites for cosmic rays (CRs) below $\sim10^{15}$ eV in the Galaxy. High energy
photons, either directly from the shocks of the SNRs or indirectly from the
interaction between SNRs and the nearby clouds, are crucial probes for the CR
acceleration. Big progresses on observations of SNRs have been achieved by
space- and ground-based $\gamma$-ray facilities. However, whether $\gamma$-rays
come from accelerated hadrons or not, as well as their connection with the CRs
observed at Earth, remains in debate. Large High Altitude Air Shower
Observatory (LHAASO), the next generation experiment, is designed to survey the
northern part of the very high energy $\gamma$-ray sky from $\sim 0.3$ TeV to
PeV with the sensitivity of $\lesssim1\%$ of the Crab nebula flux. In this
paper, we indicate that LHAASO will be dedicated to enlarging the $\gamma$-ray
SNR samples and improving the spectral and morphological measurements. These
measurements, especially at energies above 30 TeV, will be important for us to
finally understand the CR acceleration in SNRs.


Global existence to a $3D$ chemotaxis-Navier-stokes system with
  nonlinear diffusion and rotation

  This paper is concerned with the following quasilinear
chemotaxis--Navier--Stokes system with nonlinear diffusion and rotation $$
\left\{ \begin{array}{l} n_t+u\cdot\nabla n=\Delta
n^m-\nabla\cdot(nS(x,n,c)\cdot\nabla c),\quad x\in \Omega, t>0,
c_t+u\cdot\nabla c=\Delta c-nc,\quad x\in \Omega, t>0,\\ u_t+\kappa(u \cdot
\nabla)u+\nabla P=\Delta u+n\nabla \phi ,\quad x\in \Omega, t>0,\\ \nabla\cdot
u=0,\quad x\in \Omega, t>0 \end{array}\right.\eqno(CNF) $$ is considered under
the no-flux boundary conditions for $n, c$ and the Dirichlet boundary condition
for $u$ in a three-dimensional convex domain $\Omega\subseteq \mathbb{R}^3$
with smooth boundary, which describes the motion of oxygen-driven bacteria in a
fluid. Here % $\Omega\subseteq \mathbb{R}^3$ is a , $\kappa\in \mathbb{R}$ and
$S$ denotes the strength of nonlinear fluid convection and a given
tensor-valued function, respectively. Assume $m>\frac{10}{9}$ and $S$ fulfills
$|S(x,n,c)| \leq S_0(c)$ for all $(x,n,c)\in \bar{\Omega} \times [0,
\infty)\times[0, \infty)$ with $S_0(c)$ nondecreasing on $[0,\infty)$, then for
any reasonably regular initial data, the corresponding initial-boundary problem
$(CNF)$ admits at least one global weak solution.


Quantum Image Processing and Its Application to Edge Detection: Theory
  and Experiment

  Processing of digital images is continuously gaining in volume and relevance,
with concomitant demands on data storage, transmission and processing power.
Encoding the image information in quantum-mechanical systems instead of
classical ones and replacing classical with quantum information processing may
alleviate some of these challenges. By encoding and processing the image
information in quantum-mechanical systems, we here demonstrate the framework of
quantum image processing, where a pure quantum state encodes the image
information: we encode the pixel values in the probability amplitudes and the
pixel positions in the computational basis states. Our quantum image
representation reduces the required number of qubits compared to existing
implementations, and we present image processing algorithms that provide
exponential speed-up over their classical counterparts. For the commonly used
task of detecting the edge of an image, we propose and implement a quantum
algorithm that completes the task with only one single-qubit operation,
independent of the size of the image. This demonstrates the potential of
quantum image processing for highly efficient image and video processing in the
big data era.


Exp-Concavity of Proper Composite Losses

  The goal of online prediction with expert advice is to find a decision
strategy which will perform almost as well as the best expert in a given pool
of experts, on any sequence of outcomes. This problem has been widely studied
and $O(\sqrt{T})$ and $O(\log{T})$ regret bounds can be achieved for convex
losses (\cite{zinkevich2003online}) and strictly convex losses with bounded
first and second derivatives (\cite{hazan2007logarithmic}) respectively. In
special cases like the Aggregating Algorithm (\cite{vovk1995game}) with mixable
losses and the Weighted Average Algorithm (\cite{kivinen1999averaging}) with
exp-concave losses, it is possible to achieve $O(1)$ regret bounds.
\cite{van2012exp} has argued that mixability and exp-concavity are roughly
equivalent under certain conditions. Thus by understanding the underlying
relationship between these two notions we can gain the best of both algorithms
(strong theoretical performance guarantees of the Aggregating Algorithm and the
computational efficiency of the Weighted Average Algorithm). In this paper we
provide a complete characterization of the exp-concavity of any proper
composite loss. Using this characterization and the mixability condition of
proper losses (\cite{van2012mixability}), we show that it is possible to
transform (re-parameterize) any $\beta$-mixable binary proper loss into a
$\beta$-exp-concave composite loss with the same $\beta$. In the multi-class
case, we propose an approximation approach for this transformation.


Detection of thermal neutrons with the PRISMA-YBJ array in Extensive Air
  Showers selected by the ARGO-YBJ experiment

  We report on a measurement of thermal neutrons, generated by the hadronic
component of extensive air showers (EAS), by means of a small array of
EN-detectors developed for the PRISMA project (PRImary Spectrum Measurement
Array), novel devices based on a compound alloy of ZnS(Ag) and $^{6}$LiF. This
array has been operated within the ARGO-YBJ experiment at the high altitude
Cosmic Ray Observatory in Yangbajing (Tibet, 4300 m a.s.l.). Due to the tight
correlation between the air shower hadrons and thermal neutrons, this technique
can be envisaged as a simple way to estimate the number of high energy hadrons
in EAS. Coincident events generated by primary cosmic rays of energies greater
than 100 TeV have been selected and analyzed. The EN-detectors have been used
to record simultaneously thermal neutrons and the air shower electromagnetic
component. The density distributions of both components and the total number of
thermal neutrons have been measured. The correlation of these data with the
measurements carried out by ARGO-YBJ confirms the excellent performance of the
EN-detector.


Exploring genetic variation in the tomato (Solanum section Lycopersicon)
  clade by whole-genome sequencing

  Genetic variation in the tomato clade was explored by sequencing a selection
of 84 tomato accessions and related wild species representative for the
Lycopersicon, Arcanum, Eriopersicon, and Neolycopersicon groups. We present a
reconstruction of three new reference genomes in support of our comparative
genome analyses. Sequence diversity in commercial breeding lines appears
extremely low, indicating the dramatic genetic erosion of crop tomatoes. This
is reflected by the SNP count in wild species which can exceed 10 million i.e.
20 fold higher than in crop accessions. Comparative sequence alignment reveals
group, species, and accession specific polymorphisms, which explain
characteristic fruit traits and growth habits in tomato accessions. Using gene
models from the annotated Heinz reference genome, we observe a bias in dN/dS
ratio in fruit and growth diversification genes compared to a random set of
genes, which probably is the result of a positive selection. We detected highly
divergent segments in wild S. lycopersicum species, and footprints of
introgressions in crop accessions originating from a common donor accession.
Phylogenetic relationships of fruit diversification and growth specific genes
from crop accessions show incomplete resolution and are dependent on the
introgression donor. In contrast, whole genome SNP information has sufficient
power to resolve the phylogenetic placement of each accession in the four main
groups in the Lycopersicon clade using Maximum Likelihood analyses.
Phylogenetic relationships appear correlated with habitat and mating type and
point to the occurrence of geographical races within these groups and thus are
of practical importance for introgressive hybridization breeding. Our study
illustrates the need for multiple reference genomes in support of tomato
comparative genomics and Solanum genome evolution studies.


The Long-Baseline Neutrino Experiment: Exploring Fundamental Symmetries
  of the Universe

  The preponderance of matter over antimatter in the early Universe, the
dynamics of the supernova bursts that produced the heavy elements necessary for
life and whether protons eventually decay --- these mysteries at the forefront
of particle physics and astrophysics are key to understanding the early
evolution of our Universe, its current state and its eventual fate. The
Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed
plan for a world-class experiment dedicated to addressing these questions. LBNE
is conceived around three central components: (1) a new, high-intensity
neutrino source generated from a megawatt-class proton accelerator at Fermi
National Accelerator Laboratory, (2) a near neutrino detector just downstream
of the source, and (3) a massive liquid argon time-projection chamber deployed
as a far detector deep underground at the Sanford Underground Research
Facility. This facility, located at the site of the former Homestake Mine in
Lead, South Dakota, is approximately 1,300 km from the neutrino source at
Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino
charge-parity symmetry violation and mass ordering effects. This ambitious yet
cost-effective design incorporates scalability and flexibility and can
accommodate a variety of upgrades and contributions. With its exceptional
combination of experimental configuration, technical capabilities, and
potential for transformative discoveries, LBNE promises to be a vital facility
for the field of particle physics worldwide, providing physicists from around
the globe with opportunities to collaborate in a twenty to thirty year program
of exciting science. In this document we provide a comprehensive overview of
LBNE's scientific objectives, its place in the landscape of neutrino physics
worldwide, the technologies it will incorporate and the capabilities it will
possess.


