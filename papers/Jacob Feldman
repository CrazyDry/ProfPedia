Noise sensitivity on continuous products: an answer to an old question
  of J. Feldman

  A relation between sigma-additivity and linearizability, conjectured by Jacob
Feldman in 1971 for continuous products of probability spaces, is established
by relating both notions to a recent idea of noise stability/sensitivity.


Leo and me

  I arrived in Berkeley in 1957, at which time Leo was an Acting Assistant
Professor of Mathematics here. He had recently proven the "individual ergodic
theorem of information theory"---a triumph---and since this was becoming
central to my own interests, it would have been natural for us to work
together. However, Leo's interests shifted to more applied work, specifically
statistics, and he soon moved to UCLA. So we never became collaborators, but we
did became good friends, especially after 1980 when he returned to Berkeley as
a Professor of Statistics.


Noise as a Boolean algebra of sigma-fields. III. An old question of
  Jacob Feldman

  The noise-type completion C of a noise-type Boolean algebra B is generally
not the same as the closure of B. As shown in Part I (Introduction, Theorem 2),
C consists of all complemented elements of the closure. It appears that C is
the whole closure if and only if B is classical (as defined in Part II, Sect.
1a), which is the main result of this Part III.


Proceedings of the 2016 ICML Workshop on Human Interpretability in
  Machine Learning (WHI 2016)

  This is the Proceedings of the 2016 ICML Workshop on Human Interpretability
in Machine Learning (WHI 2016), which was held in New York, NY, June 23, 2016.
  Invited speakers were Susan Athey, Rich Caruana, Jacob Feldman, Percy Liang,
and Hanna Wallach.


A Search for B+ -> tau+ nu Recoiling Against B- -> D0 l- nu X

  We present a search for the decay $B^+ \to \ell^+ \nu_{\ell}$ ($\ell =
e,\mu\tau$) in $(458.9 \pm 5.1) \times 10^6$ $B\bar{B}$ pairs recorded with the
BABAR detector at the PEP-II B-Factory. We search for these B decays in a
sample of $B^+B^-$ events where one $B$-meson is reconstructed as $B^- \to D^0
\ell^- \nu X$. Using the method of Feldman and Cousins, we obtain
$\mathcal{B}(B^+ \to \tau^+ \nu) = (1.7 \pm 0.8 \pm 0.2) \times 10^{-4}$, which
excludes zero at $2.3\sigma$. We interpret the central value in the context of
the Standard Model and find the B meson decay constant to be $f^2_B = (62 \pm
31) \times 10^3 \mathrm{MeV}^2$. We find no evidence for $B^+ \to e^+ \nu_{e}$
and $B^+ \to \mu^+ \nu_{\mu}$ and set upper limits at the 90% C.L.
$\mathcal{B}(B^+ \to e^+ \nu_{e}) < 0.8 \times 10^{-5}$ and $\mathcal{B}(B^+
\to \mu^+ \nu_{\mu}) < 1.1 \times 10^{-5}$.


Superoperator Analysis of Entanglement in a Four-Qubit Cluster State

  In this paper we utilize superoperator formalism to explore the entanglement
evolution of four-qubit cluster states in a number of decohering environments.
A four-qubit cluster state is a resource for the performance of an arbitrary
single logical qubit rotation via measurement based cluster state quantum
computation. We are specifically interested in the relationship between
entanglement evolution and the fidelity with which the arbitrary single logical
qubit rotation can be implemented in the presence of decoherence as this will
have important experimental ramifications. We also note the exhibition of
entanglement sudden death (ESD) and ask how severely its onset affects the
utilization of the cluster state as a means of implementing an arbitrary single
logical qubit rotation.


Toward a Taxonomy and Computational Models of Abnormalities in Images

  The human visual system can spot an abnormal image, and reason about what
makes it strange. This task has not received enough attention in computer
vision. In this paper we study various types of atypicalities in images in a
more comprehensive way than has been done before. We propose a new dataset of
abnormal images showing a wide range of atypicalities. We design human subject
experiments to discover a coarse taxonomy of the reasons for abnormality. Our
experiments reveal three major categories of abnormality: object-centric,
scene-centric, and contextual. Based on this taxonomy, we propose a
comprehensive computational model that can predict all different types of
abnormality in images and outperform prior arts in abnormality recognition.


The Role of Typicality in Object Classification: Improving The
  Generalization Capacity of Convolutional Neural Networks

  Deep artificial neural networks have made remarkable progress in different
tasks in the field of computer vision. However, the empirical analysis of these
models and investigation of their failure cases has received attention
recently. In this work, we show that deep learning models cannot generalize to
atypical images that are substantially different from training images. This is
in contrast to the superior generalization ability of the visual system in the
human brain. We focus on Convolutional Neural Networks (CNN) as the
state-of-the-art models in object recognition and classification; investigate
this problem in more detail, and hypothesize that training CNN models suffer
from unstructured loss minimization. We propose computational models to improve
the generalization capacity of CNNs by considering how typical a training image
looks like. By conducting an extensive set of experiments we show that
involving a typicality measure can improve the classification results on a new
set of images by a large margin. More importantly, this significant improvement
is achieved without fine-tuning the CNN model on the target image set.


Synthetic Depth-of-Field with a Single-Camera Mobile Phone

  Shallow depth-of-field is commonly used by photographers to isolate a subject
from a distracting background. However, standard cell phone cameras cannot
produce such images optically, as their short focal lengths and small apertures
capture nearly all-in-focus images. We present a system to computationally
synthesize shallow depth-of-field images with a single mobile camera and a
single button press. If the image is of a person, we use a person segmentation
network to separate the person and their accessories from the background. If
available, we also use dense dual-pixel auto-focus hardware, effectively a
2-sample light field with an approximately 1 millimeter baseline, to compute a
dense depth map. These two signals are combined and used to render a defocused
image. Our system can process a 5.4 megapixel image in 4 seconds on a mobile
phone, is fully automatic, and is robust enough to be used by non-experts. The
modular nature of our system allows it to degrade naturally in the absence of a
dual-pixel sensor or a human subject.


Physics at the CLIC e+e- Linear Collider -- Input to the Snowmass
  process 2013

  This paper summarizes the physics potential of the CLIC high-energy e+e-
linear collider. It provides input to the Snowmass 2013 process for the
energy-frontier working groups on The Higgs Boson (HE1), Precision Study of
Electroweak Interactions (HE2), Fully Understanding the Top Quark (HE3), as
well as The Path Beyond the Standard Model -- New Particles, Forces, and
Dimensions (HE4). It is accompanied by a paper describing the CLIC accelerator
study, submitted to the Frontier Capabilities group of the Snowmass process.


The Large Observatory For x-ray Timing

  The Large Observatory For x-ray Timing (LOFT) was studied within ESA M3
Cosmic Vision framework and participated in the final down-selection for a
launch slot in 2022-2024. Thanks to the unprecedented combination of effective
area and spectral resolution of its main instrument, LOFT will study the
behaviour of matter under extreme conditions, such as the strong gravitational
field in the innermost regions of accretion flows close to black holes and
neutron stars, and the supra-nuclear densities in the interior of neutron
stars. The science payload is based on a Large Area Detector (LAD, 10 m 2
effective area, 2-30 keV, 240 eV spectral resolution, 1 deg collimated field of
view) and a WideField Monitor (WFM, 2-50 keV, 4 steradian field of view, 1
arcmin source location accuracy, 300 eV spectral resolution). The WFM is
equipped with an on-board system for bright events (e.g. GRB) localization. The
trigger time and position of these events are broadcast to the ground within 30
s from discovery. In this paper we present the status of the mission at the end
of its Phase A study.


