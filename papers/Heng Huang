Model Selection for Gaussian Mixture Models

  This paper is concerned with an important issue in finite mixture modelling,
the selection of the number of mixing components. We propose a new penalized
likelihood method for model selection of finite multivariate Gaussian mixture
models. The proposed method is shown to be statistically consistent in
determining of the number of components. A modified EM algorithm is developed
to simultaneously select the number of components and to estimate the mixing
weights, i.e. the mixing probabilities, and unknown parameters of Gaussian
distributions. Simulations and a real data analysis are presented to illustrate
the performance of the proposed method.


A Distributional Representation Model For Collaborative Filtering

  In this paper, we propose a very concise deep learning approach for
collaborative filtering that jointly models distributional representation for
users and items. The proposed framework obtains better performance when
compared against current state-of-art algorithms and that made the
distributional representation model a promising direction for further research
in the collaborative filtering.


Stroke-based Character Reconstruction

  Background elimination for noisy character images or character images from
real scene is still a challenging problem, due to the bewildering backgrounds,
uneven illumination, low resolution and different distortions. We propose a
stroke-based character reconstruction(SCR) method that use a weighted quadratic
Bezier curve(WQBC) to represent strokes of a character. Only training on our
synthetic data, our stroke extractor can achieve excellent reconstruction
effect in real scenes. Meanwhile. It can also help achieve great ability in
defending adversarial attacks of character recognizers.


Learning to Paint with Model-based Deep Reinforcement Learning

  We show how to teach machines to paint like human painters, who can use a few
strokes to create fantastic paintings. By combining the neural renderer and
model-based Deep Reinforcement Learning (DRL), our agent can decompose
texture-rich images into strokes and make long-term plans. For each stroke, the
agent directly determines the position and color of the stroke. Excellent
visual effect can be achieved using hundreds of strokes. The training process
does not require experience of human painting or stroke tracking data.


Are Tensor Decomposition Solutions Unique? On the global convergence of
  HOSVD and ParaFac algorithms

  For tensor decompositions such as HOSVD and ParaFac, the objective functions
are nonconvex. This implies, theoretically, there exists a large number of
local optimas: starting from different starting point, the iteratively improved
solution will converge to different local solutions. This non-uniqueness
present a stability and reliability problem for image compression and
retrieval. In this paper, we present the results of a comprehensive
investigation of this problem. We found that although all tensor decomposition
algorithms fail to reach a unique global solution on random data and severely
scrambled data; surprisingly however, on all real life several data sets (even
with substantial scramble and occlusions), HOSVD always produce the unique
global solution in the parameter region suitable to practical applications,
while ParaFac produce non-unique solutions. We provide an eigenvalue based rule
for the assessing the solution uniqueness.


Terabit optical OFDM superchannel transmission via coherent carriers of
  a hybrid chip-scale soliton frequency comb

  We demonstrate seamless channel multiplexing and high bitrate superchannel
transmission of coherent optical orthogonal-frequency-division-multiplexing
(CO-OFDM) data signals utilizing a dissipative Kerr soliton (DKS) frequency
comb generated in an on-chip microcavity. Aided by comb line multiplication
through Nyquist pulse modulation, the high stability and mutual coherence among
mode-locked Kerr comb lines are exploited for the first time to eliminate the
guard intervals between communication channels and achieve full spectral
density bandwidth utilization. Spectral efficiency as high as 2.625 bit/Hz/s is
obtained for 180 CO-OFDM bands encoded with 12.75 Gbaud 8-QAM data, adding up
to total bitrate of 6.885 Tb/s within 2.295 THz frequency comb bandwidth. Our
study confirms that high coherence is the key superiority of Kerr soliton
frequency combs over independent laser diodes, as a multi-spectral coherent
laser source for high-bandwidth high-spectral-density transmission networks.


Query Answering with Inconsistent Existential Rules under Stable Model
  Semantics

  Traditional inconsistency-tolerent query answering in ontology-based data
access relies on selecting maximal components of an ABox/database which are
consistent with the ontology. However, some rules in ontologies might be
unreliable if they are extracted from ontology learning or written by
unskillful knowledge engineers. In this paper we present a framework of
handling inconsistent existential rules under stable model semantics, which is
defined by a notion called rule repairs to select maximal components of the
existential rules. Surprisingly, for R-acyclic existential rules with
R-stratified or guarded existential rules with stratified negations, both the
data complexity and combined complexity of query answering under the rule
{repair semantics} remain the same as that under the conventional query
answering semantics. This leads us to propose several approaches to handle the
rule {repair semantics} by calling answer set programming solvers. An
experimental evaluation shows that these approaches have good scalability of
query answering under rule repairs on realistic cases.


Six-wave mixing induced by free-carrier plasma in silicon nanowire
  waveguides

  Nonlinear wave mixing in mesoscopic silicon structures is a fundamental
nonlinear process with broad impact and applications. Silicon nanowire
waveguides, in particular, have large third-order Kerr nonlinearity, enabling
salient and abundant four-wave-mixing dynamics and functionalities. Besides the
Kerr effect, in silicon waveguides two-photon absorption generates high
free-carrier densities, with corresponding fifth-order nonlinearity in the
forms of free-carrier dispersion and free-carrier absorption. However, whether
these fifth-order free-carrier nonlinear effects can lead to six-wave-mixing
dynamics still remains an open question until now. Here we report the
demonstration of free-carrier-induced six-wave mixing in silicon nanowires.
Unique features, including inverse detuning dependence of six-wave-mixing
efficiency and its higher sensitivity to pump power, are originally observed
and verfied by analytical prediction and numerical modeling. Additionally,
asymmetric sideband generation is observed for different laser detunings,
resulting from the phase-sensitive interactions between free-carrier
six-wave-mixing and Kerr four-wave-mixing dynamics. These discoveries provide a
new path for nonlinear multi-wave interactions in nanoscale platforms.


Continuous monitoring of membrane protein micro-domain association
  during cell signaling

  Central to understanding membrane bound cell signaling is to quantify how the
membrane ultra-structure consisting of transient spatial domains modulates
signaling and how the signaling influences this ultra-structure. Yet, measuring
the association of membrane proteins with domains in living, intact cells poses
considerable challenges. Here, we describe a non-destructive method to quantify
protein-lipid domain and protein cytoskeleton interactions in single, intact
cells enabling continuous monitoring of the protein domains interaction over
time during signaling.


Tunable single-photon frequency conversion in a Sagnac interferometer

  We study the single-photon frequency conversion of a five-level emitter
coupled to a Sagnac interferometer. We show that the unity conversion
efficiency can be achieved either in resonance or off-resonance case under the
ideal condition. In particular, the frequency of the output photon can be
controlled by the frequencies and Rabi frequencies of the external driving
fields.


Clinical Information Extraction via Convolutional Neural Network

  We report an implementation of a clinical information extraction tool that
leverages deep neural network to annotate event spans and their attributes from
raw clinical notes and pathology reports. Our approach uses context words and
their part-of-speech tags and shape information as features. Then we hire
temporal (1D) convolutional neural network to learn hidden feature
representations. Finally, we use Multilayer Perceptron (MLP) to predict event
spans. The empirical evaluation demonstrates that our approach significantly
outperforms baselines.


Linear absorption coefficient of in-plane graphene on a silicon
  microring resonator

  We demonstrate that linear absorption coefficient (LAC) of a graphene-silicon
hybrid waveguide (GSHW) is determined by the optical transmission spectra of a
graphene coated symmetrically coupled add-drop silicon microring resonator
(SC-ADSMR), of which the value is around 0.23 dB/um. In contrast to the
traditional cut-back method, the measured results are not dependent on the
coupling efficiency of the fiber tip and the waveguide. Moreover, precision
evaluation of graphene coated silicon microring resonator (SMR) is crucial for
the optoelectronic devices targeting for compact footprint and low power
consumption.


Leveraging Deep Neural Networks and Knowledge Graphs for Entity
  Disambiguation

  Entity Disambiguation aims to link mentions of ambiguous entities to a
knowledge base (e.g., Wikipedia). Modeling topical coherence is crucial for
this task based on the assumption that information from the same semantic
context tends to belong to the same topic. This paper presents a novel deep
semantic relatedness model (DSRM) based on deep neural networks (DNN) and
semantic knowledge graphs (KGs) to measure entity semantic relatedness for
topical coherence modeling. The DSRM is directly trained on large-scale KGs and
it maps heterogeneous types of knowledge of an entity from KGs to numerical
feature vectors in a latent space such that the distance between two
semantically-related entities is minimized. Compared with the state-of-the-art
relatedness approach proposed by (Milne and Witten, 2008a), the DSRM obtains
19.4% and 24.5% reductions in entity disambiguation errors on two publicly
available datasets respectively.


Face Aging Effect Simulation using Hidden Factor Analysis Joint Sparse
  Representation

  Face aging simulation has received rising investigations nowadays, whereas it
still remains a challenge to generate convincing and natural age-progressed
face images. In this paper, we present a novel approach to such an issue by
using hidden factor analysis joint sparse representation. In contrast to the
majority of tasks in the literature that handle the facial texture integrally,
the proposed aging approach separately models the person-specific facial
properties that tend to be stable in a relatively long period and the
age-specific clues that change gradually over time. It then merely transforms
the age component to a target age group via sparse reconstruction, yielding
aging effects, which is finally combined with the identity component to achieve
the aged face. Experiments are carried out on three aging databases, and the
results achieved clearly demonstrate the effectiveness and robustness of the
proposed method in rendering a face with aging effects. Additionally, a series
of evaluations prove its validity with respect to identity preservation and
aging effect generation.


Zero-Shot Transfer Learning for Event Extraction

  Most previous event extraction studies have relied heavily on features
derived from annotated event mentions, thus cannot be applied to new event
types without annotation effort. In this work, we take a fresh look at event
extraction and model it as a grounding problem. We design a transferable neural
architecture, mapping event mentions and types jointly into a shared semantic
space using structural and compositional neural networks, where the type of
each event mention can be determined by the closest of all candidate types . By
leveraging (1)~available manual annotations for a small set of existing event
types and (2)~existing event ontologies, our framework applies to new event
types without requiring additional annotation. Experiments on both existing
event types (e.g., ACE, ERE) and new event types (e.g., FrameNet) demonstrate
the effectiveness of our approach. \textit{Without any manual annotations} for
23 new event types, our zero-shot framework achieved performance comparable to
a state-of-the-art supervised model which is trained from the annotations of
500 event mentions.


Improving Slot Filling Performance with Attentive Neural Networks on
  Dependency Structures

  Slot Filling (SF) aims to extract the values of certain types of attributes
(or slots, such as person:cities\_of\_residence) for a given entity from a
large collection of source documents. In this paper we propose an effective DNN
architecture for SF with the following new strategies: (1). Take a regularized
dependency graph instead of a raw sentence as input to DNN, to compress the
wide contexts between query and candidate filler; (2). Incorporate two
attention mechanisms: local attention learned from query and candidate filler,
and global attention learned from external knowledge bases, to guide the model
to better select indicative contexts to determine slot type. Experiments show
that this framework outperforms state-of-the-art on both relation extraction
(16\% absolute F-score gain) and slot filling validation for each individual
system (up to 8.5\% absolute F-score gain).


Learning Phrase Embeddings from Paraphrases with GRUs

  Learning phrase representations has been widely explored in many Natural
Language Processing (NLP) tasks (e.g., Sentiment Analysis, Machine Translation)
and has shown promising improvements. Previous studies either learn
non-compositional phrase representations with general word embedding learning
techniques or learn compositional phrase representations based on syntactic
structures, which either require huge amounts of human annotations or cannot be
easily generalized to all phrases. In this work, we propose to take advantage
of large-scaled paraphrase database and present a pair-wise gated recurrent
units (pairwise-GRU) framework to generate compositional phrase
representations. Our framework can be re-used to generate representations for
any phrases. Experimental results show that our framework achieves
state-of-the-art results on several phrase similarity tasks.


Linear networks based speaker adaptation for speech synthesis

  Speaker adaptation methods aim to create fair quality synthesis speech voice
font for target speakers while only limited resources available. Recently, as
deep neural networks based statistical parametric speech synthesis (SPSS)
methods become dominant in SPSS TTS back-end modeling, speaker adaptation under
the neural network based SPSS framework has also became an important task. In
this paper, linear networks (LN) is inserted in multiple neural network layers
and fine-tuned together with output layer for best speaker adaptation
performance. When adaptation data is extremely small, the low-rank plus
diagonal(LRPD) decomposition for LN is employed to make the adapted voice more
stable. Speaker adaptation experiments are conducted under a range of
adaptation utterances numbers. Moreover, speaker adaptation from 1) female to
female, 2) male to female and 3) female to male are investigated. Objective
measurement and subjective tests show that LN with LRPD decomposition performs
most stable when adaptation data is extremely limited, and our best speaker
adaptation (SA) model with only 200 adaptation utterances achieves comparable
quality with speaker dependent (SD) model trained with 1000 utterances, in both
naturalness and similarity to target speaker.


Multi-lingual Common Semantic Space Construction via Cluster-consistent
  Word Embedding

  We construct a multilingual common semantic space based on distributional
semantics, where words from multiple languages are projected into a shared
space to enable knowledge and resource transfer across languages. Beyond word
alignment, we introduce multiple cluster-level alignments and enforce the word
clusters to be consistently distributed across multiple languages. We exploit
three signals for clustering: (1) neighbor words in the monolingual word
embedding space; (2) character-level information; and (3) linguistic properties
(e.g., apposition, locative suffix) derived from linguistic structure knowledge
bases available for thousands of languages. We introduce a new
cluster-consistent correlational neural network to construct the common
semantic space by aligning words as well as clusters. Intrinsic evaluation on
monolingual and multilingual QVEC tasks shows our approach achieves
significantly higher correlation with linguistic features than state-of-the-art
multi-lingual embedding learning methods do. Using low-resource language name
tagging as a case study for extrinsic evaluation, our approach achieves up to
24.5\% absolute F-score gain over the state of the art.


Emulating many-body localization with a superconducting quantum
  processor

  The law of statistical physics dictates that generic closed quantum many-body
systems initialized in nonequilibrium will thermalize under their own dynamics.
However, the emergence of many-body localization (MBL) owing to the interplay
between interaction and disorder, which is in stark contrast to Anderson
localization that only addresses noninteracting particles in the presence of
disorder, greatly challenges this concept because it prevents the systems from
evolving to the ergodic thermalized state. One critical evidence of MBL is the
long-time logarithmic growth of entanglement entropy, and a direct observation
of it is still elusive due to the experimental challenges in multiqubit
single-shot measurement and quantum state tomography. Here we present an
experiment of fully emulating the MBL dynamics with a 10-qubit superconducting
quantum processor, which represents a spin-1/2 XY model featuring programmable
disorder and long-range spin-spin interactions. We provide essential signatures
of MBL, such as the imbalance due to the initial nonequilibrium, the violation
of eigenstate thermalization hypothesis, and, more importantly, the direct
evidence of the long-time logarithmic growth of entanglement entropy. Our
results lay solid foundations for precisely simulating the intriguing physics
of quantum many-body systems on the platform of large-scale multiqubit
superconducting quantum processors.


Faster Gradient-Free Proximal Stochastic Methods for Nonconvex Nonsmooth
  Optimization

  Proximal gradient method has been playing an important role to solve many
machine learning tasks, especially for the nonsmooth problems. However, in some
machine learning problems such as the bandit model and the black-box learning
problem, proximal gradient method could fail because the explicit gradients of
these problems are difficult or infeasible to obtain. The gradient-free
(zeroth-order) method can address these problems because only the objective
function values are required in the optimization. Recently, the first
zeroth-order proximal stochastic algorithm was proposed to solve the nonconvex
nonsmooth problems. However, its convergence rate is $O(\frac{1}{\sqrt{T}})$
for the nonconvex problems, which is significantly slower than the best
convergence rate $O(\frac{1}{T})$ of the zeroth-order stochastic algorithm,
where $T$ is the iteration number. To fill this gap, in the paper, we propose a
class of faster zeroth-order proximal stochastic methods with the variance
reduction techniques of SVRG and SAGA, which are denoted as ZO-ProxSVRG and
ZO-ProxSAGA, respectively. In theoretical analysis, we address the main
challenge that an unbiased estimate of the true gradient does not hold in the
zeroth-order case, which was required in previous theoretical analysis of both
SVRG and SAGA. Moreover, we prove that both ZO-ProxSVRG and ZO-ProxSAGA
algorithms have $O(\frac{1}{T})$ convergence rates. Finally, the experimental
results verify that our algorithms have a faster convergence rate than the
existing zeroth-order proximal stochastic algorithm.


Dark Matter Results From 54-Ton-Day Exposure of PandaX-II Experiment

  We report a new search of weakly interacting massive particles (WIMPs) using
the combined low background data sets in 2016 and 2017 from the PandaX-II
experiment in China. The latest data set contains a new exposure of 77.1 live
day, with the background reduced to a level of 0.8$\times10^{-3}$ evt/kg/day,
improved by a factor of 2.5 in comparison to the previous run in 2016. No
excess events were found above the expected background. With a total exposure
of 5.4$\times10^4$ kg day, the most stringent upper limit on spin-independent
WIMP-nucleon cross section was set for a WIMP with mass larger than 100
GeV/c$^2$, with the lowest exclusion at 8.6$\times10^{-47}$ cm$^2$ at 40
GeV/c$^2$.


Constraining Dark Matter Models with a Light Mediator from PandaX-II
  Experiment

  We search for nuclear recoil signals of dark matter models with a light
mediator in PandaX-II, a direct detection experiment in China Jinping
underground Laboratory. Using data collected in 2016 and 2017 runs,
corresponding to a total exposure of 54 ton day, we set upper limits on the
zero-momentum dark matter-nucleon cross section. These limits have a strong
dependence on the mediator mass when it is comparable to or below the typical
momentum transfer. We apply our results to constrain self-interacting dark
matter models with a light mediator mixing with standard model particles, and
set strong limits on the model parameter space for the dark matter mass ranging
from $5~{\rm GeV}$ to $10~{\rm TeV}$.


Dark matter direct search sensitivity of the PandaX-4T experiment

  The PandaX-4T experiment, a four-ton scale dark matter direct detection
experiment, is being planned at the China Jinping Underground Laboratory. In
this paper we present a simulation study of the expected background in this
experiment. In a 2.8-ton fiducial mass and the signal region between 1 to 10
keV electron equivalent energy, the total electron recoil background is found
to be 4.9x10^{-5} /(kg day keV). The nuclear recoil background in the same
region is 2.8x10^{-7}/(kg day keV). With an exposure of 5.6 ton-years, the
sensitivity of PandaX-4T could reach a minimum spin-independent dark
matter-nucleon cross section of 6x10^{-48} cm^{2} at a dark matter mass of 40
GeV/c^{2}.


PandaX-II Constraints on Spin-Dependent WIMP-Nucleon Effective
  Interactions

  We present PandaX-II constraints on candidate WIMP-nucleon effective
interactions involving the nucleon or WIMP spin, including, in addition to
standard axial spin-dependent (SD) scattering, various couplings among vector
and axial currents, magnetic and electric dipole moments, and tensor
interactions. The data set corresponding to a total exposure of 54-ton-days is
reanalyzed to determine constraints as a function of the WIMP mass and isospin
coupling. We obtain WIMP-nucleon cross section bounds of $\rm 1.6 \times
10^{-41} cm^2$ and $\rm 9.0 \times 10^{-42} cm^2$ ($90\%$ c.l.) for
neutron-only SD and tensor coupling, respectively, for a mass $M_\mathrm{WIMP}
\sim {\rm 40~GeV}/c^2$. The SD limits are the best currently available for
$M_\mathrm{WIMP} > {\rm 40~GeV}/c^2$. We show that PandaX-II has reached a
sensitivity sufficient to probe a variety of other candidate spin-dependent
interactions at the weak scale.


Building a Fine-Grained Entity Typing System Overnight for a New X (X =
  Language, Domain, Genre)

  Recent research has shown great progress on fine-grained entity typing. Most
existing methods require pre-defining a set of types and training a multi-class
classifier from a large labeled data set based on multi-level linguistic
features. They are thus limited to certain domains, genres and languages. In
this paper, we propose a novel unsupervised entity typing framework by
combining symbolic and distributional semantics. We start from learning general
embeddings for each entity mention, compose the embeddings of specific contexts
using linguistic structures, link the mention to knowledge bases and learn its
related knowledge representations. Then we develop a novel joint hierarchical
clustering and linking algorithm to type all mentions using these
representations. This framework doesn't rely on any annotated data, predefined
typing schema, or hand-crafted features, therefore it can be quickly adapted to
a new domain, genre and language. Furthermore, it has great flexibility at
incorporating linguistic structures (e.g., Abstract Meaning Representation
(AMR), dependency relations) to improve specific context representation.
Experiments on genres (news and discussion forum) show comparable performance
with state-of-the-art supervised typing systems trained from a large amount of
labeled data. Results on various languages (English, Chinese, Japanese, Hausa,
and Yoruba) and domains (general and biomedical) demonstrate the portability of
our framework.


Optimization of synchronization in gradient clustered networks

  We consider complex clustered networks with a gradient structure, where sizes
of the clusters are distributed unevenly. Such networks describe more closely
actual networks in biophysical systems and in technological applications than
previous models. Theoretical analysis predicts that the network
synchronizability can be optimized by the strength of the gradient field but
only when the gradient field points from large to small clusters. A remarkable
finding is that, if the gradient field is sufficiently strong,
synchronizability of the network is mainly determined by the properties of the
subnetworks in the two largest clusters. These results are verified by
numerical eigenvalue analysis and by direct simulation of synchronization
dynamics on coupled-oscillator networks.


The Complexity of Planar Boolean #CSP with Complex Weights

  We prove a complexity dichotomy theorem for symmetric complex-weighted
Boolean #CSP when the constraint graph of the input must be planar. The
problems that are #P-hard over general graphs but tractable over planar graphs
are precisely those with a holographic reduction to matchgates. This
generalizes a theorem of Cai, Lu, and Xia for the case of real weights. We also
obtain a dichotomy theorem for a symmetric arity 4 signature with complex
weights in the planar Holant framework, which we use in the proof of our #CSP
dichotomy. In particular, we reduce the problem of evaluating the Tutte
polynomial of a planar graph at the point (3,3) to counting the number of
Eulerian orientations over planar 4-regular graphs to show the latter is
#P-hard. This strengthens a theorem by Huang and Lu to the planar setting. Our
proof techniques combine new ideas with refinements and extensions of existing
techniques. These include planar pairings, the recursive unary construction,
the anti-gadget technique, and pinning in the Hadamard basis.


Bidirectional Long-Short Term Memory for Video Description

  Video captioning has been attracting broad research attention in multimedia
community. However, most existing approaches either ignore temporal information
among video frames or just employ local contextual temporal knowledge. In this
work, we propose a novel video captioning framework, termed as
\emph{Bidirectional Long-Short Term Memory} (BiLSTM), which deeply captures
bidirectional global temporal structure in video. Specifically, we first devise
a joint visual modelling approach to encode video data by combining a forward
LSTM pass, a backward LSTM pass, together with visual features from
Convolutional Neural Networks (CNNs). Then, we inject the derived video
representation into the subsequent language model for initialization. The
benefits are in two folds: 1) comprehensively preserving sequential and visual
information; and 2) adaptively learning dense visual features and sparse
semantic representations for videos and sentences, respectively. We verify the
effectiveness of our proposed video captioning framework on a commonly-used
benchmark, i.e., Microsoft Video Description (MSVD) corpus, and the
experimental results demonstrate that the superiority of the proposed approach
as compared to several state-of-the-art methods.


An Iterative Locally Linear Embedding Algorithm

  Local Linear embedding (LLE) is a popular dimension reduction method. In this
paper, we first show LLE with nonnegative constraint is equivalent to the
widely used Laplacian embedding. We further propose to iterate the two steps in
LLE repeatedly to improve the results. Thirdly, we relax the kNN constraint of
LLE and present a sparse similarity learning algorithm. The final Iterative LLE
combines these three improvements. Extensive experiment results show that
iterative LLE algorithm significantly improve both classification and
clustering results.


Non-Greedy L21-Norm Maximization for Principal Component Analysis

  Principal Component Analysis (PCA) is one of the most important unsupervised
methods to handle high-dimensional data. However, due to the high computational
complexity of its eigen decomposition solution, it hard to apply PCA to the
large-scale data with high dimensionality. Meanwhile, the squared L2-norm based
objective makes it sensitive to data outliers. In recent research, the L1-norm
maximization based PCA method was proposed for efficient computation and being
robust to outliers. However, this work used a greedy strategy to solve the
eigen vectors. Moreover, the L1-norm maximization based objective may not be
the correct robust PCA formulation, because it loses the theoretical connection
to the minimization of data reconstruction error, which is one of the most
important intuitions and goals of PCA. In this paper, we propose to maximize
the L21-norm based robust PCA objective, which is theoretically connected to
the minimization of reconstruction error. More importantly, we propose the
efficient non-greedy optimization algorithms to solve our objective and the
more general L21-norm maximization problem with theoretically guaranteed
convergence. Experimental results on real world data sets show the
effectiveness of the proposed method for principal component analysis.


Enhancing Sentence Relation Modeling with Auxiliary Character-level
  Embedding

  Neural network based approaches for sentence relation modeling automatically
generate hidden matching features from raw sentence pairs. However, the quality
of matching feature representation may not be satisfied due to complex semantic
relations such as entailment or contradiction. To address this challenge, we
propose a new deep neural network architecture that jointly leverage
pre-trained word embedding and auxiliary character embedding to learn sentence
meanings. The two kinds of word sequence representations as inputs into
multi-layer bidirectional LSTM to learn enhanced sentence representation. After
that, we construct matching features followed by another temporal CNN to learn
high-level hidden matching feature representations. Experimental results
demonstrate that our approach consistently outperforms the existing methods on
standard evaluation datasets.


Improved Spectral Clustering via Embedded Label Propagation

  Spectral clustering is a key research topic in the field of machine learning
and data mining. Most of the existing spectral clustering algorithms are built
upon Gaussian Laplacian matrices, which are sensitive to parameters. We propose
a novel parameter free, distance consistent Locally Linear Embedding. The
proposed distance consistent LLE promises that edges between closer data points
have greater weight.Furthermore, we propose a novel improved spectral
clustering via embedded label propagation. Our algorithm is built upon two
advancements of the state of the art:1) label propagation,which propagates a
node\'s labels to neighboring nodes according to their proximity; and 2)
manifold learning, which has been widely used in its capacity to leverage the
manifold structure of data points. First we perform standard spectral
clustering on original data and assign each cluster to k nearest data points.
Next, we propagate labels through dense, unlabeled data regions. Extensive
experiments with various datasets validate the superiority of the proposed
algorithm compared to current state of the art spectral algorithms.


Theoretic Analysis and Extremely Easy Algorithms for Domain Adaptive
  Feature Learning

  Domain adaptation problems arise in a variety of applications, where a
training dataset from the \textit{source} domain and a test dataset from the
\textit{target} domain typically follow different distributions. The primary
difficulty in designing effective learning models to solve such problems lies
in how to bridge the gap between the source and target distributions. In this
paper, we provide comprehensive analysis of feature learning algorithms used in
conjunction with linear classifiers for domain adaptation. Our analysis shows
that in order to achieve good adaptation performance, the second moments of the
source domain distribution and target domain distribution should be similar.
Based on our new analysis, a novel extremely easy feature learning algorithm
for domain adaptation is proposed. Furthermore, our algorithm is extended by
leveraging multiple layers, leading to a deep linear model. We evaluate the
effectiveness of the proposed algorithms in terms of domain adaptation tasks on
the Amazon review dataset and the spam dataset from the ECML/PKDD 2006
discovery challenge.


A Novel Method of Encoded Multiplexing Readout for Micro-pattern Gas
  Detectors

  The requirement of a large number of electronic channels poses a big
challenge for Micro-pattern Gas Detector (MPGD) to achieve good spatial
resolution. By using the redundancy that at least two neighboring strips record
the signal of a particle, a novel method of encoded multiplexing readout for
MPGDs is presented in this paper. The method offers a feasible and
easily-extensible way of encoding and decoding, and can significantly reduce
the number of readout channels. A verification test was carried out on a 5*5
cm2 Thick Gas Electron Multiplier (THGEM) detector using a 8 keV Cu X-ray
source with 100um slit, where 166 strips are read out by 21 encoded readout
channels. The test results show a good linearity in its position response, and
the spatial resolution root-mean-square (RMS) of the test system is about 260
{\mu}m. This method has an attractive potential to build large area detectors
and can be easily adapted to other detectors like MPGDs.


Asynchronous Stochastic Gradient Descent with Variance Reduction for
  Non-Convex Optimization

  We provide the first theoretical analysis on the convergence rate of the
asynchronous stochastic variance reduced gradient (SVRG) descent algorithm on
non-convex optimization. Recent studies have shown that the asynchronous
stochastic gradient descent (SGD) based algorithms with variance reduction
converge with a linear convergent rate on convex problems. However, there is no
work to analyze asynchronous SGD with variance reduction technique on
non-convex problem. In this paper, we study two asynchronous parallel
implementations of SVRG: one is on a distributed memory system and the other is
on a shared memory system. We provide the theoretical analysis that both
algorithms can obtain a convergence rate of $O(1/T)$, and linear speed up is
achievable if the number of workers is upper bounded. V1,v2,v3 have been
withdrawn due to reference issue, please refer the newest version v4.


Distributed Asynchronous Dual Free Stochastic Dual Coordinate Ascent

  The primal-dual distributed optimization methods have broad large-scale
machine learning applications. Previous primal-dual distributed methods are not
applicable when the dual formulation is not available, e.g. the
sum-of-non-convex objectives. Moreover, these algorithms and theoretical
analysis are based on the fundamental assumption that the computing speeds of
multiple machines in a cluster are similar. However, the straggler problem is
an unavoidable practical issue in the distributed system because of the
existence of slow machines. Therefore, the total computational time of the
distributed optimization methods is highly dependent on the slowest machine. In
this paper, we address these two issues by proposing distributed asynchronous
dual free stochastic dual coordinate ascent algorithm for distributed
optimization. Our method does not need the dual formulation of the target
problem in the optimization. We tackle the straggler problem through
asynchronous communication and the negative effect of slow machines is
significantly alleviated. We also analyze the convergence rate of our method
and prove the linear convergence rate even if the individual functions in
objective are non-convex. Experiments on both convex and non-convex loss
functions are used to validate our statements.


Decoupled Asynchronous Proximal Stochastic Gradient Descent with
  Variance Reduction

  In the era of big data, optimizing large scale machine learning problems
becomes a challenging task and draws significant attention. Asynchronous
optimization algorithms come out as a promising solution. Recently, decoupled
asynchronous proximal stochastic gradient descent (DAP-SGD) is proposed to
minimize a composite function. It is claimed to be able to off-loads the
computation bottleneck from server to workers by allowing workers to evaluate
the proximal operators, therefore, server just need to do element-wise
operations. However, it still suffers from slow convergence rate because of the
variance of stochastic gradient is nonzero. In this paper, we propose a faster
method, decoupled asynchronous proximal stochastic variance reduced gradient
descent method (DAP-SVRG). We prove that our method has linear convergence for
strongly convex problem. Large-scale experiments are also conducted in this
paper, and results demonstrate our theoretical analysis.


A Closed Form Solution to Multi-View Low-Rank Regression

  Real life data often includes information from different channels. For
example, in computer vision, we can describe an image using different image
features, such as pixel intensity, color, HOG, GIST feature, SIFT features,
etc.. These different aspects of the same objects are often called multi-view
(or multi-modal) data. Low-rank regression model has been proved to be an
effective learning mechanism by exploring the low-rank structure of real life
data. But previous low-rank regression model only works on single view data. In
this paper, we propose a multi-view low-rank regression model by imposing
low-rank constraints on multi-view regression model. Most importantly, we
provide a closed-form solution to the multi-view low-rank regression model.
Extensive experiments on 4 multi-view datasets show that the multi-view
low-rank regression model outperforms single-view regression model and reveals
that multi-view low-rank structure is very helpful.


Asynchronous Stochastic Block Coordinate Descent with Variance Reduction

  Asynchronous parallel implementations for stochastic optimization have
received huge successes in theory and practice recently. Asynchronous
implementations with lock-free are more efficient than the one with writing or
reading lock. In this paper, we focus on a composite objective function
consisting of a smooth convex function $f$ and a block separable convex
function, which widely exists in machine learning and computer vision. We
propose an asynchronous stochastic block coordinate descent algorithm with the
accelerated technology of variance reduction (AsySBCDVR), which are with
lock-free in the implementation and analysis. AsySBCDVR is particularly
important because it can scale well with the sample size and dimension
simultaneously. We prove that AsySBCDVR achieves a linear convergence rate when
the function $f$ is with the optimal strong convexity property, and a sublinear
rate when $f$ is with the general convexity. More importantly, a near-linear
speedup on a parallel system with shared memory can be obtained.


Zeroth-order Asynchronous Doubly Stochastic Algorithm with Variance
  Reduction

  Zeroth-order (derivative-free) optimization attracts a lot of attention in
machine learning, because explicit gradient calculations may be computationally
expensive or infeasible. To handle large scale problems both in volume and
dimension, recently asynchronous doubly stochastic zeroth-order algorithms were
proposed. The convergence rate of existing asynchronous doubly stochastic
zeroth order algorithms is $O(\frac{1}{\sqrt{T}})$ (also for the sequential
stochastic zeroth-order optimization algorithms). In this paper, we focus on
the finite sums of smooth but not necessarily convex functions, and propose an
asynchronous doubly stochastic zeroth-order optimization algorithm using the
accelerated technology of variance reduction (AsyDSZOVR). Rigorous theoretical
analysis show that the convergence rate can be improved from
$O(\frac{1}{\sqrt{T}})$ the best result of existing algorithms to
$O(\frac{1}{T})$. Also our theoretical results is an improvement to the ones of
the sequential stochastic zeroth-order optimization algorithms.


Inexact Proximal Gradient Methods for Non-convex and Non-smooth
  Optimization

  In machine learning research, the proximal gradient methods are popular for
solving various optimization problems with non-smooth regularization. Inexact
proximal gradient methods are extremely important when exactly solving the
proximal operator is time-consuming, or the proximal operator does not have an
analytic solution. However, existing inexact proximal gradient methods only
consider convex problems. The knowledge of inexact proximal gradient methods in
the non-convex setting is very limited. % Moreover, for some machine learning
models, there is still no proposed solver for exactly solving the proximal
operator. To address this challenge, in this paper, we first propose three
inexact proximal gradient algorithms, including the basic version and
Nesterov's accelerated version. After that, we provide the theoretical analysis
to the basic and Nesterov's accelerated versions. The theoretical results show
that our inexact proximal gradient algorithms can have the same convergence
rates as the ones of exact proximal gradient algorithms in the non-convex
setting.
  Finally, we show the applications of our inexact proximal gradient algorithms
on three representative non-convex learning problems. All experimental results
confirm the superiority of our new inexact proximal gradient algorithms.


Real-time dynamics and cross-correlation gating spectroscopy of
  free-carrier Drude slow-light solitons

  Optical solitons-stable waves balancing delicately between nonlinearities and
dispersive effects-have advanced the field of ultrafast optics and dynamics,
with contributions spanning supercontinuum generation and soliton fission, to
optical event horizon, Hawking radiation, and optical rogue waves, amongst
others. Here we investigate picojoule soliton dynamics in silicon slow-light
photonic-bandgap waveguides under the influence of Drude-modeled free-carrier
induced nonlinear effects. Using real-time and single shot amplified dispersive
Fourier transform spectroscopy simultaneously with high-fidelity
cross-correlation frequency-resolved optical gating at femtojoule sensitivity
and femtosecond resolution, we examine the soliton stability limits, the
soliton dynamics including free-carrier quartic slow-light scaling and
acceleration, and the Drude electron-hole-plasma induced perturbations on
Cherenkov radiation and modulation instability. Our real-time single shot and
time-averaged cross-correlation measurements are matched with our detailed
theoretical modeling, examining the reduced group velocity free-carrier
kinetics on solitons at picojoule.


Consecutive Insulator-Metal-Insulator Phase Transitions of Vanadium
  Dioxide by Hydrogen Doping

  We report modulation of a reversible phase transition in VO2 films by
hydrogen doping. A metallic phase and a new insulating phase are successively
observed at room temperature as the doping concentration increases. It is
suggested that the polarized charges from doped hydrogens play an important
role. These charges gradually occupy V3d-O2p hybridized orbitals and
consequently modulate the filling of the VO2 crystal conduction band-edge
states, which eventually evolve into new valence band-edge states. This
demonstrates the exceptional sensitivity of VO2 electronic properties to
electron concentration and orbital occupancy, providing key information for the
phase transition mechanism.


Unsupervised Learning of Mixture Regression Models for Longitudinal Data

  This paper is concerned with learning of mixture regression models for
individuals that are measured repeatedly. The adjective "unsupervised" implies
that the number of mixing components is unknown and has to be determined,
ideally by data driven tools. For this purpose, a novel penalized method is
proposed to simultaneously select the number of mixing components and to
estimate the mixing proportions and unknown parameters in the models. The
proposed method is capable of handling both continuous and discrete responses
by only requiring the first two moment conditions of the model distribution. It
is shown to be consistent in both selecting the number of components and
estimating the mixing proportions and unknown regression parameters. Further, a
modified EM algorithm is developed to seamlessly integrate model selection and
estimation. Simulation studies are conducted to evaluate the finite sample
performance of the proposed procedure. And it is further illustrated via an
analysis of a primary biliary cirrhosis data set.


Accelerated Method for Stochastic Composition Optimization with
  Nonsmooth Regularization

  Stochastic composition optimization draws much attention recently and has
been successful in many emerging applications of machine learning, statistical
analysis, and reinforcement learning. In this paper, we focus on the
composition problem with nonsmooth regularization penalty. Previous works
either have slow convergence rate or do not provide complete convergence
analysis for the general problem. In this paper, we tackle these two issues by
proposing a new stochastic composition optimization method for composition
problem with nonsmooth regularization penalty. In our method, we apply variance
reduction technique to accelerate the speed of convergence. To the best of our
knowledge, our method admits the fastest convergence rate for stochastic
composition optimization: for strongly convex composition problem, our
algorithm is proved to admit linear convergence; for general composition
problem, our algorithm significantly improves the state-of-the-art convergence
rate from $O(T^{-1/2})$ to $O((n_1+n_2)^{{2}/{3}}T^{-1})$. Finally, we apply
our proposed algorithm to portfolio management and policy evaluation in
reinforcement learning. Experimental results verify our theoretical analysis.


Entity-aware Image Caption Generation

  Current image captioning approaches generate descriptions which lack specific
information, such as named entities that are involved in the images. In this
paper we propose a new task which aims to generate informative image captions,
given images and hashtags as input. We propose a simple but effective approach
to tackle this problem. We first train a convolutional neural networks - long
short term memory networks (CNN-LSTM) model to generate a template caption
based on the input image. Then we use a knowledge graph based collective
inference algorithm to fill in the template with specific named entities
retrieved via the hashtags. Experiments on a new benchmark dataset collected
from Flickr show that our model generates news-style image descriptions with
much richer information. Our model outperforms unimodal baselines significantly
with various evaluation metrics.


Decoupled Parallel Backpropagation with Convergence Guarantee

  Backpropagation algorithm is indispensable for the training of feedforward
neural networks. It requires propagating error gradients sequentially from the
output layer all the way back to the input layer. The backward locking in
backpropagation algorithm constrains us from updating network layers in
parallel and fully leveraging the computing resources. Recently, several
algorithms have been proposed for breaking the backward locking. However, their
performances degrade seriously when networks are deep. In this paper, we
propose decoupled parallel backpropagation algorithm for deep learning
optimization with convergence guarantee. Firstly, we decouple the
backpropagation algorithm using delayed gradients, and show that the backward
locking is removed when we split the networks into multiple modules. Then, we
utilize decoupled parallel backpropagation in two stochastic methods and prove
that our method guarantees convergence to critical points for the non-convex
problem. Finally, we perform experiments for training deep convolutional neural
networks on benchmark datasets. The experimental results not only confirm our
theoretical analysis, but also demonstrate that the proposed method can achieve
significant speedup without loss of accuracy.


Paper Abstract Writing through Editing Mechanism

  We present a paper abstract writing system based on an attentive neural
sequence-to-sequence model that can take a title as input and automatically
generate an abstract. We design a novel Writing-editing Network that can attend
to both the title and the previously generated abstract drafts and then
iteratively revise and polish the abstract. With two series of Turing tests,
where the human judges are asked to distinguish the system-generated abstracts
from human-written ones, our system passes Turing tests by junior domain
experts at a rate up to 30% and by non-expert at a rate up to 80%.


Naturally Phase Matched Lithium Niobate Nanocircuits for Integrated
  Nonlinear Photonics

  High complexity, dense integrated nanophotonic circuits possessing strong
nonlinearities are desirable for a breadth of applications in classical and
quantum optics. In this work, we study natural phase matching via modal
engineering in lithium niobate (LN) waveguides and microring resonators on chip
for second harmonic generation (SHG). By carefully engineering the geometry
dispersion, we observe a $26\%~W^{-1}cm^{-2}$ normalized efficiency for SHG in
a waveguide with submicron transverse mode confinement. With similar
cross-sectional dimensions, we demonstrate phase matched SHG in a microring
resonator with 10 times enhancement on the out-coupled second-harmonic power.
Our platform is capable of harnessing the strongest optical nonlinear and
electro-optic effects in LN on chip with unrestricted planar circuit layouts.
It offers opportunities for dense and scalable integration of efficient
photonic devices with low loss and high nonlinearity.


