Reshaping the use of digital tools to fight malaria

  In this extended abstract we present our approach to marshal digital tools in
the fight against malaria. We describe our scalable infrastructure which
leverages abstractions to support effective deployment of existing
computational models and their associated data.


Characterizing the hyper-parameter space of LSTM language models for
  mixed context applications

  Applying state of the art deep learning models to novel real world datasets
gives a practical evaluation of the generalizability of these models. Of
importance in this process is how sensitive the hyper parameters of such models
are to novel datasets as this would affect the reproducibility of a model. We
present work to characterize the hyper parameter space of an LSTM for language
modeling on a code-mixed corpus. We observe that the evaluated model shows
minimal sensitivity to our novel dataset bar a few hyper parameters.


Assessing virtualization effects in simulations of distributed robotics

  In this work, our aim is to identify whether the choice of virtualization
strategy influences the performance of simulations in robotics. Performance is
quantified in the error between a reference trajectory and the actual
trajectory for the ball moving along the surface of a smooth plate. The
two-sample Kolmogorov-Smirnov test is used to assess significance of variations
in performance under the different experimental settings. Our results show that
the selection of virtualization technology does have a significant effect on
simulation, and moreover this effect can be amplified by the use of some
operating systems. While these results are a strong cause for caution, they
also provide reason for optimism for those considering 'repeatable robotics
research' using virtualization.


Web Standards as Standard Pieces in Robotics

  Modern robotics often involves the use of web technologies as a means to cope
with the complexity of design and operation. Many of these technologies have
been formalized into standards, which are often avoided by those in robotics
and controls because of a sometimes warranted fear that "the web" is too slow,
or too uncertain for meaningful control applications.
  In this work we argue that while web technologies may not be applicable for
all control, they should not be dismissed outright because they can provide
critical help with system integration. Web technologies have also advanced
significantly over the past decade. We present the details of an application of
a web server to perform open and close-loop control (between 3Hz and 1kHz) over
a variety of different network topologies. In our study we also consider the
impact of a web browser to implement the control of the plant. Our results
confirm that meaningful control can be performed using web technologies, and
also highlight design choices that can limit their applicability.


Using Genetic Algorithms to Benchmark the Cloud

  This paper presents a novel application of Genetic Algorithms(GAs) to
quantify the performance of Platform as a Service (PaaS), a cloud service model
that plays a critical role in both industry and academia. While Cloud
benchmarks are not new, in this novel concept, the authors use a GA to take
advantage of the elasticity in Cloud services in a graceful manner that was not
previously possible. Using Google App Engine, Heroku, and Python Anywhere with
three distinct classes of client computers running our GA codebase, we
quantified the completion time for application of the GA to search for the
parameters of controllers for dynamical systems. Our results show statistically
significant differences in PaaS performance by vendor, and also that the
performance of the PaaS performance is dependent upon the client that uses it.
Results also show the effectiveness of our GA in determining the level of
service of PaaS providers, and for determining if the level of service of one
PaaS vendor is repeatable with another. Such a concept could then increase the
appeal of PaaS Cloud services by making them more financially appealing.


Novel Exploration Techniques (NETs) for Malaria Policy Interventions

  The task of decision-making under uncertainty is daunting, especially for
problems which have significant complexity. Healthcare policy makers across the
globe are facing problems under challenging constraints, with limited tools to
help them make data driven decisions. In this work we frame the process of
finding an optimal malaria policy as a stochastic multi-armed bandit problem,
and implement three agent based strategies to explore the policy space. We
apply a Gaussian Process regression to the findings of each agent, both for
comparison and to account for stochastic results from simulating the spread of
malaria in a fixed population. The generated policy spaces are compared with
published results to give a direct reference with human expert decisions for
the same simulated population. Our novel approach provides a powerful resource
for policy makers, and a platform which can be readily extended to capture
future more nuanced policy spaces.


Subset Scanning Over Neural Network Activations

  This work views neural networks as data generating systems and applies
anomalous pattern detection techniques on that data in order to detect when a
network is processing an anomalous input. Detecting anomalies is a critical
component for multiple machine learning problems including detecting
adversarial noise. More broadly, this work is a step towards giving neural
networks the ability to recognize an out-of-distribution sample. This is the
first work to introduce "Subset Scanning" methods from the anomalous pattern
detection domain to the task of detecting anomalous input of neural networks.
Subset scanning treats the detection problem as a search for the most anomalous
subset of node activations (i.e., highest scoring subset according to
non-parametric scan statistics). Mathematical properties of these scoring
functions allow the search to be completed in log-linear rather than
exponential time while still guaranteeing the most anomalous subset of nodes in
the network is identified for a given input. Quantitative results for detecting
and characterizing adversarial noise are provided for CIFAR-10 images on a
simple convolutional neural network. We observe an "interference" pattern where
anomalous activations in shallow layers suppress the activation structure of
the original image in deeper layers.


Promoting Distributed Trust in Machine Learning and Computational
  Simulation via a Blockchain Network

  Policy decisions are increasingly dependent on the outcomes of simulations
and/or machine learning models. The ability to share and interact with these
outcomes is relevant across multiple fields and is especially critical in the
disease modeling community where models are often only accessible and workable
to the researchers that generate them. This work presents a blockchain-enabled
system that establishes a decentralized trust between parties involved in a
modeling process. Utilizing the OpenMalaria framework, we demonstrate the
ability to store, share and maintain auditable logs and records of each step in
the simulation process, showing how to validate results generated by computing
workers. We also show how the system monitors worker outputs to rank and
identify faulty workers via comparison to nearest neighbors or historical
reward spaces as a means of ensuring model quality.


Trusted Multi-Party Computation and Verifiable Simulations: A Scalable
  Blockchain Approach

  Large-scale computational experiments, often running over weeks and over
large datasets, are used extensively in fields such as epidemiology,
meteorology, computational biology, and healthcare to understand phenomena, and
design high-stakes policies affecting everyday health and economy. For
instance, the OpenMalaria framework is a computationally-intensive simulation
used by various non-governmental and governmental agencies to understand
malarial disease spread and effectiveness of intervention strategies, and
subsequently design healthcare policies. Given that such shared results form
the basis of inferences drawn, technological solutions designed, and day-to-day
policies drafted, it is essential that the computations are validated and
trusted. In particular, in a multi-agent environment involving several
independent computing agents, a notion of trust in results generated by peers
is critical in facilitating transparency, accountability, and collaboration.
Using a novel combination of distributed validation of atomic computation
blocks and a blockchain-based immutable audits mechanism, this work proposes a
universal framework for distributed trust in computations. In particular we
address the scalaibility problem by reducing the storage and communication
costs using a lossy compression scheme. This framework guarantees not only
verifiability of final results, but also the validity of local computations,
and its cost-benefit tradeoffs are studied using a synthetic example of
training a neural network.


