Faculty citation measures are highly correlated with peer assessment of  computer science doctoral programs

  We study relationship between peer assessment of quality of U.S. ComputerScience (CS) doctoral programs and objective measures of research strength ofthose programs. In Fall 2016 we collected Google Scholar citation data for4,352 tenure-track CS faculty from 173 U.S. universities. The citations aremeasured by the t10 index, which represents the number of citations received bythe 10th highest cited paper of a faculty. To measure the research strength ofa CS doctoral program we use 2 groups of citation measures. The first group ofmeasures averages t10 of faculty in a program. Pearson correlation of thosemeasures with the peer assessment of U.S. CS doctoral programs published by theU.S. News in 2014 is as high as 0.890. The second group of measures counts thenumber of well cited faculty in a program. Pearson correlation of thosemeasures with the peer assessment is as high as 0.909. By combining those twogroups of measures using linear regression, we create the Scholar score whosePearson correlation with the peer assessment is 0.933 and which explains 87.2%of the variance in the peer assessment. Our evaluation shows that the highest62 ranked CS doctoral programs by the U.S. News peer assessment are much highercorrelated with the Scholar score than the next 57 ranked programs, indicatingthe deficiencies of peer assessment of less-known CS programs. Our results alsoindicate that university reputation might have a sizeable impact on peerassessment of CS doctoral programs. To promote transparency, the raw data andthe codes used in this study are made available to research community athttp://www.dabi.temple.edu/~vucetic/CSranking/.

Non-linear Label Ranking for Large-scale Prediction of Long-Term User  Interests

  We consider the problem of personalization of online services from theviewpoint of ad targeting, where we seek to find the best ad categories to beshown to each user, resulting in improved user experience and increasedadvertisers' revenue. We propose to address this problem as a task of rankingthe ad categories depending on a user's preference, and introduce a novel labelranking approach capable of efficiently learning non-linear, highly accuratemodels in large-scale settings. Experiments on a real-world advertising dataset with more than 3.2 million users show that the proposed algorithmoutperforms the existing solutions in terms of both rank loss and top-Kretrieval performance, strongly suggesting the benefit of using the proposedmodel on large-scale ranking problems.

Semi-supervised Discovery of Informative Tweets During the Emerging  Disasters

  The first objective towards the effective use of microblogging services suchas Twitter for situational awareness during the emerging disasters is discoveryof the disaster-related postings. Given the wide range of possible disasters,using a pre-selected set of disaster-related keywords for the discovery issuboptimal. An alternative that we focus on in this work is to train aclassifier using a small set of labeled postings that are becoming available asa disaster is emerging. Our hypothesis is that utilizing large quantities ofhistorical microblogs could improve the quality of classification, as comparedto training a classifier only on the labeled data. We propose to use unlabeledmicroblogs to cluster words into a limited number of clusters and use the wordclusters as features for classification. To evaluate the proposedsemi-supervised approach, we used Twitter data from 6 different disasters. Ourresults indicate that when the number of labeled tweets is 100 or less, theproposed approach is superior to the standard classification based on the bagor words feature representation. Our results also reveal that the choice of theunlabeled corpus, the choice of word clustering algorithm, and the choice ofhyperparameters can have a significant impact on the classification accuracy.

An expanded evaluation of protein function prediction methods shows an  improvement in accuracy

  Background: The increasing volume and variety of genotypic and phenotypicdata is a major defining characteristic of modern biomedical sciences. At thesame time, the limitations in technology for generating data and the inherentlystochastic nature of biomolecular events have led to the discrepancy betweenthe volume of data and the amount of knowledge gleaned from it. A majorbottleneck in our ability to understand the molecular underpinnings of life isthe assignment of function to biological macromolecules, especially proteins.While molecular experiments provide the most reliable annotation of proteins,their relatively low throughput and restricted purview have led to anincreasing role for computational function prediction. However, accuratelyassessing methods for protein function prediction and tracking progress in thefield remain challenging. Methodology: We have conducted the second CriticalAssessment of Functional Annotation (CAFA), a timed challenge to assesscomputational methods that automatically assign protein function. One hundredtwenty-six methods from 56 research groups were evaluated for their ability topredict biological functions using the Gene Ontology and gene-diseaseassociations using the Human Phenotype Ontology on a set of 3,681 proteins from18 species. CAFA2 featured significantly expanded analysis compared with CAFA1,with regards to data set size, variety, and assessment metrics. To reviewprogress in the field, the analysis also compared the best methodsparticipating in CAFA1 to those of CAFA2. Conclusions: The top performingmethods in CAFA2 outperformed the best methods from CAFA1, demonstrating thatcomputational function prediction is improving. This increased accuracy can beattributed to the combined effect of the growing number of experimentalannotations and improved methods for function prediction.

