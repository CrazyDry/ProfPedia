Faculty citation measures are highly correlated with peer assessment of
  computer science doctoral programs

  We study relationship between peer assessment of quality of U.S. Computer
Science (CS) doctoral programs and objective measures of research strength of
those programs. In Fall 2016 we collected Google Scholar citation data for
4,352 tenure-track CS faculty from 173 U.S. universities. The citations are
measured by the t10 index, which represents the number of citations received by
the 10th highest cited paper of a faculty. To measure the research strength of
a CS doctoral program we use 2 groups of citation measures. The first group of
measures averages t10 of faculty in a program. Pearson correlation of those
measures with the peer assessment of U.S. CS doctoral programs published by the
U.S. News in 2014 is as high as 0.890. The second group of measures counts the
number of well cited faculty in a program. Pearson correlation of those
measures with the peer assessment is as high as 0.909. By combining those two
groups of measures using linear regression, we create the Scholar score whose
Pearson correlation with the peer assessment is 0.933 and which explains 87.2%
of the variance in the peer assessment. Our evaluation shows that the highest
62 ranked CS doctoral programs by the U.S. News peer assessment are much higher
correlated with the Scholar score than the next 57 ranked programs, indicating
the deficiencies of peer assessment of less-known CS programs. Our results also
indicate that university reputation might have a sizeable impact on peer
assessment of CS doctoral programs. To promote transparency, the raw data and
the codes used in this study are made available to research community at
http://www.dabi.temple.edu/~vucetic/CSranking/.


Non-linear Label Ranking for Large-scale Prediction of Long-Term User
  Interests

  We consider the problem of personalization of online services from the
viewpoint of ad targeting, where we seek to find the best ad categories to be
shown to each user, resulting in improved user experience and increased
advertisers' revenue. We propose to address this problem as a task of ranking
the ad categories depending on a user's preference, and introduce a novel label
ranking approach capable of efficiently learning non-linear, highly accurate
models in large-scale settings. Experiments on a real-world advertising data
set with more than 3.2 million users show that the proposed algorithm
outperforms the existing solutions in terms of both rank loss and top-K
retrieval performance, strongly suggesting the benefit of using the proposed
model on large-scale ranking problems.


Semi-supervised Discovery of Informative Tweets During the Emerging
  Disasters

  The first objective towards the effective use of microblogging services such
as Twitter for situational awareness during the emerging disasters is discovery
of the disaster-related postings. Given the wide range of possible disasters,
using a pre-selected set of disaster-related keywords for the discovery is
suboptimal. An alternative that we focus on in this work is to train a
classifier using a small set of labeled postings that are becoming available as
a disaster is emerging. Our hypothesis is that utilizing large quantities of
historical microblogs could improve the quality of classification, as compared
to training a classifier only on the labeled data. We propose to use unlabeled
microblogs to cluster words into a limited number of clusters and use the word
clusters as features for classification. To evaluate the proposed
semi-supervised approach, we used Twitter data from 6 different disasters. Our
results indicate that when the number of labeled tweets is 100 or less, the
proposed approach is superior to the standard classification based on the bag
or words feature representation. Our results also reveal that the choice of the
unlabeled corpus, the choice of word clustering algorithm, and the choice of
hyperparameters can have a significant impact on the classification accuracy.


An expanded evaluation of protein function prediction methods shows an
  improvement in accuracy

  Background: The increasing volume and variety of genotypic and phenotypic
data is a major defining characteristic of modern biomedical sciences. At the
same time, the limitations in technology for generating data and the inherently
stochastic nature of biomolecular events have led to the discrepancy between
the volume of data and the amount of knowledge gleaned from it. A major
bottleneck in our ability to understand the molecular underpinnings of life is
the assignment of function to biological macromolecules, especially proteins.
While molecular experiments provide the most reliable annotation of proteins,
their relatively low throughput and restricted purview have led to an
increasing role for computational function prediction. However, accurately
assessing methods for protein function prediction and tracking progress in the
field remain challenging. Methodology: We have conducted the second Critical
Assessment of Functional Annotation (CAFA), a timed challenge to assess
computational methods that automatically assign protein function. One hundred
twenty-six methods from 56 research groups were evaluated for their ability to
predict biological functions using the Gene Ontology and gene-disease
associations using the Human Phenotype Ontology on a set of 3,681 proteins from
18 species. CAFA2 featured significantly expanded analysis compared with CAFA1,
with regards to data set size, variety, and assessment metrics. To review
progress in the field, the analysis also compared the best methods
participating in CAFA1 to those of CAFA2. Conclusions: The top performing
methods in CAFA2 outperformed the best methods from CAFA1, demonstrating that
computational function prediction is improving. This increased accuracy can be
attributed to the combined effect of the growing number of experimental
annotations and improved methods for function prediction.


