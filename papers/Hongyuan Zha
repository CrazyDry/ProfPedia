Parametric Fokker-Planck equation

  We derive the Fokker-Planck equation on the parametric space. It is the
Wasserstein gradient flow of relative entropy on the statistical manifold. We
pull back the PDE to a finite dimensional ODE on parameter space. Some
analytical example and numerical examples are presented.


Principal Manifolds and Nonlinear Dimension Reduction via Local Tangent
  Space Alignment

  Nonlinear manifold learning from unorganized data points is a very
challenging unsupervised learning and data visualization problem with a great
variety of applications. In this paper we present a new algorithm for manifold
learning and nonlinear dimension reduction. Based on a set of unorganized data
points sampled with noise from the manifold, we represent the local geometry of
the manifold using tangent spaces learned by fitting an affine subspace in a
neighborhood of each data point. Those tangent spaces are aligned to give the
internal global coordinates of the data points with respect to the underlying
manifold by way of a partial eigendecomposition of the neighborhood connection
matrix. We present a careful error analysis of our algorithm and show that the
reconstruction errors are of second-order accuracy. We illustrate our algorithm
using curves and surfaces both in
  2D/3D and higher dimensional Euclidean spaces, and 64-by-64 pixel face images
with various pose and lighting conditions. We also address several theoretical
and algorithmic issues for further research and improvements.


Bipartite graph partitioning and data clustering

  Many data types arising from data mining applications can be modeled as
bipartite graphs, examples include terms and documents in a text corpus,
customers and purchasing items in market basket analysis and reviewers and
movies in a movie recommender system. In this paper, we propose a new data
clustering method based on partitioning the underlying bipartite graph. The
partition is constructed by minimizing a normalized sum of edge weights between
unmatched pairs of vertices of the bipartite graph. We show that an approximate
solution to the minimization problem can be obtained by computing a partial
singular value decomposition (SVD) of the associated edge weight matrix of the
bipartite graph. We point out the connection of our clustering algorithm to
correspondence analysis used in multivariate analysis. We also briefly discuss
the issue of assigning data objects to multiple clusters. In the experimental
results, we apply our clustering algorithm to the problem of document
clustering to illustrate its effectiveness and efficiency.


Contour regression: A general approach to dimension reduction

  We propose a novel approach to sufficient dimension reduction in regression,
based on estimating contour directions of small variation in the response.
These directions span the orthogonal complement of the minimal space relevant
for the regression and can be extracted according to two measures of variation
in the response, leading to simple and general contour regression (SCR and GCR)
methodology. In comparison with existing sufficient dimension reduction
techniques, this contour-based methodology guarantees exhaustive estimation of
the central subspace under ellipticity of the predictor distribution and mild
additional assumptions, while maintaining \sqrtn-consistency and computational
ease. Moreover, it proves robust to departures from ellipticity. We establish
population properties for both SCR and GCR, and asymptotic properties for SCR.
Simulations to compare performance with that of standard techniques such as
ordinary least squares, sliced inverse regression, principal Hessian directions
and sliced average variance estimation confirm the advantages anticipated by
the theoretical analyses. We demonstrate the use of contour-based methods on a
data set concerning soil evaporation.


Consistent Computation of First- and Second-Order Differential
  Quantities for Surface Meshes

  Differential quantities, including normals, curvatures, principal directions,
and associated matrices, play a fundamental role in geometric processing and
physics-based modeling. Computing these differential quantities consistently on
surface meshes is important and challenging, and some existing methods often
produce inconsistent results and require ad hoc fixes. In this paper, we show
that the computation of the gradient and Hessian of a height function provides
the foundation for consistently computing the differential quantities. We
derive simple, explicit formulas for the transformations between the first- and
second-order differential quantities (i.e., normal vector and principal
curvature tensor) of a smooth surface and the first- and second-order
derivatives (i.e., gradient and Hessian) of its corresponding height function.
We then investigate a general, flexible numerical framework to estimate the
derivatives of the height function based on local polynomial fittings
formulated as weighted least squares approximations. We also propose an
iterative fitting scheme to improve accuracy. This framework generalizes
polynomial fitting and addresses some of its accuracy and stability issues, as
demonstrated by our theoretical analysis as well as experimental results.


Learning the Gain Values and Discount Factors of DCG

  Evaluation metrics are an essential part of a ranking system, and in the past
many evaluation metrics have been proposed in information retrieval and Web
search. Discounted Cumulated Gains (DCG) has emerged as one of the evaluation
metrics widely adopted for evaluating the performance of ranking functions used
in Web search. However, the two sets of parameters, gain values and discount
factors, used in DCG are determined in a rather ad-hoc way. In this paper we
first show that DCG is generally not coherent, meaning that comparing the
performance of ranking functions using DCG very much depends on the particular
gain values and discount factors used. We then propose a novel methodology that
can learn the gain values and discount factors from user preferences over
rankings. Numerical simulations illustrate the effectiveness of our proposed
methods. Please contact the authors for the full version of this work.


Shaping Social Activity by Incentivizing Users

  Events in an online social network can be categorized roughly into endogenous
events, where users just respond to the actions of their neighbors within the
network, or exogenous events, where users take actions due to drives external
to the network. How much external drive should be provided to each user, such
that the network activity can be steered towards a target state? In this paper,
we model social events using multivariate Hawkes processes, which can capture
both endogenous and exogenous event intensities, and derive a time dependent
linear relation between the intensity of exogenous events and the overall
network activity. Exploiting this connection, we develop a convex optimization
framework for determining the required level of external drive in order for the
network to reach a desired activity level. We experimented with event data
gathered from Twitter, and show that our method can steer the activity of the
network more accurately than alternatives.


Linear Contour Learning: A Method for Supervised Dimension Reduction

  We propose a novel approach to sufficient dimension reduction in regression,
based on estimating contour directions of negligible variation for the response
surface. These directions span the orthogonal complement of the minimal space
relevant for the regression, and can be extracted according to a measure of the
variation in the response, leading to General Contour Regression(GCR). In
comparison to exiisting sufficient dimension reduction techniques, this
sontour-based mothology guarantees exhaustive estimation of the central space
under ellipticity of the predictoor distribution and very mild additional
assumptions, while maintaining vn-consisytency and somputational ease.
Moreover, it proves to be robust to departures from ellipticity. We also
establish some useful population properties for GCR. Simulations to compare
performance with that of standard techniques such as ordinary least squares,
sliced inverse regression, principal hessian directions, and sliced average
variance estimation confirm the advntages anticipated by theoretical analyses.
We also demonstrate the use of contour-based methods on a data set concerning
grades of students from Massachusetts colleges.


Hybrid Generative/Discriminative Learning for Automatic Image Annotation

  Automatic image annotation (AIA) raises tremendous challenges to machine
learning as it requires modeling of data that are both ambiguous in input and
output, e.g., images containing multiple objects and labeled with multiple
semantic tags. Even more challenging is that the number of candidate tags is
usually huge (as large as the vocabulary size) yet each image is only related
to a few of them. This paper presents a hybrid generative-discriminative
classifier to simultaneously address the extreme data-ambiguity and
overfitting-vulnerability issues in tasks such as AIA. Particularly: (1) an
Exponential-Multinomial Mixture (EMM) model is established to capture both the
input and output ambiguity and in the meanwhile to encourage prediction
sparsity; and (2) the prediction ability of the EMM model is explicitly
maximized through discriminative learning that integrates variational inference
of graphical models and the pairwise formulation of ordinal regression.
Experiments show that our approach achieves both superior annotation
performance and better tag scalability.


Supervised Laplacian Eigenmaps with Applications in Clinical Diagnostics
  for Pediatric Cardiology

  Electronic health records contain rich textual data which possess critical
predictive information for machine-learning based diagnostic aids. However many
traditional machine learning methods fail to simultaneously integrate both
vector space data and text. We present a supervised method using Laplacian
eigenmaps to augment existing machine-learning methods with low-dimensional
representations of textual predictors which preserve the local similarities.
The proposed implementation performs alternating optimization using gradient
descent. For the evaluation we applied our method to over 2,000 patient records
from a large single-center pediatric cardiology practice to predict if patients
were diagnosed with cardiac disease. Our method was compared with latent
semantic indexing, latent Dirichlet allocation, and local Fisher discriminant
analysis. The results were assessed using AUC, MCC, specificity, and
sensitivity. Results indicate supervised Laplacian eigenmaps was the highest
performing method in our study, achieving 0.782 and 0.374 for AUC and MCC
respectively. SLE showed an increase in 8.16% in AUC and 20.6% in MCC over the
baseline which excluded textual data and a 2.69% and 5.35% increase in AUC and
MCC respectively over unsupervised Laplacian eigenmaps. This method allows many
existing machine learning predictors to effectively and efficiently utilize the
potential of textual predictors.


Influence Prediction for Continuous-Time Information Propagation on
  Networks

  We consider the problem of predicting the time evolution of influence, the
expected number of activated nodes, given a set of initially active nodes on a
propagation network. To address the significant computational challenges of
this problem on large-scale heterogeneous networks, we establish a system of
differential equations governing the dynamics of probability mass functions on
the state graph where the nodes each lumps a number of activation states of the
network, which can be considered as an analogue to the Fokker-Planck equation
in continuous space. We provides several methods to estimate the system
parameters which depend on the identities of the initially active nodes,
network topology, and activation rates etc. The influence is then estimated by
the solution of such a system of differential equations. This approach gives
rise to a class of novel and scalable algorithms that work effectively for
large-scale and dense networks. Numerical results are provided to show the very
promising performance in terms of prediction accuracy and computational
efficiency of this approach.


Learning Granger Causality for Hawkes Processes

  Learning Granger causality for general point processes is a very challenging
task. In this paper, we propose an effective method, learning Granger
causality, for a special but significant type of point processes --- Hawkes
process. We reveal the relationship between Hawkes process's impact function
and its Granger causality graph. Specifically, our model represents impact
functions using a series of basis functions and recovers the Granger causality
graph via group sparsity of the impact functions' coefficients. We propose an
effective learning algorithm combining a maximum likelihood estimator (MLE)
with a sparse-group-lasso (SGL) regularizer. Additionally, the flexibility of
our model allows to incorporate the clustering structure event types into
learning framework. We analyze our learning algorithm and propose an adaptive
procedure to select basis functions. Experiments on both synthetic and
real-world data show that our method can learn the Granger causality graph and
the triggering patterns of the Hawkes processes simultaneously.


Multistage Campaigning in Social Networks

  We consider the problem of how to optimize multi-stage campaigning over
social networks. The dynamic programming framework is employed to balance the
high present reward and large penalty on low future outcome in the presence of
extensive uncertainties. In particular, we establish theoretical foundations of
optimal campaigning over social networks where the user activities are modeled
as a multivariate Hawkes process, and we derive a time dependent linear
relation between the intensity of exogenous events and several commonly used
objective functions of campaigning. We further develop a convex dynamic
programming framework for determining the optimal intervention policy that
prescribes the required level of external drive at each stage for the desired
campaigning result. Experiments on both synthetic data and the real-world
MemeTracker dataset show that our algorithm can steer the user activities for
optimal campaigning much more accurately than baselines.


A Self-Paced Regularization Framework for Multi-Label Learning

  In this paper, we propose a novel multi-label learning framework, called
Multi-Label Self-Paced Learning (MLSPL), in an attempt to incorporate the
self-paced learning strategy into multi-label learning regime. In light of the
benefits of adopting the easy-to-hard strategy proposed by self-paced learning,
the devised MLSPL aims to learn multiple labels jointly by gradually including
label learning tasks and instances into model training from the easy to the
hard. We first introduce a self-paced function as a regularizer in the
multi-label learning formulation, so as to simultaneously rank priorities of
the label learning tasks and the instances in each learning iteration.
Considering that different multi-label learning scenarios often need different
self-paced schemes during optimization, we thus propose a general way to find
the desired self-paced functions. Experimental results on three benchmark
datasets suggest the state-of-the-art performance of our approach.


Deep Extreme Multi-label Learning

  Extreme multi-label learning (XML) or classification has been a practical and
important problem since the boom of big data. The main challenge lies in the
exponential label space which involves $2^L$ possible label sets especially
when the label dimension $L$ is huge, e.g., in millions for Wikipedia labels.
This paper is motivated to better explore the label space by originally
establishing an explicit label graph. In the meanwhile, deep learning has been
widely studied and used in various classification problems including
multi-label classification, however it has not been properly introduced to XML,
where the label space can be as large as in millions. In this paper, we propose
a practical deep embedding method for extreme multi-label classification, which
harvests the ideas of non-linear embedding and graph priors-based label space
modeling simultaneously. Extensive experiments on public datasets for XML show
that our method performs competitive against state-of-the-art result.


Back to the Past: Source Identification in Diffusion Networks from
  Partially Observed Cascades

  When a piece of malicious information becomes rampant in an information
diffusion network, can we identify the source node that originally introduced
the piece into the network and infer the time when it initiated this? Being
able to do so is critical for curtailing the spread of malicious information,
and reducing the potential losses incurred. This is a very challenging problem
since typically only incomplete traces are observed and we need to unroll the
incomplete traces into the past in order to pinpoint the source. In this paper,
we tackle this problem by developing a two-stage framework, which first learns
a continuous-time diffusion network model based on historical diffusion traces
and then identifies the source of an incomplete diffusion trace by maximizing
the likelihood of the trace under the learned model. Experiments on both large
synthetic and real-world data show that our framework can effectively go back
to the past, and pinpoint the source node and its initiation time significantly
more accurately than previous state-of-the-arts.


Correlated Cascades: Compete or Cooperate

  In real world social networks, there are multiple cascades which are rarely
independent. They usually compete or cooperate with each other. Motivated by
the reinforcement theory in sociology we leverage the fact that adoption of a
user to any behavior is modeled by the aggregation of behaviors of its
neighbors. We use a multidimensional marked Hawkes process to model users
product adoption and consequently spread of cascades in social networks. The
resulting inference problem is proved to be convex and is solved in parallel by
using the barrier method. The advantage of the proposed model is twofold; it
models correlated cascades and also learns the latent diffusion network.
Experimental results on synthetic and two real datasets gathered from Twitter,
URL shortening and music streaming services, illustrate the superior
performance of the proposed model over the alternatives.


Self-Paced Multi-Task Learning

  In this paper, we propose a novel multi-task learning (MTL) framework, called
Self-Paced Multi-Task Learning (SPMTL). Different from previous works treating
all tasks and instances equally when training, SPMTL attempts to jointly learn
the tasks by taking into consideration the complexities of both tasks and
instances. This is inspired by the cognitive process of human brain that often
learns from the easy to the hard. We construct a compact SPMTL formulation by
proposing a new task-oriented regularizer that can jointly prioritize the tasks
and the instances. Thus it can be interpreted as a self-paced learner for MTL.
A simple yet effective algorithm is designed for optimizing the proposed
objective function. An error bound for a simplified formulation is also
analyzed theoretically. Experimental results on toy and real-world datasets
demonstrate the effectiveness of the proposed approach, compared to the
state-of-the-art methods.


A hybrid approach for risk assessment of loan guarantee network

  Groups of Small and Medium Enterprises (SME) back each other and form
guarantee network to obtain loan from banks. The risk over the networked
enterprises may cause significant contagious damage. To dissolve such risks, we
propose a hybrid feature representation, which is feeded into a gradient
boosting model for credit risk assessment of guarantee network. Empirical study
is performed on a ten-year guarantee loan record from commercial banks. We find
that often hundreds or thousands of enterprises back each other and constitute
a sparse complex network. We study the risk of various structures of loan
guarantee network, and observe the high correlation between defaults with
centrality, and with the communities of the network. In particular, our
quantitative risk evaluation model shows promising prediction performance on
real-world data, which can be useful to both regulators and stakeholders.


Learning Hawkes Processes from Short Doubly-Censored Event Sequences

  Many real-world applications require robust algorithms to learn point
processes based on a type of incomplete data --- the so-called short
doubly-censored (SDC) event sequences. We study this critical problem of
quantitative asynchronous event sequence analysis under the framework of Hawkes
processes by leveraging the idea of data synthesis. Given SDC event sequences
observed in a variety of time intervals, we propose a sampling-stitching data
synthesis method --- sampling predecessors and successors for each SDC event
sequence from potential candidates and stitching them together to synthesize
long training sequences. The rationality and the feasibility of our method are
discussed in terms of arguments based on likelihood. Experiments on both
synthetic and real-world data demonstrate that the proposed data synthesis
method improves learning results indeed for both time-invariant and
time-varying Hawkes processes.


Fake News Mitigation via Point Process Based Intervention

  We propose the first multistage intervention framework that tackles fake news
in social networks by combining reinforcement learning with a point process
network activity model. The spread of fake news and mitigation events within
the network is modeled by a multivariate Hawkes process with additional
exogenous control terms. By choosing a feature representation of states,
defining mitigation actions and constructing reward functions to measure the
effectiveness of mitigation activities, we map the problem of fake news
mitigation into the reinforcement learning framework. We develop a policy
iteration method unique to the multivariate networked point process, with the
goal of optimizing the actions for maximal total reward under budget
constraints. Our method shows promising performance in real-time intervention
experiments on a Twitter network to mitigate a surrogate fake news campaign,
and outperforms alternatives on synthetic datasets.


Wasserstein Learning of Deep Generative Point Process Models

  Point processes are becoming very popular in modeling asynchronous sequential
data due to their sound mathematical foundation and strength in modeling a
variety of real-world phenomena. Currently, they are often characterized via
intensity function which limits model's expressiveness due to unrealistic
assumptions on its parametric form used in practice. Furthermore, they are
learned via maximum likelihood approach which is prone to failure in
multi-modal distributions of sequences. In this paper, we propose an
intensity-free approach for point processes modeling that transforms nuisance
processes to a target one. Furthermore, we train the model using a
likelihood-free leveraging Wasserstein distance between point processes.
Experiments on various synthetic and real-world data substantiate the
superiority of the proposed point process model over conventional ones.


THAP: A Matlab Toolkit for Learning with Hawkes Processes

  As a powerful tool of asynchronous event sequence analysis, point processes
have been studied for a long time and achieved numerous successes in different
fields. Among various point process models, Hawkes process and its variants
attract many researchers in statistics and computer science these years because
they capture the self- and mutually-triggering patterns between different
events in complicated sequences explicitly and quantitatively and are broadly
applicable to many practical problems. In this paper, we describe an
open-source toolkit implementing many learning algorithms and analysis tools
for Hawkes process model and its variants. Our toolkit systematically
summarizes recent state-of-the-art algorithms as well as most classic
algorithms of Hawkes processes, which is beneficial for both academical
education and research. Source code can be downloaded from
https://github.com/HongtengXu/Hawkes-Process-Toolkit.


Learning Registered Point Processes from Idiosyncratic Observations

  A parametric point process model is developed, with modeling based on the
assumption that sequential observations often share latent phenomena, while
also possessing idiosyncratic effects. An alternating optimization method is
proposed to learn a "registered" point process that accounts for shared
structure, as well as "warping" functions that characterize idiosyncratic
aspects of each observed sequence. Under reasonable constraints, in each
iteration we update the sample-specific warping functions by solving a set of
constrained nonlinear programming problems in parallel, and update the model by
maximum likelihood estimation. The justifiability, complexity and robustness of
the proposed method are investigated in detail, and the influence of sequence
stitching on the learning results is examined empirically. Experiments on both
synthetic and real-world data demonstrate that the method yields explainable
point process models, achieving encouraging results compared to
state-of-the-art methods.


A unified framework for manifold landmarking

  The success of semi-supervised manifold learning is highly dependent on the
quality of the labeled samples. Active manifold learning aims to select and
label representative landmarks on a manifold from a given set of samples to
improve semi-supervised manifold learning. In this paper, we propose a novel
active manifold learning method based on a unified framework of manifold
landmarking. In particular, our method combines geometric manifold landmarking
methods with algebraic ones. We achieve this by using the Gershgorin circle
theorem to construct an upper bound on the learning error that depends on the
landmarks and the manifold's alignment matrix in a way that captures both the
geometric and algebraic criteria. We then attempt to select landmarks so as to
minimize this bound by iteratively deleting the Gershgorin circles
corresponding to the selected landmarks. We also analyze the complexity,
scalability, and robustness of our method through simulations, and demonstrate
its superiority compared to existing methods. Experiments in regression and
classification further verify that our method performs better than its
competitors.


Learning Deep Mean Field Games for Modeling Large Population Behavior

  We consider the problem of representing collective behavior of large
populations and predicting the evolution of a population distribution over a
discrete state space. A discrete time mean field game (MFG) is motivated as an
interpretable model founded on game theory for understanding the aggregate
effect of individual actions and predicting the temporal evolution of
population distributions. We achieve a synthesis of MFG and Markov decision
processes (MDP) by showing that a special MFG is reducible to an MDP. This
enables us to broaden the scope of mean field game theory and infer MFG models
of large real-world systems via deep inverse reinforcement learning. Our method
learns both the reward function and forward dynamics of an MFG from real data,
and we report the first empirical test of a mean field game model of a
real-world social media population.


tau-FPL: Tolerance-Constrained Learning in Linear Time

  Learning a classifier with control on the false-positive rate plays a
critical role in many machine learning applications. Existing approaches either
introduce prior knowledge dependent label cost or tune parameters based on
traditional classifiers, which lack consistency in methodology because they do
not strictly adhere to the false-positive rate constraint. In this paper, we
propose a novel scoring-thresholding approach, tau-False Positive Learning
(tau-FPL) to address this problem. We show the scoring problem which takes the
false-positive rate tolerance into accounts can be efficiently solved in linear
time, also an out-of-bootstrap thresholding method can transform the learned
ranking function into a low false-positive classifier. Both theoretical
analysis and experimental results show superior performance of the proposed
tau-FPL over existing approaches.


Decoupled Learning for Factorial Marked Temporal Point Processes

  This paper introduces the factorial marked temporal point process model and
presents efficient learning methods. In conventional (multi-dimensional) marked
temporal point process models, event is often encoded by a single discrete
variable i.e. a marker. In this paper, we describe the factorial marked point
processes whereby time-stamped event is factored into multiple markers.
Accordingly the size of the infectivity matrix modeling the effect between
pairwise markers is in power order w.r.t. the number of the discrete marker
space. We propose a decoupled learning method with two learning procedures: i)
directly solving the model based on two techniques: Alternating Direction
Method of Multipliers and Fast Iterative Shrinkage-Thresholding Algorithm; ii)
involving a reformulation that transforms the original problem into a Logistic
Regression model for more efficient learning. Moreover, a sparse group
regularizer is added to identify the key profile features and event labels.
Empirical results on real world datasets demonstrate the efficiency of our
decoupled and reformulated method. The source code is available online.


Learning to Match via Inverse Optimal Transport

  We propose a unified data-driven framework based on inverse optimal transport
that can learn adaptive, nonlinear interaction cost function from noisy and
incomplete empirical matching matrix and predict new matching in various
matching contexts. We emphasize that the discrete optimal transport plays the
role of a variational principle which gives rise to an optimization-based
framework for modeling the observed empirical matching data. Our formulation
leads to a non-convex optimization problem which can be solved efficiently by
an alternating optimization method. A key novel aspect of our formulation is
the incorporation of marginal relaxation via regularized Wasserstein distance,
significantly improving the robustness of the method in the face of noisy or
missing empirical matching data. Our model falls into the category of
prescriptive models, which not only predict potential future matching, but is
also able to explain what leads to empirical matching and quantifies the impact
of changes in matching factors. The proposed approach has wide applicability
including predicting matching in online dating, labor market, college
application and crowdsourcing. We back up our claims with numerical experiments
on both synthetic data and real world data sets.


A Fast Proximal Point Method for Computing Wasserstein Distance

  Wasserstein distance plays increasingly important roles in machine learning,
stochastic programming and image processing. Major efforts have been under way
to address its high computational complexity, some leading to approximate or
regularized variations such as Sinkhorn distance. However, as we will
demonstrate, regularized variations with large regularization parameter will
degradate the performance in several important machine learning applications,
and small regularization parameter will fail due to numerical stability issues
with existing algorithms. We address this challenge by developing an Inexact
Proximal point method for Optimal Transport (IPOT) with the proximal operator
approximately evaluated at each iteration using projections to the probability
simplex. We prove the algorithm has linear convergence rate. We also apply IPOT
to learning generative models, and generalize the idea of IPOT to a new method
for computing Wasserstein barycenter.


Representation Learning over Dynamic Graphs

  How can we effectively encode evolving information over dynamic graphs into
low-dimensional representations? In this paper, we propose DyRep, an inductive
deep representation learning framework that learns a set of functions to
efficiently produce low-dimensional node embeddings that evolves over time. The
learned embeddings drive the dynamics of two key processes namely,
communication and association between nodes in dynamic graphs. These processes
exhibit complex nonlinear dynamics that evolve at different time scales and
subsequently contribute to the update of node embeddings. We employ a
time-scale dependent multivariate point process model to capture these
dynamics. We devise an efficient unsupervised learning procedure and
demonstrate that our approach significantly outperforms representative
baselines on two real-world datasets for the problem of dynamic link prediction
and event time prediction.


Learning to Optimize via Wasserstein Deep Inverse Optimal Control

  We study the inverse optimal control problem in social sciences: we aim at
learning a user's true cost function from the observed temporal behavior. In
contrast to traditional phenomenological works that aim to learn a generative
model to fit the behavioral data, we propose a novel variational principle and
treat user as a reinforcement learning algorithm, which acts by optimizing his
cost function. We first propose a unified KL framework that generalizes
existing maximum entropy inverse optimal control methods. We further propose a
two-step Wasserstein inverse optimal control framework. In the first step, we
compute the optimal measure with a novel mass transport equation. In the second
step, we formulate the learning problem as a generative adversarial network. In
two real world experiments - recommender systems and social networks, we show
that our framework obtains significant performance gains over both existing
inverse optimal control methods and point process based generative models.


LinkNBed: Multi-Graph Representation Learning with Entity Linkage

  Knowledge graphs have emerged as an important model for studying complex
multi-relational data. This has given rise to the construction of numerous
large scale but incomplete knowledge graphs encoding information extracted from
various resources. An effective and scalable approach to jointly learn over
multiple graphs and eventually construct a unified graph is a crucial next step
for the success of knowledge-based inference for many downstream applications.
To this end, we propose LinkNBed, a deep relational learning framework that
learns entity and relationship representations across multiple graphs. We
identify entity linkage across graphs as a vital component to achieve our goal.
We design a novel objective that leverage entity linkage and build an efficient
multi-task training procedure. Experiments on link prediction and entity
linkage demonstrate substantial improvements over the state-of-the-art
relational learning approaches.


CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement
  Learning

  We propose CM3, a new deep reinforcement learning method for cooperative
multi-agent problems where agents must coordinate for joint success in
achieving different individual goals. We restructure multi-agent learning into
a two-stage curriculum, consisting of a single-agent stage for learning to
accomplish individual tasks, followed by a multi-agent stage for learning to
cooperate in the presence of other agents. These two stages are bridged by
modular augmentation of neural network policy and value functions. We further
adapt the actor-critic framework to this curriculum by formulating local and
global views of the policy gradient and learning via a double critic,
consisting of a decentralized value function and a centralized action-value
function. We evaluated CM3 on a new high-dimensional multi-agent environment
with sparse rewards: negotiating lane changes among multiple autonomous
vehicles in the Simulation of Urban Mobility (SUMO) traffic simulator. Detailed
ablation experiments show the positive contribution of each component in CM3,
and the overall synthesis converges significantly faster to higher performance
policies than existing cooperative multi-agent methods.


A Jump Stochastic Differential Equation Approach for Influence
  Prediction on Information Propagation Networks

  We propose a novel problem formulation of continuous-time information
propagation on heterogenous networks based on jump stochastic differential
equations (SDE). The structure of the network and activation rates between
nodes are naturally taken into account in the SDE system. This new formulation
allows for efficient and stable algorithm for many challenging information
propagation problems, including estimations of individual activation
probability and influence level, by solving the SDE numerically. To this end,
we develop an efficient numerical algorithm incorporating variance reduction;
furthermore, we provide theoretical bounds for its sample complexity. Moreover,
we show that the proposed jump SDE approach can be applied to a much larger
class of critical information propagation problems with more complicated
settings. Numerical experiments on a variety of synthetic and real-world
propagation networks show that the proposed method is more accurate and
efficient compared with the state-of-the-art methods.


Gromov-Wasserstein Learning for Graph Matching and Node Embedding

  A novel Gromov-Wasserstein learning framework is proposed to jointly match
(align) graphs and learn embedding vectors for the associated graph nodes.
Using Gromov-Wasserstein discrepancy, we measure the dissimilarity between two
graphs and find their correspondence, according to the learned optimal
transport. The node embeddings associated with the two graphs are learned under
the guidance of the optimal transport, the distance of which not only reflects
the topological structure of each graph but also yields the correspondence
across the graphs. These two learning steps are mutually-beneficial, and are
unified here by minimizing the Gromov-Wasserstein discrepancy with structural
regularizers. This framework leads to an optimization problem that is solved by
a proximal point method. We apply the proposed method to matching problems in
real-world networks, and demonstrate its superior performance compared to
alternative approaches.


Scalable Influence Estimation in Continuous-Time Diffusion Networks

  If a piece of information is released from a media site, can it spread, in 1
month, to a million web pages? This influence estimation problem is very
challenging since both the time-sensitive nature of the problem and the issue
of scalability need to be addressed simultaneously. In this paper, we propose a
randomized algorithm for influence estimation in continuous-time diffusion
networks. Our algorithm can estimate the influence of every node in a network
with |V| nodes and |E| edges to an accuracy of $\varepsilon$ using
$n=O(1/\varepsilon^2)$ randomizations and up to logarithmic factors
O(n|E|+n|V|) computations. When used as a subroutine in a greedy influence
maximization algorithm, our proposed method is guaranteed to find a set of
nodes with an influence of at least (1-1/e)OPT-2$\varepsilon$, where OPT is the
optimal value. Experiments on both synthetic and real-world data show that the
proposed method can easily scale up to networks of millions of nodes while
significantly improves over previous state-of-the-arts in terms of the accuracy
of the estimated influence and the quality of the selected nodes in maximizing
the influence.


A constrained clustering based approach for matching a collection of
  feature sets

  In this paper, we consider the problem of finding the feature correspondences
among a collection of feature sets, by using their point-wise unary features.
This is a fundamental problem in computer vision and pattern recognition, which
also closely relates to other areas such as operational research. Different
from two-set matching which can be transformed to a quadratic assignment
programming task that is known NP-hard, inclusion of merely unary attributes
leads to a linear assignment problem for matching two feature sets. This
problem has been well studied and there are effective polynomial global optimum
solvers such as the Hungarian method. However, it becomes ill-posed when the
unary attributes are (heavily) corrupted. The global optimal correspondence
concerning the best score defined by the attribute affinity/cost between the
two sets can be distinct to the ground truth correspondence since the score
function is biased by noises. To combat this issue, we devise a method for
matching a collection of feature sets by synergetically exploring the
information across the sets. In general, our method can be perceived from a
(constrained) clustering perspective: in each iteration, it assigns the
features of one set to the clusters formed by the rest of feature sets, and
updates the cluster centers in turn. Results on both synthetic data and real
images suggest the efficacy of our method against state-of-the-arts.


Joint Active Learning with Feature Selection via CUR Matrix
  Decomposition

  This paper presents an unsupervised learning approach for simultaneous sample
and feature selection, which is in contrast to existing works which mainly
tackle these two problems separately. In fact the two tasks are often
interleaved with each other: noisy and high-dimensional features will bring
adverse effect on sample selection, while informative or representative samples
will be beneficial to feature selection. Specifically, we propose a framework
to jointly conduct active learning and feature selection based on the CUR
matrix decomposition. From the data reconstruction perspective, both the
selected samples and features can best approximate the original dataset
respectively, such that the selected samples characterized by the features are
highly representative. In particular, our method runs in one-shot without the
procedure of iterative sample selection for progressive labeling. Thus, our
model is especially suitable when there are few labeled samples or even in the
absence of supervision, which is a particular challenge for existing methods.
As the joint learning problem is NP-hard, the proposed formulation involves a
convex but non-smooth optimization problem. We solve it efficiently by an
iterative algorithm, and prove its global convergence. Experimental results on
publicly available datasets corroborate the efficacy of our method compared
with the state-of-the-art.


A Continuous-time Mutually-Exciting Point Process Framework for
  Prioritizing Events in Social Media

  The overwhelming amount and rate of information update in online social media
is making it increasingly difficult for users to allocate their attention to
their topics of interest, thus there is a strong need for prioritizing news
feeds. The attractiveness of a post to a user depends on many complex
contextual and temporal features of the post. For instance, the contents of the
post, the responsiveness of a third user, and the age of the post may all have
impact. So far, these static and dynamic features has not been incorporated in
a unified framework to tackle the post prioritization problem. In this paper,
we propose a novel approach for prioritizing posts based on a feature modulated
multi-dimensional point process. Our model is able to simultaneously capture
textual and sentiment features, and temporal features such as self-excitation,
mutual-excitation and bursty nature of social interaction. As an evaluation, we
also curated a real-world conversational benchmark dataset crawled from
Facebook. In our experiments, we demonstrate that our algorithm is able to
achieve the-state-of-the-art performance in terms of analyzing, predicting, and
prioritizing events. In terms of interpretability of our method, we observe
that features indicating individual user profile and linguistic characteristics
of the events work best for prediction and prioritization of new events.


Fractal Dimension Invariant Filtering and Its CNN-based Implementation

  Fractal analysis has been widely used in computer vision, especially in
texture image processing and texture analysis. The key concept of fractal-based
image model is the fractal dimension, which is invariant to bi-Lipschitz
transformation of image, and thus capable of representing intrinsic structural
information of image robustly. However, the invariance of fractal dimension
generally does not hold after filtering, which limits the application of
fractal-based image model. In this paper, we propose a novel fractal dimension
invariant filtering (FDIF) method, extending the invariance of fractal
dimension to filtering operations. Utilizing the notion of local
self-similarity, we first develop a local fractal model for images. By adding a
nonlinear post-processing step behind anisotropic filter banks, we demonstrate
that the proposed filtering method is capable of preserving the local
invariance of the fractal dimension of image. Meanwhile, we show that the FDIF
method can be re-instantiated approximately via a CNN-based architecture, where
the convolution layer extracts anisotropic structure of image and the nonlinear
layer enhances the structure via preserving local fractal dimension of image.
The proposed filtering method provides us with a novel geometric interpretation
of CNN-based image model. Focusing on a challenging image processing task ---
detecting complicated curves from the texture-like images, the proposed method
obtains superior results to the state-of-art approaches.


A General Multi-Graph Matching Approach via Graduated
  Consistency-regularized Boosting

  This paper addresses the problem of matching $N$ weighted graphs referring to
an identical object or category. More specifically, matching the common node
correspondences among graphs. This multi-graph matching problem involves two
ingredients affecting the overall accuracy: i) the local pairwise matching
affinity score among graphs; ii) the global matching consistency that measures
the uniqueness of the pairwise matching results by different chaining orders.
Previous studies typically either enforce the matching consistency constraints
in the beginning of iterative optimization, which may propagate matching error
both over iterations and across graph pairs; or separate affinity optimizing
and consistency regularization in two steps. This paper is motivated by the
observation that matching consistency can serve as a regularizer in the
affinity objective function when the function is biased due to noises or
inappropriate modeling. We propose multi-graph matching methods to incorporate
the two aspects by boosting the affinity score, meanwhile gradually infusing
the consistency as a regularizer. Furthermore, we propose a node-wise
consistency/affinity-driven mechanism to elicit the common inlier nodes out of
the irrelevant outliers. Extensive results on both synthetic and public image
datasets demonstrate the competency of the proposed algorithms.


COEVOLVE: A Joint Point Process Model for Information Diffusion and
  Network Co-evolution

  Information diffusion in online social networks is affected by the underlying
network topology, but it also has the power to change it. Online users are
constantly creating new links when exposed to new information sources, and in
turn these links are alternating the way information spreads. However, these
two highly intertwined stochastic processes, information diffusion and network
evolution, have been predominantly studied separately, ignoring their
co-evolutionary dynamics.
  We propose a temporal point process model, COEVOLVE, for such joint dynamics,
allowing the intensity of one process to be modulated by that of the other.
This model allows us to efficiently simulate interleaved diffusion and network
events, and generate traces obeying common diffusion and network patterns
observed in real-world networks. Furthermore, we also develop a convex
optimization framework to learn the parameters of the model from historical
diffusion and network evolution traces. We experimented with both synthetic
data and data gathered from Twitter, and show that our model provides a good
fit to the data as well as more accurate predictions than alternatives.


Scalable Influence Maximization for Multiple Products in Continuous-Time
  Diffusion Networks

  A typical viral marketing model identifies influential users in a social
network to maximize a single product adoption assuming unlimited user
attention, campaign budgets, and time. In reality, multiple products need
campaigns, users have limited attention, convincing users incurs costs, and
advertisers have limited budgets and expect the adoptions to be maximized soon.
Facing these user, monetary, and timing constraints, we formulate the problem
as a submodular maximization task in a continuous-time diffusion model under
the intersection of a matroid and multiple knapsack constraints. We propose a
randomized algorithm estimating the user influence in a network
($|\mathcal{V}|$ nodes, $|\mathcal{E}|$ edges) to an accuracy of $\epsilon$
with $n=\mathcal{O}(1/\epsilon^2)$ randomizations and
$\tilde{\mathcal{O}}(n|\mathcal{E}|+n|\mathcal{V}|)$ computations. By
exploiting the influence estimation algorithm as a subroutine, we develop an
adaptive threshold greedy algorithm achieving an approximation factor $k_a/(2+2
k)$ of the optimal when $k_a$ out of the $k$ knapsack constraints are active.
Extensive experiments on networks of millions of nodes demonstrate that the
proposed algorithms achieve the state-of-the-art in terms of effectiveness and
scalability.


A Dirichlet Mixture Model of Hawkes Processes for Event Sequence
  Clustering

  We propose an effective method to solve the event sequence clustering
problems based on a novel Dirichlet mixture model of a special but significant
type of point processes --- Hawkes process. In this model, each event sequence
belonging to a cluster is generated via the same Hawkes process with specific
parameters, and different clusters correspond to different Hawkes processes.
The prior distribution of the Hawkes processes is controlled via a Dirichlet
distribution. We learn the model via a maximum likelihood estimator (MLE) and
propose an effective variational Bayesian inference algorithm. We specifically
analyze the resulting EM-type algorithm in the context of inner-outer
iterations and discuss several inner iteration allocation strategies. The
identifiability of our model, the convergence of our learning method, and its
sample complexity are analyzed in both theoretical and empirical ways, which
demonstrate the superiority of our method to other competitors. The proposed
method learns the number of clusters automatically and is robust to model
misspecification. Experiments on both synthetic and real-world data show that
our method can learn diverse triggering patterns hidden in asynchronous event
sequences and achieve encouraging performance on clustering purity and
consistency.


Recurrent Poisson Factorization for Temporal Recommendation

  Poisson factorization is a probabilistic model of users and items for
recommendation systems, where the so-called implicit consumer data is modeled
by a factorized Poisson distribution. There are many variants of Poisson
factorization methods who show state-of-the-art performance on real-world
recommendation tasks. However, most of them do not explicitly take into account
the temporal behavior and the recurrent activities of users which is essential
to recommend the right item to the right user at the right time. In this paper,
we introduce Recurrent Poisson Factorization (RPF) framework that generalizes
the classical PF methods by utilizing a Poisson process for modeling the
implicit feedback. RPF treats time as a natural constituent of the model and
brings to the table a rich family of time-sensitive factorization models. To
elaborate, we instantiate several variants of RPF who are capable of handling
dynamic user preferences and item specification (DRPF), modeling the
social-aspect of product adoption (SRPF), and capturing the consumption
heterogeneity among users and items (HRPF). We also develop a variational
algorithm for approximate posterior inference that scales up to massive data
sets. Furthermore, we demonstrate RPF's superior performance over many
state-of-the-art methods on synthetic dataset, and large scale real-world
datasets on music streaming logs, and user-item interactions in M-Commerce
platforms.


Joint Modeling of Event Sequence and Time Series with Attentional Twin
  Recurrent Neural Networks

  A variety of real-world processes (over networks) produce sequences of data
whose complex temporal dynamics need to be studied. More especially, the event
timestamps can carry important information about the underlying network
dynamics, which otherwise are not available from the time-series evenly sampled
from continuous signals. Moreover, in most complex processes, event sequences
and evenly-sampled times series data can interact with each other, which
renders joint modeling of those two sources of data necessary. To tackle the
above problems, in this paper, we utilize the rich framework of (temporal)
point processes to model event data and timely update its intensity function by
the synergic twin Recurrent Neural Networks (RNNs). In the proposed
architecture, the intensity function is synergistically modulated by one RNN
with asynchronous events as input and another RNN with time series as input.
Furthermore, to enhance the interpretability of the model, the attention
mechanism for the neural point process is introduced. The whole model with
event type and timestamp prediction output layers can be trained end-to-end and
allows a black-box treatment for modeling the intensity. We substantiate the
superiority of our model in synthetic data and three real-world benchmark
datasets.


Modeling The Intensity Function Of Point Process Via Recurrent Neural
  Networks

  Event sequence, asynchronously generated with random timestamp, is ubiquitous
among applications. The precise and arbitrary timestamp can carry important
clues about the underlying dynamics, and has lent the event data fundamentally
different from the time-series whereby series is indexed with fixed and equal
time interval. One expressive mathematical tool for modeling event is point
process. The intensity functions of many point processes involve two
components: the background and the effect by the history. Due to its inherent
spontaneousness, the background can be treated as a time series while the other
need to handle the history events. In this paper, we model the background by a
Recurrent Neural Network (RNN) with its units aligned with time series indexes
while the history effect is modeled by another RNN whose units are aligned with
asynchronous events to capture the long-range dynamics. The whole model with
event type and timestamp prediction output layers can be trained end-to-end.
Our approach takes an RNN perspective to point process, and models its
background and history effect. For utility, our method allows a black-box
treatment for modeling the intensity which is often a pre-defined parametric
form in point processes. Meanwhile end-to-end training opens the venue for
reusing existing rich techniques in deep network for point process modeling. We
apply our model to the predictive maintenance problem using a log dataset by
more than 1000 ATMs from a global bank headquartered in North America.


Hawkes Processes for Invasive Species Modeling and Management

  The spread of invasive species to new areas threatens the stability of
ecosystems and causes major economic losses in agriculture and forestry. We
propose a novel approach to minimizing the spread of an invasive species given
a limited intervention budget. We first model invasive species propagation
using Hawkes processes, and then derive closed-form expressions for
characterizing the effect of an intervention action on the invasion process. We
use this to obtain an optimal intervention plan based on an integer programming
formulation, and compare the optimal plan against several
ecologically-motivated heuristic strategies used in practice. We present an
empirical study of two variants of the invasive control problem: minimizing the
final rate of invasions, and minimizing the number of invasions at the end of a
given time horizon. Our results show that the optimized intervention achieves
nearly the same level of control that would be attained by completely
eradicating the species, with a 20% cost saving. Additionally, we design a
heuristic intervention strategy based on a combination of the density and life
stage of the invasive individuals, and find that it comes surprisingly close to
the optimized strategy, suggesting that this could serve as a good rule of
thumb in invasive species management.


Visually Explainable Recommendation

  Images account for a significant part of user decisions in many application
scenarios, such as product images in e-commerce, or user image posts in social
networks. It is intuitive that user preferences on the visual patterns of image
(e.g., hue, texture, color, etc) can be highly personalized, and this provides
us with highly discriminative features to make personalized recommendations.
  Previous work that takes advantage of images for recommendation usually
transforms the images into latent representation vectors, which are adopted by
a recommendation component to assist personalized user/item profiling and
recommendation. However, such vectors are hardly useful in terms of providing
visual explanations to users about why a particular item is recommended, and
thus weakens the explainability of recommendation systems.
  As a step towards explainable recommendation models, we propose visually
explainable recommendation based on attentive neural networks to model the user
attention on images, under the supervision of both implicit feedback and
textual reviews. By this, we can not only provide recommendation results to the
users, but also tell the users why an item is recommended by providing
intuitive visual highlights in a personalized manner. Experimental results show
that our models are not only able to improve the recommendation performance,
but also can provide persuasive visual explanations for the users to take the
recommendations.


