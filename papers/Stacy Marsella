Using Virtual Humans to Understand Real Ones

  Human interactions are characterized by explicit as well as implicit channelsof communication. While the explicit channel transmits overt messages, theimplicit ones transmit hidden messages about the communicator (e.g., his/herintentions and attitudes). There is a growing consensus that providing acomputer with the ability to manipulate implicit affective cues should allowfor a more meaningful and natural way of studying particular non-verbal signalsof human-human communications by human-computer interactions. In this pilotstudy, we created a non-dynamic human-computer interaction while manipulatingthree specific non-verbal channels of communication: gaze pattern, facialexpression, and gesture. Participants rated the virtual agent on affectivedimensional scales (pleasure, arousal, and dominance) while their physiologicalsignal (electrodermal activity, EDA) was captured during the interaction.Assessment of the behavioral data revealed a significant and complex three-wayinteraction between gaze, gesture, and facial configuration on the dimension ofpleasure, as well as a main effect of gesture on the dimension of dominance.These results suggest a complex relationship between different non-verbal cuesand the social context in which they are interpreted. Qualifying considerationsas well as possible next steps are further discussed in light of theseexploratory findings.

