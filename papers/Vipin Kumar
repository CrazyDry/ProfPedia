Dirac cone in a non-honeycomb surface alloy

  We demonstrate unexpected occurrence of linear bands resembling Dirac cone at
the zone-center of Au$_2$Sn surface alloy with $\left( \begin{smallmatrix}
2&1\\ 1&3 \end{smallmatrix} \right)$ surface structure formed by deposition of
about 0.9 ML Sn on Au(111) at elevated temperature. The surface exhibits an
oblique symmetry with unequal lattice constants making it the first two
dimensional surface alloy to exhibit Dirac cone with a non-honeycomb lattice.


Automated Monitoring Cropland Using Remote Sensing Data: Challenges and
  Opportunities for Machine Learning

  This paper provides an overview of how recent advances in machine learning
and the availability of data from earth observing satellites can dramatically
improve our ability to automatically map croplands over long period and over
large regions. It discusses three applications in the domain of crop monitoring
where ML approaches are beginning to show great promise. For each application,
it highlights machine learning challenges, proposed approaches, and recent
results. The paper concludes with discussion of major challenges that need to
be addressed before ML approaches will reach their full potential for this
problem of great societal relevance.


Quasiperiodic Sn layer

  Quasicrystalline materials exhibit aperiodic long range order and forbidden
rotational symmetries, but show sharp diffraction spots. Although quasicrystals
were discovered more than 30 years ago, elemental quasicrystals have remained
elusive so far. Here, we demonstrate unique characteristics of an elemental Sn
layer: it adopts a buckled five-fold quasiperiodic (QP) structure that is
different from the icosahedral ($i$)-Al-Pd-Mn substrate. The pseudogap in the
electronic states around the Fermi level that stabilizes a quasicrystal, is
further deepened in the Sn layer compared to the substrate. On the basis of
density functional theory, we relate this intriguing observation to the
buckling with enhanced covalency and $sp^3$ bonding between Sn atoms.
Quasiperiodicity is observed up to 1.4 nm (5 ML) at 100 K, a thickness regime
where the influence of the substrate potential is negligible.


Q-PET: PET with 3rd Eye Quantum Entanglement based Positron Emission
  Tomography

  In the present ongoing study, we are proposing a prototype model for positron
emission tomography detection technology by introduction of a new
discriminatory window parameter. It can be a new generation PET detection
technique. We introduced Polarization Measurement of the annihilation
photons(generated from the annihilation of positron and electron) as an
additional parameter in proposed prototype, to correlate annihilation photons
of a particular annihilation event. The motivation behind this introduction is
Quantum Entanglement relation between the two annihilation photons. These two
oppositely emitted photons are linearly polarized at right angle to each other.
Simulations studies for this research work are undergoing and some preliminary
results are presented here.


Harnessing GANs for Addition of New Classes in VSR

  It is an easy task for humans to learn and generalize a problem, perhaps it
is due to their ability to visualize and imagine unseen objects and concepts.
The power of imagination comes handy especially when interpolating learnt
experience (like seen examples) over new classes of a problem. For a machine
learning system, acquiring such powers of imagination are still a hard task. We
present a novel approach to low-shot learning that uses the idea of imagination
over unseen classes in a classification problem setting. We combine a
classifier with a `visionary' (i.e., a GAN model) that teaches the classifier
to generalize itself over new and unseen classes. This approach can be
incorporated into a variety of problem settings where we need a classifier to
learn and generalize itself to new and unseen classes. We compare the
performance of classifiers with and without the visionary GAN model helping
them.


Mining Electronic Health Records: A Survey

  The continuously increasing cost of the US healthcare system has received
significant attention. Central to the ideas aimed at curbing this trend is the
use of technology, in the form of the mandate to implement electronic health
records (EHRs). EHRs consist of patient information such as demographics,
medications, laboratory test results, diagnosis codes and procedures. Mining
EHRs could lead to improvement in patient health management as EHRs contain
detailed information related to disease prognosis for large patient
populations. In this manuscript, we provide a structured and comprehensive
overview of data mining techniques for modeling EHR data. We first provide a
detailed understanding of the major application areas to which EHR mining has
been applied and then discuss the nature of EHR data and its accompanying
challenges. Next, we describe major approaches used for EHR mining, the metrics
associated with EHRs, and the various study designs. With this foundation, we
then provide a systematic and methodological organization of existing data
mining techniques used to model EHRs and discuss ideas for future research. We
conclude this survey with a comprehensive summary of clinical data mining
applications of EHR data, as illustrated in the online supplement.


Physics-guided Neural Networks (PGNN): An Application in Lake
  Temperature Modeling

  This paper introduces a novel framework for combining scientific knowledge of
physics-based models with neural networks to advance scientific discovery. This
framework, termed as physics-guided neural network (PGNN), leverages the output
of physics-based model simulations along with observational features to
generate predictions using a neural network architecture. Further, this paper
presents a novel framework for using physics-based loss functions in the
learning objective of neural networks, to ensure that the model predictions not
only show lower errors on the training set but are also scientifically
consistent with the known physics on the unlabeled set. We illustrate the
effectiveness of PGNN for the problem of lake temperature modeling, where
physical relationships between the temperature, density, and depth of water are
used to design a physics-based loss function. By using scientific knowledge to
guide the construction and learning of neural networks, we are able to show
that the proposed framework ensures better generalizability as well as
scientific consistency of results.


ORBIT: Ordering Based Information Transfer Across Space and Time for
  Global Surface Water Monitoring

  Many earth science applications require data at both high spatial and
temporal resolution for effective monitoring of various ecosystem resources.
Due to practical limitations in sensor design, there is often a trade-off in
different resolutions of spatio-temporal datasets and hence a single sensor
alone cannot provide the required information. Various data fusion methods have
been proposed in the literature that mainly rely on individual timesteps when
both datasets are available to learn a mapping between features values at
different resolutions using local relationships between pixels. Earth
observation data is often plagued with spatially and temporally correlated
noise, outliers and missing data due to atmospheric disturbances which pose a
challenge in learning the mapping from a local neighborhood at individual
timesteps. In this paper, we aim to exploit time-independent global
relationships between pixels for robust transfer of information across
different scales. Specifically, we propose a new framework, ORBIT (Ordering
Based Information Transfer) that uses relative ordering constraint among pixels
to transfer information across both time and scales. The effectiveness of the
framework is demonstrated for global surface water monitoring using both
synthetic and real-world datasets.


Discovery of Shifting Patterns in Sequence Classification

  In this paper, we investigate the multi-variate sequence classification
problem from a multi-instance learning perspective. Real-world sequential data
commonly show discriminative patterns only at specific time periods. For
instance, we can identify a cropland during its growing season, but it looks
similar to a barren land after harvest or before planting. Besides, even within
the same class, the discriminative patterns can appear in different periods of
sequential data. Due to such property, these discriminative patterns are also
referred to as shifting patterns. The shifting patterns in sequential data
severely degrade the performance of traditional classification methods without
sufficient training data.
  We propose a novel sequence classification method by automatically mining
shifting patterns from multi-variate sequence. The method employs a
multi-instance learning approach to detect shifting patterns while also
modeling temporal relationships within each multi-instance bag by an LSTM model
to further improve the classification performance. We extensively evaluate our
method on two real-world applications - cropland mapping and affective state
recognition. The experiments demonstrate the superiority of our proposed method
in sequence classification performance and in detecting discriminative shifting
patterns.


Physics Guided Recurrent Neural Networks For Modeling Dynamical Systems:
  Application to Monitoring Water Temperature And Quality In Lakes

  In this paper, we introduce a novel framework for combining scientific
knowledge within physics-based models and recurrent neural networks to advance
scientific discovery in many dynamical systems. We will first describe the use
of outputs from physics-based models in learning a hybrid-physics-data model.
Then, we further incorporate physical knowledge in real-world dynamical systems
as additional constraints for training recurrent neural networks. We will apply
this approach on modeling lake temperature and quality where we take into
account the physical constraints along both the depth dimension and time
dimension. By using scientific knowledge to guide the construction and learning
the data-driven model, we demonstrate that this method can achieve better
prediction accuracy as well as scientific consistency of results.


Mining Novel Multivariate Relationships in Time Series Data Using
  Correlation Networks

  In many domains, there is significant interest in capturing novel
relationships between time series that represent activities recorded at
different nodes of a highly complex system. In this paper, we introduce
multipoles, a novel class of linear relationships between more than two time
series. A multipole is a set of time series that have strong linear dependence
among themselves, with the requirement that each time series makes a
significant contribution to the linear dependence. We demonstrate that most
interesting multipoles can be identified as cliques of negative correlations in
a correlation network. Such cliques are typically rare in a real-world
correlation network, which allows us to find almost all multipoles efficiently
using a clique-enumeration approach. Using our proposed framework, we
demonstrate the utility of multipoles in discovering new physical phenomena in
two scientific domains: climate science and neuroscience. In particular, we
discovered several multipole relationships that are reproducible in multiple
other independent datasets and lead to novel domain insights.


Physics Guided RNNs for Modeling Dynamical Systems: A Case Study in
  Simulating Lake Temperature Profiles

  This paper proposes a physics-guided recurrent neural network model (PGRNN)
that combines RNNs and physics-based models to leverage their complementary
strengths and improve the modeling of physical processes. Specifically, we show
that a PGRNN can improve prediction accuracy over that of physical models,
while generating outputs consistent with physical laws, and achieving good
generalizability. Standard RNNs, even when producing superior prediction
accuracy, often produce physically inconsistent results and lack
generalizability. We further enhance this approach by using a pre-training
method that leverages the simulated data from a physics-based model to address
the scarcity of observed data. The PGRNN has the flexibility to incorporate
additional physical constraints and we incorporate a density-depth
relationship. Both enhancements further improve PGRNN performance. Although we
present and evaluate this methodology in the context of modeling the dynamics
of temperature in lakes, it is applicable more widely to a range of scientific
and engineering disciplines where mechanistic (also known as process-based)
models are used, e.g., power engineering, climate science, materials science,
computational chemistry, and biomedicine.


Influence of anti-site disorder and electron-electron correlations on
  the electronic structure of CeMnNi$_4$

  CeMnNi$_4$ exhibits an unusually large spin polarization, but its origin has
baffled researchers for more than a decade. We use bulk sensitive hard x-ray
photoelectron spectroscopy (HAXPES) and density functional theory based on the
Green's function technique to demonstrate the importance of electron-electron
correlations of both the Ni 3$d$ ($U_{Ni}$) and Mn 3$d$ ($U_{Mn}$) electrons in
explaining the valence band of this multiply correlated material. We show that
Mn-Ni anti-site disorder as well as $U_{Ni}$ play crucial role in enhancing its
spin polarization: anti-site disorder broadens a Ni 3$d$ minority-spin peak
close to the Fermi level ($E_F$), while an increase in $U_{Ni}$ shifts it
towards $E_F$, both leading to a significant increase of minority-spin states
at $E_F$. Furthermore, rare occurrence of a valence state transition between
the bulk and the surface is demonstrated highlighting the importance of HAXPES
in resolving the electronic structure of materials unhindered by surface
effects.


Integration of Differential Gene-combination Search and Gene Set
  Enrichment Analysis: A General Approach

  Gene Set Enrichment Analysis (GSEA) and its variations aim to discover
collections of genes that show moderate but coordinated differences in
expression. However, such techniques may be ineffective if many individual
genes in a phenotype-related gene set have weak discriminative power. A
potential solution is to search for combinations of genes that are highly
differentiating even when individual genes are not. Although such techniques
have been developed, these approaches have not been used with GSEA to any
significant degree because of the large number of potential gene combinations
and the heterogeneity of measures that assess the differentiation provided by
gene groups of different sizes.
  To integrate the search for differentiating gene combinations and GSEA, we
propose a general framework with two key components: (A) a procedure that
reduces the number of scores to be handled by GSEA to the number of genes by
summarizing the scores of the gene combinations involving a particular gene in
a single score, and (B) a procedure to integrate the heterogeneous scores from
combinations of different sizes and from different gene combination measures by
mapping the scores to p-values. Experiments on four gene expression data sets
demonstrate that the integration of GSEA and gene combination search can
enhance the power of traditional GSEA by discovering gene sets that include
genes with weak individual differentiation but strong joint discriminative
power. Also, gene sets discovered by the integrative framework share several
common biological processes and improve the consistency of the results among
three lung cancer data sets.


Characterizing Discriminative Patterns

  Discriminative patterns are association patterns that occur with
disproportionate frequency in some classes versus others, and have been studied
under names such as emerging patterns and contrast sets. Such patterns have
demonstrated considerable value for classification and subgroup discovery, but
a detailed understanding of the types of interactions among items in a
discriminative pattern is lacking. To address this issue, we propose to
categorize discriminative patterns according to four types of item interaction:
(i) driver-passenger, (ii) coherent, (iii) independent additive and (iv)
synergistic beyond independent additive. Either of the last three is of
practical importance, with the latter two representing a gain in the
discriminative power of a pattern over its subsets. Synergistic patterns are
most restrictive, but perhaps the most interesting since they capture a
cooperative effect. For domains such as genetic research, differentiating among
these types of patterns is critical since each yields very different biological
interpretations. For general domains, the characterization provides a novel
view of the nature of the discriminative patterns in a dataset, which yields
insights beyond those provided by current approaches that focus mostly on
pattern-based classification and subgroup discovery. This paper presents a
comprehensive discussion that defines these four pattern types and investigates
their properties and their relationship to one another. In addition, these
ideas are explored for a variety of datasets (ten UCI datasets, one gene
expression dataset and two genetic-variation datasets). The results demonstrate
the existence, characteristics and statistical significance of the different
types of patterns. They also illustrate how pattern characterization can
provide novel insights into discriminative pattern mining and the
discriminative structure of different datasets.


Enhancing the functional content of protein interaction networks

  Protein interaction networks are a promising type of data for studying
complex biological systems. However, despite the rich information embedded in
these networks, they face important data quality challenges of noise and
incompleteness that adversely affect the results obtained from their analysis.
Here, we explore the use of the concept of common neighborhood similarity
(CNS), which is a form of local structure in networks, to address these issues.
Although several CNS measures have been proposed in the literature, an
understanding of their relative efficacies for the analysis of interaction
networks has been lacking. We follow the framework of graph transformation to
convert the given interaction network into a transformed network corresponding
to a variety of CNS measures evaluated. The effectiveness of each measure is
then estimated by comparing the quality of protein function predictions
obtained from its corresponding transformed network with those from the
original network. Using a large set of S. cerevisiae interactions, and a set of
136 GO terms, we find that several of the transformed networks produce more
accurate predictions than those obtained from the original network. In
particular, the $HC.cont$ measure proposed here performs particularly well for
this task. Further investigation reveals that the two major factors
contributing to this improvement are the abilities of CNS measures, especially
$HC.cont$, to prune out noisy edges and introduce new links between
functionally related proteins.


Causal Inference in Observational Data

  Our aging population increasingly suffers from multiple chronic diseases
simultaneously, necessitating the comprehensive treatment of these conditions.
Finding the optimal set of drugs for a combinatorial set of diseases is a
combinatorial pattern exploration problem. Association rule mining is a popular
tool for such problems, but the requirement of health care for finding causal,
rather than associative, patterns renders association rule mining unsuitable.
To address this issue, we propose a novel framework based on the Rubin-Neyman
causal model for extracting causal rules from observational data, correcting
for a number of common biases. Specifically, given a set of interventions and a
set of items that define subpopulations (e.g., diseases), we wish to find all
subpopulations in which effective intervention combinations exist and in each
such subpopulation, we wish to find all intervention combinations such that
dropping any intervention from this combination will reduce the efficacy of the
treatment. A key aspect of our framework is the concept of closed intervention
sets which extend the concept of quantifying the effect of a single
intervention to a set of concurrent interventions. We also evaluated our causal
rule mining framework on the Electronic Health Records (EHR) data of a large
cohort of patients from Mayo Clinic and showed that the patterns we extracted
are sufficiently rich to explain the controversial findings in the medical
literature regarding the effect of a class of cholesterol drugs on Type-II
Diabetes Mellitus (T2DM).


Theory-guided Data Science: A New Paradigm for Scientific Discovery from
  Data

  Data science models, although successful in a number of commercial domains,
have had limited applicability in scientific problems involving complex
physical phenomena. Theory-guided data science (TGDS) is an emerging paradigm
that aims to leverage the wealth of scientific knowledge for improving the
effectiveness of data science models in enabling scientific discovery. The
overarching vision of TGDS is to introduce scientific consistency as an
essential component for learning generalizable models. Further, by producing
scientifically interpretable models, TGDS aims to advance our scientific
understanding by discovering novel domain insights. Indeed, the paradigm of
TGDS has started to gain prominence in a number of scientific disciplines such
as turbulence modeling, material discovery, quantum chemistry, bio-medical
science, bio-marker discovery, climate science, and hydrology. In this paper,
we formally conceptualize the paradigm of TGDS and present a taxonomy of
research themes in TGDS. We describe several approaches for integrating domain
knowledge in different research themes using illustrative examples from
different disciplines. We also highlight some of the promising avenues of novel
research for realizing the full potential of theory-guided data science.


Machine Learning for the Geosciences: Challenges and Opportunities

  Geosciences is a field of great societal relevance that requires solutions to
several urgent problems facing our humanity and the planet. As geosciences
enters the era of big data, machine learning (ML) -- that has been widely
successful in commercial domains -- offers immense potential to contribute to
problems in geosciences. However, problems in geosciences have several unique
challenges that are seldom found in traditional applications, requiring novel
problem formulations and methodologies in machine learning. This article
introduces researchers in the machine learning (ML) community to these
challenges offered by geoscience problems and the opportunities that exist for
advancing both machine learning and geosciences. We first highlight typical
sources of geoscience data and describe their properties that make it
challenging to use traditional machine learning techniques. We then describe
some of the common categories of geoscience problems where machine learning can
play a role, and discuss some of the existing efforts and promising directions
for methodological development in machine learning. We conclude by discussing
some of the emerging research themes in machine learning that are applicable
across all problems in the geosciences, and the importance of a deep
collaboration between machine learning and geosciences for synergistic
advancements in both disciplines.


Spatio-Temporal Data Mining: A Survey of Problems and Methods

  Large volumes of spatio-temporal data are increasingly collected and studied
in diverse domains including, climate science, social sciences, neuroscience,
epidemiology, transportation, mobile health, and Earth sciences.
Spatio-temporal data differs from relational data for which computational
approaches are developed in the data mining community for multiple decades, in
that both spatial and temporal attributes are available in addition to the
actual measurements/attributes. The presence of these attributes introduces
additional challenges that needs to be dealt with. Approaches for mining
spatio-temporal data have been studied for over a decade in the data mining
community. In this article we present a broad survey of this relatively young
field of spatio-temporal data mining. We discuss different types of
spatio-temporal data and the relevant data mining questions that arise in the
context of analyzing each of these datasets. Based on the nature of the data
mining problem studied, we classify literature on spatio-temporal data mining
into six major categories: clustering, predictive learning, change detection,
frequent pattern mining, anomaly detection, and relationship mining. We discuss
the various forms of spatio-temporal data mining problems in each of these
categories.


Mining Sub-Interval Relationships In Time Series Data

  Time-series data is being increasingly collected and stud- ied in several
areas such as neuroscience, climate science, transportation, and social media.
Discovery of complex patterns of relationships between individual time-series,
using data-driven approaches can improve our understanding of real-world
systems. While traditional approaches typically study relationships between two
entire time series, many interesting relationships in real-world applications
exist in small sub-intervals of time while remaining absent or feeble during
other sub-intervals. In this paper, we define the notion of a sub-interval
relationship (SIR) to capture inter- actions between two time series that are
prominent only in certain sub-intervals of time. We propose a novel and
efficient approach to find most interesting SIR in a pair of time series. We
evaluate our proposed approach on two real-world datasets from climate science
and neuroscience domain and demonstrated the scalability and computational
efficiency of our proposed approach. We further evaluated our discovered SIRs
based on a randomization based procedure. Our results indicated the existence
of several such relationships that are statistically significant, some of which
were also found to have physical interpretation.


Construction and Functional Analysis of Human Genetic Interaction
  Networks with Genome-wide Association Data

  Genetic interaction measures how different genes collectively contribute to a
phenotype, and can reveal functional compensation and buffering between
pathways under genetic perturbations. Recently, genome-wide screening for
genetic interactions has revealed genetic interaction networks that provide
novel insights either when analyzed by themselves or when integrated with other
functional genomic datasets. For higher eukaryotes such as human, the above
reverse-genetics approaches are not straightforward since the phenotypes of
interest for higher eukaryotes are difficult to study in a cell based assay. We
propose a general framework for constructing and analyzing human genetic
interaction networks from genome-wide single nucleotide polymorphism (SNP) data
used for case-control studies on complex diseases. Specifically, the approach
contains three major steps: (1) estimating SNP-SNP genetic interactions, (2)
identifying linkage disequilibrium (LD) blocks and mapping SNP-SNP interactions
to block-block interactions, and (3) functional mapping for LD blocks. We
performed two sets of functional analyses for each of the six datasets used in
the paper, and demonstrated that (i) the constructed genetic interaction
networks are supported by functional evidence from independent biological
databases, and (ii) the network can be used to discover pairs of compensatory
gene modules (between-pathway models) in their joint association with a disease
phenotype. The proposed framework should provide novel insights beyond existing
approaches that either ignore interactions between SNPs or model different
SNP-SNP pairs with genetic interactions separately. Furthermore, our study
provides evidence that some of the core properties of genetic interaction
networks based on reverse genetics in model organisms like yeast are also
present in genetic interactions revealed by natural variation in human
populations.


An Improved Diffuse Foreground Subtraction by ILC method: CMB Map and
  Angular Power Spectrum using Planck and WMAP Observations

  We report an improved technique for diffuse foreground minimization from
Cosmic Microwave Background (CMB) maps using a new multi-phase iterative
internal-linear-combination (ILC) approach in harmonic space. The new procedure
consists of two phases. In phase 1, a diffuse foreground cleaned map is
obtained by performing a usual ILC operation in the harmonic space in a single
iteration over the desired portion of the sky. In phase 2, we obtain the final
foreground cleaned map using an iterative ILC approach also in the harmonic
space, however, now, during each iteration of foreground minimization, some of
the regions of the sky that are not being cleaned in the current iteration, are
replaced by the corresponding cleaned portions of the phase 1 cleaned map. The
new ILC method nullifies a foreground leakage signal that is otherwise
inevitably present in the old and usual harmonic space iterative ILC method.
The new method is flexible to handle input frequency maps, irrespective of
whether or not they initially have the same instrumental and pixel resolution,
by bringing them to a common and maximum possible beam and pixel resolution at
the beginning of the analysis. This dramatically reduces data redundancy and
hence memory usage and computational cost. During the ILC weight calculation it
avoids any need to deconvolve partial sky spherical harmonic coefficients by
the beam and pixel window functions, which in strict mathematical sense, is not
well-defined for azimuthally symmetric window functions. Using WMAP 9-year and
Planck-2015 published frequency maps we obtain a pair of foreground cleaned CMB
maps and CMB angular power spectrum. Our power spectrum match well with
Planck-2015 results, with some difference. Finally, we show that the weights
for ILC foreground minimization have an intrinsic characteristic that it tends
to produce a statistically isotropic CMB map as well.


Research and Education in Computational Science and Engineering

  Over the past two decades the field of computational science and engineering
(CSE) has penetrated both basic and applied research in academia, industry, and
laboratories to advance discovery, optimize systems, support decision-makers,
and educate the scientific and engineering workforce. Informed by centuries of
theory and experiment, CSE performs computational experiments to answer
questions that neither theory nor experiment alone is equipped to answer. CSE
provides scientists and engineers of all persuasions with algorithmic
inventions and software systems that transcend disciplines and scales. Carried
on a wave of digital technology, CSE brings the power of parallelism to bear on
troves of data. Mathematics-based advanced computing has become a prevalent
means of discovery and innovation in essentially all areas of science,
engineering, technology, and society; and the CSE community is at the core of
this transformation. However, a combination of disruptive
developments---including the architectural complexity of extreme-scale
computing, the data revolution that engulfs the planet, and the specialization
required to follow the applications to new frontiers---is redefining the scope
and reach of the CSE endeavor. This report describes the rapid expansion of CSE
and the challenges to sustaining its bold advances. The report also presents
strategies and directions for CSE research and education for the next decade.


Physics Potential of the ICAL detector at the India-based Neutrino
  Observatory (INO)

  The upcoming 50 kt magnetized iron calorimeter (ICAL) detector at the
India-based Neutrino Observatory (INO) is designed to study the atmospheric
neutrinos and antineutrinos separately over a wide range of energies and path
lengths. The primary focus of this experiment is to explore the Earth matter
effects by observing the energy and zenith angle dependence of the atmospheric
neutrinos in the multi-GeV range. This study will be crucial to address some of
the outstanding issues in neutrino oscillation physics, including the
fundamental issue of neutrino mass hierarchy. In this document, we present the
physics potential of the detector as obtained from realistic detector
simulations. We describe the simulation framework, the neutrino interactions in
the detector, and the expected response of the detector to particles traversing
it. The ICAL detector can determine the energy and direction of the muons to a
high precision, and in addition, its sensitivity to multi-GeV hadrons increases
its physics reach substantially. Its charge identification capability, and
hence its ability to distinguish neutrinos from antineutrinos, makes it an
efficient detector for determining the neutrino mass hierarchy. In this report,
we outline the analyses carried out for the determination of neutrino mass
hierarchy and precision measurements of atmospheric neutrino mixing parameters
at ICAL, and give the expected physics reach of the detector with 10 years of
runtime. We also explore the potential of ICAL for probing new physics
scenarios like CPT violation and the presence of magnetic monopoles.


Evidence for the decay B0 --> K+K-pi0

  We report a search for charmless hadronic decays of neutral B mesons to the
final state K+K-pi0. The results are based on a 711 fb^-1 data sample that
contains 772x10^6 BB-bar pairs, and was collected at the Y(4S) resonance with
the Belle detector at the KEKB asymmetric-energy e+e- collider. We find the
first evidence for this decay with a significance of 3.5 standard deviations
and measure its branching fraction as BF(B0 --> K+K-pi0) = [2.17 +/- 0.60(stat)
+/- 0.24 (syst)]x10^-6.


The Long-Baseline Neutrino Experiment: Exploring Fundamental Symmetries
  of the Universe

  The preponderance of matter over antimatter in the early Universe, the
dynamics of the supernova bursts that produced the heavy elements necessary for
life and whether protons eventually decay --- these mysteries at the forefront
of particle physics and astrophysics are key to understanding the early
evolution of our Universe, its current state and its eventual fate. The
Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed
plan for a world-class experiment dedicated to addressing these questions. LBNE
is conceived around three central components: (1) a new, high-intensity
neutrino source generated from a megawatt-class proton accelerator at Fermi
National Accelerator Laboratory, (2) a near neutrino detector just downstream
of the source, and (3) a massive liquid argon time-projection chamber deployed
as a far detector deep underground at the Sanford Underground Research
Facility. This facility, located at the site of the former Homestake Mine in
Lead, South Dakota, is approximately 1,300 km from the neutrino source at
Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino
charge-parity symmetry violation and mass ordering effects. This ambitious yet
cost-effective design incorporates scalability and flexibility and can
accommodate a variety of upgrades and contributions. With its exceptional
combination of experimental configuration, technical capabilities, and
potential for transformative discoveries, LBNE promises to be a vital facility
for the field of particle physics worldwide, providing physicists from around
the globe with opportunities to collaborate in a twenty to thirty year program
of exciting science. In this document we provide a comprehensive overview of
LBNE's scientific objectives, its place in the landscape of neutrino physics
worldwide, the technologies it will incorporate and the capabilities it will
possess.


