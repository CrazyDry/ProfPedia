Solving POMDPs by Searching in Policy Space

  Most algorithms for solving POMDPs iteratively improve a value function that
implicitly represents a policy and are said to search in value function space.
This paper presents an approach to solving POMDPs that represents a policy
explicitly as a finite-state controller and iteratively improves the controller
by search in policy space. Two related algorithms illustrate this approach. The
first is a policy iteration algorithm that can outperform value iteration in
solving infinitehorizon POMDPs. It provides the foundation for a new heuristic
search algorithm that promises further speedup by focusing computational effort
on regions of the problem space that are reachable, or likely to be reached,
from a start state.


Suboptimality Bounds for Stochastic Shortest Path Problems

  We consider how to use the Bellman residual of the dynamic programming
operator to compute suboptimality bounds for solutions to stochastic shortest
path problems. Such bounds have been previously established only in the special
case that "all policies are proper," in which case the dynamic programming
operator is known to be a contraction, and have been shown to be easily
computable only in the more limited special case of discounting. Under the
condition that transition costs are positive, we show that suboptimality bounds
can be easily computed even when not all policies are proper. In the general
case when there are no restrictions on transition costs, the analysis is more
complex. But we present preliminary results that show such bounds are possible.


The Expected Size of the Rule k Dominating Set

  Rule k is a localized approximation algorithm that finds a small connected
dominating set in a graph. We estimate the expected size of the Rule k
dominating set for the model of random unit disk graphs constructed from n
random points in an s_n by s_n square region of the plane.


Probabilistic Analysis of Rule 2

  Li and Wu proposed Rule 2, a localized approximation algorithm that attempts
to find a small connected dominating set in a graph. Here we study the
asymptotic performance of Rule 2 on random unit disk graphs formed from n
random points in an s_n by s_n square region of the plane. If s_n is below the
threshold for connectivity, then Rule 2 produces a dominating set whose
expected size is O(n/(loglog n)^{3/2}). We conjecture that this bound is not
optimal.


Sparse Stochastic Finite-State Controllers for POMDPs

  Bounded policy iteration is an approach to solving infinite-horizon POMDPs
that represents policies as stochastic finite-state controllers and iteratively
improves a controller by adjusting the parameters of each node using linear
programming. In the original algorithm, the size of the linear programs, and
thus the complexity of policy improvement, depends on the number of parameters
of each node, which grows with the size of the controller. But in practice, the
number of parameters of a node with non-zero values is often very small, and
does not grow with the size of the controller. Based on this observation, we
develop a version of bounded policy iteration that leverages the sparse
structure of a stochastic finite-state controller. In each iteration, it
improves a policy by the same amount as the original algorithm, but with much
better scalability.


Gabor Transforms on the Sphere with Applications to CMB Power Spectrum
  Estimation

  The Fourier transform of a dataset apodised with a window function is known
as the Gabor transform. In this paper we extend the Gabor transform formalism
to the sphere with the intention of applying it to CMB data analysis. The Gabor
coefficients on the sphere known as the pseudo power spectrum is studied for
windows of different size. By assuming that the pseudo power spectrum
coefficients are Gaussian distributed, we formulate a likelihood ansatz using
these as input parameters to estimate the full sky power spectrum from a patch
on the sky. Since this likelihood can be calculated quickly without having to
invert huge matrices, this allows for fast power spectrum estimation. By using
the pseudo power spectrum from several patches on the sky together, the full
sky power spectrum can be estimated from full-sky or nearly full-sky
observations.


Robust, frequency-stable and accurate mid-IR laser spectrometer based on
  frequency comb metrology of quantum cascade lasers up-converted in
  orientation-patterned GaAs

  We demonstrate a robust and simple method for measurement, stabilization and
tuning of the frequency of cw mid-infrared (MIR) lasers, in particular of
quantum cascade lasers. The proof of principle is performed with a quantum
cascade laser at 5.4 \mu m, which is upconverted to 1.2 \mu m by sum-frequency
generation in orientation-patterned GaAs with the output of a standard
high-power cw 1.5 \mu m fiber laser. Both the 1.2 \mu m and the 1.5 \mu m waves
are measured by a standard Er:fiber frequency comb. Frequency measurement at
the 100 kHz-level, stabilization to sub-10 kHz level, controlled frequency
tuning and long-term stability are demonstrated.


Solving Multistage Influence Diagrams using Branch-and-Bound Search

  A branch-and-bound approach to solving influ- ence diagrams has been
previously proposed in the literature, but appears to have never been
implemented and evaluated - apparently due to the difficulties of computing
effective bounds for the branch-and-bound search. In this paper, we describe
how to efficiently compute effective bounds, and we develop a practical
implementa- tion of depth-first branch-and-bound search for influence diagram
evaluation that outperforms existing methods for solving influence diagrams
with multiple stages.


The HEALPix Primer

  HEALPix is a Hierarchical, Equal Area, and iso-Latitude Pixelisation of the
sphere designed to support efficiently
  - local operations on the pixel set,
  - a hierarchical tree structure for multi-resolution applications, and
  - the global Fast Spherical Harmonic transform.
  The HEALPix concept and the mathematical software based on it introduced in
this primer meet the challenges which future high resolution and large volume
CMB data sets including the MAP and Planck mission products will present.


Neighbourhood Structures: Bisimilarity and Basic Model Theory

  Neighbourhood structures are the standard semantic tool used to reason about
non-normal modal logics. The logic of all neighbourhood models is called
classical modal logic. In coalgebraic terms, a neighbourhood frame is a
coalgebra for the contravariant powerset functor composed with itself, denoted
by 2^2. We use this coalgebraic modelling to derive notions of equivalence
between neighbourhood structures. 2^2-bisimilarity and behavioural equivalence
are well known coalgebraic concepts, and they are distinct, since 2^2 does not
preserve weak pullbacks. We introduce a third, intermediate notion whose
witnessing relations we call precocongruences (based on pushouts). We give
back-and-forth style characterisations for 2^2-bisimulations and
precocongruences, we show that on a single coalgebra, precocongruences capture
behavioural equivalence, and that between neighbourhood structures,
precocongruences are a better approximation of behavioural equivalence than
2^2-bisimulations. We also introduce a notion of modal saturation for
neighbourhood models, and investigate its relationship with definability and
image-finiteness. We prove a Hennessy-Milner theorem for modally saturated and
for image-finite neighbourhood models. Our main results are an analogue of Van
Benthem's characterisation theorem and a model-theoretic proof of Craig
interpolation for classical modal logic.


Improving the Scalability of Optimal Bayesian Network Learning with
  External-Memory Frontier Breadth-First Branch and Bound Search

  Previous work has shown that the problem of learning the optimal structure of
a Bayesian network can be formulated as a shortest path finding problem in a
graph and solved using A* search. In this paper, we improve the scalability of
this approach by developing a memory-efficient heuristic search algorithm for
learning the structure of a Bayesian network. Instead of using A*, we propose a
frontier breadth-first branch and bound search that leverages the layered
structure of the search graph of this problem so that no more than two layers
of the graph, plus solution reconstruction information, need to be stored in
memory at a time. To further improve scalability, the algorithm stores most of
the graph in external memory, such as hard disk, when it does not fit in RAM.
Experimental results show that the resulting algorithm solves significantly
larger problems than the current state of the art.


Solving Limited-Memory Influence Diagrams Using Branch-and-Bound Search

  A limited-memory influence diagram (LIMID) generalizes a traditional
influence diagram by relaxing the assumptions of regularity and no-forgetting,
allowing a wider range of decision problems to be modeled. Algorithms for
solving traditional influence diagrams are not easily generalized to solve
LIMIDs, however, and only recently have exact algorithms for solving LIMIDs
been developed. In this paper, we introduce an exact algorithm for solving
LIMIDs that is based on branch-and-bound search. Our approach is related to the
approach of solving an influence diagram by converting it to an equivalent
decision tree, with the difference that the LIMID is converted to a much
smaller decision graph that can be searched more efficiently.


MASTER of the CMB Anisotropy Power Spectrum: A Fast Method for
  Statistical Analysis of Large and Complex CMB Data Sets

  We describe a fast and accurate method for estimation of the cosmic microwave
background (CMB) anisotropy angular power spectrum --- Monte Carlo Apodised
Spherical Transform EstimatoR. Originally devised for use in the interpretation
of the Boomerang experimental data, MASTER is both a computationally efficient
method suitable for use with the currently available CMB data sets (already
large in size, despite covering small fractions of the sky, and affected by
inhomogeneous and correlated noise), and a very promising application for the
analysis of very large future CMB satellite mission products.


HEALPix -- a Framework for High Resolution Discretization, and Fast
  Analysis of Data Distributed on the Sphere

  HEALPix -- the Hierarchical Equal Area iso-Latitude Pixelization -- is a
versatile data structure with an associated library of computational algorithms
and visualization software that supports fast scientific applications
executable directly on very large volumes of astronomical data and large area
surveys in the form of discretized spherical maps. Originally developed to
address the data processing and analysis needs of the present generation of
cosmic microwave background (CMB) experiments (e.g. BOOMERanG, WMAP), HEALPix
can be expanded to meet many of the profound challenges that will arise in
confrontation with the observational output of future missions and experiments,
including e.g. Planck, Herschel, SAFIR, and the Beyond Einstein CMB
polarization probe. In this paper we consider the requirements and constraints
to be met in order to implement a sufficient framework for the efficient
discretization and fast analysis/synthesis of functions defined on the sphere,
and summarise how they are satisfied by HEALPix.


A Heuristic Search Approach to Planning with Continuous Resources in
  Stochastic Domains

  We consider the problem of optimal planning in stochastic domains with
resource constraints, where the resources are continuous and the choice of
action at each step depends on resource availability. We introduce the HAO*
algorithm, a generalization of the AO* algorithm that performs search in a
hybrid state space that is modeled using both discrete and continuous state
variables, where the continuous variables represent monotonic resources. Like
other heuristic search algorithms, HAO* leverages knowledge of the start state
and an admissible heuristic to focus computational effort on those parts of the
state space that could be reached from the start state by following an optimal
policy. We show that this approach is especially effective when resource
constraints limit how much of the state space is reachable. Experimental
results demonstrate its effectiveness in the domain that motivates our
research: automated planning for planetary exploration rovers.


Symbolic Generalization for On-line Planning

  Symbolic representations have been used successfully in off-line planning
algorithms for Markov decision processes. We show that they can also improve
the performance of on-line planners. In addition to reducing computation time,
symbolic generalization can reduce the amount of costly real-world interactions
required for convergence. We introduce Symbolic Real-Time Dynamic Programming
(or sRTDP), an extension of RTDP. After each step of on-line interaction with
an environment, sRTDP uses symbolic model-checking techniques to generalizes
its experience by updating a group of states rather than a single state. We
examine two heuristic approaches to dynamic grouping of states and show that
they accelerate the planning process significantly in terms of both CPU time
and the number of steps of interaction with the environment.


Ice Melt, Sea Level Rise and Superstorms: Evidence from Paleoclimate
  Data, Climate Modeling, and Modern Observations that 2°C Global Warming
  is Dangerous

  We use numerical climate simulations, paleoclimate data, and modern
observations to study the effect of growing ice melt from Antarctica and
Greenland. Meltwater tends to stabilize the ocean column, inducing amplifying
feedbacks that increase subsurface ocean warming and ice shelf melting. Cold
meltwater and induced dynamical effects cause ocean surface cooling in the
Southern Ocean and North Atlantic, thus increasing Earth's energy imbalance and
heat flux into most of the global ocean's surface. Southern Ocean surface
cooling, while lower latitudes are warming, increases precipitation on the
Southern Ocean, increasing ocean stratification, slowing deepwater formation,
and increasing ice sheet mass loss. These feedbacks make ice sheets in contact
with the ocean vulnerable to accelerating disintegration. We hypothesize that
ice mass loss from the most vulnerable ice, sufficient to raise sea level
several meters, is better approximated as exponential than by a more linear
response. Doubling times of 10, 20 or 40 years yield multi-meter sea level rise
in about 50, 100 or 200 years. Recent ice melt doubling times are near the
lower end of the 10-40 year range, but the record is too short to confirm the
nature of the response. The feedbacks, including subsurface ocean warming, help
explain paleoclimate data and point to a dominant Southern Ocean role in
controlling atmospheric CO2, which in turn exercised tight control on global
temperature and sea level. The millennial (500-2000 year) time scale of deep
ocean ventilation affects the time scale for natural CO2 change and thus the
time scale for paleo global climate, ice sheet, and sea level changes, but this
paleo millennial time scale should not be misinterpreted as the time scale for
ice sheet response to a rapid large human-made climate forcing.


Policy Iteration for Decentralized Control of Markov Decision Processes

  Coordination of distributed agents is required for problems arising in many
areas, including multi-robot systems, networking and e-commerce. As a formal
framework for such problems, we use the decentralized partially observable
Markov decision process (DEC-POMDP). Though much work has been done on optimal
dynamic programming algorithms for the single-agent version of the problem,
optimal algorithms for the multiagent case have been elusive. The main
contribution of this paper is an optimal policy iteration algorithm for solving
DEC-POMDPs. The algorithm uses stochastic finite-state controllers to represent
policies. The solution can include a correlation device, which allows agents to
correlate their actions without communicating. This approach alternates between
expanding the controller and performing value-preserving transformations, which
modify the controller without sacrificing value. We present two efficient
value-preserving transformations: one can reduce the size of the controller and
the other can improve its value while keeping the size fixed. Empirical results
demonstrate the usefulness of value-preserving transformations in increasing
value while keeping controller size to a minimum. To broaden the applicability
of the approach, we also present a heuristic version of the policy iteration
algorithm, which sacrifices convergence to optimality. This algorithm further
reduces the size of the controllers at each step by assuming that probability
distributions over the other agents actions are known. While this assumption
may not hold in general, it helps produce higher quality solutions in our test
problems.


Anatomy of a Crash

  Transportation networks constitute a critical infrastructure enabling the
transfers of passengers and goods, with a significant impact on the economy at
different scales. Transportation modes, whether air, road or rail, are coupled
and interdependent. The frequent occurrence of perturbations on one or several
modes disrupts passengers' entire journeys, directly and through ripple
effects. The present paper provides a case report of the Asiana Crash in San
Francisco International Airport on July 6th 2013 and its repercussions on the
multimodal transportation network. It studies the resulting propagation of
disturbances on the transportation infrastructure in the United States. The
perturbation takes different forms and varies in scale and time frame :
cancellations and delays snowball in the airspace, highway traffic near the
airport is impacted by congestion in previously never congested locations, and
transit passenger demand exhibit unusual traffic peaks in between airports in
the Bay Area. This paper, through a case study, aims at stressing the
importance of further data-driven research on interdependent infrastructure
networks for increased resilience. The end goal is to form the basis for
optimization models behind providing more reliable passenger door-to-door
journeys.


Performance of a Large-area GEM Detector Read Out with Wide Radial
  Zigzag Strips

  A 1-meter-long trapezoidal Triple-GEM detector with wide readout strips was
tested in hadron beams at the Fermilab Test Beam Facility in October 2013. The
readout strips have a special zigzag geometry and run along the radial
direction with an azimuthal pitch of 1.37 mrad to measure the azimuthal
phi-coordinate of incident particles. The zigzag geometry of the readout
reduces the required number of electronic channels by a factor of three
compared to conventional straight readout strips while preserving good angular
resolution. The average crosstalk between zigzag strips is measured to be an
acceptable 5.5%. The detection efficiency of the detector is (98.4+-0.2)%. When
the non-linearity of the zigzag-strip response is corrected with track
information, the angular resolution is measured to be (193+-3) urad, which
corresponds to 14% of the angular strip pitch. Multiple Coulomb scattering
effects are fully taken into account in the data analysis with the help of a
stand-alone Geant4 simulation that estimates interpolated track errors.


Two Transiting Low Density Sub-Saturns from K2

  We report the discovery and confirmation of two sub-Saturn planets orbiting a
bright (V = 11.3), metal-rich ([Fe/H] = 0.42 $\pm$ 0.04 dex) G3 dwarf in the K2
Campaign 2 field. The planets are 5.68 $\pm$ 0.56 Earth-radii and 7.82 $\pm$
0.72 Earth-radii and have orbital periods of 20.8851 $\pm$ 0.0003 d and
42.3633$\pm$0.0006 d, near to the 2:1 mean-motion resonance. We obtained 32
radial velocities (RVs) with Keck/HIRES and detected the reflex motion due to
EPIC-203771098b and c. These planets have masses of 21.0 $\pm$ 5.4 Earth-masses
and 27.0 $\pm$ 6.9 Earth-masses, respectively. With low densities of 0.63 $\pm$
0.25 g/cc and 0.31 $\pm$ 0.12 g/cc, respectively, the planets require thick
envelopes of H/He to explain their large sizes and low masses. Interior
structure models predict that the planets have fairly massive cores of 17.6
$\pm$ 4.3 Earth-masses and 16.1 $\pm$ 4.2 Earth-masses, respectively. They may
have formed exterior to their present locations, accreted their H/He envelopes
at large orbital distances, and migrated in as a resonant pair. The proximity
to resonance, large transit depths, and host star brightness offer rich
opportunities for TTV follow-up. Finally, the low surface gravities of the
EPIC-203771098 planets make them favorable targets for transmission
spectroscopy by HST, Spitzer, and JWST.


The First Kepler Mission Planet Confirmed With The Hobby-Eberly
  Telescope: Kepler-15b, a Hot Jupiter Enriched In Heavy Elements

  We report the discovery of Kepler-15b, a new transiting exoplanet detected by
NASA's Kepler mission. The transit signal with a period of 4.94 days was
detected in the quarter 1 (Q1) Kepler photometry. For the first time, we have
used the High-Resolution-Spectrograph (HRS) at the Hobby-Eberly Telescope (HET)
to determine the mass of a Kepler planet via precise radial velocity (RV)
measurements. The 24 HET/HRS radial velocities (RV) and 6 additional
measurements from the FIES spectrograph at the Nordic Optical Telescope (NOT)
reveal a Doppler signal with the same period and phase as the transit
ephemeris. We used one HET/HRS spectrum of Kepler-15 taken without the iodine
cell to determine accurate stellar parameters. The host star is a metal-rich
([Fe/H]=0.36+/-0.07) G-type main sequence star with T_eff=5515+/-124 K. The
amplitude of the RV-orbit yields a mass of the planet of 0.66+/-0.1 M_Jup. The
planet has a radius of 0.96+/-0.06 R_Jup and a mean bulk density of 0.9+/-0.2
g/cm^3. The planetary radius resides on the lower envelope for transiting
planets with similar mass and irradiation level. This suggests significant
enrichment of the planet with heavy elements. We estimate a heavy element mass
of 30-40 M_Earth within Kepler-15b.


4MOST - 4-metre Multi-Object Spectroscopic Telescope

  The 4MOST consortium is currently halfway through a Conceptual Design study
for ESO with the aim to develop a wide-field (>3 square degree, goal >5 square
degree), high-multiplex (>1500 fibres, goal 3000 fibres) spectroscopic survey
facility for an ESO 4m-class telescope (VISTA). 4MOST will run permanently on
the telescope to perform a 5 year public survey yielding more than 20 million
spectra at resolution R~5000 ({\lambda}=390-1000 nm) and more than 2 million
spectra at R~20,000 (395-456.5 nm & 587-673 nm). The 4MOST design is especially
intended to complement three key all-sky, space-based observatories of prime
European interest: Gaia, eROSITA and Euclid. Initial design and performance
estimates for the wide-field corrector concepts are presented. We consider two
fibre positioner concepts, a well-known Phi-Theta system and a new R-Theta
concept with a large patrol area. The spectrographs are fixed configuration
two-arm spectrographs, with dedicated spectrographs for the high- and
low-resolution. A full facility simulator is being developed to guide trade-off
decisions regarding the optimal field-of-view, number of fibres needed, and the
relative fraction of high-to-low resolution fibres. Mock catalogues with
template spectra from seven Design Reference Surveys are simulated to verify
the science requirements of 4MOST. The 4MOST consortium aims to deliver the
full 4MOST facility by the end of 2018 and start delivering high-level data
products for both consortium and ESO community targets a year later with yearly
increments.


The Detailed Science Case for the Maunakea Spectroscopic Explorer, 2019
  edition

  (Abridged) The Maunakea Spectroscopic Explorer (MSE) is an end-to-end science
platform for the design, execution and scientific exploitation of spectroscopic
surveys. It will unveil the composition and dynamics of the faint Universe and
impact nearly every field of astrophysics across all spatial scales, from
individual stars to the largest scale structures in the Universe. Major pillars
in the science program for MSE include (i) the ultimate Gaia follow-up facility
for understanding the chemistry and dynamics of the distant Milky Way,
including the outer disk and faint stellar halo at high spectral resolution
(ii) galaxy formation and evolution at cosmic noon, via the type of
revolutionary surveys that have occurred in the nearby Universe, but now
conducted at the peak of the star formation history of the Universe (iii)
derivation of the mass of the neutrino and insights into inflationary physics
through a cosmological redshift survey that probes a large volume of the
Universe with a high galaxy density. MSE is positioned to become a critical hub
in the emerging international network of front-line astronomical facilities,
with scientific capabilities that naturally complement and extend the
scientific power of Gaia, the Large Synoptic Survey Telescope, the Square
Kilometer Array, Euclid, WFIRST, the 30m telescopes and many more.


The Pierre Auger Observatory: Contributions to the 33rd International
  Cosmic Ray Conference (ICRC 2013)

  Contributions of the Pierre Auger Collaboration to the 33rd International
Cosmic Ray Conference, Rio de Janeiro, Brazil, July 2013


Energy Estimation of Cosmic Rays with the Engineering Radio Array of the
  Pierre Auger Observatory

  The Auger Engineering Radio Array (AERA) is part of the Pierre Auger
Observatory and is used to detect the radio emission of cosmic-ray air showers.
These observations are compared to the data of the surface detector stations of
the Observatory, which provide well-calibrated information on the cosmic-ray
energies and arrival directions. The response of the radio stations in the 30
to 80 MHz regime has been thoroughly calibrated to enable the reconstruction of
the incoming electric field. For the latter, the energy deposit per area is
determined from the radio pulses at each observer position and is interpolated
using a two-dimensional function that takes into account signal asymmetries due
to interference between the geomagnetic and charge-excess emission components.
The spatial integral over the signal distribution gives a direct measurement of
the energy transferred from the primary cosmic ray into radio emission in the
AERA frequency range. We measure 15.8 MeV of radiation energy for a 1 EeV air
shower arriving perpendicularly to the geomagnetic field. This radiation energy
-- corrected for geometrical effects -- is used as a cosmic-ray energy
estimator. Performing an absolute energy calibration against the
surface-detector information, we observe that this radio-energy estimator
scales quadratically with the cosmic-ray energy as expected for coherent
emission. We find an energy resolution of the radio reconstruction of 22% for
the data set and 17% for a high-quality subset containing only events with at
least five radio stations with signal.


Measurement of the cosmic ray spectrum above $4{\times}10^{18}$ eV using
  inclined events detected with the Pierre Auger Observatory

  A measurement of the cosmic-ray spectrum for energies exceeding
$4{\times}10^{18}$ eV is presented, which is based on the analysis of showers
with zenith angles greater than $60^{\circ}$ detected with the Pierre Auger
Observatory between 1 January 2004 and 31 December 2013. The measured spectrum
confirms a flux suppression at the highest energies. Above $5.3{\times}10^{18}$
eV, the "ankle", the flux can be described by a power law $E^{-\gamma}$ with
index $\gamma=2.70 \pm 0.02 \,\text{(stat)} \pm 0.1\,\text{(sys)}$ followed by
a smooth suppression region. For the energy ($E_\text{s}$) at which the
spectral flux has fallen to one-half of its extrapolated value in the absence
of suppression, we find
$E_\text{s}=(5.12\pm0.25\,\text{(stat)}^{+1.0}_{-1.2}\,\text{(sys)}){\times}10^{19}$
eV.


Measurement of the Radiation Energy in the Radio Signal of Extensive Air
  Showers as a Universal Estimator of Cosmic-Ray Energy

  We measure the energy emitted by extensive air showers in the form of radio
emission in the frequency range from 30 to 80 MHz. Exploiting the accurate
energy scale of the Pierre Auger Observatory, we obtain a radiation energy of
15.8 \pm 0.7 (stat) \pm 6.7 (sys) MeV for cosmic rays with an energy of 1 EeV
arriving perpendicularly to a geomagnetic field of 0.24 G, scaling
quadratically with the cosmic-ray energy. A comparison with predictions from
state-of-the-art first-principle calculations shows agreement with our
measurement. The radiation energy provides direct access to the calorimetric
energy in the electromagnetic cascade of extensive air showers. Comparison with
our result thus allows the direct calibration of any cosmic-ray radio detector
against the well-established energy scale of the Pierre Auger Observatory.


An improved limit to the diffuse flux of ultra-high energy neutrinos
  from the Pierre Auger Observatory

  Neutrinos in the cosmic ray flux with energies near 1 EeV and above are
detectable with the Surface Detector array of the Pierre Auger Observatory. We
report here on searches through Auger data from 1 January 2004 until 20 June
2013. No neutrino candidates were found, yielding a limit to the diffuse flux
of ultra-high energy neutrinos that challenges the Waxman-Bahcall bound
predictions. Neutrino identification is attempted using the broad
time-structure of the signals expected in the SD stations, and is efficiently
done for neutrinos of all flavors interacting in the atmosphere at large zenith
angles, as well as for "Earth-skimming" neutrino interactions in the case of
tau neutrinos. In this paper the searches for downward-going neutrinos in the
zenith angle bins $60^\circ-75^\circ$ and $75^\circ-90^\circ$ as well as for
upward-going neutrinos, are combined to give a single limit. The $90\%$ C.L.
single-flavor limit to the diffuse flux of ultra-high energy neutrinos with an
$E^{-2}$ spectrum in the energy range $1.0 \times 10^{17}$ eV - $2.5 \times
10^{19}$ eV is $E_\nu^2 dN_\nu/dE_\nu < 6.4 \times 10^{-9}~ {\rm GeV~ cm^{-2}~
s^{-1}~ sr^{-1}}$.


