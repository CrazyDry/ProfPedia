Knuthian Drawings of Series-Parallel Flowcharts

  Inspired by a classic paper by Knuth, we revisit the problem of drawing
flowcharts of loop-free algorithms, that is, degree-three series-parallel
digraphs. Our drawing algorithms show that it is possible to produce Knuthian
drawings of degree-three series-parallel digraphs with good aspect ratios and
small numbers of edge bends.


On the Algorithmic Complexity of the Mastermind Game with Black-Peg
  Results

  In this paper, we study the algorithmic complexity of the Mastermind game,
where results are single-color black pegs. This differs from the usual
dual-color version of the game, but better corresponds to applications in
genetics. We show that it is NP-complete to determine if a sequence of
single-color Mastermind results have a satisfying vector. We also show how to
devise efficient algorithms for discovering a hidden vector through
single-color queries. Indeed, our algorithm improves a previous method of
Chvatal by almost a factor of 2.


Discrepancy-Sensitive Dynamic Fractional Cascading, Dominated Maxima
  Searching, and 2-d Nearest Neighbors in Any Minkowski Metric

  This paper studies a discrepancy-sensitive approach to dynamic fractional
cascading. We provide an efficient data structure for dominated maxima
searching in a dynamic set of points in the plane, which in turn leads to an
efficient dynamic data structure that can answer queries for nearest neighbors
using any Minkowski metric. We provide an efficient data structure for
dominated maxima searching in a dynamic set of points in the plane, which in
turn leads to an efficient dynamic data structure that can answer queries for
nearest neighbors using any Minkowski metric.


Data-Oblivious Graph Drawing Model and Algorithms

  We study graph drawing in a cloud-computing context where data is stored
externally and processed using a small local working storage. We show that a
number of classic graph drawing algorithms can be efficiently implemented in
such a framework where the client can maintain privacy while constructing a
drawing of her graph.


Delta-confluent Drawings

  We generalize the tree-confluent graphs to a broader class of graphs called
Delta-confluent graphs. This class of graphs and distance-hereditary graphs, a
well-known class of graphs, coincide. Some results about the visualization of
Delta-confluent graphs are also given.


Geometric Fingerprint Recognition via Oriented Point-Set Pattern
  Matching

  Motivated by the problem of fingerprint matching, we present geometric
approximation algorithms for matching a pattern point set against a background
point set, where the points have angular orientations in addition to their
positions.


Balanced Circle Packings for Planar Graphs

  We study balanced circle packings and circle-contact representations for
planar graphs, where the ratio of the largest circle's diameter to the smallest
circle's diameter is polynomial in the number of circles. We provide a number
of positive and negative results for the existence of such balanced
configurations.


The Melbourne Shuffle: Improving Oblivious Storage in the Cloud

  We present a simple, efficient, and secure data-oblivious randomized shuffle
algorithm. This is the first secure data-oblivious shuffle that is not based on
sorting. Our method can be used to improve previous oblivious storage solutions
for network-based outsourcing of data.


Invertible Bloom Lookup Tables

  We present a version of the Bloom filter data structure that supports not
only the insertion, deletion, and lookup of key-value pairs, but also allows a
complete listing of its contents with high probability, as long the number of
key-value pairs is below a designed threshold. Our structure allows the number
of key-value pairs to greatly exceed this threshold during normal operation.
Exceeding the threshold simply temporarily prevents content listing and reduces
the probability of a successful lookup. If later entries are deleted to return
the structure below the threshold, everything again functions appropriately. We
also show that simple variations of our structure are robust to certain
standard errors, such as the deletion of a key without a corresponding
insertion or the insertion of two distinct values for a key. The properties of
our structure make it suitable for several applications, including database and
networking applications that we highlight.


Privacy-Preserving Access of Outsourced Data via Oblivious RAM
  Simulation

  Suppose a client, Alice, has outsourced her data to an external storage
provider, Bob, because he has capacity for her massive data set, of size n,
whereas her private storage is much smaller--say, of size O(n^{1/r}), for some
constant r > 1. Alice trusts Bob to maintain her data, but she would like to
keep its contents private. She can encrypt her data, of course, but she also
wishes to keep her access patterns hidden from Bob as well. We describe schemes
for the oblivious RAM simulation problem with a small logarithmic or
polylogarithmic amortized increase in access times, with a very high
probability of success, while keeping the external storage to be of size O(n).
To achieve this, our algorithmic contributions include a parallel MapReduce
cuckoo-hashing algorithm and an external-memory dataoblivious sorting
algorithm.


The Rainbow Skip Graph: A Fault-Tolerant Constant-Degree P2P Relay
  Structure

  We present a distributed data structure, which we call the rainbow skip
graph. To our knowledge, this is the first peer-to-peer data structure that
simultaneously achieves high fault tolerance, constant-sized nodes, and fast
update and query times for ordered data. It is a non-trivial adaptation of the
SkipNet/skip-graph structures of Harvey et al. and Aspnes and Shah, so as to
provide fault-tolerance as these structures do, but to do so using
constant-sized nodes, as in the family tree structure of Zatloukal and Harvey.
It supports successor queries on a set of n items using O(log n) messages with
high probability, an improvement over the expected O(log n) messages of the
family tree.


Anonymous Card Shuffling and its Applications to Parallel Mixnets

  We study the question of how to shuffle $n$ cards when faced with an opponent
who knows the initial position of all the cards {\em and} can track every card
when permuted, {\em except} when one takes $K< n$ cards at a time and shuffles
them in a private buffer "behind your back," which we call {\em buffer
shuffling}. The problem arises naturally in the context of parallel mixnet
servers as well as other security applications. Our analysis is based on
related analyses of load-balancing processes. We include extensions to
variations that involve corrupted servers and adversarially injected messages,
which correspond to an opponent who can peek at some shuffles in the buffer and
who can mark some number of the cards. In addition, our analysis makes novel
use of a sum-of-squares metric for anonymity, which leads to improved
performance bounds for parallel mixnets and can also be used to bound
well-known existing anonymity measures.


Going Off-road: Transversal Complexity in Road Networks

  A geometric graph is a graph embedded in the plane with vertices at points
and edges drawn as curves (which are usually straight line segments) between
those points. The average transversal complexity of a geometric graph is the
number of edges of that graph that are crossed by random line or line segment.
In this paper, we study the average transversal complexity of road networks. By
viewing road networks as multiscale-dispersed graphs, we show that a random
line will cross the edges of such a graph O(sqrt(n)) times on average. In
addition, we provide by empirical evidence from experiments on the road
networks of the fifty states of United States and the District of Columbia that
this bound holds in practice and has a small constant factor. Combining this
result with data structuring techniques from computational geometry, allows us
to show that we can then do point location and ray-shooting navigational
queries with respect to road networks in O(sqrt(n) log n) expected time.
Finally, we provide empirical justification for this claim as well.


BIOS ORAM: Improved Privacy-Preserving Data Access for Parameterized
  Outsourced Storage

  Algorithms for oblivious random access machine (ORAM) simulation allow a
client, Alice, to obfuscate a pattern of data accesses with a server, Bob, who
is maintaining Alice's outsourced data while trying to learn information about
her data. We present a novel ORAM scheme that improves the asymptotic I/O
overhead of previous schemes for a wide range of size parameters for
client-side private memory and message blocks, from logarithmic to polynomial.
Our method achieves statistical security for hiding Alice's access pattern and,
with high probability, achieves an I/O overhead that ranges from $O(1)$ to
$O(\log^2 n/(\log\log n)^2)$, depending on these size parameters, where $n$ is
the size of Alice's outsourced memory. Our scheme, which we call BIOS ORAM,
combines multiple uses of B-trees with a reduction of ORAM simulation to
isogrammic access sequences.


An Efficient Dynamic and Distributed RSA Accumulator

  We show how to use the RSA one-way accumulator to realize an efficient and
dynamic authenticated dictionary, where untrusted directories provide
cryptographically verifiable answers to membership queries on a set maintained
by a trusted source. Our accumulator-based scheme for authenticated
dictionaries supports efficient incremental updates of the underlying set by
insertions and deletions of elements. Also, the user can optimally verify in
constant time the authenticity of the answer provided by a directory with a
simple and practical algorithm. We have also implemented this scheme and we
give empirical results that can be used to determine the best strategy for
systems implementation with respect to resources that are available. This work
has applications to certificate revocation in public key infrastructure and
end-to-end integrity of data collections published by third parties on the
Internet.


Data-Oblivious External-Memory Algorithms for the Compaction, Selection,
  and Sorting of Outsourced Data

  We present data-oblivious algorithms in the external-memory model for
compaction, selection, and sorting. Motivation for such problems comes from
clients who use outsourced data storage services and wish to mask their data
access patterns. We show that compaction and selection can be done
data-obliviously using $O(N/B)$ I/Os, and sorting can be done, with a high
probability of success, using $O((N/B)\log_{M/B} (N/B))$ I/Os. Our methods use
a number of new algorithmic techniques, including data-oblivious uses of
invertible Bloom lookup tables, a butterfly-like compression network,
randomized data thinning, and "shuffle-and-deal" data perturbation. In
addition, since data-oblivious sorting is the bottleneck in the "inner loop" in
existing oblivious RAM simulations, our sorting result improves the amortized
time overhead to do oblivious RAM simulation by a logarithmic factor in the
external-memory model.


Simulating Parallel Algorithms in the MapReduce Framework with
  Applications to Parallel Computational Geometry

  In this paper, we describe efficient MapReduce simulations of parallel
algorithms specified in the BSP and PRAM models. We also provide some
applications of these simulation results to problems in parallel computational
geometry for the MapReduce framework, which result in efficient MapReduce
algorithms for sorting, 1-dimensional all nearest-neighbors, 2-dimensional
convex hulls, 3-dimensional convex hulls, and fixed-dimensional linear
programming. For the case when reducers can have a buffer size of
$B=O(n^\epsilon)$, for a small constant $\epsilon>0$, all of our MapReduce
algorithms for these applications run in a constant number of rounds and have a
linear-sized message complexity, with high probability, while guaranteeing with
high probability that all reducer lists are of size $O(B)$.


Cloning Voronoi Diagrams via Retroactive Data Structures

  We address the problem of replicating a Voronoi diagram $V(S)$ of a planar
point set $S$ by making proximity queries, which are of three possible (in
decreasing order of information content): 1. the exact location of the nearest
site(s) in $S$; 2. the distance to and label(s) of the nearest site(s) in $S$;
3. a unique label for every nearest site in $S$. We provide algorithms showing
how queries of Type 1 and Type 2 allow an exact cloning of $V(S)$ with $O(n)$
queries and $O(n \log^2 n)$ processing time. We also prove that queries of Type
3 can never exactly clone $V(S)$, but we show that with $O(n
\log\frac{1}{\epsilon})$ queries we can construct an $\epsilon$-approximate
cloning of $V(S)$. In addition to showing the limits of nearest-neighbor
database security, our methods also provide one of the first natural
algorithmic applications of retroactive data structures.


Spin-the-bottle Sort and Annealing Sort: Oblivious Sorting via
  Round-robin Random Comparisons

  We study sorting algorithms based on randomized round-robin comparisons.
Specifically, we study Spin-the-bottle sort, where comparisons are
unrestricted, and Annealing sort, where comparisons are restricted to a
distance bounded by a \emph{temperature} parameter. Both algorithms are simple,
randomized, data-oblivious sorting algorithms, which are useful in
privacy-preserving computations, but, as we show, Annealing sort is much more
efficient. We show that there is an input permutation that causes
Spin-the-bottle sort to require $\Omega(n^2\log n)$ expected time in order to
succeed, and that in $O(n^2\log n)$ time this algorithm succeeds with high
probability for any input. We also show there is an implementation of Annealing
sort that runs in $O(n\log n)$ time and succeeds with very high probability.


Randomized Shellsort: A Simple Oblivious Sorting Algorithm

  In this paper, we describe randomized Shellsort--a simple, randomized,
data-oblivious version of the Shellsort algorithm that always runs in O(n log
n) time and, as we show, succeeds in sorting any given input permutation with
very high probability. Thus, randomized Shellsort is simultaneously simple,
time-optimal, and data-oblivious. Taken together, these properties imply
applications in the design of new efficient privacy-preserving computations
based on the secure multi-party computation (SMC) paradigm. In addition, by a
trivial conversion of this Monte Carlo algorithm to its Las Vegas equivalent,
one gets the first version of Shellsort with a running time that is provably
O(n log n) with very high probability.


Windows into Geometric Events: Data Structures for Time-Windowed
  Querying of Temporal Point Sets

  We study geometric data structures for sets of point-based temporal events,
answering time-windowed queries, i.e., given a contiguous time interval we
answer common geometric queries about the point events with time stamps in this
interval. The geometric queries we consider include queries based on the
skyline, convex hull, and proximity relations of the point set. We provide
space efficient data structures which answer queries in polylogarithmic time.


Privacy-Enhanced Reputation-Feedback Methods to Reduce Feedback
  Extortion in Online Auctions

  In this paper, we study methods for improving the utility and privacy of
reputation scores for online auctions, such as used in eBay, so as to reduce
the effectiveness of feedback extortion. The main ideas behind our techniques
are to use randomization and various schemes to escrow reputations scores until
appropriate external events occur. Depending on the degree of utility and
privacy needed, these external techniques could depend on the number and type
of reputation scores collected. Moreover, if additional privacy protection is
needed, then random sampling can be used with respect reputation scores in such
a way that reputation aggregates remain useful, but individual reputation
scores are probabilistically hidden from users. Finally, we show that if
privacy is also desired with respect to the the reputation aggregator, then we
can use zero-knowledge proofs for reputation comparisons.


Parallel Algorithms for Summing Floating-Point Numbers

  The problem of exactly summing n floating-point numbers is a fundamental
problem that has many applications in large-scale simulations and computational
geometry. Unfortunately, due to the round-off error in standard floating-point
operations, this problem becomes very challenging. Moreover, all existing
solutions rely on sequential algorithms which cannot scale to the huge datasets
that need to be processed.
  In this paper, we provide several efficient parallel algorithms for summing n
floating point numbers, so as to produce a faithfully rounded floating-point
representation of the sum. We present algorithms in PRAM, external-memory, and
MapReduce models, and we also provide an experimental analysis of our MapReduce
algorithms, due to their simplicity and practical efficiency.


Answering Spatial Multiple-Set Intersection Queries Using 2-3 Cuckoo
  Hash-Filters

  We show how to answer spatial multiple-set intersection queries in O(n(log
w)/w + kt) expected time, where n is the total size of the t sets involved in
the query, w is the number of bits in a memory word, k is the output size, and
c is any fixed constant. This improves the asymptotic performance over previous
solutions and is based on an interesting data structure, known as 2-3 cuckoo
hash-filters. Our results apply in the word-RAM model (or practical RAM model),
which allows for constant-time bit-parallel operations, such as bitwise AND,
OR, NOT, and MSB (most-significant 1-bit), as exist in modern CPUs and GPUs.
Our solutions apply to any multiple-set intersection queries in spatial data
sets that can be reduced to one-dimensional range queries, such as spatial join
queries for one-dimensional points or sets of points stored along space-filling
curves, which are used in GIS applications.


Wear Minimization for Cuckoo Hashing: How Not to Throw a Lot of Eggs
  into One Basket

  We study wear-leveling techniques for cuckoo hashing, showing that it is
possible to achieve a memory wear bound of $\log\log n+O(1)$ after the
insertion of $n$ items into a table of size $Cn$ for a suitable constant $C$
using cuckoo hashing. Moreover, we study our cuckoo hashing method empirically,
showing that it significantly improves on the memory wear performance for
classic cuckoo hashing and linear probing in practice.


Oblivious RAM Simulation with Efficient Worst-Case Access Overhead

  Oblivious RAM simulation is a method for achieving confidentiality and
privacy in cloud computing environments. It involves obscuring the access
patterns to a remote storage so that the manager of that storage cannot infer
information about its contents. Existing solutions typically involve small
amortized overheads for achieving this goal, but nevertheless involve
potentially huge variations in access times, depending on when they occur. In
this paper, we show how to de-amortize oblivious RAM simulations, so that each
access takes a worst-case bounded amount of time.


Guard Placement For Wireless Localization

  Motivated by secure wireless networking, we consider the problem of placing
fixed localizers that enable mobile communication devices to prove they belong
to a secure region that is defined by the interior of a polygon. Each localizer
views an infinite wedge of the plane, and a device can prove membership in the
secure region if it is inside the wedges for a set of localizers whose common
intersection contains no points outside the polygon. This model leads to a
broad class of new art gallery type problems, for which we provide upper and
lower bounds.


Set-Difference Range Queries

  We introduce the problem of performing set-difference range queries, where
answers to queries are set-theoretic symmetric differences between sets of
items in two geometric ranges. We describe a general framework for answering
such queries based on a novel use of data-streaming sketches we call signed
symmetric-difference sketches. We show that such sketches can be realized using
invertible Bloom filters (IBFs), which can be composed, differenced, and
searched so as to solve set-difference range queries in a wide range of
scenarios.


Scheduling Autonomous Vehicle Platoons Through an Unregulated
  Intersection

  We study various versions of the problem of scheduling platoons of autonomous
vehicles through an unregulated intersection, where an algorithm must schedule
which platoons should wait so that others can go through, so as to minimize the
maximum delay for any vehicle. We provide polynomial-time algorithms for
constructing such schedules for a $k$-way merge intersection, for constant $k$,
and for a crossing intersection involving two-way traffic. We also show that
the more general problem of scheduling autonomous platoons through an
intersection that includes both a $k$-way merge, for non-constant $k$, and a
crossing of two-way traffic is NP-complete.


Achieving Good Angular Resolution in 3D Arc Diagrams

  We study a three-dimensional analogue to the well-known graph visualization
approach known as arc diagrams. We provide several algorithms that achieve good
angular resolution for 3D arc diagrams, even for cases when the arcs must
project to a given 2D straight-line drawing of the input graph. Our methods
make use of various graph coloring algorithms, including an algorithm for a new
coloring problem, which we call localized edge coloring.


External-Memory Network Analysis Algorithms for Naturally Sparse Graphs

  In this paper, we present a number of network-analysis algorithms in the
external-memory model. We focus on methods for large naturally sparse graphs,
that is, n-vertex graphs that have O(n) edges and are structured so that this
sparsity property holds for any subgraph of such a graph. We give efficient
external-memory algorithms for the following problems for such graphs: -
Finding an approximate d-degeneracy ordering; - Finding a cycle of length
exactly c; - Enumerating all maximal cliques. Such problems are of interest,
for example, in the analysis of social networks, where they are used to study
network cohesion.


Parallel Equivalence Class Sorting: Algorithms, Lower Bounds, and
  Distribution-Based Analysis

  We study parallel comparison-based algorithms for finding all equivalence
classes of a set of $n$ elements, where sorting according to some total order
is not possible. Such scenarios arise, for example, in applications, such as in
distributed computer security, where each of $n$ agents are working to identify
the private group to which they belong, with the only operation available to
them being a zero-knowledge pairwise-comparison (which is sometimes called a
"secret handshake") that reveals only whether two agents are in the same group
or in different groups. We provide new parallel algorithms for this problem, as
well as new lower bounds and distribution-based analysis.


J-Viz: Sibling-First Recursive Graph Drawing for Visualizing Java
  Bytecode

  We describe a graph visualization tool for visualizing Java bytecode. Our
tool, which we call J-Viz, visualizes connected directed graphs according to a
canonical node ordering, which we call the sibling-first recursive (SFR)
numbering. The particular graphs we consider are derived from applying Shiver's
k-CFA framework to Java bytecode, and our visualizer includes helpful links
between the nodes of an input graph and the Java bytecode that produced it, as
well as a decompiled version of that Java bytecode. We show through several
case studies that the canonical drawing paradigm used in J-Viz is effective for
identifying potential security vulnerabilities and repeated use of the same
code in Java applications.


Improved Combinatorial Group Testing Algorithms for Real-World Problem
  Sizes

  We study practically efficient methods for performing combinatorial group
testing. We present efficient non-adaptive and two-stage combinatorial group
testing algorithms, which identify the at most d items out of a given set of n
items that are defective, using fewer tests for all practical set sizes. For
example, our two-stage algorithm matches the information theoretic lower bound
for the number of tests in a combinatorial group testing regimen.


Combinatorial Pair Testing: Distinguishing Workers from Slackers

  We formalize a problem we call combinatorial pair testing (CPT), which has
applications to the identification of uncooperative or unproductive
participants in pair programming, massively distributed computing, and
crowdsourcing environments. We give efficient adaptive and nonadaptive CPT
algorithms and we show that our methods use an optimal number of testing rounds
to within constant factors. We also provide an empirical evaluation of some of
our methods.


Privacy-Enhanced Methods for Comparing Compressed DNA Sequences

  In this paper, we study methods for improving the efficiency and privacy of
compressed DNA sequence comparison computations, under various querying
scenarios. For instance, one scenario involves a querier, Bob, who wants to
test if his DNA string, $Q$, is close to a DNA string, $Y$, owned by a data
owner, Alice, but Bob does not want to reveal $Q$ to Alice and Alice is willing
to reveal $Y$ to Bob \emph{only if} it is close to $Q$. We describe a
privacy-enhanced method for comparing two compressed DNA sequences, which can
be used to achieve the goals of such a scenario. Our method involves a
reduction to set differencing, and we describe a privacy-enhanced protocol for
set differencing that achieves absolute privacy for Bob (in the information
theoretic sense), and a quantifiable degree of privacy protection for Alice.
One of the important features of our protocols, which makes them ideally suited
to privacy-enhanced DNA sequence comparison problems, is that the communication
complexity of our solutions is proportional to a threshold that bounds the
cardinality of the set differences that are of interest, rather than the
cardinality of the sets involved (which correlates to the length of the DNA
sequences). Moreover, in our protocols, the querier, Bob, can easily compute
the set difference only if its cardinality is close to or below a specified
threshold.


Lombardi Drawings of Graphs

  We introduce the notion of Lombardi graph drawings, named after the American
abstract artist Mark Lombardi. In these drawings, edges are represented as
circular arcs rather than as line segments or polylines, and the vertices have
perfect angular resolution: the edges are equally spaced around each vertex. We
describe algorithms for finding Lombardi drawings of regular graphs, graphs of
bounded degeneracy, and certain families of planar graphs.


Learning Character Strings via Mastermind Queries, with a Case Study
  Involving mtDNA

  We study the degree to which a character string, $Q$, leaks details about
itself any time it engages in comparison protocols with a strings provided by a
querier, Bob, even if those protocols are cryptographically guaranteed to
produce no additional information other than the scores that assess the degree
to which $Q$ matches strings offered by Bob. We show that such scenarios allow
Bob to play variants of the game of Mastermind with $Q$ so as to learn the
complete identity of $Q$. We show that there are a number of efficient
implementations for Bob to employ in these Mastermind attacks, depending on
knowledge he has about the structure of $Q$, which show how quickly he can
determine $Q$. Indeed, we show that Bob can discover $Q$ using a number of
rounds of test comparisons that is much smaller than the length of $Q$, under
reasonable assumptions regarding the types of scores that are returned by the
cryptographic protocols and whether he can use knowledge about the distribution
that $Q$ comes from. We also provide the results of a case study we performed
on a database of mitochondrial DNA, showing the vulnerability of existing
real-world DNA data to the Mastermind attack.


On the Approximability of Geometric and Geographic Generalization and
  the Min-Max Bin Covering Problem

  We study the problem of abstracting a table of data about individuals so that
no selection query can identify fewer than k individuals. We show that it is
impossible to achieve arbitrarily good polynomial-time approximations for a
number of natural variations of the generalization technique, unless P = NP,
even when the table has only a single quasi-identifying attribute that
represents a geographic or unordered attribute:
  Zip-codes: nodes of a planar graph generalized into connected subgraphs
  GPS coordinates: points in R2 generalized into non-overlapping rectangles
  Unordered data: text labels that can be grouped arbitrarily. In addition to
impossibility results, we provide approximation algorithms for these difficult
single-attribute generalization problems, which, of course, apply to
multiple-attribute instances with one that is quasi-identifying. We show
theoretically and experimentally that our approximation algorithms can come
reasonably close to optimal solutions. Incidentally, the generalization problem
for unordered data can be viewed as a novel type of bin packing
problem--min-max bin covering--which may be of independent interest.


Improved Adaptive Group Testing Algorithms with Applications to Multiple
  Access Channels and Dead Sensor Diagnosis

  We study group-testing algorithms for resolving broadcast conflicts on a
multiple access channel (MAC) and for identifying the dead sensors in a mobile
ad hoc wireless network. In group-testing algorithms, we are asked to identify
all the defective items in a set of items when we can test arbitrary subsets of
items. In the standard group-testing problem, the result of a test is
binary--the tested subset either contains defective items or not. In the more
generalized versions we study in this paper, the result of each test is
non-binary. For example, it may indicate whether the number of defective items
contained in the tested subset is zero, one, or at least two. We give adaptive
algorithms that are provably more efficient than previous group testing
algorithms. We also show how our algorithms can be applied to solve conflict
resolution on a MAC and dead sensor diagnosis. Dead sensor diagnosis poses an
interesting challenge compared to MAC resolution, because dead sensors are not
locally detectable, nor are they themselves active participants.


Zig-zag Sort: A Simple Deterministic Data-Oblivious Sorting Algorithm
  Running in O(n log n) Time

  We describe and analyze Zig-zag Sort--a deterministic data-oblivious sorting
algorithm running in O(n log n) time that is arguably simpler than previously
known algorithms with similar properties, which are based on the AKS sorting
network. Because it is data-oblivious and deterministic, Zig-zag Sort can be
implemented as a simple O(n log n)-size sorting network, thereby providing a
solution to an open problem posed by Incerpi and Sedgewick in 1985. In
addition, Zig-zag Sort is a variant of Shellsort, and is, in fact, the first
deterministic Shellsort variant running in O(n log n) time. The existence of
such an algorithm was posed as an open problem by Plaxton et al. in 1992 and
also by Sedgewick in 1996. More relevant for today, however, is the fact that
the existence of a simple data-oblivious deterministic sorting algorithm
running in O(n log n) time simplifies the inner-loop computation in several
proposed oblivious-RAM simulation methods (which utilize AKS sorting networks),
and this, in turn, implies simplified mechanisms for privacy-preserving data
outsourcing in several cloud computing applications. We provide both
constructive and non-constructive implementations of Zig-zag Sort, based on the
existence of a circuit known as an epsilon-halver, such that the constant
factors in our constructive implementations are orders of magnitude smaller
than those for constructive variants of the AKS sorting network, which are also
based on the use of epsilon-halvers.


Pipelined Algorithms to Detect Cheating in Long-Term Grid Computations

  This paper studies pipelined algorithms for protecting distributed grid
computations from cheating participants, who wish to be rewarded for tasks they
receive but don't perform. We present improved cheater detection algorithms
that utilize natural delays that exist in long-term grid computations. In
particular, we partition the sequence of grid tasks into two interleaved
sequences of task rounds, and we show how to use those rounds to devise the
first general-purpose scheme that can catch all cheaters, even when cheaters
collude. The main idea of this algorithm might at first seem
counter-intuitive--we have the participants check each other's work. A naive
implementation of this approach would, of course, be susceptible to collusion
attacks, but we show that by, adapting efficient solutions to the parallel
processor diagnosis problem, we can tolerate collusions of lazy cheaters, even
if the number of such cheaters is a fraction of the total number of
participants. We also include a simple economic analysis of cheaters in grid
computations and a parameterization of the main deterrent that can be used
against them--the probability of being caught.


Force-Directed Graph Drawing Using Social Gravity and Scaling

  Force-directed layout algorithms produce graph drawings by resolving a system
of emulated physical forces. We present techniques for using social gravity as
an additional force in force-directed layouts, together with a scaling
technique, to produce drawings of trees and forests, as well as more complex
social networks. Social gravity assigns mass to vertices in proportion to their
network centrality, which allows vertices that are more graph-theoretically
central to be visualized in physically central locations. Scaling varies the
gravitational force throughout the simulation, and reduces crossings relative
to unscaled gravity. In addition to providing this algorithmic framework, we
apply our algorithms to social networks produced by Mark Lombardi, and we show
how social gravity can be incorporated into force-directed Lombardi-style
drawings.


Privacy-Preserving Group Data Access via Stateless Oblivious RAM
  Simulation

  We study the problem of providing privacy-preserving access to an outsourced
honest-but-curious data repository for a group of trusted users. We show that
such privacy-preserving data access is possible using a combination of
probabilistic encryption, which directly hides data values, and stateless
oblivious RAM simulation, which hides the pattern of data accesses. We give
simulations that have only an $O(\log n)$ amortized time overhead for
simulating a RAM algorithm, $\cal A$, that has a memory of size $n$, using a
scheme that is data-oblivious with very high probability assuming the
simulation has access to a private workspace of size $O(n^\nu)$, for any given
fixed constant $\nu>0$. This simulation makes use of pseudorandom hash
functions and is based on a novel hierarchy of cuckoo hash tables that all
share a common stash. We also provide results from an experimental simulation
of this scheme, showing its practicality. In addition, in a result that may be
of some theoretical interest, we also show that one can eliminate the
dependence on pseudorandom hash functions in our simulation while having the
overhead rise to be $O(\log^2 n)$.


External-Memory Multimaps

  Many data structures support dictionaries, also known as maps or associative
arrays, which store and manage a set of key-value pairs. A \emph{multimap} is
generalization that allows multiple values to be associated with the same key.
For example, the inverted file data structure that is used prevalently in the
infrastructure supporting search engines is a type of multimap, where words are
used as keys and document pointers are used as values. We study the multimap
abstract data type and how it can be implemented efficiently online in external
memory frameworks, with constant expected I/O performance. The key technique
used to achieve our results is a combination of cuckoo hashing using buckets
that hold multiple items with a multiqueue implementation to cope with varying
numbers of values per key. Our external-memory results are for the standard
two-level memory model.


Oblivious Storage with Low I/O Overhead

  We study oblivious storage (OS), a natural way to model privacy-preserving
data outsourcing where a client, Alice, stores sensitive data at an
honest-but-curious server, Bob. We show that Alice can hide both the content of
her data and the pattern in which she accesses her data, with high probability,
using a method that achieves O(1) amortized rounds of communication between her
and Bob for each data access. We assume that Alice and Bob exchange small
messages, of size $O(N^{1/c})$, for some constant $c\ge2$, in a single round,
where $N$ is the size of the data set that Alice is storing with Bob. We also
assume that Alice has a private memory of size $2N^{1/c}$. These assumptions
model real-world cloud storage scenarios, where trade-offs occur between
latency, bandwidth, and the size of the client's private memory.


Choosing Colors for Geometric Graphs via Color Space Embeddings

  Graph drawing research traditionally focuses on producing geometric
embeddings of graphs satisfying various aesthetic constraints. After the
geometric embedding is specified, there is an additional step that is often
overlooked or ignored: assigning display colors to the graph's vertices. We
study the additional aesthetic criterion of assigning distinct colors to
vertices of a geometric graph so that the colors assigned to adjacent vertices
are as different from one another as possible. We formulate this as a problem
involving perceptual metrics in color space and we develop algorithms for
solving this problem by embedding the graph in color space. We also present an
application of this work to a distributed load-balancing visualization problem.


Capturing Lombardi Flow in Orthogonal Drawings by Minimizing the Number
  of Segments

  Inspired by the artwork of Mark Lombardi, we study the problem of
constructing orthogonal drawings where a small number of horizontal and
vertical line segments covers all vertices. We study two problems on orthogonal
drawings of planar graphs, one that minimizes the total number of line segments
and another that minimizes the number of line segments that cover all the
vertices. We show that the first problem can be solved by a non-trivial
modification of the flow-network orthogonal bend-minimization algorithm of
Tamassia, resulting in a polynomial-time algorithm. We show that the second
problem is NP-hard even for planar graphs with maximum degree 3. Given this
result, we then address this second optimization problem for trees and
series-parallel graphs with maximum degree 3. For both graph classes, we give
polynomial-time algorithms for upward orthogonal drawings with the minimum
number of segments covering the vertices.


Models and Algorithms for Graph Watermarking

  We introduce models and algorithmic foundations for graph watermarking. Our
frameworks include security definitions and proofs, as well as
characterizations when graph watermarking is algorithmically feasible, in spite
of the fact that the general problem is NP-complete by simple reductions from
the subgraph isomorphism or graph edit distance problems. In the digital
watermarking of many types of files, an implicit step in the recovery of a
watermark is the mapping of individual pieces of data, such as image pixels or
movie frames, from one object to another. In graphs, this step corresponds to
approximately matching vertices of one graph to another based on graph
invariants such as vertex degree. Our approach is based on characterizing the
feasibility of graph watermarking in terms of keygen, marking, and
identification functions defined over graph families with known distributions.
We demonstrate the strength of this approach with exemplary watermarking
schemes for two random graph models, the classic Erd\H{o}s-R\'{e}nyi model and
a random power-law graph model, both of which are used to model real-world
networks.


Planar Drawings of Higher-Genus Graphs

  In this paper, we give polynomial-time algorithms that can take a graph G
with a given combinatorial embedding on an orientable surface S of genus g and
produce a planar drawing of G in R^2, with a bounding face defined by a
polygonal schema P for S. Our drawings are planar, but they allow for multiple
copies of vertices and edges on P's boundary, which is a common way of
visualizing higher-genus graphs in the plane. Our drawings can be defined with
respect to either a canonical polygonal schema or a polygonal cutset schema,
which provides an interesting tradeoff, since canonical schemas have fewer
sides, and have a nice topological structure, but they can have many more
repeated vertices and edges than general polygonal cutsets. As a side note, we
show that it is NP-complete to determine whether a given graph embedded in a
genus-g surface has a set of 2g fundamental cycles with vertex-disjoint
interiors, which would be desirable from a graph-drawing perspective.


