Combining Answer Set Programming and POMDPs for Knowledge Representation
  and Reasoning on Mobile Robots

  For widespread deployment in domains characterized by partial observability,
non-deterministic actions and unforeseen changes, robots need to adapt sensing,
processing and interaction with humans to the tasks at hand. While robots
typically cannot process all sensor inputs or operate without substantial
domain knowledge, it is a challenge to provide accurate domain knowledge and
humans may not have the time and expertise to provide elaborate and accurate
feedback. The architecture described in this paper combines declarative
programming and probabilistic reasoning to address these challenges, enabling
robots to: (a) represent and reason with incomplete domain knowledge, resolving
ambiguities and revising existing knowledge using sensor inputs and minimal
human feedback; and (b) probabilistically model the uncertainty in sensor input
processing and navigation. Specifically, Answer Set Programming (ASP), a
declarative programming paradigm, is combined with hierarchical partially
observable Markov decision processes (POMDPs), using domain knowledge to revise
probabilistic beliefs, and using positive and negative observations for early
termination of tasks that can no longer be pursued. All algorithms are
evaluated in simulation and on mobile robots locating target objects in indoor
domains.


KR$^3$: An Architecture for Knowledge Representation and Reasoning in
  Robotics

  This paper describes an architecture that combines the complementary
strengths of declarative programming and probabilistic graphical models to
enable robots to represent, reason with, and learn from, qualitative and
quantitative descriptions of uncertainty and knowledge. An action language is
used for the low-level (LL) and high-level (HL) system descriptions in the
architecture, and the definition of recorded histories in the HL is expanded to
allow prioritized defaults. For any given goal, tentative plans created in the
HL using default knowledge and commonsense reasoning are implemented in the LL
using probabilistic algorithms, with the corresponding observations used to
update the HL history. Tight coupling between the two levels enables automatic
selection of relevant variables and generation of suitable action policies in
the LL for each HL action, and supports reasoning with violation of defaults,
noisy observations and unreliable actions in large and complex domains. The
architecture is evaluated in simulation and on physical robots transporting
objects in indoor domains; the benefit on robots is a reduction in task
execution time of 39% compared with a purely probabilistic, but still
hierarchical, approach.


Evidence for mixed phases and percolation at the metal-insulator
  transition in two dimensions

  The in-plane magnetoconductance of the strongly interacting two-dimensional
electron system in a silicon MOSFET (metal-oxide-semiconductor-field-effect
transistor) exhibits an unmistakeable kink at a well-defined electron density,
$n_k$. The kink at $n_k$ is near, but not at the critical density $n_c$
determined from resistivity measurements, and the density at which $n_k$ occurs
varies with temperature. These features are inconsistent with expectations for
a quantum phase transition. We suggest instead that this is a percolation
transition and present a detailed model based on the formation of a mixed
insulating and metallic phase within which a metal-insulator transition takes
place by percolation.


THUMT: An Open Source Toolkit for Neural Machine Translation

  This paper introduces THUMT, an open-source toolkit for neural machine
translation (NMT) developed by the Natural Language Processing Group at
Tsinghua University. THUMT implements the standard attention-based
encoder-decoder framework on top of Theano and supports three training
criteria: maximum likelihood estimation, minimum risk training, and
semi-supervised training. It features a visualization tool for displaying the
relevance between hidden states in neural networks and contextual words, which
helps to analyze the internal workings of NMT. Experiments on Chinese-English
datasets show that THUMT using minimum risk training significantly outperforms
GroundHog, a state-of-the-art toolkit for NMT.


Task Planning in Robotics: an Empirical Comparison of PDDL-based and
  ASP-based Systems

  Robots need task planning algorithms to sequence actions toward accomplishing
goals that are impossible through individual actions. Off-the-shelf task
planners can be used by intelligent robotics practitioners to solve a variety
of planning problems. However, many different planners exist, each with
different strengths and weaknesses, and there are no general rules for which
planner would be best to apply to a given problem.
  In this article, we empirically compare the performance of state-of-the-art
planners that use either the Planning Domain Description Language (PDDL), or
Answer Set Programming (ASP) as the underlying action language. PDDL is
designed for task planning, and PDDL-based planners are widely used for a
variety of planning problems. ASP is designed for knowledge-intensive
reasoning, but can also be used for solving task planning problems. Given
domain encodings that are as similar as possible, we find that PDDL-based
planners perform better on problems with longer solutions, and ASP-based
planners are better on tasks with a large number of objects or in which complex
reasoning is required to reason about action preconditions and effects. The
resulting analysis can inform selection among general purpose planning systems
for particular robot task planning domains.


Invisible Steganography via Generative Adversarial Networks

  Nowadays, there are plenty of works introducing convolutional neural networks
(CNNs) to the steganalysis and exceeding conventional steganalysis algorithms.
These works have shown the improving potential of deep learning in information
hiding domain. There are also several works based on deep learning to do image
steganography, but these works still have problems in capacity, invisibility
and security. In this paper, we propose a novel CNN architecture named as
\isgan to conceal a secret gray image into a color cover image on the sender
side and exactly extract the secret image out on the receiver side. There are
three contributions in our work: (i) we improve the invisibility by hiding the
secret image only in the Y channel of the cover image; (ii) We introduce the
generative adversarial networks to strengthen the security by minimizing the
divergence between the empirical probability distributions of stego images and
natural images. (iii) In order to associate with the human visual system
better, we construct a mixed loss function which is more appropriate for
steganography to generate more realistic stego images and reveal out more
better secret images. Experiment results show that ISGAN can achieve
start-of-art performances on LFW, Pascal VOC2012 and ImageNet datasets.


Spatial-Temporal Residue Network Based In-Loop Filter for Video Coding

  Deep learning has demonstrated tremendous break through in the area of
image/video processing. In this paper, a spatial-temporal residue network
(STResNet) based in-loop filter is proposed to suppress visual artifacts such
as blocking, ringing in video coding. Specifically, the spatial and temporal
information is jointly exploited by taking both current block and co-located
block in reference frame into consideration during the processing of in-loop
filter. The architecture of STResNet only consists of four convolution layers
which shows hospitality to memory and coding complexity. Moreover, to fully
adapt the input content and improve the performance of the proposed in-loop
filter, coding tree unit (CTU) level control flag is applied in the sense of
rate-distortion optimization. Extensive experimental results show that our
scheme provides up to 5.1% bit-rate reduction compared to the state-of-the-art
video coding standard.


Goal-oriented Dialogue Policy Learning from Failures

  Reinforcement learning methods have been used for learning dialogue policies.
However, learning an effective dialogue policy frequently requires
prohibitively many conversations. This is partly because of the sparse rewards
in dialogues, and the very few successful dialogues in early learning phase.
Hindsight experience replay (HER) enables learning from failures, but the
vanilla HER is inapplicable to dialogue learning due to the implicit goals. In
this work, we develop two complex HER methods providing different trade-offs
between complexity and performance, and, for the first time, enabled HER-based
dialogue policy learning. Experiments using a realistic user simulator show
that our HER methods perform better than existing experience replay methods (as
applied to deep Q-networks) in learning rate.


Robot Representation and Reasoning with Knowledge from Reinforcement
  Learning

  Reinforcement learning (RL) agents aim at learning by interacting with an
environment, and are not designed for representing or reasoning with
declarative knowledge. Knowledge representation and reasoning (KRR) paradigms
are strong in declarative KRR tasks, but are ill-equipped to learn from such
experiences. In this work, we integrate logical-probabilistic KRR with
model-based RL, enabling agents to simultaneously reason with declarative
knowledge and learn from interaction experiences. The knowledge from humans and
RL is unified and used for dynamically computing task-specific planning models
under potentially new environments. Experiments were conducted using a mobile
robot working on dialog, navigation, and delivery tasks. Results show
significant improvements, in comparison to existing model-based RL methods.


Robot Sequential Decision Making using LSTM-based Learning and
  Logical-probabilistic Reasoning

  Sequential decision-making (SDM) plays a key role in intelligent robotics,
and can be realized in very different ways, such as supervised learning,
automated reasoning, and probabilistic planning. The three families of methods
follow different assumptions and have different (dis)advantages. In this work,
we aim at a robot SDM framework that exploits the complementary features of
learning, reasoning, and planning. We utilize long short-term memory (LSTM),
for passive state estimation with streaming sensor data, and commonsense
reasoning and probabilistic planning (CORPP) for active information collection
and task accomplishment. In experiments, a mobile robot is tasked with
estimating human intentions using their motion trajectories, declarative
contextual knowledge, and human-robot interaction (dialog-based and
motion-based). Results suggest that our framework performs better than its
no-learning and no-reasoning versions in a real-world office environment.


Scalable Facial Image Compression with Deep Feature Reconstruction

  In this paper, we propose a scalable image compression scheme, including the
base layer for feature representation and enhancement layer for texture
representation. More specifically, the base layer is designed as the deep
learning feature for analysis purpose, and it can also be converted to the fine
structure with deep feature reconstruction. The enhancement layer, which serves
to compress the residuals between the input image and the signals generated
from the base layer, aims to faithfully reconstruct the input texture. The
proposed scheme can feasibly inherit the advantages of both
compress-then-analyze and analyze-then-compress schemes in surveillance
applications. The performance of this framework is validated with facial
images, and the conducted experiments provide useful evidences to show that the
proposed framework can achieve better rate-accuracy and rate-distortion
performance over conventional image compression schemes.


Globally Variance-Constrained Sparse Representation and Its Application
  in Image Set Coding

  Sparse representation leads to an efficient way to approximately recover a
signal by the linear composition of a few bases from a learnt dictionary, based
on which various successful applications have been achieved. However, in the
scenario of data compression, its efficiency and popularity are hindered. It is
because of the fact that encoding sparsely distributed coefficients may consume
more bits for representing the index of nonzero coefficients. Therefore,
introducing an accurate rate-constraint in sparse coding and dictionary
learning becomes meaningful, which has not been fully exploited in the context
of sparse representation. According to the Shannon entropy inequality, the
variance of a Gaussian distributed data bounds its entropy, indicating the
actual bitrate can be well estimated by its variance. Hence, a Globally
Variance-Constrained Sparse Representation (GVCSR) model is proposed in this
work, where a variance-constrained rate term is introduced to the optimization
process. Specifically, we employ the Alternating Direction Method of
Multipliers (ADMM) to solve the non-convex optimization problem for sparse
coding and dictionary learning, both of them have shown the state-of-the-art
rate-distortion performance for image representation. Furthermore, we
investigate the potential of applying the GVCSR algorithm in the practical
image set compression, where the optimized dictionary is trained to efficiently
represent the images captured in similar scenarios by implicitly utilizing
inter-image correlations. Experimental results have demonstrated superior
rate-distortion performance against the state-of-the-art methods.


Fast MPEG-CDVS Encoder with GPU-CPU Hybrid Computing

  The compact descriptors for visual search (CDVS) standard from ISO/IEC moving
pictures experts group (MPEG) has succeeded in enabling the interoperability
for efficient and effective image retrieval by standardizing the bitstream
syntax of compact feature descriptors. However, the intensive computation of
CDVS encoder unfortunately hinders its widely deployment in industry for
large-scale visual search. In this paper, we revisit the merits of low
complexity design of CDVS core techniques and present a very fast CDVS encoder
by leveraging the massive parallel execution resources of GPU. We elegantly
shift the computation-intensive and parallel-friendly modules to the
state-of-the-arts GPU platforms, in which the thread block allocation and the
memory access are jointly optimized to eliminate performance loss. In addition,
those operations with heavy data dependence are allocated to CPU to resolve the
extra but non-necessary computation burden for GPU. Furthermore, we have
demonstrated the proposed fast CDVS encoder can work well with those
convolution neural network approaches which has harmoniously leveraged the
advantages of GPU platforms, and yielded significant performance improvements.
Comprehensive experimental results over benchmarks are evaluated, which has
shown that the fast CDVS encoder using GPU-CPU hybrid computing is promising
for scalable visual search.


REBA: A Refinement-Based Architecture for Knowledge Representation and
  Reasoning in Robotics

  This paper describes an architecture for robots that combines the
complementary strengths of probabilistic graphical models and declarative
programming to represent and reason with logic-based and probabilistic
descriptions of uncertainty and domain knowledge. An action language is
extended to support non-boolean fluents and non-deterministic causal laws. This
action language is used to describe tightly-coupled transition diagrams at two
levels of granularity, with a fine-resolution transition diagram defined as a
refinement of a coarse-resolution transition diagram of the domain. The
coarse-resolution system description, and a history that includes (prioritized)
defaults, are translated into an Answer Set Prolog (ASP) program. For any given
goal, inference in the ASP program provides a plan of abstract actions. To
implement each such abstract action, the robot automatically zooms to the part
of the fine-resolution transition diagram relevant to this action. A
probabilistic representation of the uncertainty in sensing and actuation is
then included in this zoomed fine-resolution system description, and used to
construct a partially observable Markov decision process (POMDP). The policy
obtained by solving the POMDP is invoked repeatedly to implement the abstract
action as a sequence of concrete actions, with the corresponding observations
being recorded in the coarse-resolution history and used for subsequent
reasoning. The architecture is evaluated in simulation and on a mobile robot
moving objects in an indoor domain, to show that it supports reasoning with
violation of defaults, noisy observations and unreliable actions, in complex
domains.


Integrating Task-Motion Planning with Reinforcement Learning for Robust
  Decision Making in Mobile Robots

  Task-motion planning (TMP) addresses the problem of efficiently generating
executable and low-cost task plans in a discrete space such that the (initially
unknown) action costs are determined by motion plans in a corresponding
continuous space. However, a task-motion plan can be sensitive to unexpected
domain uncertainty and changes, leading to suboptimal behaviors or execution
failures. In this paper, we propose a novel framework, TMP-RL, which is an
integration of TMP and reinforcement learning (RL) from the execution
experience, to solve the problem of robust task-motion planning in dynamic and
uncertain domains. TMP-RL features two nested planning-learning loops. In the
inner TMP loop, the robot generates a low-cost, feasible task-motion plan by
iteratively planning in the discrete space and updating relevant action costs
evaluated by the motion planner in continuous space. In the outer loop, the
plan is executed, and the robot learns from the execution experience via
model-free RL, to further improve its task-motion plans. RL in the outer loop
is more accurate to the current domain but also more expensive, and using less
costly task and motion planning leads to a jump-start for learning in the real
world. Our approach is evaluated on a mobile service robot conducting
navigation tasks in an office area. Results show that TMP-RL approach
significantly improves adaptability and robustness (in comparison to TMP
methods) and leads to rapid convergence (in comparison to task planning (TP)-RL
methods). We also show that TMP-RL can reuse learned values to smoothly adapt
to new scenarios during long-term deployments.


Image and Video Compression with Neural Networks: A Review

  In recent years, the image and video coding technologies have advanced by
leaps and bounds. However, due to the popularization of image and video
acquisition devices, the growth rate of image and video data is far beyond the
improvement of the compression ratio. In particular, it has been widely
recognized that there are increasing challenges of pursuing further coding
performance improvement within the traditional hybrid coding framework. Deep
convolution neural network (CNN) which makes the neural network resurge in
recent years and has achieved great success in both artificial intelligent and
signal processing fields, also provides a novel and promising solution for
image and video compression. In this paper, we provide a systematic,
comprehensive and up-to-date review of neural network based image and video
compression techniques. The evolution and development of neural network based
compression methodologies are introduced for images and video respectively.
More specifically, the cutting-edge video coding techniques by leveraging deep
learning and HEVC framework are presented and discussed, which promote the
state-of-the-art video coding performance substantially. Moreover, the
end-to-end image and video coding frameworks based on neural networks are also
reviewed, revealing interesting explorations on next generation image and video
coding frameworks/standards. The most significant research works on the image
and video coding related topics using neural networks are highlighted, and
future trends are also envisioned. In particular, the joint compression on
semantic and visual information is tentatively explored to formulate high
efficiency signal representation structure for both human vision and machine
vision, which are the two dominant signal receptor in the age of artificial
intelligence.


