Decentralized Knowledge and Learning in Strategic Multi-user  Communication

  Please see the content of this report.

Business Mode Selection in Digital Content Markets

  NA

User Subscription, Revenue Maximization, and Competition in  Communications Markets

  An updated version of this paper (but with a different title) can be found atarXiv:1204.4262

Distributed Power Allocation in Multi-User Multi-Channel Relay Networks

  This paper has been withdrawn by the authors as they feel it inappropriate topublish this paper for the time being.

A Simple Characterization of Strategic Behaviors in Broadcast Channels

  In this paper, we consider the problem of resource allocation among twocompeting users sharing a binary symmetric broadcast channel. We model theinteraction between autonomous selfish users in the resource allocation andanalyze their strategic behavior in manipulating the allocation outcome. Weanalytically show that users will improve their performance (i.e. gain higherallocated rates) if they have more information about the strategy of thecompeting user.

Designing Incentive Schemes Based on Intervention: The Case of Perfect  Monitoring

  This paper studies a class of incentive schemes based on intervention, wherethere exists an intervention device that is able to monitor the actions ofusers and to take an action that affects the payoffs of users. We consider thecase of perfect monitoring, where the intervention device can immediatelyobserve the actions of users without errors. We also assume that there existactions of the intervention device that are most and least preferred by all theusers and the intervention device, regardless of the actions of users. Wederive analytical results about the outcomes achievable with intervention, andillustrate our results with an example based on the Cournot model.

Designing Rating Systems to Promote Mutual Security for Interconnected  Networks

  Interconnected autonomous systems often share security risks. However, anautonomous system lacks the incentive to make (sufficient) security investmentsif the cost exceeds its own benefit even though doing that would be sociallybeneficial. In this paper, we develop a systematic and rigorous framework foranalyzing and significantly improving the mutual security of a collection ofASs that interact frequently over a long period of time. Using this framework,we show that simple incentive schemes based on rating systems can be designedto encourage the autonomous systems' security investments, therebysignificantly improving their mutual security.

A Theory of Individualism, Collectivism and Economic Outcomes

  This paper presents a dynamic model to study the impact on the economicoutcomes in different societies during the Malthusian Era of individualism(time spent working alone) and collectivism (complementary time spent workingwith others). The model is driven by opposing forces: a greater degree ofcollectivism provides a higher safety net for low quality workers but a greaterdegree of individualism allows high quality workers to leave larger bequests.The model suggests that more individualistic societies display smallerpopulations, greater per capita income and greater income inequality. Some(limited) historical evidence is consistent with these predictions.

Forecasting Disease Trajectories in Alzheimer's Disease Using Deep  Learning

  Joint models for longitudinal and time-to-event data are commonly used inlongitudinal studies to forecast disease trajectories over time. Despite themany advantages of joint modeling, the standard forms suffer from limitationsthat arise from a fixed model specification and computational difficulties whenapplied to large datasets. We adopt a deep learning approach to address theselimitations, enhancing existing methods with the flexibility and scalability ofdeep neural networks while retaining the benefits of joint modeling. Using datafrom the Alzheimer's Disease Neuroimaging Institute, we show improvements inperformance and scalability compared to traditional methods.

Stackelberg Contention Games in Multiuser Networks

  Interactions among selfish users sharing a common transmission channel can bemodeled as a non-cooperative game using the game theory framework. When selfishusers choose their transmission probabilities independently without anycoordination mechanism, Nash equilibria usually result in a network collapse.We propose a methodology that transforms the non-cooperative game into aStackelberg game. Stackelberg equilibria of the Stackelberg game can overcomethe deficiency of the Nash equilibria of the original game. A particular typeof Stackelberg intervention is constructed to show that any positive payoffprofile feasible with independent transmission probabilities can be achieved asa Stackelberg equilibrium payoff profile. We discuss criteria to select anoperating point of the network and informational requirements for theStackelberg game. We relax the requirements and examine the effects ofrelaxation on performance.

Mission-Aware Medium Access Control in Random Access Networks

  We study mission-critical networking in wireless communication networks,where network users are subject to critical events such as emergencies andcrises. If a critical event occurs to a user, the user needs to send necessaryinformation for help as early as possible. However, most existing medium accesscontrol (MAC) protocols are not adequate to meet the urgent need forinformation transmission by users in a critical situation. In this paer, wepropose a novel class of MAC protocols that utilize available past informationas well as current information. Our proposed protocols are mission-aware sincethey prescribe different transmission decision rules to users in differentsituations. We show that the proposed protocols perform well not only when thesystem faces a critical situation but also when there is no critical situation.By utilizing past information, the proposed protocols coordinate transmissionsby users to achieve high throughput in the normal phase of operation and to leta user in a critical situation make successful transmissions while it is in thecritical situation. Moreover, the proposed protocols require short memory andno message exchanges.

Medium Access Control Protocols With Memory

  Many existing medium access control (MAC) protocols utilize past information(e.g., the results of transmission attempts) to adjust the transmissionparameters of users. This paper provides a general framework to express andevaluate distributed MAC protocols utilizing a finite length of memory for agiven form of feedback information. We define protocols with memory in thecontext of a slotted random access network with saturated arrivals. Weintroduce two performance metrics, throughput and average delay, and formulatethe problem of finding an optimal protocol. We first show that a TDMA outcome,which is the best outcome in the considered scenario, can be obtained after atransient period by a protocol with (N-1)-slot memory, where N is the totalnumber of users. Next, we analyze the performance of protocols with 1-slotmemory using a Markov chain and numerical methods. Protocols with 1-slot memorycan achieve throughput arbitrarily close to 1 (i.e., 100% channel utilization)at the expense of large average delay, by correlating successful users in twoconsecutive slots. Finally, we apply our framework to wireless local areanetworks.

Linearly Coupled Communication Games

  This paper discusses a special type of multi-user communication scenario, inwhich users' utilities are linearly impacted by their competitors' actions.First, we explicitly characterize the Nash equilibrium and Pareto boundary ofthe achievable utility region. Second, the price of anarchy incurred by thenon-collaborative Nash strategy is quantified. Third, to improve theperformance in the non-cooperative scenarios, we investigate the properties ofan alternative solution concept named conjectural equilibrium, in whichindividual users compensate for their lack of information by forming internalbeliefs about their competitors. The global convergence of the best responseand Jacobi update dynamics that achieve various conjectural equilibria areanalyzed. It is shown that the Pareto boundaries of the investigated linearlycoupled games can be sustained as stable conjectural equilibria if the belieffunctions are properly initialized. The investigated models apply to a varietyof realistic applications encountered in the multiple access design, includingwireless random access and flow control.

Cognitive MAC Protocols Using Memory for Distributed Spectrum Sharing  Under Limited Spectrum Sensing

  The main challenges of cognitive radio include spectrum sensing at thephysical (PHY) layer to detect the activity of primary users and spectrumsharing at the medium access control (MAC) layer to coordinate access amongcoexisting secondary users. In this paper, we consider a cognitive radionetwork in which a primary user shares a channel with secondary users thatcannot distinguish the signals of the primary user from those of a secondaryuser. We propose a class of distributed cognitive MAC protocols to achieveefficient spectrum sharing among the secondary users while protecting theprimary user from potential interference by the secondary users. By using a MACprotocol with one-slot memory, we can obtain high channel utilization by thesecondary users while limiting interference to the primary user at a low level.The results of this paper suggest the possibility of utilizing MAC design incognitive radio networks to overcome limitations in spectrum sensing at the PHYlayer as well as to achieve spectrum sharing at the MAC layer.

Structure-Aware Stochastic Control for Transmission Scheduling

  In this paper, we consider the problem of real-time transmission schedulingover time-varying channels. We first formulate the transmission schedulingproblem as a Markov decision process (MDP) and systematically unravel thestructural properties (e.g. concavity in the state-value function andmonotonicity in the optimal scheduling policy) exhibited by the optimalsolutions. We then propose an online learning algorithm which preserves thesestructural properties and achieves -optimal solutions for an arbitrarily small. The advantages of the proposed online method are that: (i) it does notrequire a priori knowledge of the traffic arrival and channel statistics and(ii) it adaptively approximates the state-value functions using piece-wiselinear functions and has low storage and computation complexity. We also extendthe proposed low-complexity online learning solution to the prioritized datatransmission. The simulation results demonstrate that the proposed methodachieves significantly better utility (or delay)-energy trade-offs whencomparing to existing state-of-art online optimization methods.

Adaptive MAC Protocols Using Memory for Networks with Critical Traffic

  We consider wireless communication networks where network users are subjectto critical events such as emergencies and crises. If a critical event occursto a user, the user needs to send critical traffic as early as possible.However, most existing medium access control (MAC) protocols are not adequateto meet the urgent need for data transmission by users with critical traffic.In this paper, we devise a class of distributed MAC protocols that achievecoordination using the finite-length memory of users containing their ownobservations and traffic types. We formulate a protocol design problem and findoptimal protocols that solve the problem. We show that the proposed protocolsenable a user with critical traffic to transmit its critical traffic withoutinterruption from other users after a short delay while allowing users to sharethe channel efficiently when there is no critical traffic. Moreover, theproposed protocols require short memory and can be implemented without explicitmessage passing.

Structural Solutions For Additively Coupled Sum Constrained Games

  We propose and analyze a broad family of games played by resource-constrainedplayers, which are characterized by the following central features: 1) eachuser has a multi-dimensional action space, subject to a single sum resourceconstraint; 2) each user's utility in a particular dimension depends on anadditive coupling between the user's action in the same dimension and theactions of the other users; and 3) each user's total utility is the sum of theutilities obtained in each dimension. Familiar examples of such multi-userenvironments in communication systems include power control overfrequency-selective Gaussian interference channels and flow control in Jacksonnetworks. In settings where users cannot exchange messages in real-time, westudy how users can adjust their actions based on their local observations. Wederive sufficient conditions under which a unique Nash equilibrium exists andthe best-response algorithm converges globally and linearly to the Nashequilibrium. In settings where users can exchange messages in real-time, wefocus on user choices that optimize the overall utility. We provide theconvergence conditions of two distributed action update mechanisms, gradientplay and Jacobi update.

Near-Optimal Deviation-Proof Medium Access Control Designs in Wireless  Networks

  Distributed medium access control (MAC) protocols are essential for theproliferation of low cost, decentralized wireless local area networks (WLANs).Most MAC protocols are designed with the presumption that nodes comply withprescribed rules. However, selfish nodes have natural motives to manipulateprotocols in order to improve their own performance. This often degrades theperformance of other nodes as well as that of the overall system. In this work,we propose a class of protocols that limit the performance gain which nodes canobtain through selfish manipulation while incurring only a small efficiencyloss. The proposed protocols are based on the idea of a review strategy, withwhich nodes collect signals about the actions of other nodes over a period oftime, use a statistical test to infer whether or not other nodes are followingthe prescribed protocol, and trigger a punishment if a departure from theprotocol is perceived. We consider the cases of private and public signals andprovide analytical and numerical results to demonstrate the properties of theproposed protocols.

Intervention Mechanism Design for Networks With Selfish Users

  We consider a multi-user network where a network manager and selfish usersinteract. The network manager monitors the behavior of users and intervenes inthe interaction among users if necessary, while users make decisionsindependently to optimize their individual objectives. In this paper, wedevelop a framework of intervention mechanism design, which is aimed tooptimize the objective of the manager, or the network performance, taking theincentives of selfish users into account. Our framework is general enough tocover a wide range of application scenarios, and it has advantages overexisting approaches such as Stackelberg strategies and pricing. To design anintervention mechanism and to predict the resulting operating point, weformulate a new class of games called intervention games and a new solutionconcept called intervention equilibrium. We provide analytic results aboutintervention equilibrium and optimal intervention mechanisms in the case of abenevolent manager with perfect monitoring. We illustrate these results with arandom access model. Our illustrative example suggests that interventionrequires less knowledge about users than pricing.

Designing Incentive Schemes Based on Intervention: The Case of Imperfect  Monitoring

  We propose an incentive scheme based on intervention to sustain cooperationamong self-interested users. In the proposed scheme, an intervention devicecollects imperfect signals about the actions of the users for a test period,and then chooses the level of intervention that degrades the performance of thenetwork for the remaining time period. We analyze the problems of designing anoptimal intervention rule given a test period and choosing an optimal length ofthe test period. The intervention device can provide the incentive forcooperation by exerting intervention following signals that involve a highlikelihood of deviation. Increasing the length of the test period has twocounteracting effects on the performance: It improves the quality of signals,but at the same time it weakens the incentive for cooperation due to increaseddelay.

The Theory of Intervention Games for Resource Sharing in Wireless  Communications

  This paper develops a game-theoretic framework for the design and analysis ofa new class of incentive schemes called intervention schemes. We formulateintervention games, propose a solution concept of intervention equilibrium, andprove its existence in a finite intervention game. We apply our framework toresource sharing scenarios in wireless communications, whose non-cooperativeoutcomes without intervention yield suboptimal performance. We deriveanalytical results and analyze illustrative examples in the cases of imperfectand perfect monitoring. In the case of imperfect monitoring, interventionschemes can improve the suboptimal performance of non-cooperative equilibriumwhen the intervention device has a sufficiently accurate monitoring technology,although it may not be possible to achieve the best feasible performance. Inthe case of perfect monitoring, the best feasible performance can be obtainedwith an intervention scheme when the intervention device has a sufficientlystrong intervention capability.

Robust Stackelberg game in communication systems

  This paper studies multi-user communication systems with two groups of users:leaders which possess system information, and followers which have no systeminformation using the formulation of Stackelberg games. In such games, theleaders play and choose their actions based on their information about thesystem and the followers choose their actions myopically according to theirobservations of the aggregate impact of other users. However, obtaining theexact value of these parameters is not practical in communication systems. Tostudy the effect of uncertainty and preserve the players' utilities in theseconditions, we introduce a robust equilibrium for Stackelberg games. In thisframework, the leaders' information and the followers' observations areuncertain parameters, and the leaders and the followers choose their actions bysolving the worst-case robust optimizations. We show that the followers'uncertain parameters always increase the leaders' utilities and decrease thefollowers' utilities. Conversely, the leaders' uncertain information reducesthe leaders' utilities and increases the followers' utilities. We illustrateour theoretical results with the numerical results obtained based on the powercontrol games in the interference channels.

Designing Practical Distributed Exchange for Online Communities

  In many online systems, individuals provide services for each other; therecipient of the service obtains a benefit but the provider of the serviceincurs a cost. If benefit exceeds cost, provision of the service increasessocial welfare and should therefore be encouraged -- but the individualsproviding the service gain no (immediate) benefit from providing the serviceand hence have an incentive to withhold service. Hence there is scope fordesigning a system that improves welfare by encouraging exchange. To operatesuccessfully within the confines of the online environment, such a systemshould be distributed, practicable, and consistent with individual incentives.This paper proposes and analyzes a simple such system that relies on theexchange of {\em tokens}; the emphasis is on the design of a protocol (numberof tokens and suggested strategies). We provide estimates for the efficiency ofsuch protocols and show that choosing the right protocol will lead to almostfull efficiency if agents are sufficiently patient. However, choosing the wrongprotocols may lead to an enormous loss of efficiency.

Pricing and Intervention in Slotted-Aloha: Technical Report

  In many wireless communication networks a common channel is shared bymultiple users who must compete to gain access to it. The operation of thenetwork by self-interested and strategic users usually leads to the overuse ofthe channel resources and to substantial inefficiencies. Hence, incentiveschemes are needed to overcome the inefficiencies of non-cooperativeequilibrium. In this work we consider a slotted-Aloha like random accessprotocol and two incentive schemes: pricing and intervention. We provide somecriteria for the designer of the protocol to choose one scheme between them andto design the best policy for the selected scheme, depending on the systemparameters. Our results show that intervention can achieve the maximumefficiency in the perfect monitoring scenario. In the imperfect monitoringscenario, instead, the performance of the system depends on the informationheld by the different entities and, in some cases, there exists a threshold forthe number of users such that, for a number of users lower than the threshold,intervention outperforms pricing, whereas, for a number of users higher thanthe threshold pricing outperforms intervention.

Distributed Online Big Data Classification Using Context Information

  Distributed, online data mining systems have emerged as a result ofapplications requiring analysis of large amounts of correlated andhigh-dimensional data produced by multiple distributed data sources. We proposea distributed online data classification framework where data is gathered bydistributed data sources and processed by a heterogeneous set of distributedlearners which learn online, at run-time, how to classify the different datastreams either by using their locally available classification functions or byhelping each other by classifying each other's data. Importantly, since thedata is gathered at different locations, sending the data to another learner toprocess incurs additional costs such as delays, and hence this will be onlybeneficial if the benefits obtained from a better classification will exceedthe costs. We model the problem of joint classification by the distributed andheterogeneous learners from multiple data sources as a distributed contextualbandit problem where each data is characterized by a specific context. Wedevelop a distributed online learning algorithm for which we can provesublinear regret. Compared to prior work in distributed online data mining, ourwork is the first to provide analytic regret results characterizing theperformance of the proposed algorithm.

Designing Efficient Resource Sharing For Impatient Players Using Limited  Monitoring

  The problem of efficient sharing of a resource is nearly ubiquitous. Exceptfor pure public goods, each agent's use creates a negative externality; oftenthe negative externality is so strong that efficient sharing is impossible inthe short run. We show that, paradoxically, the impossibility of efficientsharing in the short run enhances the possibility of efficient sharing in thelong run, even if outcomes depend stochastically on actions, monitoring islimited and users are not patient. We base our analysis on the familiarframework of repeated games with imperfect public monitoring, but we extend theframework to view the monitoring structure as chosen by a designer who balancesthe benefits and costs of more accurate observations and reports. Ourconclusions are much stronger than in the usual folk theorems: we do notrequire a rich signal structure or patient users and provide an explicit onlineconstruction of equilibrium strategies.

Socially-Optimal Design of Service Exchange Platforms with Imperfect  Monitoring

  In service exchange platforms, anonymous users exchange services with eachother: clients request services and are matched to servers who provideservices. Because providing good-quality services requires effort, in anysingle interaction a server will have no incentive to exert effort and willshirk. We show that if current servers will later become clients and wantgood-quality services, shirking can be eliminated by rating protocols, whichmaintain ratings for each user, prescribe behavior in each client-serverinteraction, and update ratings based on whether observed/reported behaviorconforms with prescribed behavior. The rating protocols proposed are the firstto achieve social optimum even when observation/reporting is imperfect (qualityis incorrectly assessed/reported or reports are lost). The proposed protocolsare remarkably simple, requiring only binary ratings and three possibleprescribed behaviors. Key to the efficacy of the proposed protocols is thatthey are nonstationary, and tailor prescriptions to both current and pastrating distributions.

Forecasting Popularity of Videos using Social Media

  This paper presents a systematic online prediction method (Social-Forecast)that is capable to accurately forecast the popularity of videos promoted bysocial media. Social-Forecast explicitly considers the dynamically changing andevolving propagation patterns of videos in social media when making popularityforecasts, thereby being situation and context aware. Social-Forecast aims tomaximize the forecast reward, which is defined as a tradeoff between thepopularity prediction accuracy and the timeliness with which a prediction isissued. The forecasting is performed online and requires no training phase or apriori knowledge. We analytically bound the prediction performance loss ofSocial-Forecast as compared to that obtained by an omniscient oracle and provethat the bound is sublinear in the number of video arrivals, therebyguaranteeing its short-term performance as well as its asymptotic convergenceto the optimal performance. In addition, we conduct extensive experiments usingreal-world data traces collected from the videos shared in RenRen, one of thelargest online social networks in China. These experiments show that ourproposed method outperforms existing view-based approaches for popularityprediction (which are not context-aware) by more than 30% in terms ofprediction rewards.

Jamming Bandits

  Can an intelligent jammer learn and adapt to unknown environments in anelectronic warfare-type scenario? In this paper, we answer this question in thepositive, by developing a cognitive jammer that adaptively and optimallydisrupts the communication between a victim transmitter-receiver pair. Weformalize the problem using a novel multi-armed bandit framework where thejammer can choose various physical layer parameters such as the signalingscheme, power level and the on-off/pulsing duration in an attempt to obtainpower efficient jamming strategies. We first present novel online learningalgorithms to maximize the jamming efficacy against static transmitter-receiverpairs and prove that our learning algorithm converges to the optimal (in termsof the error rate inflicted at the victim and the energy used) jammingstrategy. Even more importantly, we prove that the rate of convergence to theoptimal jamming strategy is sub-linear, i.e. the learning is fast in comparisonto existing reinforcement learning algorithms, which is particularly importantin dynamically changing wireless environments. Also, we characterize theperformance of the proposed bandit-based learning algorithm against multiplestatic and adaptive transmitter-receiver pairs.

Towards a Theory of Societal Co-Evolution: Individualism versus  Collectivism

  Substantial empirical research has shown that the level of individualism vs.collectivism is one of the most critical and important determinants of societaltraits, such as economic growth, economic institutions and health conditions.But the exact nature of this impact has thus far not been well understood in ananalytical setting. In this work, we develop one of the first theoreticalmodels that analytically studies the impact of individualism-collectivism onthe society. We model the growth of an individual's welfare (wealth, resourcesand health) as depending not only on himself, but also on the level ofcollectivism, i.e. the level of dependence on the rest of the individuals inthe society, which leads to a co-evolutionary setting. Based on our model, weare able to predict the impact of individualism-collectivism on varioussocietal metrics, such as average welfare, average life-time, total population,cumulative welfare and average inequality. We analytically show thatindividualism has a positive impact on average welfare and cumulative welfare,but comes with the drawbacks of lower average life-time, lower total populationand higher average inequality.

Dynamic Network Formation with Foresighted Agents

  What networks can form and persist when agents are self-interested? Can suchnetworks be efficient? A substantial theoretical literature predicts that theonly networks that can form and persist must have very special shapes and thatsuch networks cannot be efficient, but these predictions are in stark contrastto empirical findings. In this paper, we present a new model of networkformation. In contrast to the existing literature, our model is dynamic (ratherthan static), we model agents as foresighted (rather than myopic) and we allowfor the possibility that agents are heterogeneous (rather than homogeneous). Weshow that a very wide variety of networks can form and persist; in particular,efficient networks can form and persist if they provide every agent a strictlypositive payoff. For the widely-studied connections model, we provide a fullcharacterization of the set of efficient networks that can form and persist.Our predictions are consistent with empirical findings.

Adaptive Ensemble Learning with Confidence Bounds

  Extracting actionable intelligence from distributed, heterogeneous,correlated and high-dimensional data sources requires run-time processing andlearning both locally and globally. In the last decade, a large number ofmeta-learning techniques have been proposed in which local learners make onlinepredictions based on their locally-collected data instances, and feed thesepredictions to an ensemble learner, which fuses them and issues a globalprediction. However, most of these works do not provide performance guaranteesor, when they do, these guarantees are asymptotic. None of these existing worksprovide confidence estimates about the issued predictions or rate of learningguarantees for the ensemble learner. In this paper, we provide a systematicensemble learning method called Hedged Bandits, which comes with both long run(asymptotic) and short run (rate of learning) performance guarantees. Moreover,our approach yields performance guarantees with respect to the optimal localprediction strategy, and is also able to adapt its predictions in a data-drivenmanner. We illustrate the performance of Hedged Bandits in the context ofmedical informatics and show that it outperforms numerous online and offlineensemble learning methods.

Personalized Course Sequence Recommendations

  Given the variability in student learning it is becoming increasinglyimportant to tailor courses as well as course sequences to student needs. Thispaper presents a systematic methodology for offering personalized coursesequence recommendations to students. First, a forward-searchbackward-induction algorithm is developed that can optimally select coursesequences to decrease the time required for a student to graduate. Thealgorithm accounts for prerequisite requirements (typically present in higherlevel education) and course availability. Second, using the tools ofmulti-armed bandits, an algorithm is developed that can optimally recommend acourse sequence that both reduces the time to graduate while also increasingthe overall GPA of the student. The algorithm dynamically learns how studentswith different contextual backgrounds perform for given course sequences andthen recommends an optimal course sequence for new students. Using real-worldstudent data from the UCLA Mechanical and Aerospace Engineering department, weillustrate how the proposed algorithms outperform other methods that do notinclude student contextual information when making course sequencerecommendations.

Data-Driven Online Decision Making with Costly Information Acquisition

  In most real-world settings such as recommender systems, finance, andhealthcare, collecting useful information is costly and requires an activechoice on the part of the decision maker. The decision-maker needs to learnsimultaneously what observations to make and what actions to take. This paperincorporates the information acquisition decision into an online learningframework. We propose two different algorithms for this dual learning problem:Sim-OOS and Seq-OOS where observations are made simultaneously andsequentially, respectively. We prove that both algorithms achieve a regret thatis sublinear in time. The developed framework and algorithms can be used inmany applications including medical informatics, recommender systems andactionable intelligence in transportation, finance, cyber-security etc., inwhich collecting information prior to making decisions is costly. We validateour algorithms in a breast cancer example setting in which we show substantialperformance gains for our proposed algorithms.

Personalized Risk Scoring for Critical Care Patients using Mixtures of  Gaussian Process Experts

  We develop a personalized real time risk scoring algorithm that providestimely and granular assessments for the clinical acuity of ward patients basedon their (temporal) lab tests and vital signs. Heterogeneity of the patientspopulation is captured via a hierarchical latent class model. The proposedalgorithm aims to discover the number of latent classes in the patientspopulation, and train a mixture of Gaussian Process (GP) experts, where eachexpert models the physiological data streams associated with a specific class.Self-taught transfer learning is used to transfer the knowledge of latentclasses learned from the domain of clinically stable patients to the domain ofclinically deteriorating patients. For new patients, the posterior beliefs ofall GP experts about the patient's clinical status given her physiological datastream are computed, and a personalized risk score is evaluated as a weightedaverage of those beliefs, where the weights are learned from the patient'shospital admission information. Experiments on a heterogeneous cohort of 6,313patients admitted to Ronald Regan UCLA medical center show that our risk scoreoutperforms the currently deployed risk scores, such as MEWS and Rothmanscores.

Distributed Learning for Stochastic Generalized Nash Equilibrium  Problems

  This work examines a stochastic formulation of the generalized Nashequilibrium problem (GNEP) where agents are subject to randomness in theenvironment of unknown statistical distribution. We focus on fully-distributedonline learning by agents and employ penalized individual cost functions todeal with coupled constraints. Three stochastic gradient strategies aredeveloped with constant step-sizes. We allow the agents to use heterogeneousstep-sizes and show that the penalty solution is able to approach the Nashequilibrium in a stable manner within $O(\mu_\text{max})$, for small step-sizevalue $\mu_\text{max}$ and sufficiently large penalty parameters. The operationof the algorithm is illustrated by considering the network Cournot competitionproblem.

A Semi-Markov Switching Linear Gaussian Model for Censored Physiological  Data

  Critically ill patients in regular wards are vulnerable to unanticipatedclinical dete- rioration which requires timely transfer to the intensive careunit (ICU). To allow for risk scoring and patient monitoring in such a setting,we develop a novel Semi- Markov Switching Linear Gaussian Model (SSLGM) for theinpatients' physiol- ogy. The model captures the patients' latent clinicalstates and their corresponding observable lab tests and vital signs. We presentan efficient unsupervised learn- ing algorithm that capitalizes on theinformatively censored data in the electronic health records (EHR) to learn theparameters of the SSLGM; the learned model is then used to assess the newinpatients' risk for clinical deterioration in an online fashion, allowing fortimely ICU admission. Experiments conducted on a het- erogeneous cohort of6,094 patients admitted to a large academic medical center show that theproposed model significantly outperforms the currently deployed risk scoressuch as Rothman index, MEWS, SOFA and APACHE.

A Hidden Absorbing Semi-Markov Model for Informatively Censored Temporal  Data: Learning and Inference

  Modeling continuous-time physiological processes that manifest a patient'sevolving clinical states is a key step in approaching many problems inhealthcare. In this paper, we develop the Hidden Absorbing Semi-Markov Model(HASMM): a versatile probabilistic model that is capable of capturing themodern electronic health record (EHR) data. Unlike exist- ing models, an HASMMaccommodates irregularly sampled, temporally correlated, and informativelycensored physiological data, and can describe non-stationary clinical statetransitions. Learning an HASMM from the EHR data is achieved via a novelforward- filtering backward-sampling Monte-Carlo EM algorithm that exploits theknowledge of the end-point clinical outcomes (informative censoring) in the EHRdata, and implements the E-step by sequentially sampling the patients' clinicalstates in the reverse-time direction while conditioning on the future states.Real-time inferences are drawn via a forward- filtering algorithm that operateson a virtually constructed discrete-time embedded Markov chain that mirrors thepatient's continuous-time state trajectory. We demonstrate the di- agnostic andprognostic utility of the HASMM in a critical care prognosis setting using areal-world dataset for patients admitted to the Ronald Reagan UCLA MedicalCenter.

Learning from Clinical Judgments: Semi-Markov-Modulated Marked Hawkes  Processes for Risk Prognosis

  Critically ill patients in regular wards are vulnerable to unanticipatedadverse events which require prompt transfer to the intensive care unit (ICU).To allow for accurate prognosis of deteriorating patients, we develop a novelcontinuous-time probabilistic model for a monitored patient's temporal sequenceof physiological data. Our model captures "informatively sampled" patientepisodes: the clinicians' decisions on when to observe a hospitalized patient'svital signs and lab tests over time are represented by a marked Hawkes process,with intensity parameters that are modulated by the patient's latent clinicalstates, and with observable physiological data (mark process) modeled as aswitching multi-task Gaussian process. In addition, our model captures"informatively censored" patient episodes by representing the patient's latentclinical states as an absorbing semi-Markov jump process. The model parametersare learned from offline patient episodes in the electronic health records viaan EM-based algorithm. Experiments conducted on a cohort of patients admittedto a major medical center over a 3-year period show that risk prognosis basedon our model significantly outperforms the currently deployed medical riskscores and other baseline machine learning algorithms.

Deep Counterfactual Networks with Propensity-Dropout

  We propose a novel approach for inferring the individualized causal effectsof a treatment (intervention) from observational data. Our approachconceptualizes causal inference as a multitask learning problem; we model asubject's potential outcomes using a deep multitask network with a set ofshared layers among the factual and counterfactual outcomes, and a set ofoutcome-specific layers. The impact of selection bias in the observational datais alleviated via a propensity-dropout regularization scheme, in which thenetwork is thinned for every training example via a dropout probability thatdepends on the associated propensity score. The network is trained inalternating phases, where in each phase we use the training examples of one ofthe two potential outcomes (treated and control populations) to update theweights of the shared layers and the respective outcome-specific layers.Experiments conducted on data based on a real-world observational study showthat our algorithm outperforms the state-of-the-art.

RadialGAN: Leveraging multiple datasets to improve target-specific  predictive models using Generative Adversarial Networks

  Training complex machine learning models for prediction often requires alarge amount of data that is not always readily available. Leveraging theseexternal datasets from related but different sources is therefore an importanttask if good predictive models are to be built for deployment in settings wheredata can be rare. In this paper we propose a novel approach to the problem inwhich we use multiple GAN architectures to learn to translate from one datasetto another, thereby allowing us to effectively enlarge the target dataset, andtherefore learn better predictive models than if we simply used the targetdataset. We show the utility of such an approach, demonstrating that our methodimproves the prediction performance on the target domain over using just thetarget dataset and also show that our framework outperforms several otherbenchmarks on a collection of real-world medical datasets.

AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian  Optimization with Structured Kernel Learning

  Clinical prognostic models derived from largescale healthcare data can informcritical diagnostic and therapeutic decisions. To enable off-theshelf usage ofmachine learning (ML) in prognostic research, we developed AUTOPROGNOSIS: asystem for automating the design of predictive modeling pipelines tailored forclinical prognosis. AUTOPROGNOSIS optimizes ensembles of pipelineconfigurations efficiently using a novel batched Bayesian optimization (BO)algorithm that learns a low-dimensional decomposition of the pipelineshigh-dimensional hyperparameter space in concurrence with the BO procedure.This is achieved by modeling the pipelines performances as a black-box functionwith a Gaussian process prior, and modeling the similarities between thepipelines baseline algorithms via a sparse additive kernel with a Dirichletprior. Meta-learning is used to warmstart BO with external data from similarpatient cohorts by calibrating the priors using an algorithm that mimics theempirical Bayes method. The system automatically explains its predictions bypresenting the clinicians with logical association rules that link patientsfeatures to predicted risk strata. We demonstrate the utility of AUTOPROGNOSISusing 10 major patient cohorts representing various aspects of cardiovascularpatient care.

Disease-Atlas: Navigating Disease Trajectories with Deep Learning

  Joint models for longitudinal and time-to-event data are commonly used inlongitudinal studies to forecast disease trajectories over time. While thereare many advantages to joint modeling, the standard forms suffer fromlimitations that arise from a fixed model specification, and computationaldifficulties when applied to high-dimensional datasets. In this paper, wepropose a deep learning approach to address these limitations, enhancingexisting methods with the inherent flexibility and scalability of deep neuralnetworks, while retaining the benefits of joint modeling. Using longitudinaldata from a real-world medical dataset, we demonstrate improvements inperformance and scalability, as well as robustness in the presence ofirregularly sampled data.

GAIN: Missing Data Imputation using Generative Adversarial Nets

  We propose a novel method for imputing missing data by adapting thewell-known Generative Adversarial Nets (GAN) framework. Accordingly, we callour method Generative Adversarial Imputation Nets (GAIN). The generator (G)observes some components of a real data vector, imputes the missing componentsconditioned on what is actually observed, and outputs a completed vector. Thediscriminator (D) then takes a completed vector and attempts to determine whichcomponents were actually observed and which were imputed. To ensure that Dforces G to learn the desired distribution, we provide D with some additionalinformation in the form of a hint vector. The hint reveals to D partialinformation about the missingness of the original sample, which is used by D tofocus its attention on the imputation quality of particular components. Thishint ensures that G does in fact learn to generate according to the true datadistribution. We tested our method on various datasets and found that GAINsignificantly outperforms state-of-the-art imputation methods.

Piecewise Approximations of Black Box Models for Model Interpretation

  Machine Learning models have proved extremely successful for a wide varietyof supervised learning problems, but the predictions of many of these modelsare difficult to interpret. A recent literature interprets the predictions ofmore general "black-box" machine learning models by approximating these modelsin terms of simpler models such as piecewise linear or piecewise constantmodels. Existing literature constructs these approximations in an ad-hocmanner. We provide a tractable dynamic programming algorithm that partitionsthe feature space into clusters in a principled way and then uses thispartition to provide both piecewise constant and piecewise linearinterpretations of an arbitrary "black-box" model. When loss is measured interms of mean squared error, our approximation is optimal (under certainconditions); for more general loss functions, our interpretation is probablyapproximately optimal (in the sense of PAC learning). Experiments with real andsynthetic data show that it continues to provide significant improvements (interms of mean squared error) over competing approaches.

Measuring the quality of Synthetic data for use in competitions

  Machine learning has the potential to assist many communities in using thelarge datasets that are becoming more and more available. Unfortunately, muchof that potential is not being realized because it would require sharing datain a way that compromises privacy. In order to overcome this hurdle, severalmethods have been proposed that generate synthetic data while preserving theprivacy of the real data. In this paper we consider a key characteristic thatsynthetic data should have in order to be useful for machine learningresearchers - the relative performance of two algorithms (trained and tested)on the synthetic dataset should be the same as their relative performance (whentrained and tested) on the original dataset.

Siamese Survival Analysis with Competing Risks

  Survival analysis in the presence of multiple possible adverse events, i.e.,competing risks, is a pervasive problem in many industries (healthcare,finance, etc.). Since only one event is typically observed, the incidence of anevent of interest is often obscured by other related competing events. Thisnonidentifiability, or inability to estimate true cause-specific survivalcurves from empirical data, further complicates competing risk survivalanalysis. We introduce Siamese Survival Prognosis Network (SSPN), a novel deeplearning architecture for estimating personalized risk scores in the presenceof competing risks. SSPN circumvents the nonidentifiability problem by avoidingthe estimation of cause-specific survival curves and instead determinespairwise concordant time-dependent risks, where longer event times are assignedlower risks. Furthermore, SSPN is able to directly optimize an approximation tothe C-discrimination index, rather than relying on well-known metrics which areunable to capture the unique requirements of survival analysis with competingrisks.

Forecasting Individualized Disease Trajectories using Interpretable Deep  Learning

  Disease progression models are instrumental in predicting individual-levelhealth trajectories and understanding disease dynamics. Existing models arecapable of providing either accurate predictions of patients prognoses orclinically interpretable representations of disease pathophysiology, but notboth. In this paper, we develop the phased attentive state space (PASS) modelof disease progression, a deep probabilistic model that captures complexrepresentations for disease progression while maintaining clinicalinterpretability. Unlike Markovian state space models which assume memorylessdynamics, PASS uses an attention mechanism to induce "memoryful" statetransitions, whereby repeatedly updated attention weights are used to focus onpast state realizations that best predict future states. This gives rise tocomplex, non-stationary state dynamics that remain interpretable through thegenerated attention weights, which designate the relationships between therealized state variables for individual patients. PASS uses phased LSTM units(with time gates controlled by parametrized oscillations) to generate theattention weights in continuous time, which enables handlingirregularly-sampled and potentially missing medical observations. Experimentson data from a realworld cohort of patients show that PASS successfullybalances the tradeoff between accuracy and interpretability: it demonstratessuperior predictive accuracy and learns insightful individual-levelrepresentations of disease progression.

Generalized Concordance for Competing Risks

  Existing metrics in competing risks survival analysis such as concordance andaccuracy do not evaluate a model's ability to jointly predict the event typeand the event time. To address these limitations, we propose a new metric,which we call the generalized concordance. The different components of thegeneralized concordance correspond to the probabilities that a model makes anerror in the event-type prediction only, or the discrimination only or both. Wedevelop a consistent estimator for the new metric that accounts for thecensoring bias. Using the real and synthetic data experiments, we show thatmodels selected using the existing metrics are worse than those selected usinggeneralized concordance at jointly predicting the event type and event time. Weuse the new metric to develop a variable importance ranking approach, which wecall the stepwise competing risks regression. The purpose of this approach isto identify the factors that are important for predicting both the event typeand the event time. We use real and synthetic datasets to show that theexisting approaches for variable importance ranking often fail to recognize theimportance of the event-specific risk factors, whereas, our approach does not.

Estimation of Individual Treatment Effect in Latent Confounder Models  via Adversarial Learning

  Estimating the individual treatment effect (ITE) from observational data isessential in medicine. A central challenge in estimating the ITE is handlingconfounders, which are factors that affect both an intervention and itsoutcome. Most previous work relies on the unconfoundedness assumption, whichposits that all the confounders are measured in the observational data.However, if there are unmeasurable (latent) confounders, then confounding biasis introduced. Fortunately, noisy proxies for the latent confounders are oftenavailable and can be used to make an unbiased estimate of the ITE. In thispaper, we develop a novel adversarial learning framework to make unbiasedestimates of the ITE using noisy proxies.

