An easy proof of the Stone-von Neumann-Mackey theorem

  The Stone-von Neumann-Mackey Theorem for Heisenberg groups associated tolocally compact abelian groups is proved using the Peter-Weyl theorem and thetheory of Fourier transforms for finite dimensional real vector spaces. Atheorem of Pontryagin and van Kampen on the structure of locally compactabelian groups (which is evident in any particular case) is assumed.

Domain and Function: A Dual-Space Model of Semantic Relations and  Compositions

  Given appropriate representations of the semantic relations between carpenterand wood and between mason and stone (for example, vectors in a vector spacemodel), a suitable algorithm should be able to recognize that these relationsare highly similar (carpenter is to wood as mason is to stone; the relationsare analogous). Likewise, with representations of dog, house, and kennel, analgorithm should be able to recognize that the semantic composition of dog andhouse, dog house, is highly similar to kennel (dog house and kennel aresynonymous). It seems that these two tasks, recognizing relations andcompositions, are closely connected. However, up to now, the best models forrelations are significantly different from the best models for compositions. Inthis paper, we introduce a dual-space model that unifies these two tasks. Thismodel matches the performance of the best previous models for relations andcompositions. The dual-space model consists of a space for measuring domainsimilarity and a space for measuring function similarity. Carpenter and woodshare the same domain, the domain of carpentry. Mason and stone share the samedomain, the domain of masonry. Carpenter and mason share the same function, thefunction of artisans. Wood and stone share the same function, the function ofmaterials. In the composition dog house, kennel has some domain overlap withboth dog and house (the domains of pets and buildings). The function of kennelis similar to the function of house (the function of shelters). By combiningdomain and function similarities in various ways, we can model relations,compositions, and other aspects of semantics.

Continuum-sites stepping-stone models, coalescing exhcangeable  partitions, and random trees

  Analogues of stepping--stone models are considered where the site--space iscontinuous, the migration process is a general Markov process, and thetype--space is infinite. Such processes were defined in previous work of thesecond author by specifying a Feller transition semigroup in terms ofexpectations of suitable functionals for systems of coalescing Markovprocesses. An alternative representation is obtained here in terms of a limitof interacting particle systems. It is shown that, under a mild condition onthe migration process, the continuum--sites stepping--stone process hascontinuous sample paths. The case when the migration process is Brownian motionon the circle is examined in detail using a duality relation between coalescingand annihilating Brownian motion. This duality relation is also used to showthat a random compact metric space that is naturally associated to an infinitefamily of coalescing Brownian motions on the circle has Hausdorff and packingdimension both almost surely equal to 1/2 and, moreover, this space is capacityequivalent to the middle--1/2 Cantor set (and hence also to the Brownian zeroset).

An analogue of the Erd≈ës-Stone theorem for finite geometries

  For a set $G$ of points in $\PG(m-1,q)$, let $\ex_q(G;n)$, denote the maximumsize of a collection of points in $\PG(n-1,q)$ not containing a copy of $G$, upto projective equivalence. We show that \[\lim_{n\rightarrow \infty}\frac{\ex_q(G;n)}{|\PG(n-1,q)|} = 1-q^{1-c},\] where $c$ is the smallestinteger such that there is a rank-$(m-c)$ flat in $\PG(m-1,q)$ that is disjointfrom $G$. The result is an elementary application of the density version of theHales-Jewett Theorem.

Temperley-Lieb and Birman-Murakami-Wenzl like relations from  multiplicity free semi-simple tensor system

  In this article we consider conditions under which projection operators inmultiplicity free semi-simple tensor categories satisfy Temperley-Lieb likerelations. This is then used as a stepping stone to prove sufficient conditionsfor obtaining a representation of the Birman-Murakami-Wenzl algebra from abraided multiplicity free semi-simple tensor category. The results are found byutalising the data of the categories. There is considerable overlap with theresults found in arXiv:1607.08908, where proofs are shown by manipulatingdiagrams.

Tuning of ferromagnetism through anion substitution in Ga-Mn-pnictide  ferromagnetic semiconductors

  We have synthesized Ga1-xMnxAs1-yPy and Ga1-xMnxP1-yNy by the combination ofion implantation and pulsed-laser melting. We find that the incorporation ofisovalent impurities with smaller atomic radii leads to a realignment of themagnetic easy axis in Ga1-xMnxP1-yNy/GaP and Ga1-xMnxAs1-yPy/GaAs thin filmsfrom in-plane to out-of-plane. This tensile-strain-induced magnetic anisotropyis reminiscent of that observed in Ga1-xMnxAs grown on larger lattice constant(In,Ga)As buffer layers indicating that the role of strain in determiningmagnetic anisotropy is fundamental to III-Mn-V materials. In addition, weobserve a decrease in the ferromagnetic Curie temperature in Ga1-xMnxAs1-yPywith increasing y from 0 to 0.028. Such a decrease may result from localizationof holes as the P/As ratio on the Group V sublattice increases.

Mn L3,2 X-ray Absorption Spectroscopy And Magnetic Circular Dichroism In  Ferromagnetic (Ga,Mn)P

  We have measured the X-ray absorption (XAS) and X-ray magnetic circulardichroism (XMCD) at the Mn L3,2 edges in ferromagnetic Ga1-xMnxP films for0.018<x<0.042. Large XMCD asymmetries at the L3 edge indicate significantspin-polarization of the density of states at the Fermi energy. The spectralshapes of the XAS and XMCD are nearly identical with those for Ga1-xMnxAsindicating that the hybridization of Mn d states and anion p states is similarin the two materials. Finally, compensation with sulfur donors not only lowersthe ferromagnetic Curie temperature but also reduces the spin polarization ofthe hole states.

Metal-insulator transition by isovalent anion substitution in  Ga1-xMnxAs: Implications to ferromagnetism

  We have investigated the effect of partial isovalent anion substitution inGa1-xMnxAs on electrical transport and ferromagnetism. Substitution of only2.4% of As by P induces a metal-insulator transition at a constant Mn doping ofx=0.046 while the replacement of 0.4 % As with N results in the crossover frommetal to insulator for x=0.037. This remarkable behavior is consistent with ascenario in which holes located within an impurity band are scattered by alloydisorder in the anion sublattice. The shorter mean free path of holes, whichmediate ferromagnetism, reduces the Curie temperature TC from 113 K to 60 K(100 K to 65 K) upon the introduction of 3.1 % P (1% N) into the As sublattice.

Braids and combinatorial knot Floer homology

  We present a braid-theoretic approach to combinatorially computing knot Floerhomology. To a knot or link K, which is braided about the standard disk openbook decomposition for (S^3,\xi_std), we associate a correspondingmulti-pointed nice Heegaard diagram. We then describe an explicit algorithm forcomputing the associated knot Floer homology groups. We compute explicit boundsfor the computational complexity of our algorithm and demonstrate that, in manycases, it is significantly faster than the previous approach using griddiagrams.

Transverse braids and combinatorial knot Floer homology

  We describe a new method for combinatorially computing the transverseinvariant in knot Floer homology. Previous work of the authors and Stone usedbraid diagrams to combinatorially compute knot Floer homology of braidclosures. However, that approach was unable to explicitly identify theinvariant of transverse links that naturally appears in braid diagrams. In thispaper, we improve the previous approach in order to compute the transverseinvariant. We define a new combinatorial complex that computes knot Floerhomology and identify the BRAID invariant of transverse knots and links in thehomology of this complex.

Sprague-Grundy Function of Symmetric Hypergraphs

  We consider a generalization of the classical game of $NIM$ called hypergraph$NIM$. Given a hypergraph $\cH$ on the ground set $V = \{1, \ldots, n\}$ of $n$piles of stones, two players alternate in choosing a hyperedge $H \in \cH$ andstrictly decreasing all piles $i\in H$. The player who makes the last move isthe winner. Recently it was shown that for many classes of hypergraphs theSprague-Grundy function of the corresponding game is given by the formulaintroduced originally by Jenkyns and Mayberry (1980). In this paper wecharacterize symmetric hypergraphs for which the Sprague-Grundy function isdescribed by the same formula.

Learning a Policy for Opportunistic Active Learning

  Active learning identifies data points to label that are expected to be themost useful in improving a supervised model. Opportunistic active learningincorporates active learning into interactive tasks that constrain possiblequeries during interactions. Prior work has shown that opportunistic activelearning can be used to improve grounding of natural language descriptions inan interactive object retrieval task. In this work, we use reinforcementlearning for such an object retrieval task, to learn a policy that effectivelytrades off task completion with model improvement that would benefit futuretasks.

Algorithm for obtaining the gradient expansion of the local density of  states and the free energy of a superconductor

  We present an efficient algorithm for obtaining the gauge-invariant gradientexpansion of the local density of states and the free energy of a cleansuperconductor. Our method is based on a new mapping of the semiclassicallinearized Gorkov equations onto a pseudo-Schroedinger equation for athree-component wave-function psi(x), where one component is directly relatedto the local density of states. Because psi(x) satisfies a linear equation ofmotion, successive terms in the gradient expansion can be obtained by simplelinear iteration. Our method works equally well for real and complex orderparameter, and in the presence of arbitrary external fields. We confirm arecent calculation of the fourth order correction to the free energy byKosztin, Kos, Stone and Leggett [Phys. Rev. B 58, 9365 (1998)], who obtained adiscrepancy with an earlier result by Tewordt [Z. Phys. 180, 385 (1964)]. Wealso give the fourth order correction to the local density of states, which hasnot been published before.

An effective theory for omega << k << gT color dynamics in hot  non-Abelian plasmas

  A proper sequence of effective theories, corresponding to larger and largerdistance scales, is crucial for analyzing real-time equilibrium physics in hotnon-Abelian plasmas. For the study of color dynamics (by which I mean physicsinvolving long wavelength gauge fluctuations), an important stepping stone inthe sequence of effective theories is to have a good effective theory fordynamics with wave number k well below the Debye screening mass. I review howsuch dynamics is associated with inverse time scales omega << k. I then give acompact way to package, in the omega << k limit, Bodeker's description of k <<m physics, which was in terms of Vlasov equations with collision terms.Finally, I show how the resulting effective theory can be reformulated as apath integral.

Characterizing the variation of propagation constants in multicore fibre

  We demonstrate a numerical technique that can evaluate the core-to-corevariations in propagation constant in multicore fibre. Using a Markov ChainMonte Carlo process, we replicate the interference patterns of light that hascoupled between the cores during propagation. We describe the algorithm andverify its operation by successfully reconstructing target propagationconstants in a fictional fibre. Then we carry out a reconstruction of thepropagation constants in a real fibre containing 37 single-mode cores. We findthat the range of fractional propagation constant variation across the cores isapproximately $\pm2 \times 10^{-5}$.

Deep Spiking Networks

  We introduce an algorithm to do backpropagation on a spiking network. Ournetwork is "spiking" in the sense that our neurons accumulate their activationinto a potential over time, and only send out a signal (a "spike") when thispotential crosses a threshold and the neuron is reset. Neurons only updatetheir states when receiving signals from other neurons. Total computation ofthe network thus scales with the number of spikes caused by an input ratherthan network size. We show that the spiking Multi-Layer Perceptron behavesidentically, during both prediction and training, to a conventional deepnetwork of rectified-linear units, in the limiting case where we run thespiking network for a long time. We apply this architecture to a conventionalclassification problem (MNIST) and achieve performance very close to that of aconventional Multi-Layer Perceptron with the same architecture. Our network isa natural architecture for learning based on streaming event-based data, and isa stepping stone towards using spiking neural networks to learn efficiently onstreaming data.

Athena: A New Code for Astrophysical MHD

  A new code for astrophysical magnetohydrodynamics (MHD) is described. Thecode has been designed to be easily extensible for use with static and adaptivemesh refinement. It combines higher-order Godunov methods with the constrainedtransport (CT) technique to enforce the divergence-free constraint on themagnetic field. Discretization is based on cell-centered volume-averages formass, momentum, and energy, and face-centered area-averages for the magneticfield. Novel features of the algorithm include (1) a consistent framework forcomputing the time- and edge-averaged electric fields used by CT to evolve themagnetic field from the time- and area-averaged Godunov fluxes, (2) theextension to MHD of spatial reconstruction schemes that involve adimensionally-split time advance, and (3) the extension to MHD of two differentdimensionally-unsplit integration methods. Implementation of the algorithm inboth C and Fortran95 is detailed, including strategies for parallelizationusing domain decomposition. Results from a test suite which includes problemsin one-, two-, and three-dimensions for both hydrodynamics and MHD are given,not only to demonstrate the fidelity of the algorithms, but also to enablecomparisons to other methods. The source code is freely available for downloadon the web.

Compensation-dependent in-plane magnetization reversal processes in  Ga1-xMnxP1-ySy

  We report the effect of dilute alloying of the anion sublattice with S on thein-plane uniaxial magnetic anisotropy and magnetization reversal process inGa1-xMnxP as measured by both ferromagnetic resonance (FMR) and superconductingquantum interference device (SQUID) magnetometry. At T=5K, raising the Sconcentration increases the uniaxial magnetic anisotropy between in-plane <011>directions while decreasing the magnitude of the (negative) cubic anisotropyfield. Simulation of the SQUID magnetometry indicates that the energy requiredfor the nucleation and growth of domain walls decreases with increasing y.These combined effects have a marked influence on the shape of thefield-dependent magnetization curves; while the direction remains the easy axisin the plane of the film, the field dependence of the magnetization developsdouble hysteresis loops in the [011] direction as the S concentration increasessimilar to those observed for perpendicular magnetization reversal in lightlydoped Ga1-xMnxAs. The incidence of double hysteresis loops is explained with asimple model whereby magnetization reversal occurs by a combination of coherentspin rotation and noncoherent spin switching, which is consistent with both FMRand magnetometry experiments. The evolution of magnetic properties with Sconcentration is attributed to compensation of Mn acceptors by S donors, whichresults in a lowering of the concentration of holes that mediateferromagnetism.

Computational Topology for Regular Closed Sets

  The Boolean algebra of regular closed sets is prominent in topology,particularly as a dual for the Stone-Cech compactification. This algebra isalso central for the theory of geometric computation, as a representation forcombinatorial operations on geometric sets. However, the issue of computationalapproximation introduces unresolved subtleties that do not occur within "pure"topology. One major effort towards reconciling this mathematical theory withcomputational practice is our ongoing I-TANGO project. The acronym I-TANGO isan abbreviation for "Intersections - Topology, Accuracy and Numerics forGeometric Objects". The long-range goals and initial progress of the I-TANGOteam in development of computational topology are presented.

Correlation between structure and electrical transport in ion-irradiated  graphene grown on Cu foils

  Graphene grown by chemical vapor deposition and supported on SiO2 andsapphire substrates was studied following controlled introduction of defectsinduced by 35 keV carbon ion irradiation. Changes in Raman spectra followingfluences ranging from 10^12 cm^-2 to 10^15 cm^-2 indicate that the structure ofgraphene evolves from a highly ordered layer, to a patchwork of disordereddomains, to an essentially amorphous film. These structural changes result in adramatic decrease in the Hall mobility by orders of magnitude while,remarkably, the Hall concentration remains almost unchanged, suggesting thatthe Fermi level is pinned at a hole concentration near 1x10^13 cm^-2. A modelfor scattering by resonant scatterers is in good agreement with mobilitymeasurements up to an ion fluence of 1x10^14 cm^-2.

A Real-Time Model-Based Reinforcement Learning Architecture for Robot  Control

  Reinforcement Learning (RL) is a method for learning decision-making tasksthat could enable robots to learn and adapt to their situation on-line. For anRL algorithm to be practical for robotic control tasks, it must learn in veryfew actions, while continually taking those actions in real-time. Existingmodel-based RL methods learn in relatively few actions, but typically take toomuch time between each action for practical on-line learning. In this paper, wepresent a novel parallel architecture for model-based RL that runs in real-timeby 1) taking advantage of sample-based approximate planning methods and 2)parallelizing the acting, model learning, and planning processes such that theacting process is sufficiently fast for typical robot control cycles. Wedemonstrate that algorithms using this architecture perform nearly as well asmethods using the typical sequential architecture when both are given unlimitedtime, and greatly out-perform these methods on tasks that require real-timeactions such as controlling an autonomous vehicle.

Gaussian Processes for Sample Efficient Reinforcement Learning with  RMAX-like Exploration

  We present an implementation of model-based online reinforcement learning(RL) for continuous domains with deterministic transitions that is specificallydesigned to achieve low sample complexity. To achieve low sample complexity,since the environment is unknown, an agent must intelligently balanceexploration and exploitation, and must be able to rapidly generalize fromobservations. While in the past a number of related sample efficient RLalgorithms have been proposed, to allow theoretical analysis, mainlymodel-learners with weak generalization capabilities were considered. Here, weseparate function approximation in the model learner (which does requiresamples) from the interpolation in the planner (which does not requiresamples). For model-learning we apply Gaussian processes regression (GP) whichis able to automatically adjust itself to the complexity of the problem (viaBayesian hyperparameter selection) and, in practice, often able to learn ahighly accurate model from very little data. In addition, a GP provides anatural way to determine the uncertainty of its predictions, which allows us toimplement the "optimism in the face of uncertainty" principle used toefficiently control exploration. Our method is evaluated on four commonbenchmark domains.

Feature Selection for Value Function Approximation Using Bayesian Model  Selection

  Feature selection in reinforcement learning (RL), i.e. choosing basisfunctions such that useful approximations of the unkown value function can beobtained, is one of the main challenges in scaling RL to real-worldapplications. Here we consider the Gaussian process based framework GPTD forapproximate policy evaluation, and propose feature selection through marginallikelihood optimization of the associated hyperparameters. Our approach has twoappealing benefits: (1) given just sample transitions, we can solve the policyevaluation problem fully automatically (without looking at the learning task,and, in theory, independent of the dimensionality of the state space), and (2)model selection allows us to consider more sophisticated kernels, which in turnenable us to identify relevant subspaces and eliminate irrelevant statevariables such that we can achieve substantial computational savings andimproved prediction performance.

DJ-MC: A Reinforcement-Learning Agent for Music Playlist Recommendation

  In recent years, there has been growing focus on the study of automatedrecommender systems. Music recommendation systems serve as a prominent domainfor such works, both from an academic and a commercial perspective. Afundamental aspect of music perception is that music is experienced in temporalcontext and in sequence. In this work we present DJ-MC, a novelreinforcement-learning framework for music recommendation that does notrecommend songs individually but rather song sequences, or playlists, based ona model of preferences for both songs and song transitions. The model islearned online and is uniquely adapted for each listener. To reduce explorationtime, DJ-MC exploits user feedback to initialize a model, which it subsequentlyupdates by reinforcement. We evaluate our framework with human participantsusing both real song and playlist data. Our results indicate that DJ-MC'sability to recommend sequences of songs provides a significant improvement overmore straightforward approaches, which do not take transitions into account.

Curvature suppresses the Rayleigh-Taylor instability

  The dynamics of a thin liquid film on the underside of a curved cylindricalsubstrate is studied. The evolution of the liquid layer is investigated as thefilm thickness and the radius of curvature of the substrate are varied. Adimensionless parameter (a modified Bond number) that incorporates bothgeometric parameters, gravity, and surface tension is identified, and allowsthe observations to be classified according to three different flow regimes:stable films, films with transient growth of perturbations followed by decay,and unstable films. Experiments and theory confirm that, below a critical valueof the Bond number, curvature of the substrate suppresses the Rayleigh-Taylorinstability.

Representative Selection in Non Metric Datasets

  This paper considers the problem of representative selection: choosing asubset of data points from a dataset that best represents its overall set ofelements. This subset needs to inherently reflect the type of informationcontained in the entire set, while minimizing redundancy. For such purposes,clustering may seem like a natural approach. However, existing clusteringmethods are not ideally suited for representative selection, especially whendealing with non-metric data, where only a pairwise similarity measure exists.In this paper we propose $\delta$-medoids, a novel approach that can be viewedas an extension to the $k$-medoids algorithm and is specifically suited forsample representative selection from non-metric data. We empirically validate$\delta$-medoids in two domains, namely music analysis and motion analysis. Wealso show some theoretical bounds on the performance of $\delta$-medoids andthe hardness of representative selection in general.

Deep Recurrent Q-Learning for Partially Observable MDPs

  Deep Reinforcement Learning has yielded proficient controllers for complextasks. However, these controllers have limited memory and rely on being able toperceive the complete game screen at each decision point. To address theseshortcomings, this article investigates the effects of adding recurrency to aDeep Q-Network (DQN) by replacing the first post-convolutional fully-connectedlayer with a recurrent LSTM. The resulting \textit{Deep Recurrent Q-Network}(DRQN), although capable of seeing only a single frame at each timestep,successfully integrates information through time and replicates DQN'sperformance on standard Atari games and partially observed equivalentsfeaturing flickering game screens. Additionally, when trained with partialobservations and evaluated with incrementally more complete observations,DRQN's performance scales as a function of observability. Conversely, whentrained with full observations and evaluated with partial observations, DRQN'sperformance degrades less than DQN's. Thus, given the same length of history,recurrency is a viable alternative to stacking a history of frames in the DQN'sinput layer and while recurrency confers no systematic advantage when learningto play the game, the recurrent net can better adapt at evaluation time if thequality of observations changes.

Deep Reinforcement Learning in Parameterized Action Space

  Recent work has shown that deep neural networks are capable of approximatingboth value functions and policies in reinforcement learning domains featuringcontinuous state and action spaces. However, to the best of our knowledge noprevious work has succeeded at using deep neural networks in structured(parameterized) continuous action spaces. To fill this gap, this paper focuseson learning within the domain of simulated RoboCup soccer, which features asmall set of discrete action types, each of which is parameterized withcontinuous variables. The best learned agent can score goals more reliably thanthe 2012 RoboCup champion agent. As such, this paper represents a successfulextension of deep reinforcement learning to the class of parameterized actionspace MDPs.

Data-Efficient Policy Evaluation Through Behavior Policy Search

  We consider the task of evaluating a policy for a Markov decision process(MDP). The standard unbiased technique for evaluating a policy is to deploy thepolicy and observe its performance. We show that the data collected fromdeploying a different policy, commonly called the behavior policy, can be usedto produce unbiased estimates with lower mean squared error than this standardtechnique. We derive an analytic expression for the optimal behavior policy ---the behavior policy that minimizes the mean squared error of the resultingestimates. Because this expression depends on terms that are unknown inpractice, we propose a novel policy evaluation sub-problem, behavior policysearch: searching for a behavior policy that reduces mean squared error. Wepresent a behavior policy search algorithm and empirically demonstrate itseffectiveness in lowering the mean squared error of policy performanceestimates.

FPGA-Based Tracklet Approach to Level-1 Track Finding at CMS for the  HL-LHC

  During the High Luminosity LHC, the CMS detector will need charged particletracking at the hardware trigger level to maintain a manageable trigger rateand achieve its physics goals. The tracklet approach is a track-findingalgorithm based on a road-search algorithm that has been implemented oncommercially available FPGA technology. The tracklet algorithm has achievedhigh performance in track-finding and completes tracking within 3.4 $\mu$s on aXilinx Virtex-7 FPGA. An overview of the algorithm and its implementation on anFPGA is given, results are shown from a demonstrator test stand and systemperformance studies are presented.

Scalable Training of Artificial Neural Networks with Adaptive Sparse  Connectivity inspired by Network Science

  Through the success of deep learning in various domains, artificial neuralnetworks are currently among the most used artificial intelligence methods.Taking inspiration from the network properties of biological neural networks(e.g. sparsity, scale-freeness), we argue that (contrary to general practice)artificial neural networks, too, should not have fully-connected layers. Herewe propose sparse evolutionary training of artificial neural networks, analgorithm which evolves an initial sparse topology (Erd\H{o}s-R\'enyi randomgraph) of two consecutive layers of neurons into a scale-free topology, duringlearning. Our method replaces artificial neural networks fully-connected layerswith sparse ones before training, reducing quadratically the number ofparameters, with no decrease in accuracy. We demonstrate our claims onrestricted Boltzmann machines, multi-layer perceptrons, and convolutionalneural networks for unsupervised and supervised learning on 15 datasets. Ourapproach has the potential to enable artificial neural networks to scale upbeyond what is currently possible.

Breaking Bellman's Curse of Dimensionality: Efficient Kernel Gradient  Temporal Difference

  We consider policy evaluation in infinite-horizon discounted Markov decisionproblems (MDPs) with infinite spaces. We reformulate this task a compositionalstochastic program with a function-valued decision variable that belongs to areproducing kernel Hilbert space (RKHS). We approach this problem via a newfunctional generalization of stochastic quasi-gradient methods operating intandem with stochastic sparse subspace projections. The result is an extensionof gradient temporal difference learning that yields nonlinearly parameterizedvalue function estimates of the solution to the Bellman evaluation equation.Our main contribution is a memory-efficient non-parametric stochastic methodguaranteed to converge exactly to the Bellman fixed point with probability $1$with attenuating step-sizes. Further, with constant step-sizes, we obtain meanconvergence to a neighborhood and that the value function estimates have finitecomplexity. In the Mountain Car domain, we observe faster convergence to lowerBellman error solutions than existing approaches with a fraction of therequired memory.

Autonomous Agents Modelling Other Agents: A Comprehensive Survey and  Open Problems

  Much research in artificial intelligence is concerned with the development ofautonomous agents that can interact effectively with other agents. An importantaspect of such agents is the ability to reason about the behaviours of otheragents, by constructing models which make predictions about various propertiesof interest (such as actions, goals, beliefs) of the modelled agents. A varietyof modelling approaches now exist which vary widely in their methodology andunderlying assumptions, catering to the needs of the different sub-communitieswithin which they were developed and reflecting the different practical usesfor which they are intended. The purpose of the present article is to provide acomprehensive survey of the salient modelling methods which can be found in theliterature. The article concludes with a discussion of open problems which mayform the basis for fruitful future research.

Sprague-Grundy Function of Matroids and Related Hypergraphs

  We consider a generalization of the classical game of $NIM$ called hypergraph$NIM$. Given a hypergraph $\cH$ on the ground set $V = \{1, \ldots, n\}$ of $n$piles of stones, two players alternate in choosing a hyperedge $H \in \cH$ andstrictly decreasing all piles $i\in H$. The player who makes the last move isthe winner. In this paper we give an explicit formula that describes theSprague-Grundy function of hypergraph $NIM$ for several classes of hypergraphs.In particular we characterize all $2$-uniform hypergraphs (that is graphs) andall matroids for which the formula works. We show that all self-dual matroidsare included in this class.

Behavioral Cloning from Observation

  Humans often learn how to perform tasks via imitation: they observe othersperform a task, and then very quickly infer the appropriate actions to takebased on their observations. While extending this paradigm to autonomous agentsis a well-studied problem in general, there are two particular aspects thathave largely been overlooked: (1) that the learning is done from observationonly (i.e., without explicit action information), and (2) that the learning istypically done very quickly. In this work, we propose a two-phase, autonomousimitation learning technique called behavioral cloning from observation (BCO),that aims to provide improved performance with respect to both of theseaspects. First, we allow the agent to acquire experience in a self-supervisedfashion. This experience is used to develop a model which is then utilized tolearn a particular task by observing an expert perform that task without theknowledge of the specific actions taken. We experimentally compare BCO toimitation learning methods, including the state-of-the-art, generativeadversarial imitation learning (GAIL) technique, and we show comparable taskperformance in several different simulation domains while exhibiting increasedlearning speed after expert trajectories become available.

Importance Sampling Policy Evaluation with an Estimated Behavior Policy

  We consider the problem of off-policy evaluation in Markov decisionprocesses. Off-policy evaluation is the task of evaluating the expected returnof one policy with data generated by a different, behavior policy. Importancesampling is a technique for off-policy evaluation that re-weights off-policyreturns to account for differences in the likelihood of the returns between thetwo policies. In this paper, we study importance sampling with an estimatedbehavior policy where the behavior policy estimate comes from the same set ofdata used to compute the importance sampling estimate. We find that thisestimator often lowers the mean squared error of off-policy evaluation comparedto importance sampling with the true behavior policy or using a behavior policythat is estimated from a separate data set. Our empirical results also extendto other popular variants of importance sampling and show that estimating anon-Markovian behavior policy can further lower mean squared error even whenthe true behavior policy is Markovian.

Generative Adversarial Imitation from Observation

  Imitation from observation (IfO) is the problem of learning directly fromstate-only demonstrations without having access to the demonstrator's actions.The lack of action information both distinguishes IfO from most of theliterature in imitation learning, and also sets it apart as a method that mayenable agents to learn from a large set of previously inapplicable resourcessuch as internet videos. In this paper, we propose both a general framework forIfO approaches and also a new IfO approach based on generative adversarialnetworks called generative adversarial imitation from observation (GAIfO). Weconduct experiments in two different settings: (1) when demonstrations consistof low-dimensional, manually-defined state features, and (2) whendemonstrations consist of high-dimensional, raw visual data. We demonstratethat our approach performs comparably to classical imitation learningapproaches (which have access to the demonstrator's actions) and significantlyoutperforms existing imitation from observation methods in high-dimensionalsimulation environments.

A Century Long Commitment to Assessing Artificial Intelligence and its  Impact on Society

  In September 2016, Stanford's "One Hundred Year Study on ArtificialIntelligence" project (AI100) issued the first report of its planned long-termperiodic assessment of artificial intelligence (AI) and its impact on society.The report, entitled "Artificial Intelligence and Life in 2030," examines eightdomains of typical urban settings on which AI is likely to have impact over thecoming years: transportation, home and service robots, healthcare, education,public safety and security, low-resource communities, employment and workplace,and entertainment. It aims to provide the general public with a scientificallyand technologically accurate portrayal of the current state of AI and itspotential and to help guide decisions in industry and governments, as well asto inform research and development in the field. This article by the chair ofthe 2016 Study Panel and the inaugural chair of the AI100 Standing Committeedescribes the origins of this ambitious longitudinal study, discusses theframing of the inaugural report, and presents the report's main findings. Itconcludes with a brief description of the AI100 project's ongoing efforts andplanned next steps.

Deterministic Implementations for Reproducibility in Deep Reinforcement  Learning

  While deep reinforcement learning (DRL) has led to numerous successes inrecent years, reproducing these successes can be extremely challenging. Onereproducibility challenge particularly relevant to DRL is nondeterminism in thetraining process, which can substantially affect the results. Motivated by thischallenge, we study the positive impacts of deterministic implementations ineliminating nondeterminism in training. To do so, we consider the particularcase of the deep Q-learning algorithm, for which we produce a deterministicimplementation by identifying and controlling all sources of nondeterminism inthe training process. One by one, we then allow individual sources ofnondeterminism to affect our otherwise deterministic implementation, andmeasure the impact of each source on the variance in performance. We find thatindividual sources of nondeterminism can substantially impact the performanceof agent, illustrating the benefits of deterministic implementations. Inaddition, we also discuss the important role of deterministic implementationsin achieving exact replicability of results.

An Architecture for Person-Following using Active Target Search

  This paper addresses a novel architecture for person-following robots usingactive search. The proposed system can be applied in real-time to generalmobile robots for learning features of a human, detecting and tracking, andfinally navigating towards that person. To succeed at person-following,perception, planning, and robot behavior need to be integrated properly. Towardthis end, an active target searching capability, including prediction andnavigation toward vantage locations for finding human targets, is proposed. Theproposed capability aims at improving the robustness and efficiency fortracking and following people under dynamic conditions such as crowdedenvironments. A multi-modal sensor information approach including fusing anRGB-D sensor and a laser scanner, is pursued to robustly track and identifyhuman targets. Bayesian filtering for keeping track of human and a regressionalgorithm to predict the trajectory of people are investigated. In order tomake the robot autonomous, the proposed framework relies on a behavior-treestructure. Using Toyota Human Support Robot (HSR), real-time experimentsdemonstrate that the proposed architecture can generate fast, efficientperson-following behaviors.

Robot Representation and Reasoning with Knowledge from Reinforcement  Learning

  Reinforcement learning (RL) agents aim at learning by interacting with anenvironment, and are not designed for representing or reasoning withdeclarative knowledge. Knowledge representation and reasoning (KRR) paradigmsare strong in declarative KRR tasks, but are ill-equipped to learn from suchexperiences. In this work, we integrate logical-probabilistic KRR withmodel-based RL, enabling agents to simultaneously reason with declarativeknowledge and learn from interaction experiences. The knowledge from humans andRL is unified and used for dynamically computing task-specific planning modelsunder potentially new environments. Experiments were conducted using a mobilerobot working on dialog, navigation, and delivery tasks. Results showsignificant improvements, in comparison to existing model-based RL methods.

Interaction and Autonomy in RoboCup@Home and Building-Wide Intelligence

  Efforts are underway at UT Austin to build autonomous robot systems thataddress the challenges of long-term deployments in office environments and ofthe more prescribed domestic service tasks of the RoboCup@Home competition. Wediscuss the contrasts and synergies of these efforts, highlighting how our workto build a RoboCup@Home Domestic Standard Platform League entry led us toidentify an integrated software architecture that could support both projects.Further, naturalistic deployments of our office robot platform as part of theBuilding-Wide Intelligence project have led us to identify and research newproblems in a traditional laboratory setting.

Learning Curriculum Policies for Reinforcement Learning

  Curriculum learning in reinforcement learning is a training methodology thatseeks to speed up learning of a difficult target task, by first training on aseries of simpler tasks and transferring the knowledge acquired to the targettask. Automatically choosing a sequence of such tasks (i.e. a curriculum) is anopen problem that has been the subject of much recent work in this area. Inthis paper, we build upon a recent method for curriculum design, whichformulates the curriculum sequencing problem as a Markov Decision Process. Weextend this model to handle multiple transfer learning algorithms, and show forthe first time that a curriculum policy over this MDP can be learned fromexperience. We explore various representations that make this possible, andevaluate our approach by learning curriculum policies for multiple agents intwo different domains. The results show that our method produces curricula thatcan train agents to perform on a target task as fast or faster than existingmethods.

Improving Grounded Natural Language Understanding through Human-Robot  Dialog

  Natural language understanding for robotics can require substantial domain-and platform-specific engineering. For example, for mobile robots topick-and-place objects in an environment to satisfy human commands, we canspecify the language humans use to issue such commands, and connect conceptwords like red can to physical object properties. One way to alleviate thisengineering for a new domain is to enable robots in human environments to adaptdynamically---continually learning new language constructions and perceptualconcepts. In this work, we present an end-to-end pipeline for translatingnatural language commands to discrete robot actions, and use clarificationdialogs to jointly improve language parsing and concept grounding. We train andevaluate this agent in a virtual setting on Amazon Mechanical Turk, and wetransfer the learned agent to a physical robot platform to demonstrate it inthe real world.

Learning Analogies and Semantic Relations

  We present an algorithm for learning from unlabeled text, based on the VectorSpace Model (VSM) of information retrieval, that can solve verbal analogyquestions of the kind found in the Scholastic Aptitude Test (SAT). A verbalanalogy has the form A:B::C:D, meaning "A is to B as C is to D"; for example,mason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,and the problem is to select the most analogous word pair, C:D, from a set offive choices. The VSM algorithm correctly answers 47% of a collection of 374college-level analogy questions (random guessing would yield 20% correct). Wemotivate this research by relating it to work in cognitive science andlinguistics, and by applying it to a difficult problem in natural languageprocessing, determining semantic relations in noun-modifier pairs. The problemis to classify a noun-modifier pair, such as "laser printer", according to thesemantic relation between the noun (printer) and the modifier (laser). We use asupervised nearest-neighbour algorithm that assigns a class to a givennoun-modifier pair by finding the most analogous noun-modifier pair in thetraining data. With 30 classes of semantic relations, on a collection of 600labeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%(random guessing: 3.3%). With 5 classes of semantic relations, the F value is43.2% (random: 20%). The performance is state-of-the-art for these challengingproblems.

Human-Level Performance on Word Analogy Questions by Latent Relational  Analysis

  This paper introduces Latent Relational Analysis (LRA), a method formeasuring relational similarity. LRA has potential applications in many areas,including information extraction, word sense disambiguation, machinetranslation, and information retrieval. Relational similarity is correspondencebetween relations, in contrast with attributional similarity, which iscorrespondence between attributes. When two words have a high degree ofattributional similarity, we call them synonyms. When two pairs of words have ahigh degree of relational similarity, we say that their relations areanalogous. For example, the word pair mason/stone is analogous to the paircarpenter/wood. Past work on semantic similarity measures has mainly beenconcerned with attributional similarity. Recently the Vector Space Model (VSM)of information retrieval has been adapted to the task of measuring relationalsimilarity, achieving a score of 47% on a collection of 374 college-levelmultiple-choice word analogy questions. In the VSM approach, the relationbetween a pair of words is characterized by a vector of frequencies ofpredefined patterns in a large corpus. LRA extends the VSM approach in threeways: (1) the patterns are derived automatically from the corpus (they are notpredefined), (2) the Singular Value Decomposition (SVD) is used to smooth thefrequency data (it is also used this way in Latent Semantic Analysis), and (3)automatically generated synonyms are used to explore reformulations of the wordpairs. LRA achieves 56% on the 374 analogy questions, statistically equivalentto the average human score of 57%. On the related problem of classifyingnoun-modifier relations, LRA achieves similar gains over the VSM, while using asmaller corpus.

Corpus-based Learning of Analogies and Semantic Relations

  We present an algorithm for learning from unlabeled text, based on the VectorSpace Model (VSM) of information retrieval, that can solve verbal analogyquestions of the kind found in the SAT college entrance exam. A verbal analogyhas the form A:B::C:D, meaning "A is to B as C is to D"; for example,mason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,and the problem is to select the most analogous word pair, C:D, from a set offive choices. The VSM algorithm correctly answers 47% of a collection of 374college-level analogy questions (random guessing would yield 20% correct; theaverage college-bound senior high school student answers about 57% correctly).We motivate this research by applying it to a difficult problem in naturallanguage processing, determining semantic relations in noun-modifier pairs. Theproblem is to classify a noun-modifier pair, such as "laser printer", accordingto the semantic relation between the noun (printer) and the modifier (laser).We use a supervised nearest-neighbour algorithm that assigns a class to a givennoun-modifier pair by finding the most analogous noun-modifier pair in thetraining data. With 30 classes of semantic relations, on a collection of 600labeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%(random guessing: 3.3%). With 5 classes of semantic relations, the F value is43.2% (random: 20%). The performance is state-of-the-art for both verbalanalogies and noun-modifier relations.

Similarity of Semantic Relations

  There are at least two kinds of similarity. Relational similarity iscorrespondence between relations, in contrast with attributional similarity,which is correspondence between attributes. When two words have a high degreeof attributional similarity, we call them synonyms. When two pairs of wordshave a high degree of relational similarity, we say that their relations areanalogous. For example, the word pair mason:stone is analogous to the paircarpenter:wood. This paper introduces Latent Relational Analysis (LRA), amethod for measuring relational similarity. LRA has potential applications inmany areas, including information extraction, word sense disambiguation, andinformation retrieval. Recently the Vector Space Model (VSM) of informationretrieval has been adapted to measuring relational similarity, achieving ascore of 47% on a collection of 374 college-level multiple-choice word analogyquestions. In the VSM approach, the relation between a pair of words ischaracterized by a vector of frequencies of predefined patterns in a largecorpus. LRA extends the VSM approach in three ways: (1) the patterns arederived automatically from the corpus, (2) the Singular Value Decomposition(SVD) is used to smooth the frequency data, and (3) automatically generatedsynonyms are used to explore variations of the word pairs. LRA achieves 56% onthe 374 analogy questions, statistically equivalent to the average human scoreof 57%. On the related problem of classifying semantic relations, LRA achievessimilar gains over the VSM.

Analogy perception applied to seven tests of word comprehension

  It has been argued that analogy is the core of cognition. In AI research,algorithms for analogy are often limited by the need for hand-coded high-levelrepresentations as input. An alternative approach is to use high-levelperception, in which high-level representations are automatically generatedfrom raw data. Analogy perception is the process of recognizing analogies usinghigh-level perception. We present PairClass, an algorithm for analogyperception that recognizes lexical proportional analogies using representationsthat are automatically generated from a large corpus of raw textual data. Aproportional analogy is an analogy of the form A:B::C:D, meaning "A is to B asC is to D". A lexical proportional analogy is a proportional analogy withwords, such as carpenter:wood::mason:stone. PairClass represents the semanticrelations between two words using a high-dimensional feature vector, in whichthe elements are based on frequencies of patterns in the corpus. PairClassrecognizes analogies by applying standard supervised machine learningtechniques to the feature vectors. We show how seven different tests of wordcomprehension can be framed as problems of analogy perception and we then applyPairClass to the seven resulting sets of analogy perception problems. Weachieve competitive results on all seven tests. This is the first time auniform approach has handled such a range of tests of word comprehension.

Constraints on the Progenitors of SNeIa & Implications for the  Cosmological Equation of State

  Detailed calculations for the stellar evolution, explosion and light curveshave been performed to quantify the influence of the main sequence mass M(MS)and the metallicity of the progenitor on the structure of the exploding WDwhich are thought to be the progenitors of SNe Ia. In particular,we study theeffects of progenitors on the brightness decline relation M(dM_15) which is acorner stone for the use of SNe Ia as cosmological yard-stick.M(MS) has beenidentified as the decisive factor to change the energetics of the explosion anddominates the variations in the rise-time to decline relation of light curves.M(MS) has little effect on the color index B-V. For similar decline ratesdM_15, the flux at maximum brightness relative to the flux on the radioactivetail decreases systematically with M(MS) by about 0.2mag. This change goesalong with a reduc- tion of the photospheric expansion velocity $v_{ph}$ byabout 2000 km/sec. A change in the central density has the opposite dependency.The metallicity Z affects mainly the intrinsic color index B-V by up to-0.06mag, and it alters the fluxes in the U band and the UV. B-V is critical ifextinction corrections are applied. The spread in the fiducial rise-time todecline relation in local SNe Ia restricts the range of main sequence masses toa factor of 2. The upper limit of 1 day for the difference between the localand distance sample support the need for a positive cosmological constant. Thesize of evolutionary effects are small (dM abou 0.2mag) but are absolutelycritical for the reconstruction of the cosmological equation of state.

