An easy proof of the Stone-von Neumann-Mackey theorem

  The Stone-von Neumann-Mackey Theorem for Heisenberg groups associated to
locally compact abelian groups is proved using the Peter-Weyl theorem and the
theory of Fourier transforms for finite dimensional real vector spaces. A
theorem of Pontryagin and van Kampen on the structure of locally compact
abelian groups (which is evident in any particular case) is assumed.


Domain and Function: A Dual-Space Model of Semantic Relations and
  Compositions

  Given appropriate representations of the semantic relations between carpenter
and wood and between mason and stone (for example, vectors in a vector space
model), a suitable algorithm should be able to recognize that these relations
are highly similar (carpenter is to wood as mason is to stone; the relations
are analogous). Likewise, with representations of dog, house, and kennel, an
algorithm should be able to recognize that the semantic composition of dog and
house, dog house, is highly similar to kennel (dog house and kennel are
synonymous). It seems that these two tasks, recognizing relations and
compositions, are closely connected. However, up to now, the best models for
relations are significantly different from the best models for compositions. In
this paper, we introduce a dual-space model that unifies these two tasks. This
model matches the performance of the best previous models for relations and
compositions. The dual-space model consists of a space for measuring domain
similarity and a space for measuring function similarity. Carpenter and wood
share the same domain, the domain of carpentry. Mason and stone share the same
domain, the domain of masonry. Carpenter and mason share the same function, the
function of artisans. Wood and stone share the same function, the function of
materials. In the composition dog house, kennel has some domain overlap with
both dog and house (the domains of pets and buildings). The function of kennel
is similar to the function of house (the function of shelters). By combining
domain and function similarities in various ways, we can model relations,
compositions, and other aspects of semantics.


Continuum-sites stepping-stone models, coalescing exhcangeable
  partitions, and random trees

  Analogues of stepping--stone models are considered where the site--space is
continuous, the migration process is a general Markov process, and the
type--space is infinite. Such processes were defined in previous work of the
second author by specifying a Feller transition semigroup in terms of
expectations of suitable functionals for systems of coalescing Markov
processes. An alternative representation is obtained here in terms of a limit
of interacting particle systems. It is shown that, under a mild condition on
the migration process, the continuum--sites stepping--stone process has
continuous sample paths. The case when the migration process is Brownian motion
on the circle is examined in detail using a duality relation between coalescing
and annihilating Brownian motion. This duality relation is also used to show
that a random compact metric space that is naturally associated to an infinite
family of coalescing Brownian motions on the circle has Hausdorff and packing
dimension both almost surely equal to 1/2 and, moreover, this space is capacity
equivalent to the middle--1/2 Cantor set (and hence also to the Brownian zero
set).


An analogue of the Erd≈ës-Stone theorem for finite geometries

  For a set $G$ of points in $\PG(m-1,q)$, let $\ex_q(G;n)$, denote the maximum
size of a collection of points in $\PG(n-1,q)$ not containing a copy of $G$, up
to projective equivalence. We show that \[\lim_{n\rightarrow \infty}
\frac{\ex_q(G;n)}{|\PG(n-1,q)|} = 1-q^{1-c},\] where $c$ is the smallest
integer such that there is a rank-$(m-c)$ flat in $\PG(m-1,q)$ that is disjoint
from $G$. The result is an elementary application of the density version of the
Hales-Jewett Theorem.


Temperley-Lieb and Birman-Murakami-Wenzl like relations from
  multiplicity free semi-simple tensor system

  In this article we consider conditions under which projection operators in
multiplicity free semi-simple tensor categories satisfy Temperley-Lieb like
relations. This is then used as a stepping stone to prove sufficient conditions
for obtaining a representation of the Birman-Murakami-Wenzl algebra from a
braided multiplicity free semi-simple tensor category. The results are found by
utalising the data of the categories. There is considerable overlap with the
results found in arXiv:1607.08908, where proofs are shown by manipulating
diagrams.


Tuning of ferromagnetism through anion substitution in Ga-Mn-pnictide
  ferromagnetic semiconductors

  We have synthesized Ga1-xMnxAs1-yPy and Ga1-xMnxP1-yNy by the combination of
ion implantation and pulsed-laser melting. We find that the incorporation of
isovalent impurities with smaller atomic radii leads to a realignment of the
magnetic easy axis in Ga1-xMnxP1-yNy/GaP and Ga1-xMnxAs1-yPy/GaAs thin films
from in-plane to out-of-plane. This tensile-strain-induced magnetic anisotropy
is reminiscent of that observed in Ga1-xMnxAs grown on larger lattice constant
(In,Ga)As buffer layers indicating that the role of strain in determining
magnetic anisotropy is fundamental to III-Mn-V materials. In addition, we
observe a decrease in the ferromagnetic Curie temperature in Ga1-xMnxAs1-yPy
with increasing y from 0 to 0.028. Such a decrease may result from localization
of holes as the P/As ratio on the Group V sublattice increases.


Mn L3,2 X-ray Absorption Spectroscopy And Magnetic Circular Dichroism In
  Ferromagnetic (Ga,Mn)P

  We have measured the X-ray absorption (XAS) and X-ray magnetic circular
dichroism (XMCD) at the Mn L3,2 edges in ferromagnetic Ga1-xMnxP films for
0.018<x<0.042. Large XMCD asymmetries at the L3 edge indicate significant
spin-polarization of the density of states at the Fermi energy. The spectral
shapes of the XAS and XMCD are nearly identical with those for Ga1-xMnxAs
indicating that the hybridization of Mn d states and anion p states is similar
in the two materials. Finally, compensation with sulfur donors not only lowers
the ferromagnetic Curie temperature but also reduces the spin polarization of
the hole states.


Metal-insulator transition by isovalent anion substitution in
  Ga1-xMnxAs: Implications to ferromagnetism

  We have investigated the effect of partial isovalent anion substitution in
Ga1-xMnxAs on electrical transport and ferromagnetism. Substitution of only
2.4% of As by P induces a metal-insulator transition at a constant Mn doping of
x=0.046 while the replacement of 0.4 % As with N results in the crossover from
metal to insulator for x=0.037. This remarkable behavior is consistent with a
scenario in which holes located within an impurity band are scattered by alloy
disorder in the anion sublattice. The shorter mean free path of holes, which
mediate ferromagnetism, reduces the Curie temperature TC from 113 K to 60 K
(100 K to 65 K) upon the introduction of 3.1 % P (1% N) into the As sublattice.


Braids and combinatorial knot Floer homology

  We present a braid-theoretic approach to combinatorially computing knot Floer
homology. To a knot or link K, which is braided about the standard disk open
book decomposition for (S^3,\xi_std), we associate a corresponding
multi-pointed nice Heegaard diagram. We then describe an explicit algorithm for
computing the associated knot Floer homology groups. We compute explicit bounds
for the computational complexity of our algorithm and demonstrate that, in many
cases, it is significantly faster than the previous approach using grid
diagrams.


Transverse braids and combinatorial knot Floer homology

  We describe a new method for combinatorially computing the transverse
invariant in knot Floer homology. Previous work of the authors and Stone used
braid diagrams to combinatorially compute knot Floer homology of braid
closures. However, that approach was unable to explicitly identify the
invariant of transverse links that naturally appears in braid diagrams. In this
paper, we improve the previous approach in order to compute the transverse
invariant. We define a new combinatorial complex that computes knot Floer
homology and identify the BRAID invariant of transverse knots and links in the
homology of this complex.


Sprague-Grundy Function of Symmetric Hypergraphs

  We consider a generalization of the classical game of $NIM$ called hypergraph
$NIM$. Given a hypergraph $\cH$ on the ground set $V = \{1, \ldots, n\}$ of $n$
piles of stones, two players alternate in choosing a hyperedge $H \in \cH$ and
strictly decreasing all piles $i\in H$. The player who makes the last move is
the winner. Recently it was shown that for many classes of hypergraphs the
Sprague-Grundy function of the corresponding game is given by the formula
introduced originally by Jenkyns and Mayberry (1980). In this paper we
characterize symmetric hypergraphs for which the Sprague-Grundy function is
described by the same formula.


Learning a Policy for Opportunistic Active Learning

  Active learning identifies data points to label that are expected to be the
most useful in improving a supervised model. Opportunistic active learning
incorporates active learning into interactive tasks that constrain possible
queries during interactions. Prior work has shown that opportunistic active
learning can be used to improve grounding of natural language descriptions in
an interactive object retrieval task. In this work, we use reinforcement
learning for such an object retrieval task, to learn a policy that effectively
trades off task completion with model improvement that would benefit future
tasks.


Algorithm for obtaining the gradient expansion of the local density of
  states and the free energy of a superconductor

  We present an efficient algorithm for obtaining the gauge-invariant gradient
expansion of the local density of states and the free energy of a clean
superconductor. Our method is based on a new mapping of the semiclassical
linearized Gorkov equations onto a pseudo-Schroedinger equation for a
three-component wave-function psi(x), where one component is directly related
to the local density of states. Because psi(x) satisfies a linear equation of
motion, successive terms in the gradient expansion can be obtained by simple
linear iteration. Our method works equally well for real and complex order
parameter, and in the presence of arbitrary external fields. We confirm a
recent calculation of the fourth order correction to the free energy by
Kosztin, Kos, Stone and Leggett [Phys. Rev. B 58, 9365 (1998)], who obtained a
discrepancy with an earlier result by Tewordt [Z. Phys. 180, 385 (1964)]. We
also give the fourth order correction to the local density of states, which has
not been published before.


An effective theory for omega << k << gT color dynamics in hot
  non-Abelian plasmas

  A proper sequence of effective theories, corresponding to larger and larger
distance scales, is crucial for analyzing real-time equilibrium physics in hot
non-Abelian plasmas. For the study of color dynamics (by which I mean physics
involving long wavelength gauge fluctuations), an important stepping stone in
the sequence of effective theories is to have a good effective theory for
dynamics with wave number k well below the Debye screening mass. I review how
such dynamics is associated with inverse time scales omega << k. I then give a
compact way to package, in the omega << k limit, Bodeker's description of k <<
m physics, which was in terms of Vlasov equations with collision terms.
Finally, I show how the resulting effective theory can be reformulated as a
path integral.


Characterizing the variation of propagation constants in multicore fibre

  We demonstrate a numerical technique that can evaluate the core-to-core
variations in propagation constant in multicore fibre. Using a Markov Chain
Monte Carlo process, we replicate the interference patterns of light that has
coupled between the cores during propagation. We describe the algorithm and
verify its operation by successfully reconstructing target propagation
constants in a fictional fibre. Then we carry out a reconstruction of the
propagation constants in a real fibre containing 37 single-mode cores. We find
that the range of fractional propagation constant variation across the cores is
approximately $\pm2 \times 10^{-5}$.


Deep Spiking Networks

  We introduce an algorithm to do backpropagation on a spiking network. Our
network is "spiking" in the sense that our neurons accumulate their activation
into a potential over time, and only send out a signal (a "spike") when this
potential crosses a threshold and the neuron is reset. Neurons only update
their states when receiving signals from other neurons. Total computation of
the network thus scales with the number of spikes caused by an input rather
than network size. We show that the spiking Multi-Layer Perceptron behaves
identically, during both prediction and training, to a conventional deep
network of rectified-linear units, in the limiting case where we run the
spiking network for a long time. We apply this architecture to a conventional
classification problem (MNIST) and achieve performance very close to that of a
conventional Multi-Layer Perceptron with the same architecture. Our network is
a natural architecture for learning based on streaming event-based data, and is
a stepping stone towards using spiking neural networks to learn efficiently on
streaming data.


Athena: A New Code for Astrophysical MHD

  A new code for astrophysical magnetohydrodynamics (MHD) is described. The
code has been designed to be easily extensible for use with static and adaptive
mesh refinement. It combines higher-order Godunov methods with the constrained
transport (CT) technique to enforce the divergence-free constraint on the
magnetic field. Discretization is based on cell-centered volume-averages for
mass, momentum, and energy, and face-centered area-averages for the magnetic
field. Novel features of the algorithm include (1) a consistent framework for
computing the time- and edge-averaged electric fields used by CT to evolve the
magnetic field from the time- and area-averaged Godunov fluxes, (2) the
extension to MHD of spatial reconstruction schemes that involve a
dimensionally-split time advance, and (3) the extension to MHD of two different
dimensionally-unsplit integration methods. Implementation of the algorithm in
both C and Fortran95 is detailed, including strategies for parallelization
using domain decomposition. Results from a test suite which includes problems
in one-, two-, and three-dimensions for both hydrodynamics and MHD are given,
not only to demonstrate the fidelity of the algorithms, but also to enable
comparisons to other methods. The source code is freely available for download
on the web.


Compensation-dependent in-plane magnetization reversal processes in
  Ga1-xMnxP1-ySy

  We report the effect of dilute alloying of the anion sublattice with S on the
in-plane uniaxial magnetic anisotropy and magnetization reversal process in
Ga1-xMnxP as measured by both ferromagnetic resonance (FMR) and superconducting
quantum interference device (SQUID) magnetometry. At T=5K, raising the S
concentration increases the uniaxial magnetic anisotropy between in-plane <011>
directions while decreasing the magnitude of the (negative) cubic anisotropy
field. Simulation of the SQUID magnetometry indicates that the energy required
for the nucleation and growth of domain walls decreases with increasing y.
These combined effects have a marked influence on the shape of the
field-dependent magnetization curves; while the direction remains the easy axis
in the plane of the film, the field dependence of the magnetization develops
double hysteresis loops in the [011] direction as the S concentration increases
similar to those observed for perpendicular magnetization reversal in lightly
doped Ga1-xMnxAs. The incidence of double hysteresis loops is explained with a
simple model whereby magnetization reversal occurs by a combination of coherent
spin rotation and noncoherent spin switching, which is consistent with both FMR
and magnetometry experiments. The evolution of magnetic properties with S
concentration is attributed to compensation of Mn acceptors by S donors, which
results in a lowering of the concentration of holes that mediate
ferromagnetism.


Computational Topology for Regular Closed Sets

  The Boolean algebra of regular closed sets is prominent in topology,
particularly as a dual for the Stone-Cech compactification. This algebra is
also central for the theory of geometric computation, as a representation for
combinatorial operations on geometric sets. However, the issue of computational
approximation introduces unresolved subtleties that do not occur within "pure"
topology. One major effort towards reconciling this mathematical theory with
computational practice is our ongoing I-TANGO project. The acronym I-TANGO is
an abbreviation for "Intersections - Topology, Accuracy and Numerics for
Geometric Objects". The long-range goals and initial progress of the I-TANGO
team in development of computational topology are presented.


Correlation between structure and electrical transport in ion-irradiated
  graphene grown on Cu foils

  Graphene grown by chemical vapor deposition and supported on SiO2 and
sapphire substrates was studied following controlled introduction of defects
induced by 35 keV carbon ion irradiation. Changes in Raman spectra following
fluences ranging from 10^12 cm^-2 to 10^15 cm^-2 indicate that the structure of
graphene evolves from a highly ordered layer, to a patchwork of disordered
domains, to an essentially amorphous film. These structural changes result in a
dramatic decrease in the Hall mobility by orders of magnitude while,
remarkably, the Hall concentration remains almost unchanged, suggesting that
the Fermi level is pinned at a hole concentration near 1x10^13 cm^-2. A model
for scattering by resonant scatterers is in good agreement with mobility
measurements up to an ion fluence of 1x10^14 cm^-2.


A Real-Time Model-Based Reinforcement Learning Architecture for Robot
  Control

  Reinforcement Learning (RL) is a method for learning decision-making tasks
that could enable robots to learn and adapt to their situation on-line. For an
RL algorithm to be practical for robotic control tasks, it must learn in very
few actions, while continually taking those actions in real-time. Existing
model-based RL methods learn in relatively few actions, but typically take too
much time between each action for practical on-line learning. In this paper, we
present a novel parallel architecture for model-based RL that runs in real-time
by 1) taking advantage of sample-based approximate planning methods and 2)
parallelizing the acting, model learning, and planning processes such that the
acting process is sufficiently fast for typical robot control cycles. We
demonstrate that algorithms using this architecture perform nearly as well as
methods using the typical sequential architecture when both are given unlimited
time, and greatly out-perform these methods on tasks that require real-time
actions such as controlling an autonomous vehicle.


Gaussian Processes for Sample Efficient Reinforcement Learning with
  RMAX-like Exploration

  We present an implementation of model-based online reinforcement learning
(RL) for continuous domains with deterministic transitions that is specifically
designed to achieve low sample complexity. To achieve low sample complexity,
since the environment is unknown, an agent must intelligently balance
exploration and exploitation, and must be able to rapidly generalize from
observations. While in the past a number of related sample efficient RL
algorithms have been proposed, to allow theoretical analysis, mainly
model-learners with weak generalization capabilities were considered. Here, we
separate function approximation in the model learner (which does require
samples) from the interpolation in the planner (which does not require
samples). For model-learning we apply Gaussian processes regression (GP) which
is able to automatically adjust itself to the complexity of the problem (via
Bayesian hyperparameter selection) and, in practice, often able to learn a
highly accurate model from very little data. In addition, a GP provides a
natural way to determine the uncertainty of its predictions, which allows us to
implement the "optimism in the face of uncertainty" principle used to
efficiently control exploration. Our method is evaluated on four common
benchmark domains.


Feature Selection for Value Function Approximation Using Bayesian Model
  Selection

  Feature selection in reinforcement learning (RL), i.e. choosing basis
functions such that useful approximations of the unkown value function can be
obtained, is one of the main challenges in scaling RL to real-world
applications. Here we consider the Gaussian process based framework GPTD for
approximate policy evaluation, and propose feature selection through marginal
likelihood optimization of the associated hyperparameters. Our approach has two
appealing benefits: (1) given just sample transitions, we can solve the policy
evaluation problem fully automatically (without looking at the learning task,
and, in theory, independent of the dimensionality of the state space), and (2)
model selection allows us to consider more sophisticated kernels, which in turn
enable us to identify relevant subspaces and eliminate irrelevant state
variables such that we can achieve substantial computational savings and
improved prediction performance.


DJ-MC: A Reinforcement-Learning Agent for Music Playlist Recommendation

  In recent years, there has been growing focus on the study of automated
recommender systems. Music recommendation systems serve as a prominent domain
for such works, both from an academic and a commercial perspective. A
fundamental aspect of music perception is that music is experienced in temporal
context and in sequence. In this work we present DJ-MC, a novel
reinforcement-learning framework for music recommendation that does not
recommend songs individually but rather song sequences, or playlists, based on
a model of preferences for both songs and song transitions. The model is
learned online and is uniquely adapted for each listener. To reduce exploration
time, DJ-MC exploits user feedback to initialize a model, which it subsequently
updates by reinforcement. We evaluate our framework with human participants
using both real song and playlist data. Our results indicate that DJ-MC's
ability to recommend sequences of songs provides a significant improvement over
more straightforward approaches, which do not take transitions into account.


Curvature suppresses the Rayleigh-Taylor instability

  The dynamics of a thin liquid film on the underside of a curved cylindrical
substrate is studied. The evolution of the liquid layer is investigated as the
film thickness and the radius of curvature of the substrate are varied. A
dimensionless parameter (a modified Bond number) that incorporates both
geometric parameters, gravity, and surface tension is identified, and allows
the observations to be classified according to three different flow regimes:
stable films, films with transient growth of perturbations followed by decay,
and unstable films. Experiments and theory confirm that, below a critical value
of the Bond number, curvature of the substrate suppresses the Rayleigh-Taylor
instability.


Deep Reinforcement Learning in Parameterized Action Space

  Recent work has shown that deep neural networks are capable of approximating
both value functions and policies in reinforcement learning domains featuring
continuous state and action spaces. However, to the best of our knowledge no
previous work has succeeded at using deep neural networks in structured
(parameterized) continuous action spaces. To fill this gap, this paper focuses
on learning within the domain of simulated RoboCup soccer, which features a
small set of discrete action types, each of which is parameterized with
continuous variables. The best learned agent can score goals more reliably than
the 2012 RoboCup champion agent. As such, this paper represents a successful
extension of deep reinforcement learning to the class of parameterized action
space MDPs.


Representative Selection in Non Metric Datasets

  This paper considers the problem of representative selection: choosing a
subset of data points from a dataset that best represents its overall set of
elements. This subset needs to inherently reflect the type of information
contained in the entire set, while minimizing redundancy. For such purposes,
clustering may seem like a natural approach. However, existing clustering
methods are not ideally suited for representative selection, especially when
dealing with non-metric data, where only a pairwise similarity measure exists.
In this paper we propose $\delta$-medoids, a novel approach that can be viewed
as an extension to the $k$-medoids algorithm and is specifically suited for
sample representative selection from non-metric data. We empirically validate
$\delta$-medoids in two domains, namely music analysis and motion analysis. We
also show some theoretical bounds on the performance of $\delta$-medoids and
the hardness of representative selection in general.


Deep Recurrent Q-Learning for Partially Observable MDPs

  Deep Reinforcement Learning has yielded proficient controllers for complex
tasks. However, these controllers have limited memory and rely on being able to
perceive the complete game screen at each decision point. To address these
shortcomings, this article investigates the effects of adding recurrency to a
Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected
layer with a recurrent LSTM. The resulting \textit{Deep Recurrent Q-Network}
(DRQN), although capable of seeing only a single frame at each timestep,
successfully integrates information through time and replicates DQN's
performance on standard Atari games and partially observed equivalents
featuring flickering game screens. Additionally, when trained with partial
observations and evaluated with incrementally more complete observations,
DRQN's performance scales as a function of observability. Conversely, when
trained with full observations and evaluated with partial observations, DRQN's
performance degrades less than DQN's. Thus, given the same length of history,
recurrency is a viable alternative to stacking a history of frames in the DQN's
input layer and while recurrency confers no systematic advantage when learning
to play the game, the recurrent net can better adapt at evaluation time if the
quality of observations changes.


Data-Efficient Policy Evaluation Through Behavior Policy Search

  We consider the task of evaluating a policy for a Markov decision process
(MDP). The standard unbiased technique for evaluating a policy is to deploy the
policy and observe its performance. We show that the data collected from
deploying a different policy, commonly called the behavior policy, can be used
to produce unbiased estimates with lower mean squared error than this standard
technique. We derive an analytic expression for the optimal behavior policy ---
the behavior policy that minimizes the mean squared error of the resulting
estimates. Because this expression depends on terms that are unknown in
practice, we propose a novel policy evaluation sub-problem, behavior policy
search: searching for a behavior policy that reduces mean squared error. We
present a behavior policy search algorithm and empirically demonstrate its
effectiveness in lowering the mean squared error of policy performance
estimates.


FPGA-Based Tracklet Approach to Level-1 Track Finding at CMS for the
  HL-LHC

  During the High Luminosity LHC, the CMS detector will need charged particle
tracking at the hardware trigger level to maintain a manageable trigger rate
and achieve its physics goals. The tracklet approach is a track-finding
algorithm based on a road-search algorithm that has been implemented on
commercially available FPGA technology. The tracklet algorithm has achieved
high performance in track-finding and completes tracking within 3.4 $\mu$s on a
Xilinx Virtex-7 FPGA. An overview of the algorithm and its implementation on an
FPGA is given, results are shown from a demonstrator test stand and system
performance studies are presented.


Scalable Training of Artificial Neural Networks with Adaptive Sparse
  Connectivity inspired by Network Science

  Through the success of deep learning in various domains, artificial neural
networks are currently among the most used artificial intelligence methods.
Taking inspiration from the network properties of biological neural networks
(e.g. sparsity, scale-freeness), we argue that (contrary to general practice)
artificial neural networks, too, should not have fully-connected layers. Here
we propose sparse evolutionary training of artificial neural networks, an
algorithm which evolves an initial sparse topology (Erd\H{o}s-R\'enyi random
graph) of two consecutive layers of neurons into a scale-free topology, during
learning. Our method replaces artificial neural networks fully-connected layers
with sparse ones before training, reducing quadratically the number of
parameters, with no decrease in accuracy. We demonstrate our claims on
restricted Boltzmann machines, multi-layer perceptrons, and convolutional
neural networks for unsupervised and supervised learning on 15 datasets. Our
approach has the potential to enable artificial neural networks to scale up
beyond what is currently possible.


Breaking Bellman's Curse of Dimensionality: Efficient Kernel Gradient
  Temporal Difference

  We consider policy evaluation in infinite-horizon discounted Markov decision
problems (MDPs) with infinite spaces. We reformulate this task a compositional
stochastic program with a function-valued decision variable that belongs to a
reproducing kernel Hilbert space (RKHS). We approach this problem via a new
functional generalization of stochastic quasi-gradient methods operating in
tandem with stochastic sparse subspace projections. The result is an extension
of gradient temporal difference learning that yields nonlinearly parameterized
value function estimates of the solution to the Bellman evaluation equation.
Our main contribution is a memory-efficient non-parametric stochastic method
guaranteed to converge exactly to the Bellman fixed point with probability $1$
with attenuating step-sizes. Further, with constant step-sizes, we obtain mean
convergence to a neighborhood and that the value function estimates have finite
complexity. In the Mountain Car domain, we observe faster convergence to lower
Bellman error solutions than existing approaches with a fraction of the
required memory.


Autonomous Agents Modelling Other Agents: A Comprehensive Survey and
  Open Problems

  Much research in artificial intelligence is concerned with the development of
autonomous agents that can interact effectively with other agents. An important
aspect of such agents is the ability to reason about the behaviours of other
agents, by constructing models which make predictions about various properties
of interest (such as actions, goals, beliefs) of the modelled agents. A variety
of modelling approaches now exist which vary widely in their methodology and
underlying assumptions, catering to the needs of the different sub-communities
within which they were developed and reflecting the different practical uses
for which they are intended. The purpose of the present article is to provide a
comprehensive survey of the salient modelling methods which can be found in the
literature. The article concludes with a discussion of open problems which may
form the basis for fruitful future research.


Sprague-Grundy Function of Matroids and Related Hypergraphs

  We consider a generalization of the classical game of $NIM$ called hypergraph
$NIM$. Given a hypergraph $\cH$ on the ground set $V = \{1, \ldots, n\}$ of $n$
piles of stones, two players alternate in choosing a hyperedge $H \in \cH$ and
strictly decreasing all piles $i\in H$. The player who makes the last move is
the winner. In this paper we give an explicit formula that describes the
Sprague-Grundy function of hypergraph $NIM$ for several classes of hypergraphs.
In particular we characterize all $2$-uniform hypergraphs (that is graphs) and
all matroids for which the formula works. We show that all self-dual matroids
are included in this class.


Behavioral Cloning from Observation

  Humans often learn how to perform tasks via imitation: they observe others
perform a task, and then very quickly infer the appropriate actions to take
based on their observations. While extending this paradigm to autonomous agents
is a well-studied problem in general, there are two particular aspects that
have largely been overlooked: (1) that the learning is done from observation
only (i.e., without explicit action information), and (2) that the learning is
typically done very quickly. In this work, we propose a two-phase, autonomous
imitation learning technique called behavioral cloning from observation (BCO),
that aims to provide improved performance with respect to both of these
aspects. First, we allow the agent to acquire experience in a self-supervised
fashion. This experience is used to develop a model which is then utilized to
learn a particular task by observing an expert perform that task without the
knowledge of the specific actions taken. We experimentally compare BCO to
imitation learning methods, including the state-of-the-art, generative
adversarial imitation learning (GAIL) technique, and we show comparable task
performance in several different simulation domains while exhibiting increased
learning speed after expert trajectories become available.


Importance Sampling Policy Evaluation with an Estimated Behavior Policy

  We consider the problem of off-policy evaluation in Markov decision
processes. Off-policy evaluation is the task of evaluating the expected return
of one policy with data generated by a different, behavior policy. Importance
sampling is a technique for off-policy evaluation that re-weights off-policy
returns to account for differences in the likelihood of the returns between the
two policies. In this paper, we study importance sampling with an estimated
behavior policy where the behavior policy estimate comes from the same set of
data used to compute the importance sampling estimate. We find that this
estimator often lowers the mean squared error of off-policy evaluation compared
to importance sampling with the true behavior policy or using a behavior policy
that is estimated from a separate data set. Our empirical results also extend
to other popular variants of importance sampling and show that estimating a
non-Markovian behavior policy can further lower mean squared error even when
the true behavior policy is Markovian.


Generative Adversarial Imitation from Observation

  Imitation from observation (IfO) is the problem of learning directly from
state-only demonstrations without having access to the demonstrator's actions.
The lack of action information both distinguishes IfO from most of the
literature in imitation learning, and also sets it apart as a method that may
enable agents to learn from a large set of previously inapplicable resources
such as internet videos. In this paper, we propose both a general framework for
IfO approaches and also a new IfO approach based on generative adversarial
networks called generative adversarial imitation from observation (GAIfO). We
conduct experiments in two different settings: (1) when demonstrations consist
of low-dimensional, manually-defined state features, and (2) when
demonstrations consist of high-dimensional, raw visual data. We demonstrate
that our approach performs comparably to classical imitation learning
approaches (which have access to the demonstrator's actions) and significantly
outperforms existing imitation from observation methods in high-dimensional
simulation environments.


A Century Long Commitment to Assessing Artificial Intelligence and its
  Impact on Society

  In September 2016, Stanford's "One Hundred Year Study on Artificial
Intelligence" project (AI100) issued the first report of its planned long-term
periodic assessment of artificial intelligence (AI) and its impact on society.
The report, entitled "Artificial Intelligence and Life in 2030," examines eight
domains of typical urban settings on which AI is likely to have impact over the
coming years: transportation, home and service robots, healthcare, education,
public safety and security, low-resource communities, employment and workplace,
and entertainment. It aims to provide the general public with a scientifically
and technologically accurate portrayal of the current state of AI and its
potential and to help guide decisions in industry and governments, as well as
to inform research and development in the field. This article by the chair of
the 2016 Study Panel and the inaugural chair of the AI100 Standing Committee
describes the origins of this ambitious longitudinal study, discusses the
framing of the inaugural report, and presents the report's main findings. It
concludes with a brief description of the AI100 project's ongoing efforts and
planned next steps.


Deterministic Implementations for Reproducibility in Deep Reinforcement
  Learning

  While deep reinforcement learning (DRL) has led to numerous successes in
recent years, reproducing these successes can be extremely challenging. One
reproducibility challenge particularly relevant to DRL is nondeterminism in the
training process, which can substantially affect the results. Motivated by this
challenge, we study the positive impacts of deterministic implementations in
eliminating nondeterminism in training. To do so, we consider the particular
case of the deep Q-learning algorithm, for which we produce a deterministic
implementation by identifying and controlling all sources of nondeterminism in
the training process. One by one, we then allow individual sources of
nondeterminism to affect our otherwise deterministic implementation, and
measure the impact of each source on the variance in performance. We find that
individual sources of nondeterminism can substantially impact the performance
of agent, illustrating the benefits of deterministic implementations. In
addition, we also discuss the important role of deterministic implementations
in achieving exact replicability of results.


An Architecture for Person-Following using Active Target Search

  This paper addresses a novel architecture for person-following robots using
active search. The proposed system can be applied in real-time to general
mobile robots for learning features of a human, detecting and tracking, and
finally navigating towards that person. To succeed at person-following,
perception, planning, and robot behavior need to be integrated properly. Toward
this end, an active target searching capability, including prediction and
navigation toward vantage locations for finding human targets, is proposed. The
proposed capability aims at improving the robustness and efficiency for
tracking and following people under dynamic conditions such as crowded
environments. A multi-modal sensor information approach including fusing an
RGB-D sensor and a laser scanner, is pursued to robustly track and identify
human targets. Bayesian filtering for keeping track of human and a regression
algorithm to predict the trajectory of people are investigated. In order to
make the robot autonomous, the proposed framework relies on a behavior-tree
structure. Using Toyota Human Support Robot (HSR), real-time experiments
demonstrate that the proposed architecture can generate fast, efficient
person-following behaviors.


Robot Representation and Reasoning with Knowledge from Reinforcement
  Learning

  Reinforcement learning (RL) agents aim at learning by interacting with an
environment, and are not designed for representing or reasoning with
declarative knowledge. Knowledge representation and reasoning (KRR) paradigms
are strong in declarative KRR tasks, but are ill-equipped to learn from such
experiences. In this work, we integrate logical-probabilistic KRR with
model-based RL, enabling agents to simultaneously reason with declarative
knowledge and learn from interaction experiences. The knowledge from humans and
RL is unified and used for dynamically computing task-specific planning models
under potentially new environments. Experiments were conducted using a mobile
robot working on dialog, navigation, and delivery tasks. Results show
significant improvements, in comparison to existing model-based RL methods.


Interaction and Autonomy in RoboCup@Home and Building-Wide Intelligence

  Efforts are underway at UT Austin to build autonomous robot systems that
address the challenges of long-term deployments in office environments and of
the more prescribed domestic service tasks of the RoboCup@Home competition. We
discuss the contrasts and synergies of these efforts, highlighting how our work
to build a RoboCup@Home Domestic Standard Platform League entry led us to
identify an integrated software architecture that could support both projects.
Further, naturalistic deployments of our office robot platform as part of the
Building-Wide Intelligence project have led us to identify and research new
problems in a traditional laboratory setting.


Learning Curriculum Policies for Reinforcement Learning

  Curriculum learning in reinforcement learning is a training methodology that
seeks to speed up learning of a difficult target task, by first training on a
series of simpler tasks and transferring the knowledge acquired to the target
task. Automatically choosing a sequence of such tasks (i.e. a curriculum) is an
open problem that has been the subject of much recent work in this area. In
this paper, we build upon a recent method for curriculum design, which
formulates the curriculum sequencing problem as a Markov Decision Process. We
extend this model to handle multiple transfer learning algorithms, and show for
the first time that a curriculum policy over this MDP can be learned from
experience. We explore various representations that make this possible, and
evaluate our approach by learning curriculum policies for multiple agents in
two different domains. The results show that our method produces curricula that
can train agents to perform on a target task as fast or faster than existing
methods.


Improving Grounded Natural Language Understanding through Human-Robot
  Dialog

  Natural language understanding for robotics can require substantial domain-
and platform-specific engineering. For example, for mobile robots to
pick-and-place objects in an environment to satisfy human commands, we can
specify the language humans use to issue such commands, and connect concept
words like red can to physical object properties. One way to alleviate this
engineering for a new domain is to enable robots in human environments to adapt
dynamically---continually learning new language constructions and perceptual
concepts. In this work, we present an end-to-end pipeline for translating
natural language commands to discrete robot actions, and use clarification
dialogs to jointly improve language parsing and concept grounding. We train and
evaluate this agent in a virtual setting on Amazon Mechanical Turk, and we
transfer the learned agent to a physical robot platform to demonstrate it in
the real world.


Learning Analogies and Semantic Relations

  We present an algorithm for learning from unlabeled text, based on the Vector
Space Model (VSM) of information retrieval, that can solve verbal analogy
questions of the kind found in the Scholastic Aptitude Test (SAT). A verbal
analogy has the form A:B::C:D, meaning "A is to B as C is to D"; for example,
mason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,
and the problem is to select the most analogous word pair, C:D, from a set of
five choices. The VSM algorithm correctly answers 47% of a collection of 374
college-level analogy questions (random guessing would yield 20% correct). We
motivate this research by relating it to work in cognitive science and
linguistics, and by applying it to a difficult problem in natural language
processing, determining semantic relations in noun-modifier pairs. The problem
is to classify a noun-modifier pair, such as "laser printer", according to the
semantic relation between the noun (printer) and the modifier (laser). We use a
supervised nearest-neighbour algorithm that assigns a class to a given
noun-modifier pair by finding the most analogous noun-modifier pair in the
training data. With 30 classes of semantic relations, on a collection of 600
labeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%
(random guessing: 3.3%). With 5 classes of semantic relations, the F value is
43.2% (random: 20%). The performance is state-of-the-art for these challenging
problems.


Human-Level Performance on Word Analogy Questions by Latent Relational
  Analysis

  This paper introduces Latent Relational Analysis (LRA), a method for
measuring relational similarity. LRA has potential applications in many areas,
including information extraction, word sense disambiguation, machine
translation, and information retrieval. Relational similarity is correspondence
between relations, in contrast with attributional similarity, which is
correspondence between attributes. When two words have a high degree of
attributional similarity, we call them synonyms. When two pairs of words have a
high degree of relational similarity, we say that their relations are
analogous. For example, the word pair mason/stone is analogous to the pair
carpenter/wood. Past work on semantic similarity measures has mainly been
concerned with attributional similarity. Recently the Vector Space Model (VSM)
of information retrieval has been adapted to the task of measuring relational
similarity, achieving a score of 47% on a collection of 374 college-level
multiple-choice word analogy questions. In the VSM approach, the relation
between a pair of words is characterized by a vector of frequencies of
predefined patterns in a large corpus. LRA extends the VSM approach in three
ways: (1) the patterns are derived automatically from the corpus (they are not
predefined), (2) the Singular Value Decomposition (SVD) is used to smooth the
frequency data (it is also used this way in Latent Semantic Analysis), and (3)
automatically generated synonyms are used to explore reformulations of the word
pairs. LRA achieves 56% on the 374 analogy questions, statistically equivalent
to the average human score of 57%. On the related problem of classifying
noun-modifier relations, LRA achieves similar gains over the VSM, while using a
smaller corpus.


Corpus-based Learning of Analogies and Semantic Relations

  We present an algorithm for learning from unlabeled text, based on the Vector
Space Model (VSM) of information retrieval, that can solve verbal analogy
questions of the kind found in the SAT college entrance exam. A verbal analogy
has the form A:B::C:D, meaning "A is to B as C is to D"; for example,
mason:stone::carpenter:wood. SAT analogy questions provide a word pair, A:B,
and the problem is to select the most analogous word pair, C:D, from a set of
five choices. The VSM algorithm correctly answers 47% of a collection of 374
college-level analogy questions (random guessing would yield 20% correct; the
average college-bound senior high school student answers about 57% correctly).
We motivate this research by applying it to a difficult problem in natural
language processing, determining semantic relations in noun-modifier pairs. The
problem is to classify a noun-modifier pair, such as "laser printer", according
to the semantic relation between the noun (printer) and the modifier (laser).
We use a supervised nearest-neighbour algorithm that assigns a class to a given
noun-modifier pair by finding the most analogous noun-modifier pair in the
training data. With 30 classes of semantic relations, on a collection of 600
labeled noun-modifier pairs, the learning algorithm attains an F value of 26.5%
(random guessing: 3.3%). With 5 classes of semantic relations, the F value is
43.2% (random: 20%). The performance is state-of-the-art for both verbal
analogies and noun-modifier relations.


Similarity of Semantic Relations

  There are at least two kinds of similarity. Relational similarity is
correspondence between relations, in contrast with attributional similarity,
which is correspondence between attributes. When two words have a high degree
of attributional similarity, we call them synonyms. When two pairs of words
have a high degree of relational similarity, we say that their relations are
analogous. For example, the word pair mason:stone is analogous to the pair
carpenter:wood. This paper introduces Latent Relational Analysis (LRA), a
method for measuring relational similarity. LRA has potential applications in
many areas, including information extraction, word sense disambiguation, and
information retrieval. Recently the Vector Space Model (VSM) of information
retrieval has been adapted to measuring relational similarity, achieving a
score of 47% on a collection of 374 college-level multiple-choice word analogy
questions. In the VSM approach, the relation between a pair of words is
characterized by a vector of frequencies of predefined patterns in a large
corpus. LRA extends the VSM approach in three ways: (1) the patterns are
derived automatically from the corpus, (2) the Singular Value Decomposition
(SVD) is used to smooth the frequency data, and (3) automatically generated
synonyms are used to explore variations of the word pairs. LRA achieves 56% on
the 374 analogy questions, statistically equivalent to the average human score
of 57%. On the related problem of classifying semantic relations, LRA achieves
similar gains over the VSM.


Analogy perception applied to seven tests of word comprehension

  It has been argued that analogy is the core of cognition. In AI research,
algorithms for analogy are often limited by the need for hand-coded high-level
representations as input. An alternative approach is to use high-level
perception, in which high-level representations are automatically generated
from raw data. Analogy perception is the process of recognizing analogies using
high-level perception. We present PairClass, an algorithm for analogy
perception that recognizes lexical proportional analogies using representations
that are automatically generated from a large corpus of raw textual data. A
proportional analogy is an analogy of the form A:B::C:D, meaning "A is to B as
C is to D". A lexical proportional analogy is a proportional analogy with
words, such as carpenter:wood::mason:stone. PairClass represents the semantic
relations between two words using a high-dimensional feature vector, in which
the elements are based on frequencies of patterns in the corpus. PairClass
recognizes analogies by applying standard supervised machine learning
techniques to the feature vectors. We show how seven different tests of word
comprehension can be framed as problems of analogy perception and we then apply
PairClass to the seven resulting sets of analogy perception problems. We
achieve competitive results on all seven tests. This is the first time a
uniform approach has handled such a range of tests of word comprehension.


Constraints on the Progenitors of SNeIa & Implications for the
  Cosmological Equation of State

  Detailed calculations for the stellar evolution, explosion and light curves
have been performed to quantify the influence of the main sequence mass M(MS)
and the metallicity of the progenitor on the structure of the exploding WD
which are thought to be the progenitors of SNe Ia. In particular,we study the
effects of progenitors on the brightness decline relation M(dM_15) which is a
corner stone for the use of SNe Ia as cosmological yard-stick.M(MS) has been
identified as the decisive factor to change the energetics of the explosion and
dominates the variations in the rise-time to decline relation of light curves.
M(MS) has little effect on the color index B-V. For similar decline rates
dM_15, the flux at maximum brightness relative to the flux on the radioactive
tail decreases systematically with M(MS) by about 0.2mag. This change goes
along with a reduc- tion of the photospheric expansion velocity $v_{ph}$ by
about 2000 km/sec. A change in the central density has the opposite dependency.
The metallicity Z affects mainly the intrinsic color index B-V by up to
-0.06mag, and it alters the fluxes in the U band and the UV. B-V is critical if
extinction corrections are applied. The spread in the fiducial rise-time to
decline relation in local SNe Ia restricts the range of main sequence masses to
a factor of 2. The upper limit of 1 day for the difference between the local
and distance sample support the need for a positive cosmological constant. The
size of evolutionary effects are small (dM abou 0.2mag) but are absolutely
critical for the reconstruction of the cosmological equation of state.


