Probing Hamiltonian field redefinition on the nontrivial conformal
  algebra

  The compatibility between the conformal symmetry and the closure of conformal
algebras is discussed on the nonlinear sigma model. The present approach, above
the basis of field redefinition employed in the Hamiltonian scheme, attempts
the method of quantisation with intuitive picture. As a general field theoretic
treatment, the consistency is ensured by means of the interesting features
which are observed in the historical studies for the gauge-invariant conformal
symmetry. The identification of conformal anomaly is also shown coincident with
the conventional one approached within the path-integral formulation.


Exploring Network Economics

  In this paper, we explore what \emph{network economics} is all about,
focusing on the interesting topics brought about by the Internet. Our intent is
make this a brief survey, useful as an outline for a course on this topic, with
an extended list of references. We try to make it as intuitive and readable as
possible. We also deliberately try to be critical at times, and hope our
interpretation of the topic will lead to interests for further discussions by
those doing research in the same field.


The Finite-time Ruin Probabilities of a Bidimensional risk model with
  Constant Interest Force and correlated Brownian Motions

  We follow some recent works to study bidimensional perturbed compound Poisson
risk models with constant interest force and correlated Brownian Motions.
Several asymptotic formulae for three different type of ruin probabilities over
a finite-time horizon are established.
  Our approach appeals directly to very recent developments in the ruin theory
in the presence of heavy tails of unidimensional risk models and the dependence
theory of stochastic processes and random vectors.


Kernel Sparse Subspace Clustering on Symmetric Positive Definite
  Manifolds

  Sparse subspace clustering (SSC), as one of the most successful subspace
clustering methods, has achieved notable clustering accuracy in computer vision
tasks. However, SSC applies only to vector data in Euclidean space. As such,
there is still no satisfactory approach to solve subspace clustering by ${\it
self-expressive}$ principle for symmetric positive definite (SPD) matrices
which is very useful in computer vision. In this paper, by embedding the SPD
matrices into a Reproducing Kernel Hilbert Space (RKHS), a kernel subspace
clustering method is constructed on the SPD manifold through an appropriate
Log-Euclidean kernel, termed as kernel sparse subspace clustering on the SPD
Riemannian manifold (KSSCR). By exploiting the intrinsic Riemannian geometry
within data, KSSCR can effectively characterize the geodesic distance between
SPD matrices to uncover the underlying subspace structure. Experimental results
on two famous database demonstrate that the proposed method achieves better
clustering results than the state-of-the-art approaches.


Neighborhood Preserved Sparse Representation for Robust Classification
  on Symmetric Positive Definite Matrices

  Due to its promising classification performance, sparse representation based
classification(SRC) algorithm has attracted great attention in the past few
years. However, the existing SRC type methods apply only to vector data in
Euclidean space. As such, there is still no satisfactory approach to conduct
classification task for symmetric positive definite (SPD) matrices which is
very useful in computer vision. To address this problem, in this paper, a
neighborhood preserved kernel SRC method is proposed on SPD manifolds.
Specifically, by embedding the SPD matrices into a Reproducing Kernel Hilbert
Space (RKHS), the proposed method can perform classification on SPD manifolds
through an appropriate Log-Euclidean kernel. Through exploiting the geodesic
distance between SPD matrices, our method can effectively characterize the
intrinsic local Riemannian geometry within data so as to well unravel the
underlying sub-manifold structure. Despite its simplicity, experimental results
on several famous database demonstrate that the proposed method achieves better
classification results than the state-of-the-art approaches.


Unsupervised Word and Dependency Path Embeddings for Aspect Term
  Extraction

  In this paper, we develop a novel approach to aspect term extraction based on
unsupervised learning of distributed representations of words and dependency
paths. The basic idea is to connect two words (w1 and w2) with the dependency
path (r) between them in the embedding space. Specifically, our method
optimizes the objective w1 + r = w2 in the low-dimensional space, where the
multi-hop dependency paths are treated as a sequence of grammatical relations
and modeled by a recurrent neural network. Then, we design the embedding
features that consider linear context and dependency context information, for
the conditional random field (CRF) based aspect term extraction. Experimental
results on the SemEval datasets show that, (1) with only embedding features, we
can achieve state-of-the-art results; (2) our embedding method which
incorporates the syntactic information among words yields better performance
than other representative ones in aspect term extraction.


Low-rank Multi-view Clustering in Third-Order Tensor Space

  The plenty information from multiple views data as well as the complementary
information among different views are usually beneficial to various tasks,
e.g., clustering, classification, de-noising. Multi-view subspace clustering is
based on the fact that the multi-view data are generated from a latent
subspace. To recover the underlying subspace structure, the success of the
sparse and/or low-rank subspace clustering has been witnessed recently. Despite
some state-of-the-art subspace clustering approaches can numerically handle
multi-view data, by simultaneously exploring all possible pairwise correlation
within views, the high order statistics is often disregarded which can only be
captured by simultaneously utilizing all views. As a consequence, the
clustering performance for multi-view data is compromised. To address this
issue, in this paper, a novel multi-view clustering method is proposed by using
\textit{t-product} in third-order tensor space. Based on the circular
convolution operation, multi-view data can be effectively represented by a
\textit{t-linear} combination with sparse and low-rank penalty using
"self-expressiveness". Our extensive experimental results on facial, object,
digits image and text data demonstrate that the proposed method outperforms the
state-of-the-art methods in terms of many criteria.


A New Look at the Sub-electron Controversy Of Milikan & Ehrenhaft

  The measurements of the electronic charge e, by Ehrenhaft and Millikan in the
early nineteen hundreds generated a bitter controversy between the orthodox and
the atomic points of views. Guided by the Pauli-Fermi neutrino model for
beta-decay in this paper we speculate that the introduction of a small
hypothetical force is adequate to account for most of the contentious
differences between the observations of Millikan and Ehrenhaft.


Light (anti-)nuclei production and flow in relativistic heavy-ion
  collisions

  Using the coalescence model based on the phase-space distributions of
protons, neutrons, Lambdas and their antiparticles from a multiphase transport
(AMPT) model, we study the production of deuteron, triton, helium 3,
hypertriton, hyperhelium 3 and their antinuclei in Pb+Pb collisions at
$\sqrt{s_{NN}}=2.76$ TeV. The resulting transverse momentum spectra, elliptic
flows and coalescence parameters for these nuclei are presented and compared
with available experimental data. We also show the constituent number scaled
elliptic flows of these nuclei and discuss their implications.


Entangling cavity modes in a double-cavity optomechanical system

  We study entanglement of the cavity modes in a double-cavity optomechanical
system in strong-coupling regime. The system consists of two optomechanical
systems coupled by a single photon hopping between them. With the radiation
pressure of the photon, entanglement of the cavity modes can be generated. The
concurrence between the cavity modes is at least twice larger than that between
the mechanical modes. Moreover, when we change the ratio between coupling
strength and resonant frequency of mechanical modes, the entanglement in cavity
and mechanical modes are influenced differently.


Propagating Profiles of a Chemotaxis Model with Degenerate Diffusion:
  Initial Shrinking, Eventual Smoothness and Expanding

  We investigate the propagating profiles of a degenerate chemotaxis model
describing the bacteria chemotaxis and consumption of oxygen by aerobic
bacteria, in particular, the effect of the initial attractant distribution on
bacterial clustering. We prove that the compact support of solutions may shrink
if the signal concentration satisfies a special structure, and show the finite
speed propagating property without assuming the special structure on attractant
concentration, and obtain an explicit formula of the population spreading speed
in terms of model parameters. The presented results suggest that bacterial
cluster formation can be affected by chemotactic attractants and
density-dependent dispersal.


One condition for solution uniqueness and robustness of both
  l1-synthesis and l1-analysis minimizations

  The $\ell_1$-synthesis model and the $\ell_1$-analysis model recover
structured signals from their undersampled measurements. The solution of former
is a sparse sum of dictionary atoms, and that of the latter makes sparse
correlations with dictionary atoms. This paper addresses the question: when can
we trust these models to recover specific signals? We answer the question with
a condition that is both necessary and sufficient to guarantee the recovery to
be unique and exact and, in presence of measurement noise, to be robust. The
condition is one--for--all in the sense that it applies to both of the
$\ell_1$-synthesis and $\ell_1$-analysis models, to both of their constrained
and unconstrained formulations, and to both the exact recovery and robust
recovery cases. Furthermore, a convex infinity--norm program is introduced for
numerically verifying the condition. A comprehensive comparison with related
existing conditions are included.


Proposal for quantum many-body simulation and torsional matter-wave
  interferometry with a levitated nanodiamond

  Hybrid spin-mechanical systems have great potentials in sensing, macroscopic
quantum mechanics, and quantum information science. In order to induce strong
coupling between an electron spin and the center-of-mass motion of a mechanical
oscillator, a large magnetic gradient is usually required, which is difficult
to achieve. Here we show that strong coupling between the electron spin of a
nitrogen-vacancy (NV) center and the torsional vibration of an optically
levitated nanodiamond can be achieved in a uniform magnetic field. Thanks to
the uniform magnetic field, multiple spins can strongly couple to the torsional
vibration at the same time. We propose to utilize this new coupling mechanism
to realize the Lipkin-Meshkov-Glick (LMG) model by an ensemble of NV centers in
a levitated nanodiamond. The quantum phase transition in the LMG model and
finite number effects can be observed with this system. We also propose to
generate torsional superposition states and realize torsional matter-wave
interferometry with spin-torsional coupling.


Coordinate Friendly Structures, Algorithms and Applications

  This paper focuses on coordinate update methods, which are useful for solving
problems involving large or high-dimensional datasets. They decompose a problem
into simple subproblems, where each updates one, or a small block of, variables
while fixing others. These methods can deal with linear and nonlinear mappings,
smooth and nonsmooth functions, as well as convex and nonconvex problems. In
addition, they are easy to parallelize.
  The great performance of coordinate update methods depends on solving simple
sub-problems. To derive simple subproblems for several new classes of
applications, this paper systematically studies coordinate-friendly operators
that perform low-cost coordinate updates.
  Based on the discovered coordinate friendly operators, as well as operator
splitting techniques, we obtain new coordinate update algorithms for a variety
of problems in machine learning, image processing, as well as sub-areas of
optimization. Several problems are treated with coordinate update for the first
time in history. The obtained algorithms are scalable to large instances
through parallel and even asynchronous computing. We present numerical examples
to illustrate how effective these algorithms are.


Universal driven critical dynamics across a quantum phase transition in
  ferromagnetic spinor atomic Bose-Einstein condensates

  We study the equilibrium and dynamical properties of a ferromagnetic spinor
atomic Bose-Einstein condensate. In the vicinity of the critical point for a
continuous quantum phase transition, universal behaviors are observed both in
the equilibrium state and in the dynamics when the quadratic Zeeman shift is
swept linearly. Three distinct dynamical regions are identified for different
sweeping time scales ($\tau$), when compared to the time scale $\tau_{\rm
KZ}\sim N^{(1+\nu z)/\nu d}$ decided by external driving in a system with
finite size $N$ ($\nu,z$ are critical exponents and $d$ the dimensionality).
They are manifested by the excitation probability $\mathcal{P}$ and the excess
heat density $\mathcal{Q}$. The adiabatic region of
$\,\mathcal{P}\sim\mathcal{Q}\sim\tau^{-2}\,$ follows from the adiabatic
perturbation theory when $\tau >\tau_{\rm KZ}$, while the non-adiabatic
universal region of $\,\mathcal{P}\sim\mathcal{Q}\sim\tau^{-1}\,$ in the
thermodynamic limit is described by the Kibble-Zurek mechanism when $\tau_{\rm
KZ}>\tau >$ the time scale given by initial gap. The Kibble-Zurek scaling
hypothesis is augmented with finite-size scaling in the latter region and
several experimentally falsifiable features for the finite system we consider
are predicted. The region of the fastest sweeping is found to be non-universal
and far-from-equilibrium with $\mathcal{P}$ and $\mathcal{Q}$ essentially being
constants independent of $\tau$.


Universal Direct Proportionality: A New Analysis of Quantum Hall Effect

  We address the researchers studying the magneto-transport properties of
unconventional systems such as bulk samples and new materials or those working
in the soft quantum limit. We have developed a procedure for the analysis of
experimental data, so as to increase the confidence level about the presence of
quantum hall effect in these data. It is shown that irrespective of
temperature, sample material and sign of the charge carriers, for both integer
and fractional QHE's, an universal direct proportionality exists in the
dimensionless variables B and R (defined in the text). This procedure does not
preassign, Landau level filling factor (f) but determines both f and carrier
density in a statistically significant manner. We also find a natural
definition of the soft limit regime. Results of the analyses of several sets of
literature and synthetic data are reported.


Quantum Hall Effect at 40 kelvin: Evidence of MacroscopicQuantization in
  the Extreme Soft Limit

  Evidence of both fractional and integer quantum hall effects (QHE) in three
dimensional bulk replica opal (250nm diameter) structures of non-crystalline
carbon are presented. In a remarkably soft quantum limit of ~ 40K temperature
and about one tesla of magnetic field clear hall steps, such as n= 2/3, 4/5, 1
and others were observed to be coordinated with the minima of longitudinal
magneto-resistance. This behavior is indicative of macroscopic quantum
phenomenon associated with electronic condensation into a strongly correlated
quantum liquid (QL). For other systems, such as very high mobility,
two-dimensional, electron (hole)-gas or (TDEG) these effects typically arise
under high magnetic fields (B) and at low temperatures (T), i.e., in the
extreme quantum limit (B/T>1). Currently, QHE is applied as calibration
benchmark, international resistance standard, and a characterization technique
for semiconductor heterostructures. We believe that applications can be
widespread if the devices and the operating conditions were more accessible.


Experimental Indications of Electro-Gravity

  Recent results from our on going experimental investigation of the influence
of space dependant electric fields on the weight of test particles are
reported. Test particles were gold coated metal spheres of same size but of
different masses. Data collected from a number of runs over several years
continue to indicate an intriguing effect. For experimental parameters in
question this effect is manifested as a ppm level sample mass dependent force
additional to expected electrostatic forces. A force that is proportional to
mass is the unique signature of gravity furthermore it is non-zero only when
the field is applied; hence these observations may be further evidence in
support of electro-gravity.


Exact solution of mean geodesic distance for Vicsek fractals

  The Vicsek fractals are one of the most interesting classes of fractals and
the study of their structural properties is important. In this paper, the exact
formula for the mean geodesic distance of Vicsek fractals is found. The
quantity is computed precisely through the recurrence relations derived from
the self-similar structure of the fractals considered. The obtained exact
solution exhibits that the mean geodesic distance approximately increases as an
exponential function of the number of nodes, with the exponent equal to the
reciprocal of the fractal dimension. The closed-form solution is confirmed by
extensive numerical calculations.


An efficient approach of controlling traffic congestion in scale-free
  networks

  We propose and study a model of traffic in communication networks. The
underlying network has a structure that is tunable between a scale-free growing
network with preferential attachments and a random growing network. To model
realistic situations where different nodes in a network may have different
capabilities, the message or packet creation and delivering rates at a node are
assumed to depend on the degree of the node. Noting that congestions are more
likely to take place at the nodes with high degrees in networks with scale-free
character, an efficient approach of selectively enhancing the
message-processing capability of a small fraction (e.g. 3%) of the nodes is
shown to perform just as good as enhancing the capability of all nodes. The
interplay between the creation rate and the delivering rate in determining
non-congested or congested traffic in a network is studied more numerically and
analytically.


Non-specular Reflective Optics

  Geometrically decorated two-dimensional (2D) discrete surfaces can be more
effective than conventional smooth reflectors in managing wave radiation.
Constructive non-specular wave scattering permits the scattering angle to be
other than twice that of incidence and can result in gross violations of the
law of reflection. Hence significant fraction of the phase space becomes
accessible. A wide range of novel reflective behaviors ensues; including the
phenomenon of negative reflection were energy transport remains on the same
side of the normal. Also, at a critical incidence coherent superposition can
force both the transmitted and reflected waves to graze the scattering surface
thus synergistically reinforcing the diffractive process in a behavior
reminiscent of critical internal reflection of ray optics. We experimentally
demonstrate the concept with measurements on a one-dimensionally periodic
system (grating) where the scattering angle is shown to be an inverse circular
function of a function that depends on the diffractive index and the two
angles. Excellent agreement is found between experimental data and theory.


Electron-Lattice Systems in Weak Gravitation: The Schiff Dessler Problem

  The behavior of composite matter in external fields can be very revealing.
The quantum mechanical problem of a material object (test mass) placed in a
uniform (weak) gravitational field, g, was considered by many authors starting
with Schiff [Phys. Rev. 151, 1067 (1966)]. Depending on the theoretical
treatment opposing results of gravity induced (electric) field have been
reported. In the Schiff model [L.I. Schiff, PRB, 1, 4649 (1970)] the field is
predicted to be oriented anti-parallel (with reference to g). On the other hand
it is found to be parallel in the elastic lattice model [A. J. Dessler et al,
Phys.Rev, 168, 737, (1968); Edward Teller, PNAS, 74, 2664 (1977)].
Surprisingly, modern researchers have largely overlooked this interesting
contradiction. Here an experimental test is suggested. We also reason that
advanced density functional type calculations can provide valuable guidance.


Do Quantum Systems Break The Equivalence Principle?

  Gravitational response of real objects is a fascinating topic. Einstein
formalized the Galileo-Newton ideas of equality of free falls into complete
physical equivalence or the Principle of Equivalence [Albert Einstein, The
meaning of Relativity, 5 ed. Princeton, (1921)]. However, in this article we
point out that in a gravitational field, g, the bulk response of an
electrically neutral but atomistic test mass is model dependant. Depending on
the particular quantum approximation scheme, opposing results for the gravity
induced (electric) polarization P have been reported. For instance, P is small
and oriented anti-parallel to g, if the deformations of the positive background
lattice is neglected But, it is about ~ 100,1000 times larger and opposite in
direction in the elastic lattice approximation. Hence, the elastic model
contradicts reports of polarization in accelerated metals [Richard C. Tolman &
T.Dale Stewart, Phys Rev 28, 794 (1926); G. F. Moorhead & G. I. Opat, Class.
Quant. Grav, 13, 3129 (1996)]. Surprisingly, the rigid system is consistent
with EP but the elastic system breaks EP. Here the historical literature is
surveyed and some implications are outlined.


Detection of Solar and Lunar Tidal Forces via Non-resonant Oscillations
  of A Pendulum

  The FFT power spectrum of time deflection data from a pendulum bob shows a
broad structure in the micro-Hz regime is consistent with non-resonant response
due to forced acceleration. Harmonic analyses of pass Butterworth filtered data
and the horizontal components of the theoretical tidal forces were compared. We
conclude that the observed diurnal and semi-diurnal oscillations with about 10
micro-gal amplitude are due to solar and lunar tides. Our results presented
here clearly indicate that under the appropriate conditions the horizontal
forces are also present and have to be accounted for and provide useful
information. To the best of our knowledge this is the first reported detection
of the horizontal tides with a pendulum.


Optimal Power Allocation for OFDM-Based Wire-Tap Channels with
  Arbitrarily Distributed Inputs

  In this paper, we investigate power allocation that maximizes the secrecy
rate of orthogonal frequency division multiplexing (OFDM) systems under
arbitrarily distributed inputs. Considering commonly assumed Gaussian inputs
are unrealistic, we focus on secrecy systems with more practical discrete
distributed inputs, such as PSK, QAM, etc. While the secrecy rate achieved by
Gaussian distributed inputs is concave with respect to the transmit power, we
have found and rigorously proved that the secrecy rate is non-concave under any
discrete inputs. Hence, traditional convex optimization methods are not
applicable any more. To address this non-concave power allocation problem, we
propose an efficient algorithm. Its gap from optimality vanishes asymptotically
at the rate of $O(1/\sqrt{N})$, and its complexity grows in the order of O(N),
where $N$ is the number of sub-carriers. Numerical results are provided to
illustrate the efficacy of the proposed algorithm.


Observation of Piezoelectricity in Monolayer Molybdenum Disulfide

  Piezoelectricity offers precise and robust conversion between electricity and
mechanical force. Here we report the first experimental evidence of
piezoelectricity in a single layer of molybdenum disulfide (MoS2) crystal as a
result of inversion symmetry breaking of the atomic structure, with measured
piezoelectric coefficient e11 = 2.9e-10 C/m. Through the angular dependence of
electro-mechanical coupling, we uniquely determined the two-dimensional (2D)
crystal orientation. We observed that only MoS2 membranes with odd number of
layers exhibited piezoelectricity, in sharp contrast to the conventional
materials. The piezoelectricity discovered in single molecular membrane
promises scaling down of nano-electro-mechanical systems (NEMS) to single
atomic unit cell - the ultimate material limit.


Optical Monitoring of the Seyfert Galaxy NGC 4151 and Possible
  Periodicities in the Historical Light Curve

  We report B, V, and R band CCD photometry of the Seyfert galaxy NGC 4151
obtained with the 1.0-m telescope at Weihai Observatory of Shandong University
and the 1.56-m telescope at Shanghai Astronomical Observatory from 2005
December to 2013 February. Combining all available data from literature, we
have constructed a historical light curve from 1910 to 2013 to study the
periodicity of the source using three different methods (the Jurkevich method,
the Lomb-Scargle periodogram method and the Discrete Correlation Function
method). We find possible periods of P_1=4\pm0.1, P_2=7.5\pm0.3 and
P_3=15.9\pm0.3 yr.


Quantization of the Atom plus Attempting to Answer Heilbron & Kuhn

  The idea of atoms is old but X-rays provided the first probe into the
physical atom. Photographs of X-ray scattering from crystals -Laue spots- were
the first visual proof for the physical existence of atoms arranged in a
perfect geometric pattern. Thereby conclusively established the stability and
physical reality of atoms. The Braggs developed Laue technique to study atoms.
Moseley applied (Bragg) X-ray spectroscopy to determine the nuclear charge
number of Rutherford atom. We argue that Bohr also at Manchester and
contemporary of Moseley likely was inspired by Laue discovery to get busy with
the mechanics of the nuclear atom. Roentgens discovery was awarded the first
Nobel prize ever in 1901, Laue was honored in 1914, the Braggs in 1915, making
Lawrence Bragg then at 25 the youngest ever. Eleven of the cited authors (Bohr
himself included) in the trilogy (but not Nicholson the most cited), were later
recognized by ten Noble prize awards, seven Laureates in physics and four in
chemistry. The ensuing synergy between science and Nobel honors has been
critical.


Representing data by sparse combination of contextual data points for
  classification

  In this paper, we study the problem of using contextual da- ta points of a
data point for its classification problem. We propose to represent a data point
as the sparse linear reconstruction of its context, and learn the sparse
context to gather with a linear classifier in a su- pervised way to increase
its discriminative ability. We proposed a novel formulation for context
learning, by modeling the learning of context reconstruction coefficients and
classifier in a unified objective. In this objective, the reconstruction error
is minimized and the coefficient spar- sity is encouraged. Moreover, the hinge
loss of the classifier is minimized and the complexity of the classifier is
reduced. This objective is opti- mized by an alternative strategy in an
iterative algorithm. Experiments on three benchmark data set show its advantage
over state-of-the-art context-based data representation and classification
methods.


Supervised learning of sparse context reconstruction coefficients for
  data representation and classification

  Context of data points, which is usually defined as the other data points in
a data set, has been found to play important roles in data representation and
classification. In this paper, we study the problem of using context of a data
point for its classification problem. Our work is inspired by the observation
that actually only very few data points are critical in the context of a data
point for its representation and classification. We propose to represent a data
point as the sparse linear combination of its context, and learn the sparse
context in a supervised way to increase its discriminative ability. To this
end, we proposed a novel formulation for context learning, by modeling the
learning of context parameter and classifier in a unified objective, and
optimizing it with an alternative strategy in an iterative algorithm.
Experiments on three benchmark data set show its advantage over
state-of-the-art context-based data representation and classification methods.


Elliptic flows of light nuclei

  Using the coalescence model based on nucleons from a blast-wave model with
its parameters fitted to the measured proton transverse momentum spectrum and
elliptic flow in heavy ion collisions at the Relativistic Heavy Ion Collider,
we study the elliptic flows of light nuclei in these collisions. We find that
to describe the measured elliptic flows of deuterons (anti-deuterons) and
tritons (helium-3) requires that the emission source for nucleons of high
transverse momentum is more elongated along the reaction plane than in the
perpendicular direction. Our results thus suggest that the elliptic flows of
light nuclei can be used to study the nucleon emission source in relativistic
heavy ion collisions.


Scattering, weak localization and Shubnikov-de Haas oscillation in high
  carrier density AlInN/GaN heterostructures

  We provide the first observation of weak localization in high carrier density
two-dimensional electron gas in AlInN/GaN heterostructures; at low temperatures
and low fields the conductivity increases with increasing magnetic field. Weak
localization is further confirmed by the lnT dependence of the zero-field
conductivity and angle dependence of magnetoresistance. The inelastic
scattering rate is linearly proportional to temperature, demonstrating that
electron-electron scattering is the principal phase breaking mechanism.
Shubnikov-de Haas (SdH) oscillations at high magnetic fields are also observed.
From the temperature dependent amplitude of SdH oscillation and Dingle plot,
the effective mass of electron is extracted to be 0.2327me; in addition the
quantum lifetime is smaller than transport time from Hall measurement,
indicating small angle scattering such as from remote ionized impurities is
dominant. Above 20 K, the scattering changes from acoustic phonon to optical
phonon scattering, resulting in a rapid decrease in carrier mobility with
increasing temperature.


Early and late stage profiles for a new chemotaxis model with
  density-dependent jump probability and quorum-sensing mechanisms

  In this paper, we derive a new chemotaxis model with degenerate diffusion and
density-dependent chemotactic sensitivity, and we provide a more realistic
description of cell migration process for its early and late stages. Different
from the existing studies focusing on the case of non-degenerate diffusion, the
new model with degenerate diffusion causes us some essential difficulty on the
boundedness estimates and the propagation behavior of its compact support. In
the presence of logistic damping, for the early stage before tumour cells
spread to the whole body, we first estimate the expanding speed of tumour
region as $O(t^{\beta})$ for $0<\beta<\frac{1}{2}$. Then, for the late stage of
cell migration, we further prove that the asymptotic profile of the original
system is just its corresponding steady state. The global convergence of the
original weak solution to the steady state with exponential rate $O(e^{-ct})$
for some $c>0$ is also obtained.


Question Generation from SQL Queries Improves Neural Semantic Parsing

  We study how to learn a semantic parser of state-of-the-art accuracy with
less supervised training data. We conduct our study on WikiSQL, the largest
hand-annotated semantic parsing dataset to date. First, we demonstrate that
question generation is an effective method that empowers us to learn a
state-of-the-art neural network based semantic parser with thirty percent of
the supervised training data. Second, we show that applying question generation
to the full supervised training data further improves the state-of-the-art
model. In addition, we observe that there is a logarithmic relationship between
the accuracy of a semantic parser and the amount of training data.


Improving Question Answering by Commonsense-Based Pre-Training

  Although neural network approaches achieve remarkable success on a variety of
NLP tasks, many of them struggle to answer questions that require commonsense
knowledge. We believe the main reason is the lack of commonsense
\mbox{connections} between concepts. To remedy this, we provide a simple and
effective method that leverages external commonsense knowledge base such as
ConceptNet. We pre-train direct and indirect relational functions between
concepts, and show that these pre-trained functions could be easily added to
existing neural network models. Results show that incorporating
commonsense-based function improves the baseline on three question answering
tasks that require commonsense reasoning. Further analysis shows that our
system \mbox{discovers} and leverages useful evidence from an external
commonsense knowledge base, which is missing in existing neural network models
and help derive the correct answer.


Theoretical and numerical studies on global stability of traveling waves
  with oscillations for time-delayed nonlocal dispersion equations

  This paper is concerned with the global stability of non-critical/critical
traveling waves with oscillations for time-delayed nonlocal dispersion
equations. We first theoretically prove that all traveling waves, especially
the critical oscillatory traveling waves, are globally stable in a certain
weighted space, where the convergence rates to the non-critical oscillatory
traveling waves are time-exponential, and the convergence to the critical
oscillatory traveling waves are time-algebraic. Both of the rates are optimal.
The approach adopted is the weighted energy method with the fundamental
solution theory for time-delayed equations. Secondly, we carry out numerical
computations in different cases, which also confirm our theoretical results.
Because of oscillations of the solutions and nonlocality of the equation, the
numerical results obtained by the regular finite difference scheme are not
stable, even worse to be blow-up. In order to overcome these obstacles, we
propose a new finite difference scheme by adding artificial viscosities to both
sides of the equation, and obtain the desired numerical results.


Working in Pairs: Understanding the Effects of Worker Interactions in
  Crowdwork

  Crowdsourcing has gained popularity as a tool to harness human brain power to
help solve problems that are difficult for computers. Previous work in
crowdsourcing often assumes that workers complete crowdwork independently. In
this paper, we relax the independent property of crowdwork and explore how
introducing direct, synchronous, and free-style interactions between workers
would affect crowdwork. In particular, motivated by the concept of peer
instruction in educational settings, we study the effects of peer communication
in crowdsourcing environments. In the crowdsourcing setting with peer
communication, pairs of workers are asked to complete the same task together by
first generating their initial answers to the task independently and then
freely discussing the tasks with each other and updating their answers after
the discussion. We experimentally examine the effects of peer communication in
crowdwork on various common types of tasks on crowdsourcing platforms,
including image labeling, optical character recognition (OCR), audio
transcription, and nutrition analysis. Our experiment results show that the
work quality is significantly improved in tasks with peer communication
compared to tasks where workers complete the work independently. However,
participating in tasks with peer communication has limited effects on
influencing worker's independent performance in tasks of the same type in the
future.


Experimental Demonstration of 503.61-Gbit/s DMT over 10-km 7-Core Fiber
  with 1.5-μm SM-VCSEL for Optical Interconnects

  We experimentally demonstrate a net-rate 503.61-Gbit/s discrete multitone
(DMT) transmission over 10-km 7-core fiber with 1.5-\mu m single mode VCSEL,
where low-complexity kernelrecursive-least-squares algorithm is employed for
nonlinear channel equalization.


Self Equivalence of the Alternating Direction Method of Multipliers

  The alternating direction method of multipliers (ADM or ADMM) breaks a
complex optimization problem into much simpler subproblems. The ADM algorithms
are typically short and easy to implement yet exhibit (nearly) state-of-the-art
performance for large-scale optimization problems.
  To apply ADM, we first formulate a given problem into the "ADM-ready" form,
so the final algorithm depends on the formulation. A problem like
$\mbox{minimize}_\mathbf{x} u(\mathbf{x}) + v(\mathbf{C}\mathbf{x})$ has six
different "ADM-ready" formulations. They can be in the primal or dual forms,
and they differ by how dummy variables are introduced. To each "ADM-ready"
formulation, ADM can be applied in two different orders depending on how the
primal variables are updated. Finally, we get twelve different ADM algorithms!
How do they compare to each other? Which algorithm should one choose?
  In this paper, we show that many of the different ways of applying ADM are
equivalent. Specifically, we show that ADM applied to a primal formulation is
equivalent to ADM applied to its Lagrange dual; ADM is equivalent to a
primal-dual algorithm applied to the saddle-point formulation of the same
problem. These results are surprising since the primal and dual variables in
ADM are seemingly treated very differently, and some previous work exhibit
preferences in one over the other on specific problems. In addition, when one
of the two objective functions is quadratic, possibly subject to an affine
constraint, we show that swapping the update order of the two primal variables
in ADM gives the same algorithm. These results identify the few truly different
ADM algorithms for a problem, which generally have different forms of
subproblems from which it is easy to pick one with the most computationally
friendly subproblems.


Satellite-Based Entanglement Distribution Over 1200 kilometers

  Long-distance entanglement distribution is essential both for foundational
tests of quantum physics and scalable quantum networks. Owing to channel loss,
however, the previously achieved distance was limited to ~100 km. Here, we
demonstrate satellite-based distribution of entangled photon pairs to two
locations separated by 1203 km on the Earth, through satellite-to-ground
two-downlink with a sum of length varies from 1600 km to 2400 km. We observe a
survival of two-photon entanglement and a violation of Bell inequality by
2.37+/-0.09 under strict Einstein locality conditions. The obtained effective
link efficiency at 1200 km in this work is over 12 orders of magnitude higher
than the direct bidirectional transmission of the two photons through the best
commercial telecommunication fibers with a loss of 0.16 dB/km.


An analysis of the X-ray emission from the supernova remnant 3C397

  The ASCA SIS and the ROSAT PSPC spectral data of the SNR 3C397 are analysed
with a two-component non-equilibrium ionization model. Besides, the ASCA SIS0
and SIS1 spectra are also fitted simultaneously in an equilibrium case. The
resulting values of the hydrogen column density yield a distance of $\sim8\kpc$
to 3C397. It is found that the hard X-ray emission, containing S and Fe
K$\alpha$ lines, arises primarily from the hot component, while most of the
soft emission, composed mainly of Mg, Si, Fe L lines, and continuum, is
produced by the cool component. The emission measures suggest that the remnant
evolves in a cloudy medium and imply that the supernova progenitor might not be
a massive early-type star. The cool component is approaching ionization
equilibrium. The ages estimated from the ionization parameters and dynamics are
all much greater than the previous determination. We restore the X-ray maps
using the ASCA SIS data and compare them with the ROSAT HRI and the NRAO VLA
Sky Survey (NVSS) 20 cm maps. The morphology with two bright concentrations
suggests a bipolar remnant encountering a denser medium in the west.


Influences of degree inhomogeneity on average path length and random
  walks in disassortative scale-free networks

  Various real-life networks exhibit degree correlations and heterogeneous
structure, with the latter being characterized by power-law degree distribution
$P(k)\sim k^{-\gamma}$, where the degree exponent $\gamma$ describes the extent
of heterogeneity. In this paper, we study analytically the average path length
(APL) of and random walks (RWs) on a family of deterministic networks,
recursive scale-free trees (RSFTs), with negative degree correlations and
various $\gamma \in (2,1+\frac{\ln 3}{\ln 2}]$, with an aim to explore the
impacts of structure heterogeneity on APL and RWs. We show that the degree
exponent $\gamma$ has no effect on APL $d$ of RSFTs: In the full range of
$\gamma$, $d$ behaves as a logarithmic scaling with the number of network nodes
$N$ (i.e. $d \sim \ln N$), which is in sharp contrast to the well-known double
logarithmic scaling ($d \sim \ln \ln N$) previously obtained for uncorrelated
scale-free networks with $2 \leq \gamma <3$. In addition, we present that some
scaling efficiency exponents of random walks are reliant on degree exponent
$\gamma$.


Tunable magnetic exchange interactions in manganese-doped inverted
  core/shell ZnSe/CdSe nanocrystals

  Magnetic doping of semiconductor nanostructures is actively pursued for
applications in magnetic memory and spin-based electronics. Central to these
efforts is a drive to control the interaction strength between carriers
(electrons and holes) and the embedded magnetic atoms. In this respect,
colloidal nanocrystal heterostructures provide great flexibility via
growth-controlled `engineering' of electron and hole wavefunctions within
individual nanocrystals. Here we demonstrate a widely tunable magnetic sp-d
exchange interaction between electron-hole excitations (excitons) and
paramagnetic manganese ions using `inverted' core-shell nanocrystals composed
of Mn-doped ZnSe cores overcoated with undoped shells of narrower-gap CdSe.
Magnetic circular dichroism studies reveal giant Zeeman spin splittings of the
band-edge exciton that, surprisingly, are tunable in both magnitude and sign.
Effective exciton g-factors are controllably tuned from -200 to +30 solely by
increasing the CdSe shell thickness, demonstrating that strong quantum
confinement and wavefunction engineering in heterostructured nanocrystal
materials can be utilized to manipulate carrier-Mn wavefunction overlap and the
sp-d exchange parameters themselves.


Tidal Accelerometry: Exploring the Cosmos Via Gravitational Correlations

  Newtonian gravitation is non-radiative but is extremely pervasive and
penetrates equally into every media because it cannot be shielded. The extra
terrestrial fgravity is responsible for earth's trajectory. However its
correlation or geodesic deviation is manifested as semi-diurnal and diurnal
tides. Tidal signals, A(t) are temporal modulations in the field differential
which can be observed in a wide variety of natural and laboratory situations.
A(t) is a quasi-static, low frequency signal which arises from the relative
changes in positions of the detector and source and is not part of the
electromagnetic spectrum. Isaac Newton was the first to recognize the
importance of tides in astrometry and attempetd to estimate lunar mass from
ocean tides. By a case study we show, how the systematics of the gravitational
correlation can be used for calibration and de-trending which can significantly
increase the confidence level of high precision experiments. A(t) can also be
used to determine the distribution of celestial masses independently of the
"1-2-3" law. Guided by modern advances in gravity wave detectors we argue that
it is important to develop high precision accelerometry. With a resolution of
about a nano-m it will be possible to determine solar system masses and detect
the SMBH at the center of our galaxy. Observations of the gravitational
correlation can potentially open up yet to be explored vistas of the cosmos.


Power Allocation and Time-Domain Artificial Noise Design for Wiretap
  OFDM with Discrete Inputs

  Optimal power allocation for orthogonal frequency division multiplexing
(OFDM) wiretap channels with Gaussian channel inputs has already been studied
in some previous works from an information theoretical viewpoint. However,
these results are not sufficient for practical system design. One reason is
that discrete channel inputs, such as quadrature amplitude modulation (QAM)
signals, instead of Gaussian channel inputs, are deployed in current practical
wireless systems to maintain moderate peak transmission power and receiver
complexity. In this paper, we investigate the power allocation and artificial
noise design for OFDM wiretap channels with discrete channel inputs. We first
prove that the secrecy rate function for discrete channel inputs is nonconcave
with respect to the transmission power. To resolve the corresponding nonconvex
secrecy rate maximization problem, we develop a low-complexity power allocation
algorithm, which yields a duality gap diminishing in the order of
O(1/\sqrt{N}), where N is the number of subcarriers of OFDM. We then show that
independent frequency-domain artificial noise cannot improve the secrecy rate
of single-antenna wiretap channels. Towards this end, we propose a novel
time-domain artificial noise design which exploits temporal degrees of freedom
provided by the cyclic prefix of OFDM systems {to jam the eavesdropper and
boost the secrecy rate even with a single antenna at the transmitter}.
Numerical results are provided to illustrate the performance of the proposed
design schemes.


Landmark-matching Transformation with Large Deformation via
  n-dimensional Quasi-conformal Maps

  We propose a new method to obtain landmark-matching transformations between
n-dimensional Euclidean spaces with large deformations. Given a set of feature
correspondences, our algorithm searches for an optimal folding-free mapping
that satisfies the prescribed landmark constraints. The standard conformality
distortion defined for mappings between 2-dimensional spaces is first
generalized to the $n$-dimensional conformality distortion $K(f)$ for a mapping
$f$ between $n$-dimensional Euclidean spaces $(n \geq 3)$. We then propose a
variational model involving $K(f)$ to tackle the landmark-matching problem in
higher dimensional spaces. The generalized conformality term $K(f)$ enforces
the bijectivity of the optimized mapping and minimizes its local geometric
distortions even with large deformations. Another challenge is the high
computational cost of the proposed model. To tackle this, we have also proposed
a numerical method to solve the optimization problem more efficiently.
Alternating direction method with multiplier (ADMM) is applied to split the
optimization problem into two subproblems. Preconditioned conjugate gradient
method with multi-grid preconditioner is applied to solve one of the
sub-problems, while a fixed-point iteration is proposed to solve another
subproblem. Experiments have been carried out on both synthetic examples and
lung CT images to compute the diffeomorphic landmark-matching transformation
with different landmark constraints. Results show the efficacy of our proposed
model to obtain a folding-free landmark-matching transformation between
$n$-dimensional spaces with large deformations.


ARock: an Algorithmic Framework for Asynchronous Parallel Coordinate
  Updates

  Finding a fixed point to a nonexpansive operator, i.e., $x^*=Tx^*$, abstracts
many problems in numerical linear algebra, optimization, and other areas of
scientific computing. To solve fixed-point problems, we propose ARock, an
algorithmic framework in which multiple agents (machines, processors, or cores)
update $x$ in an asynchronous parallel fashion. Asynchrony is crucial to
parallel computing since it reduces synchronization wait, relaxes communication
bottleneck, and thus speeds up computing significantly. At each step of ARock,
an agent updates a randomly selected coordinate $x_i$ based on possibly
out-of-date information on $x$. The agents share $x$ through either global
memory or communication. If writing $x_i$ is atomic, the agents can read and
write $x$ without memory locks.
  Theoretically, we show that if the nonexpansive operator $T$ has a fixed
point, then with probability one, ARock generates a sequence that converges to
a fixed points of $T$. Our conditions on $T$ and step sizes are weaker than
comparable work. Linear convergence is also obtained.
  We propose special cases of ARock for linear systems, convex optimization,
machine learning, as well as distributed and decentralized consensus problems.
Numerical experiments of solving sparse logistic regression problems are
presented.


On the Convergence of Asynchronous Parallel Iteration with Unbounded
  Delays

  Recent years have witnessed the surge of asynchronous parallel
(async-parallel) iterative algorithms due to problems involving very
large-scale data and a large number of decision variables. Because of
asynchrony, the iterates are computed with outdated information, and the age of
the outdated information, which we call delay, is the number of times it has
been updated since its creation. Almost all recent works prove convergence
under the assumption of a finite maximum delay and set their stepsize
parameters accordingly. However, the maximum delay is practically unknown.
  This paper presents convergence analysis of an async-parallel method from a
probabilistic viewpoint, and it allows for large unbounded delays. An explicit
formula of stepsize that guarantees convergence is given depending on delays'
statistics. With $p+1$ identical processors, we empirically measured that
delays closely follow the Poisson distribution with parameter $p$, matching our
theoretical model, and thus the stepsize can be set accordingly. Simulations on
both convex and nonconvex optimization problems demonstrate the validness of
our analysis and also show that the existing maximum-delay induced stepsize is
too conservative, often slowing down the convergence of the algorithm.


High-resolution and Fully-programmable Microwave-shaper

  We here propose and demonstrate a point-by-point programmable broadband
microwave spectrum processor with high-resolution up to tens of MHz. We achieve
this by bandwidth-minified mapping a programmable optical spectrum processor,
which has much larger bandwidth and lower frequency resolution, to a microwave
one, and make sure the mapping is a similarity transformation. As a comparison,
the traditional optical-to-microwave mapping based on super-heterodyne is
bandwidth-preserved and identical. Here the optical spectrum processor is
firstly sliced by a high-quality-factor optical resonator, which has periodic
transmission peak with MHz-level bandwidth, and then is mapped to microwave
domain by optical-frequency-comb-assisted multi-heterodyne. We demonstrate the
high frequency resolution and full function reconfigurability experimentally.
In a numerical example, we show that the group delay variation of optical
spectrum processor could be greatly enlarged after mapping. The resolution
improvement and group delay magnification distinguish our proposal
significantly from previous spectrum mapping from optics to microwave.


Arago Optics: Maximal Confinement of Traveling Waves

  Optics is limited in the 'ray-approximation'-inclusion of wave properties
result in additional phenomena and applications; interferometers and
diffraction gratings are two manifestations of such non-geometric, physical
optics. Incidentally, the most precise measurement ever, at one part per 10^21
in the (2017) Nobel winning discovery of gravitational waves was achieved with
an interferometer. Amendments to the properties of the medium promise negative
refractive index meta-materials, perfect imaging, light cloaking, and other
ultra-natural marvels. Attention to photon phase, correlations, statistics and
wavelength independent phase shifts result in singular optics, quantum optics
and anholonomy. Here we present another possibility, namely 'Arago-optics' to
maximize the efficacy of a device by strategically deploying the key qualities
along its perimeter. For instance, in conventional sources, waves are generated
with maximum intensity at the core; whereas in an Arago-source, intensity is
minimal or zero at the center, but highest on villus stretches at the margins.
We reason that for a given size and energy output, this radiation profile,
produces the highest concentration of energy at the focus, with the maximal
confinement of the wave packet. Likewise, the utmost detector resolution is
attained when sensitivity is highest on the perimeter and less at the center.
This concept holds beyond ultra-focus and Gaussian beams, but generally applies
to beams of 'waves' that show constructive and destructive interference. The
idea is particularly well suited for a fresh integration of geometry and
topology with electronics and materials into real-time wave engineering.


