Event Detection with Neural Networks: A Rigorous Empirical Evaluation

  Detecting events and classifying them into predefined types is an important
step in knowledge extraction from natural language texts. While the neural
network models have generally led the state-of-the-art, the differences in
performance between different architectures have not been rigorously studied.
In this paper we present a novel GRU-based model that combines syntactic
information along with temporal structure through an attention mechanism. We
show that it is competitive with other neural network architectures through
empirical evaluations under different random initializations and
training-validation-test splits of ACE2005 dataset.


Conservative Agency via Attainable Utility Preservation

  Reward functions are often misspecified. An agent optimizing an incorrect
reward function can change its environment in large, undesirable, and
potentially irreversible ways. Work on impact measurement seeks a means of
identifying (and thereby avoiding) large changes to the environment. We propose
a novel impact measure which induces conservative, effective behavior across a
range of situations. The approach attempts to preserve the attainable utility
of auxiliary objectives. We evaluate our proposal on an array of benchmark
tasks and show that it matches or outperforms relative reachability, the
state-of-the-art in impact measurement.


Coactive Learning for Locally Optimal Problem Solving

  Coactive learning is an online problem solving setting where the solutions
provided by a solver are interactively improved by a domain expert, which in
turn drives learning. In this paper we extend the study of coactive learning to
problems where obtaining a globally optimal or near-optimal solution may be
intractable or where an expert can only be expected to make small, local
improvements to a candidate solution. The goal of learning in this new setting
is to minimize the cost as measured by the expert effort over time. We first
establish theoretical bounds on the average cost of the existing coactive
Perceptron algorithm. In addition, we consider new online algorithms that use
cost-sensitive and Passive-Aggressive (PA) updates, showing similar or improved
theoretical bounds. We provide an empirical evaluation of the learners in
various domains, which show that the Perceptron based algorithms are quite
effective and that unlike the case for online classification, the PA algorithms
do not yield significant performance gains.


Output Space Search for Structured Prediction

  We consider a framework for structured prediction based on search in the
space of complete structured outputs. Given a structured input, an output is
produced by running a time-bounded search procedure guided by a learned cost
function, and then returning the least cost output uncovered during the search.
This framework can be instantiated for a wide range of search spaces and search
procedures, and easily incorporates arbitrary structured-prediction loss
functions. In this paper, we make two main technical contributions. First, we
define the limited-discrepancy search space over structured outputs, which is
able to leverage powerful classification learning algorithms to improve the
search space quality. Second, we give a generic cost function learning
approach, where the key idea is to learn a cost function that attempts to mimic
the behavior of conducting searches guided by the true loss function. Our
experiments on six benchmark domains demonstrate that using our framework with
only a small amount of search is sufficient for significantly improving on
state-of-the-art structured-prediction performance.


Event Nugget Detection with Forward-Backward Recurrent Neural Networks

  Traditional event detection methods heavily rely on manually engineered rich
features. Recent deep learning approaches alleviate this problem by automatic
feature engineering. But such efforts, like tradition methods, have so far only
focused on single-token event mentions, whereas in practice events can also be
a phrase. We instead use forward-backward recurrent neural networks (FBRNNs) to
detect events that can be either words or phrases. To the best our knowledge,
this is one of the first efforts to handle multi-word events and also the first
attempt to use RNNs for event detection. Experimental results demonstrate that
FBRNN is competitive with the state-of-the-art methods on the ACE 2005 and the
Rich ERE 2015 event detection tasks.


Dependent Gated Reading for Cloze-Style Question Answering

  We present a novel deep learning architecture to address the cloze-style
question answering task. Existing approaches employ reading mechanisms that do
not fully exploit the interdependency between the document and the query. In
this paper, we propose a novel \emph{dependent gated reading} bidirectional GRU
network (DGR) to efficiently model the relationship between the document and
the query during encoding and decision making. Our evaluation shows that DGR
obtains highly competitive performance on well-known machine comprehension
benchmarks such as the Children's Book Test (CBT-NE and CBT-CN) and Who DiD
What (WDW, Strict and Relaxed). Finally, we extensively analyze and validate
our model by ablation and attention studies.


Joint Neural Entity Disambiguation with Output Space Search

  In this paper, we present a novel model for entity disambiguation that
combines both local contextual information and global evidences through Limited
Discrepancy Search (LDS). Given an input document, we start from a complete
solution constructed by a local model and conduct a search in the space of
possible corrections to improve the local solution from a global view point.
Our search utilizes a heuristic function to focus more on the least confident
local decisions and a pruning function to score the global solutions based on
their local fitness and the global coherences among the predicted entities.
Experimental results on CoNLL 2003 and TAC 2010 benchmarks verify the
effectiveness of our model.


Interpreting Recurrent and Attention-Based Neural Models: a Case Study
  on Natural Language Inference

  Deep learning models have achieved remarkable success in natural language
inference (NLI) tasks. While these models are widely explored, they are hard to
interpret and it is often unclear how and why they actually work. In this
paper, we take a step toward explaining such deep learning based models through
a case study on a popular neural model for NLI. In particular, we propose to
interpret the intermediate layers of NLI models by visualizing the saliency of
attention and LSTM gating signals. We present several examples for which our
methods are able to reveal interesting insights and identify the critical
information contributing to the model decisions.


Attentional Multi-Reading Sarcasm Detection

  Recognizing sarcasm often requires a deep understanding of multiple sources
of information, including the utterance, the conversational context, and real
world facts. Most of the current sarcasm detection systems consider only the
utterance in isolation. There are some limited attempts toward taking into
account the conversational context. In this paper, we propose an interpretable
end-to-end model that combines information from both the utterance and the
conversational context to detect sarcasm, and demonstrate its effectiveness
through empirical evaluations. We also study the behavior of the proposed model
to provide explanations for the model's decisions. Importantly, our model is
capable of determining the impact of utterance and conversational context on
the model's decisions. Finally, we provide an ablation study to illustrate the
impact of different components of the proposed model.


Learning Scripts as Hidden Markov Models

  Scripts have been proposed to model the stereotypical event sequences found
in narratives. They can be applied to make a variety of inferences including
filling gaps in the narratives and resolving ambiguous references. This paper
proposes the first formal framework for scripts based on Hidden Markov Models
(HMMs). Our framework supports robust inference and learning algorithms, which
are lacking in previous clustering models. We develop an algorithm for
structure and parameter learning based on Expectation Maximization and evaluate
it on a number of natural datasets. The results show that our algorithm is
superior to several informed baselines for predicting missing events in partial
observation sequences.


Saliency Learning: Teaching the Model Where to Pay Attention

  Deep learning has emerged as a compelling solution to many NLP tasks with
remarkable performances. However, due to their opacity, such models are hard to
interpret and trust. Recent work on explaining deep models has introduced
approaches to provide insights toward the model's behaviour and predictions,
which are helpful for assessing the reliability of the model's predictions.
However, such methods do not improve the model's reliability. In this paper, we
aim to teach the model to make the right prediction for the right reason by
providing explanation training and ensuring the alignment of the model's
explanation with the ground truth explanation. Our experimental results on
multiple tasks and datasets demonstrate the effectiveness of the proposed
method, which produces more reliable predictions while delivering better
results compared to traditionally trained models.


Interactive Naming for Explaining Deep Neural Networks: A Formative
  Study

  We consider the problem of explaining the decisions of deep neural networks
for image recognition in terms of human-recognizable visual concepts. In
particular, given a test set of images, we aim to explain each classification
in terms of a small number of image regions, or activation maps, which have
been associated with semantic concepts by a human annotator. This allows for
generating summary views of the typical reasons for classifications, which can
help build trust in a classifier and/or identify example types for which the
classifier may not be trusted. For this purpose, we developed a user interface
for "interactive naming," which allows a human annotator to manually cluster
significant activation maps in a test set into meaningful groups called "visual
concepts". The main contribution of this paper is a systematic study of the
visual concepts produced by five human annotators using the interactive naming
interface. In particular, we consider the adequacy of the concepts for
explaining the classification of test-set images, correspondence of the
concepts to activations of individual neurons, and the inter-annotator
agreement of visual concepts. We find that a large fraction of the activation
maps have recognizable visual concepts, and that there is significant agreement
between the different annotators about their denotations. Our work is an
exploratory study of the interplay between machine learning and human
recognition mediated by visualizations of the results of learning.


The SeaQuest Spectrometer at Fermilab

  The SeaQuest spectrometer at Fermilab was designed to detect
oppositely-charged pairs of muons (dimuons) produced by interactions between a
120 GeV proton beam and liquid hydrogen, liquid deuterium and solid nuclear
targets. The primary physics program uses the Drell-Yan process to probe
antiquark distributions in the target nucleon. The spectrometer consists of a
target system, two dipole magnets and four detector stations. The upstream
magnet is a closed-aperture solid iron magnet which also serves as the beam
dump, while the second magnet is an open aperture magnet. Each of the detector
stations consists of scintillator hodoscopes and a high-resolution tracking
device. The FPGA-based trigger compares the hodoscope signals to a set of
pre-programmed roads to determine if the event contains oppositely-signed,
high-mass muon pairs.


