Interactive Policy Learning through Confidence-Based Autonomy

  We present Confidence-Based Autonomy (CBA), an interactive algorithm forpolicy learning from demonstration. The CBA algorithm consists of twocomponents which take advantage of the complimentary abilities of humans andcomputer agents. The first component, Confident Execution, enables the agent toidentify states in which demonstration is required, to request a demonstrationfrom the human teacher and to learn a policy based on the acquired data. Thealgorithm selects demonstrations based on a measure of action selectionconfidence, and our results show that using Confident Execution the agentrequires fewer demonstrations to learn the policy than when demonstrations areselected by a human teacher. The second algorithmic component, CorrectiveDemonstration, enables the teacher to correct any mistakes made by the agentthrough additional demonstrations in order to improve the policy and futuretask performance. CBA and its individual components are compared and evaluatedin a complex simulated driving domain. The complete CBA algorithm results inthe best overall learning performance, successfully reproducing the behavior ofthe teacher while balancing the tradeoff between number of demonstrations andnumber of incorrect actions during learning.

Effects of Interruptibility-Aware Robot Behavior

  As robots become increasingly prevalent in human environments, there willinevitably be times when a robot needs to interrupt a human to initiate aninteraction. Our work introduces the first interruptibility-aware mobile robotsystem, and evaluates the effects of interruptibility-awareness on human taskperformance, robot task performance, and on human interpretation of the robot'ssocial aptitude. Our results show that our robot is effective at predictinginterruptibility at high accuracy, allowing it to interrupt at more appropriatetimes. Results of a large-scale user study show that while participants areable to maintain task performance even in the presence of interruptions,interruptibility-awareness improves the robot's task performance and improvesparticipant social perception of the robot.

Action Categorization for Computationally Improved Task Learning and  Planning

  This paper explores the problem of task learning and planning, contributingthe Action-Category Representation (ACR) to improve computational performanceof both Planning and Reinforcement Learning (RL). ACR is an algorithm-agnostic,abstract data representation that maps objects to action categories (groups ofactions), inspired by the psychological concept of action codes. We validateour approach in StarCraft and Lightworld domains; our results demonstrateseveral benefits of ACR relating to improved computational performance ofplanning and RL, by reducing the action space for the agent.

Tool Macgyvering: Tool Construction Using Geometric Reasoning

  MacGyvering is defined as creating or repairing something in an inventive orimprovised way by utilizing objects that are available at hand. In this paper,we explore a subset of Macgyvering problems involving tool construction, i.e.,creating tools from parts available in the environment. We formalize theoverall problem domain of tool Macgyvering, introducing three levels ofcomplexity for tool construction and substitution problems, and presenting anovel computational framework aimed at solving one level of the toolMacgyvering problem, specifically contributing a novel algorithm for toolconstruction based on geometric reasoning. We validate our approach byconstructing three tools using a 7-DOF robot arm.

Situated Structure Learning of a Bayesian Logic Network for Commonsense  Reasoning

  This paper details the implementation of an algorithm for automaticallygenerating a high-level knowledge network to perform commonsense reasoning,specifically with the application of robotic task repair. The network isrepresented using a Bayesian Logic Network (BLN) (Jain, Waldherr, and Beetz2009), which combines a set of directed relations between abstract concepts,including IsA, AtLocation, HasProperty, and UsedFor, with a correspondingprobability distribution that models the uncertainty inherent in theserelations. Inference over this network enables reasoning over the abstractconcepts in order to perform appropriate object substitution or to locatemissing objects in the robot's environment. The structure of the network isgenerated by combining information from two existing knowledge sources:ConceptNet (Speer and Havasi 2012), and WordNet (Miller 1995). This is done ina "situated" manner by only including information relevant a given context.Results show that the generated network is able to accurately predict objectcategories, locations, properties, and affordances in three different householdscenarios.

Learning Generalizable Robot Skills from Demonstrations in Cluttered  Environments

  Learning from Demonstration (LfD) is a popular approach to endowing robotswith skills without having to program them by hand. Typically, LfD relies onhuman demonstrations in clutter-free environments. This prevents thedemonstrations from being affected by irrelevant objects, whose influence canobfuscate the true intention of the human or the constraints of the desiredskill. However, it is unrealistic to assume that the robot's environment canalways be restructured to remove clutter when capturing human demonstrations.To contend with this problem, we develop an importance weighted batch andincremental skill learning approach, building on a recent inference-basedtechnique for skill representation and reproduction. Our approach reducesunwanted environmental influences on the learned skill, while still capturingthe salient human behavior. We provide both batch and incremental versions ofour approach and validate our algorithms on a 7-DOF JACO2 manipulator withreaching and placing skills.

Unbiasing Semantic Segmentation For Robot Perception using Synthetic  Data Feature Transfer

  Robot perception systems need to perform reliable image segmentation inreal-time on noisy, raw perception data. State-of-the-art segmentationapproaches use large CNN models and carefully constructed datasets; however,these models focus on accuracy at the cost of real-time inference. Furthermore,the standard semantic segmentation datasets are not large enough for trainingCNNs without augmentation and are not representative of noisy, uncurated robotperception data. We propose improving the performance of real-time segmentationframeworks on robot perception data by transferring features learned fromsynthetic segmentation data. We show that pretraining real-time segmentationarchitectures with synthetic segmentation data instead of ImageNet improvesfine-tuning performance by reducing the bias learned in pretraining and closingthe \textit{transfer gap} as a result. Our experiments show that our real-timerobot perception models pretrained on synthetic data outperform thosepretrained on ImageNet for every scale of fine-tuning data examined. Moreover,the degree to which synthetic pretraining outperforms ImageNet pretrainingincreases as the availability of robot data decreases, making our approachattractive for robotics domains where dataset collection is hard and/orexpensive.

RoboCSE: Robot Common Sense Embedding

  Autonomous service robots require computational frameworks that allow them togeneralize knowledge to new situations in a manner that models uncertaintywhile scaling to real-world problem sizes. The Robot Common Sense Embedding(RoboCSE) showcases a class of computational frameworks, multi-relationalembeddings, that have not been leveraged in robotics to model semanticknowledge. We validate RoboCSE on a realistic home environment simulator(AI2Thor) to measure how well it generalizes learned knowledge about objectaffordances, locations, and materials. Our experiments show that RoboCSE canperform prediction better than a baseline that uses pre-trained embeddings,such as Word2Vec, achieving statistically significant improvements while usingorders of magnitude less memory than our Bayesian Logic Network baseline. Inaddition, we show that predictions made by RoboCSE are robust to significantreductions in data available for training as well as domain transfer toMatterPort3D, achieving statistically significant improvements over a baselinethat memorizes training data.

STRATA: A Unified Framework for Task Assignments in Large Teams of  Heterogeneous Robots

  Large teams of robots have the potential to solve complex multi-task problemsthat are intractable for a single robot working independently. However, solvingcomplex multi-task problems requires leveraging the relative strengths ofdifferent robots in the team. We present Stochastic TRAit-based Task Assignment(STRATA), a unified framework that models large teams of heterogeneous robotsand performs optimal task assignments. Specifically, given information on whichtraits (capabilities) are required for various tasks, STRATA computes theoptimal assignments of robots to tasks such that the task-trait requirementsare achieved. Inspired by prior work in robot swarms and biodiversity, wecategorize robots into different species (groups) based on their traits. Wemodel each trait as a continuous variable and differentiate between traits thatcan and cannot be aggregated from different robots. STRATA is capable ofreasoning about both species-level and robot-level differences in traits.Further, we define measures of diversity for any given team based on the team'scontinuous-space trait model. We illustrate the necessity and effectiveness ofSTRATA using detailed simulations and a capture the flag game environment.

Skill Acquisition via Automated Multi-Coordinate Cost Balancing

  We propose a learning framework, named Multi-Coordinate Cost Balancing(MCCB), to address the problem of acquiring point-to-point movement skills fromdemonstrations. MCCB encodes demonstrations simultaneously in multipledifferential coordinates that specify local geometric properties. MCCBgenerates reproductions by solving a convex optimization problem with amulti-coordinate cost function and linear constraints on the reproductions,such as initial, target, and via points. Further, since the relative importanceof each coordinate system in the cost function might be unknown for a givenskill, MCCB learns optimal weighting factors that balance the cost function. Wedemonstrate the effectiveness of MCCB via detailed experiments conducted on onehandwriting dataset and three complex skill datasets.

Semi-Supervised Haptic Material Recognition for Robots using Generative  Adversarial Networks

  Material recognition enables robots to incorporate knowledge of materialproperties into their interactions with everyday objects. For example, materialrecognition opens up opportunities for clearer communication with a robot, suchas "bring me the metal coffee mug", and recognizing plastic versus metal iscrucial when using a microwave or oven. However, collecting labeled trainingdata with a robot is often more difficult than unlabeled data. We present asemi-supervised learning approach for material recognition that uses generativeadversarial networks (GANs) with haptic features such as force, temperature,and vibration. Our approach achieves state-of-the-art results and enables arobot to estimate the material class of household objects with ~90% accuracywhen 92% of the training data are unlabeled. We explore how well this approachcan recognize the material of new objects and we discuss challenges facinggeneralization. To motivate learning from unlabeled training data, we alsocompare results against several common supervised learning classifiers. Inaddition, we have released the dataset used for this work which consists oftime-series haptic measurements from a robot that conducted thousands ofinteractions with 72 household objects.

Classification of Household Materials via Spectroscopy

  Recognizing an object's material can inform a robot on the object's fragilityor appropriate use. To estimate an object's material during manipulation, manyprior works have explored the use of haptic sensing. In this paper, we explorea technique for robots to estimate the materials of objects using spectroscopy.We demonstrate that spectrometers provide several benefits for materialrecognition, including fast response times and accurate measurements with lownoise. Furthermore, spectrometers do not require direct contact with an object.To explore this, we collected a dataset of spectral measurements from twocommercially available spectrometers during which a robotic platform interactedwith 50 flat material objects, and we show that a neural network model canaccurately analyze these measurements. Due to the similarity betweenconsecutive spectral measurements, our model achieved a material classificationaccuracy of 94.6% when given only one spectral sample per object. Similar toprior works with haptic sensors, we found that generalizing materialrecognition to new objects posed a greater challenge, for which we achieved anaccuracy of 79.1% via leave-one-object-out cross-validation. Finally, wedemonstrate how a PR2 robot can leverage spectrometers to estimate thematerials of everyday objects found in the home. From this work, we find thatspectroscopy poses a promising approach for material classification duringrobotic manipulation.

