Automated Cloud Provisioning on AWS using Deep Reinforcement Learning

  As the use of cloud computing continues to rise, controlling cost becomes
increasingly important. Yet there is evidence that 30\% - 45\% of cloud spend
is wasted. Existing tools for cloud provisioning typically rely on highly
trained human experts to specify what to monitor, thresholds for triggering
action, and actions. In this paper we explore the use of reinforcement learning
(RL) to acquire policies to balance performance and spend, allowing humans to
specify what they want as opposed to how to do it, minimizing the need for
cloud expertise. Empirical results with tabular, deep, and dueling double deep
Q-learning with the CloudSim simulator show the utility of RL and the relative
merits of the approaches. We also demonstrate effective policy transfer
learning from an extremely simple simulator to CloudSim, with the next step
being transfer from CloudSim to an Amazon Web Services physical environment.


Spatially Encoding Temporal Correlations to Classify Temporal Data Using
  Convolutional Neural Networks

  We propose an off-line approach to explicitly encode temporal patterns
spatially as different types of images, namely, Gramian Angular Fields and
Markov Transition Fields. This enables the use of techniques from computer
vision for feature learning and classification. We used Tiled Convolutional
Neural Networks to learn high-level features from individual GAF, MTF, and
GAF-MTF images on 12 benchmark time series datasets and two real
spatial-temporal trajectory datasets. The classification results of our
approach are competitive with state-of-the-art approaches on both types of
data. An analysis of the features and weights learned by the CNNs explains why
the approach works.


Probabilistic Numerical Methods for PDE-constrained Bayesian Inverse
  Problems

  This paper develops meshless methods for probabilistically describing
discretisation error in the numerical solution of partial differential
equations. This construction enables the solution of Bayesian inverse problems
while accounting for the impact of the discretisation of the forward problem.
In particular, this drives statistical inferences to be more conservative in
the presence of significant solver error. Theoretical results are presented
describing rates of convergence for the posteriors in both the forward and
inverse problems. This method is tested on a challenging inverse problem with a
nonlinear forward model.


Cognitive Techniques for Early Detection of Cybersecurity Events

  The early detection of cybersecurity events such as attacks is challenging
given the constantly evolving threat landscape. Even with advanced monitoring,
sophisticated attackers can spend as many as 146 days in a system before being
detected. This paper describes a novel, cognitive framework that assists a
security analyst by exploiting the power of semantically rich knowledge
representation and reasoning with machine learning techniques. Our Cognitive
Cybersecurity system ingests information from textual sources, and various
agents representing host and network-based sensors, and represents this
information in a knowledge graph. This graph uses terms from an extended
version of the Unified Cybersecurity Ontology. The system reasons over the
knowledge graph to derive better actionable intelligence to security
administrators, thus decreasing their cognitive load and increasing their
confidence in the system. We have developed a proof of concept framework for
our approach and demonstrate its capabilities using a custom-built ransomware
instance that is similar to WannaCry.


The Thing That We Tried Didn't Work Very Well : Deictic Representation
  in Reinforcement Learning

  Most reinforcement learning methods operate on propositional representations
of the world state. Such representations are often intractably large and
generalize poorly. Using a deictic representation is believed to be a viable
alternative: they promise generalization while allowing the use of existing
reinforcement-learning methods. Yet, there are few experiments on learning with
deictic representations reported in the literature. In this paper we explore
the effectiveness of two forms of deictic representation and a na\"{i}ve
propositional representation in a simple blocks-world domain. We find,
empirically, that the deictic representations actually worsen learning
performance. We conclude with a discussion of possible causes of these results
and strategies for more effective learning in domains with objects.


Detecting Epileptic Seizures from EEG Data using Neural Networks

  We explore the use of neural networks trained with dropout in predicting
epileptic seizures from electroencephalographic data (scalp EEG). The input to
the neural network is a 126 feature vector containing 9 features for each of
the 14 EEG channels obtained over 1-second, non-overlapping windows. The models
in our experiments achieved high sensitivity and specificity on patient records
not used in the training process. This is demonstrated using
leave-one-out-cross-validation across patient records, where we hold out one
patient's record as the test set and use all other patients' records for
training; repeating this procedure for all patients in the database.


Imaging Time-Series to Improve Classification and Imputation

  Inspired by recent successes of deep learning in computer vision, we propose
a novel framework for encoding time series as different types of images,
namely, Gramian Angular Summation/Difference Fields (GASF/GADF) and Markov
Transition Fields (MTF). This enables the use of techniques from computer
vision for time series classification and imputation. We used Tiled
Convolutional Neural Networks (tiled CNNs) on 20 standard datasets to learn
high-level features from the individual and compound GASF-GADF-MTF images. Our
approaches achieve highly competitive results when compared to nine of the
current best time series classification approaches. Inspired by the bijection
property of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) on
the GASF images of four standard and one synthesized compound dataset. The
imputation MSE on test data is reduced by 12.18%-48.02% when compared to using
the raw data. An analysis of the features and weights learned via tiled CNNs
and DAs explains why the approaches work.


Adopting Robustness and Optimality in Fitting and Learning

  We generalized a modified exponentialized estimator by pushing the
robust-optimal (RO) index $\lambda$ to $-\infty$ for achieving robustness to
outliers by optimizing a quasi-Minimin function. The robustness is realized and
controlled adaptively by the RO index without any predefined threshold.
Optimality is guaranteed by expansion of the convexity region in the Hessian
matrix to largely avoid local optima. Detailed quantitative analysis on both
robustness and optimality are provided. The results of proposed experiments on
fitting tasks for three noisy non-convex functions and the digits recognition
task on the MNIST dataset consolidate the conclusions.


Probabilistic Numerical Methods for Partial Differential Equations and
  Bayesian Inverse Problems

  This paper develops a probabilistic numerical method for solution of partial
differential equations (PDEs) and studies application of that method to
PDE-constrained inverse problems. This approach enables the solution of
challenging inverse problems whilst accounting, in a statistically principled
way, for the impact of discretisation error due to numerical solution of the
PDE. In particular, the approach confers robustness to failure of the numerical
PDE solver, with statistical inferences driven to be more conservative in the
presence of substantial discretisation error. Going further, the problem of
choosing a PDE solver is cast as a problem in the Bayesian design of
experiments, where the aim is to minimise the impact of solver error on
statistical inferences; here the challenge of non-linear PDEs is also
considered. The method is applied to parameter inference problems in which
discretisation error in non-negligible and must be accounted for in order to
reach conclusions that are statistically valid.


Neuroevolution-Based Inverse Reinforcement Learning

  The problem of Learning from Demonstration is targeted at learning to perform
tasks based on observed examples. One approach to Learning from Demonstration
is Inverse Reinforcement Learning, in which actions are observed to infer
rewards. This work combines a feature based state evaluation approach to
Inverse Reinforcement Learning with neuroevolution, a paradigm for modifying
neural networks based on their performance on a given task. Neural networks are
used to learn from a demonstrated expert policy and are evolved to generate a
policy similar to the demonstration. The algorithm is discussed and evaluated
against competitive feature-based Inverse Reinforcement Learning approaches. At
the cost of execution time, neural networks allow for non-linear combinations
of features in state evaluations. These valuations may correspond to state
value or state reward. This results in better correspondence to observed
examples as opposed to using linear combinations. This work also extends
existing work on Bayesian Non-Parametric Feature Construction for Inverse
Reinforcement Learning by using non-linear combinations of intermediate data to
improve performance. The algorithm is observed to be specifically suitable for
a linearly solvable non-deterministic Markov Decision Processes in which
multiple rewards are sparsely scattered in state space. A conclusive
performance hierarchy between evaluated algorithms is presented.


Finding Representative Points in Multivariate Data Using PCA

  The idea of representation has been used in various fields of study from data
analysis to political science. In this paper, we define representativeness and
describe a method to isolate data points that can represent the entire data
set. Also, we show how the minimum set of representative data points can be
generated. We use data from GLOBE (a project to study the effects on Land
Change based on a set of parameters that include temperature, forest cover,
human population, atmospheric parameters and many other variables) to test &
validate the algorithm. Principal Component Analysis (PCA) is used to reduce
the dimensions of the multivariate data set, so that the representative points
can be generated efficiently and its Representativeness has been compared
against Random Sampling of points from the data set.


Time Series Classification from Scratch with Deep Neural Networks: A
  Strong Baseline

  We propose a simple but strong baseline for time series classification from
scratch with deep neural networks. Our proposed baseline models are pure
end-to-end without any heavy preprocessing on the raw data or feature crafting.
The proposed Fully Convolutional Network (FCN) achieves premium performance to
other state-of-the-art approaches and our exploration of the very deep neural
networks with the ResNet structure is also competitive. The global average
pooling in our convolutional model enables the exploitation of the Class
Activation Map (CAM) to find out the contributing region in the raw data for
the specific labels. Our models provides a simple choice for the real world
application and a good starting point for the future research. An overall
analysis is provided to discuss the generalization capability of our models,
learned features, network structures and the classification semantics.


Bayesian Probabilistic Numerical Methods

  The emergent field of probabilistic numerics has thus far lacked clear
statistical principals. This paper establishes Bayesian probabilistic numerical
methods as those which can be cast as solutions to certain inverse problems
within the Bayesian framework. This allows us to establish general conditions
under which Bayesian probabilistic numerical methods are well-defined,
encompassing both non-linear and non-Gaussian models. For general computation,
a numerical approximation scheme is proposed and its asymptotic convergence
established. The theoretical development is then extended to pipelines of
computation, wherein probabilistic numerical methods are composed to solve more
challenging numerical tasks. The contribution highlights an important research
frontier at the interface of numerical analysis and uncertainty quantification,
with a challenging industrial application presented.


Fashioning with Networks: Neural Style Transfer to Design Clothes

  Convolutional Neural Networks have been highly successful in performing a
host of computer vision tasks such as object recognition, object detection,
image segmentation and texture synthesis. In 2015, Gatys et. al [7] show how
the style of a painter can be extracted from an image of the painting and
applied to another normal photograph, thus recreating the photo in the style of
the painter. The method has been successfully applied to a wide range of images
and has since spawned multiple applications and mobile apps. In this paper, the
neural style transfer algorithm is applied to fashion so as to synthesize new
custom clothes. We construct an approach to personalize and generate new custom
clothes based on a users preference and by learning the users fashion choices
from a limited set of clothes from their closet. The approach is evaluated by
analyzing the generated images of clothes and how well they align with the
users fashion style.


Deep Belief Networks used on High Resolution Multichannel
  Electroencephalography Data for Seizure Detection

  Ubiquitous bio-sensing for personalized health monitoring is slowly becoming
a reality with the increasing availability of small, diverse, robust, high
fidelity sensors. This oncoming flood of data begs the question of how we will
extract useful information from it. In this paper we explore the use of a
variety of representations and machine learning algorithms applied to the task
of seizure detection in high resolution, multichannel EEG data. We explore
classification accuracy, computational complexity and memory requirements with
a view toward understanding which approaches are most suitable for such tasks
as the number of people involved and the amount of data they produce grows to
be quite large. In particular, we show that layered learning approaches such as
Deep Belief Networks excel along these dimensions.


A Modern Retrospective on Probabilistic Numerics

  This article attempts to place the emergence of probabilistic numerics as a
mathematical-statistical research field within its historical context and to
explore how its gradual development can be related both to applications and to
a modern formal treatment. We highlight in particular the parallel
contributions of Sul'din and Larkin in the 1960s and how their pioneering early
ideas have reached a degree of maturity in the intervening period, mediated by
paradigms such as average-case analysis and information-based complexity. We
provide a subjective assessment of the state of research in probabilistic
numerics and highlight some difficulties to be addressed by future works.


On the use of Deep Autoencoders for Efficient Embedded Reinforcement
  Learning

  In autonomous embedded systems, it is often vital to reduce the amount of
actions taken in the real world and energy required to learn a policy. Training
reinforcement learning agents from high dimensional image representations can
be very expensive and time consuming. Autoencoders are deep neural network used
to compress high dimensional data such as pixelated images into small latent
representations. This compression model is vital to efficiently learn policies,
especially when learning on embedded systems. We have implemented this model on
the NVIDIA Jetson TX2 embedded GPU, and evaluated the power consumption,
throughput, and energy consumption of the autoencoders for various CPU/GPU core
combinations, frequencies, and model parameters. Additionally, we have shown
the reconstructions generated by the autoencoder to analyze the quality of the
generated compressed representation and also the performance of the
reinforcement learning agent. Finally, we have presented an assessment of the
viability of training these models on embedded systems and their usefulness in
developing autonomous policies. Using autoencoders, we were able to achieve 4-5
$\times$ improved performance compared to a baseline RL agent with a
convolutional feature extractor, while using less than 2W of power.


Extending Signature-based Intrusion Detection Systems WithBayesian
  Abductive Reasoning

  Evolving cybersecurity threats are a persistent challenge for
systemadministrators and security experts as new malwares are continu-ally
released. Attackers may look for vulnerabilities in commercialproducts or
execute sophisticated reconnaissance campaigns tounderstand a targets network
and gather information on securityproducts like firewalls and intrusion
detection / prevention systems(network or host-based). Many new attacks tend to
be modificationsof existing ones. In such a scenario, rule-based systems fail
to detectthe attack, even though there are minor differences in conditions
/attributes between rules to identify the new and existing attack. Todetect
these differences the IDS must be able to isolate the subset ofconditions that
are true and predict the likely conditions (differentfrom the original) that
must be observed. In this paper, we proposeaprobabilistic abductive
reasoningapproach that augments an exist-ing rule-based IDS (snort [29]) to
detect these evolved attacks by (a)Predicting rule conditions that are likely
to occur (based on existingrules) and (b) able to generate new snort rules when
provided withseed rule (i.e. a starting rule) to reduce the burden on experts
toconstantly update them. We demonstrate the effectiveness of theapproach by
generating new rules from the snort 2012 rules set andtesting it on the MACCDC
2012 dataset [6].


Adaptive Normalized Risk-Averting Training For Deep Neural Networks

  This paper proposes a set of new error criteria and learning approaches,
Adaptive Normalized Risk-Averting Training (ANRAT), to attack the non-convex
optimization problem in training deep neural networks (DNNs). Theoretically, we
demonstrate its effectiveness on global and local convexity lower-bounded by
the standard $L_p$-norm error. By analyzing the gradient on the convexity index
$\lambda$, we explain the reason why to learn $\lambda$ adaptively using
gradient descent works. In practice, we show how this method improves training
of deep neural networks to solve visual recognition tasks on the MNIST and
CIFAR-10 datasets. Without using pretraining or other tricks, we obtain results
comparable or superior to those reported in recent literature on the same tasks
using standard ConvNets + MSE/cross entropy. Performance on deep/shallow
multilayer perceptrons and Denoised Auto-encoders is also explored. ANRAT can
be combined with other quasi-Newton training methods, innovative network
variants, regularization techniques and other specific tricks in DNNs. Other
than unsupervised pretraining, it provides a new perspective to address the
non-convex optimization problem in DNNs.


Identifying Spatial Relations in Images using Convolutional Neural
  Networks

  Traditional approaches to building a large scale knowledge graph have usually
relied on extracting information (entities, their properties, and relations
between them) from unstructured text (e.g. Dbpedia). Recent advances in
Convolutional Neural Networks (CNN) allow us to shift our focus to learning
entities and relations from images, as they build robust models that require
little or no pre-processing of the images. In this paper, we present an
approach to identify and extract spatial relations (e.g., The girl is standing
behind the table) from images using CNNs. Our research addresses two specific
challenges: providing insight into how spatial relations are learned by the
network and which parts of the image are used to predict these relations. We
use the pre-trained network VGGNet to extract features from an image and train
a Multi-layer Perceptron (MLP) on a set of synthetic images and the sun09
dataset to extract spatial relations. The MLP predicts spatial relations
without a bounding box around the objects or the space in the image depicting
the relation. To understand how the spatial relations are represented in the
network, a heatmap is overlayed on the image to show the regions that are
deemed important by the network. Also, we analyze the MLP to show the
relationship between the activation of consistent groups of nodes and the
prediction of a spatial relation. We show how the loss of these groups affects
the networks ability to identify relations.


