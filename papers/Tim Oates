Automated Cloud Provisioning on AWS using Deep Reinforcement Learning

  As the use of cloud computing continues to rise, controlling cost becomesincreasingly important. Yet there is evidence that 30\% - 45\% of cloud spendis wasted. Existing tools for cloud provisioning typically rely on highlytrained human experts to specify what to monitor, thresholds for triggeringaction, and actions. In this paper we explore the use of reinforcement learning(RL) to acquire policies to balance performance and spend, allowing humans tospecify what they want as opposed to how to do it, minimizing the need forcloud expertise. Empirical results with tabular, deep, and dueling double deepQ-learning with the CloudSim simulator show the utility of RL and the relativemerits of the approaches. We also demonstrate effective policy transferlearning from an extremely simple simulator to CloudSim, with the next stepbeing transfer from CloudSim to an Amazon Web Services physical environment.

Spatially Encoding Temporal Correlations to Classify Temporal Data Using  Convolutional Neural Networks

  We propose an off-line approach to explicitly encode temporal patternsspatially as different types of images, namely, Gramian Angular Fields andMarkov Transition Fields. This enables the use of techniques from computervision for feature learning and classification. We used Tiled ConvolutionalNeural Networks to learn high-level features from individual GAF, MTF, andGAF-MTF images on 12 benchmark time series datasets and two realspatial-temporal trajectory datasets. The classification results of ourapproach are competitive with state-of-the-art approaches on both types ofdata. An analysis of the features and weights learned by the CNNs explains whythe approach works.

Probabilistic Numerical Methods for PDE-constrained Bayesian Inverse  Problems

  This paper develops meshless methods for probabilistically describingdiscretisation error in the numerical solution of partial differentialequations. This construction enables the solution of Bayesian inverse problemswhile accounting for the impact of the discretisation of the forward problem.In particular, this drives statistical inferences to be more conservative inthe presence of significant solver error. Theoretical results are presenteddescribing rates of convergence for the posteriors in both the forward andinverse problems. This method is tested on a challenging inverse problem with anonlinear forward model.

Cognitive Techniques for Early Detection of Cybersecurity Events

  The early detection of cybersecurity events such as attacks is challenginggiven the constantly evolving threat landscape. Even with advanced monitoring,sophisticated attackers can spend as many as 146 days in a system before beingdetected. This paper describes a novel, cognitive framework that assists asecurity analyst by exploiting the power of semantically rich knowledgerepresentation and reasoning with machine learning techniques. Our CognitiveCybersecurity system ingests information from textual sources, and variousagents representing host and network-based sensors, and represents thisinformation in a knowledge graph. This graph uses terms from an extendedversion of the Unified Cybersecurity Ontology. The system reasons over theknowledge graph to derive better actionable intelligence to securityadministrators, thus decreasing their cognitive load and increasing theirconfidence in the system. We have developed a proof of concept framework forour approach and demonstrate its capabilities using a custom-built ransomwareinstance that is similar to WannaCry.

The Thing That We Tried Didn't Work Very Well : Deictic Representation  in Reinforcement Learning

  Most reinforcement learning methods operate on propositional representationsof the world state. Such representations are often intractably large andgeneralize poorly. Using a deictic representation is believed to be a viablealternative: they promise generalization while allowing the use of existingreinforcement-learning methods. Yet, there are few experiments on learning withdeictic representations reported in the literature. In this paper we explorethe effectiveness of two forms of deictic representation and a na\"{i}vepropositional representation in a simple blocks-world domain. We find,empirically, that the deictic representations actually worsen learningperformance. We conclude with a discussion of possible causes of these resultsand strategies for more effective learning in domains with objects.

Detecting Epileptic Seizures from EEG Data using Neural Networks

  We explore the use of neural networks trained with dropout in predictingepileptic seizures from electroencephalographic data (scalp EEG). The input tothe neural network is a 126 feature vector containing 9 features for each ofthe 14 EEG channels obtained over 1-second, non-overlapping windows. The modelsin our experiments achieved high sensitivity and specificity on patient recordsnot used in the training process. This is demonstrated usingleave-one-out-cross-validation across patient records, where we hold out onepatient's record as the test set and use all other patients' records fortraining; repeating this procedure for all patients in the database.

Imaging Time-Series to Improve Classification and Imputation

  Inspired by recent successes of deep learning in computer vision, we proposea novel framework for encoding time series as different types of images,namely, Gramian Angular Summation/Difference Fields (GASF/GADF) and MarkovTransition Fields (MTF). This enables the use of techniques from computervision for time series classification and imputation. We used TiledConvolutional Neural Networks (tiled CNNs) on 20 standard datasets to learnhigh-level features from the individual and compound GASF-GADF-MTF images. Ourapproaches achieve highly competitive results when compared to nine of thecurrent best time series classification approaches. Inspired by the bijectionproperty of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) onthe GASF images of four standard and one synthesized compound dataset. Theimputation MSE on test data is reduced by 12.18%-48.02% when compared to usingthe raw data. An analysis of the features and weights learned via tiled CNNsand DAs explains why the approaches work.

Adopting Robustness and Optimality in Fitting and Learning

  We generalized a modified exponentialized estimator by pushing therobust-optimal (RO) index $\lambda$ to $-\infty$ for achieving robustness tooutliers by optimizing a quasi-Minimin function. The robustness is realized andcontrolled adaptively by the RO index without any predefined threshold.Optimality is guaranteed by expansion of the convexity region in the Hessianmatrix to largely avoid local optima. Detailed quantitative analysis on bothrobustness and optimality are provided. The results of proposed experiments onfitting tasks for three noisy non-convex functions and the digits recognitiontask on the MNIST dataset consolidate the conclusions.

Probabilistic Numerical Methods for Partial Differential Equations and  Bayesian Inverse Problems

  This paper develops a probabilistic numerical method for solution of partialdifferential equations (PDEs) and studies application of that method toPDE-constrained inverse problems. This approach enables the solution ofchallenging inverse problems whilst accounting, in a statistically principledway, for the impact of discretisation error due to numerical solution of thePDE. In particular, the approach confers robustness to failure of the numericalPDE solver, with statistical inferences driven to be more conservative in thepresence of substantial discretisation error. Going further, the problem ofchoosing a PDE solver is cast as a problem in the Bayesian design ofexperiments, where the aim is to minimise the impact of solver error onstatistical inferences; here the challenge of non-linear PDEs is alsoconsidered. The method is applied to parameter inference problems in whichdiscretisation error in non-negligible and must be accounted for in order toreach conclusions that are statistically valid.

Neuroevolution-Based Inverse Reinforcement Learning

  The problem of Learning from Demonstration is targeted at learning to performtasks based on observed examples. One approach to Learning from Demonstrationis Inverse Reinforcement Learning, in which actions are observed to inferrewards. This work combines a feature based state evaluation approach toInverse Reinforcement Learning with neuroevolution, a paradigm for modifyingneural networks based on their performance on a given task. Neural networks areused to learn from a demonstrated expert policy and are evolved to generate apolicy similar to the demonstration. The algorithm is discussed and evaluatedagainst competitive feature-based Inverse Reinforcement Learning approaches. Atthe cost of execution time, neural networks allow for non-linear combinationsof features in state evaluations. These valuations may correspond to statevalue or state reward. This results in better correspondence to observedexamples as opposed to using linear combinations. This work also extendsexisting work on Bayesian Non-Parametric Feature Construction for InverseReinforcement Learning by using non-linear combinations of intermediate data toimprove performance. The algorithm is observed to be specifically suitable fora linearly solvable non-deterministic Markov Decision Processes in whichmultiple rewards are sparsely scattered in state space. A conclusiveperformance hierarchy between evaluated algorithms is presented.

Finding Representative Points in Multivariate Data Using PCA

  The idea of representation has been used in various fields of study from dataanalysis to political science. In this paper, we define representativeness anddescribe a method to isolate data points that can represent the entire dataset. Also, we show how the minimum set of representative data points can begenerated. We use data from GLOBE (a project to study the effects on LandChange based on a set of parameters that include temperature, forest cover,human population, atmospheric parameters and many other variables) to test &validate the algorithm. Principal Component Analysis (PCA) is used to reducethe dimensions of the multivariate data set, so that the representative pointscan be generated efficiently and its Representativeness has been comparedagainst Random Sampling of points from the data set.

Time Series Classification from Scratch with Deep Neural Networks: A  Strong Baseline

  We propose a simple but strong baseline for time series classification fromscratch with deep neural networks. Our proposed baseline models are pureend-to-end without any heavy preprocessing on the raw data or feature crafting.The proposed Fully Convolutional Network (FCN) achieves premium performance toother state-of-the-art approaches and our exploration of the very deep neuralnetworks with the ResNet structure is also competitive. The global averagepooling in our convolutional model enables the exploitation of the ClassActivation Map (CAM) to find out the contributing region in the raw data forthe specific labels. Our models provides a simple choice for the real worldapplication and a good starting point for the future research. An overallanalysis is provided to discuss the generalization capability of our models,learned features, network structures and the classification semantics.

Bayesian Probabilistic Numerical Methods

  The emergent field of probabilistic numerics has thus far lacked clearstatistical principals. This paper establishes Bayesian probabilistic numericalmethods as those which can be cast as solutions to certain inverse problemswithin the Bayesian framework. This allows us to establish general conditionsunder which Bayesian probabilistic numerical methods are well-defined,encompassing both non-linear and non-Gaussian models. For general computation,a numerical approximation scheme is proposed and its asymptotic convergenceestablished. The theoretical development is then extended to pipelines ofcomputation, wherein probabilistic numerical methods are composed to solve morechallenging numerical tasks. The contribution highlights an important researchfrontier at the interface of numerical analysis and uncertainty quantification,with a challenging industrial application presented.

Fashioning with Networks: Neural Style Transfer to Design Clothes

  Convolutional Neural Networks have been highly successful in performing ahost of computer vision tasks such as object recognition, object detection,image segmentation and texture synthesis. In 2015, Gatys et. al [7] show howthe style of a painter can be extracted from an image of the painting andapplied to another normal photograph, thus recreating the photo in the style ofthe painter. The method has been successfully applied to a wide range of imagesand has since spawned multiple applications and mobile apps. In this paper, theneural style transfer algorithm is applied to fashion so as to synthesize newcustom clothes. We construct an approach to personalize and generate new customclothes based on a users preference and by learning the users fashion choicesfrom a limited set of clothes from their closet. The approach is evaluated byanalyzing the generated images of clothes and how well they align with theusers fashion style.

Deep Belief Networks used on High Resolution Multichannel  Electroencephalography Data for Seizure Detection

  Ubiquitous bio-sensing for personalized health monitoring is slowly becominga reality with the increasing availability of small, diverse, robust, highfidelity sensors. This oncoming flood of data begs the question of how we willextract useful information from it. In this paper we explore the use of avariety of representations and machine learning algorithms applied to the taskof seizure detection in high resolution, multichannel EEG data. We exploreclassification accuracy, computational complexity and memory requirements witha view toward understanding which approaches are most suitable for such tasksas the number of people involved and the amount of data they produce grows tobe quite large. In particular, we show that layered learning approaches such asDeep Belief Networks excel along these dimensions.

A Modern Retrospective on Probabilistic Numerics

  This article attempts to place the emergence of probabilistic numerics as amathematical-statistical research field within its historical context and toexplore how its gradual development can be related both to applications and toa modern formal treatment. We highlight in particular the parallelcontributions of Sul'din and Larkin in the 1960s and how their pioneering earlyideas have reached a degree of maturity in the intervening period, mediated byparadigms such as average-case analysis and information-based complexity. Weprovide a subjective assessment of the state of research in probabilisticnumerics and highlight some difficulties to be addressed by future works.

On the use of Deep Autoencoders for Efficient Embedded Reinforcement  Learning

  In autonomous embedded systems, it is often vital to reduce the amount ofactions taken in the real world and energy required to learn a policy. Trainingreinforcement learning agents from high dimensional image representations canbe very expensive and time consuming. Autoencoders are deep neural network usedto compress high dimensional data such as pixelated images into small latentrepresentations. This compression model is vital to efficiently learn policies,especially when learning on embedded systems. We have implemented this model onthe NVIDIA Jetson TX2 embedded GPU, and evaluated the power consumption,throughput, and energy consumption of the autoencoders for various CPU/GPU corecombinations, frequencies, and model parameters. Additionally, we have shownthe reconstructions generated by the autoencoder to analyze the quality of thegenerated compressed representation and also the performance of thereinforcement learning agent. Finally, we have presented an assessment of theviability of training these models on embedded systems and their usefulness indeveloping autonomous policies. Using autoencoders, we were able to achieve 4-5$\times$ improved performance compared to a baseline RL agent with aconvolutional feature extractor, while using less than 2W of power.

Extending Signature-based Intrusion Detection Systems WithBayesian  Abductive Reasoning

  Evolving cybersecurity threats are a persistent challenge forsystemadministrators and security experts as new malwares are continu-allyreleased. Attackers may look for vulnerabilities in commercialproducts orexecute sophisticated reconnaissance campaigns tounderstand a targets networkand gather information on securityproducts like firewalls and intrusiondetection / prevention systems(network or host-based). Many new attacks tend tobe modificationsof existing ones. In such a scenario, rule-based systems failto detectthe attack, even though there are minor differences in conditions/attributes between rules to identify the new and existing attack. Todetectthese differences the IDS must be able to isolate the subset ofconditions thatare true and predict the likely conditions (differentfrom the original) thatmust be observed. In this paper, we proposeaprobabilistic abductivereasoningapproach that augments an exist-ing rule-based IDS (snort [29]) todetect these evolved attacks by (a)Predicting rule conditions that are likelyto occur (based on existingrules) and (b) able to generate new snort rules whenprovided withseed rule (i.e. a starting rule) to reduce the burden on expertstoconstantly update them. We demonstrate the effectiveness of theapproach bygenerating new rules from the snort 2012 rules set andtesting it on the MACCDC2012 dataset [6].

Adaptive Normalized Risk-Averting Training For Deep Neural Networks

  This paper proposes a set of new error criteria and learning approaches,Adaptive Normalized Risk-Averting Training (ANRAT), to attack the non-convexoptimization problem in training deep neural networks (DNNs). Theoretically, wedemonstrate its effectiveness on global and local convexity lower-bounded bythe standard $L_p$-norm error. By analyzing the gradient on the convexity index$\lambda$, we explain the reason why to learn $\lambda$ adaptively usinggradient descent works. In practice, we show how this method improves trainingof deep neural networks to solve visual recognition tasks on the MNIST andCIFAR-10 datasets. Without using pretraining or other tricks, we obtain resultscomparable or superior to those reported in recent literature on the same tasksusing standard ConvNets + MSE/cross entropy. Performance on deep/shallowmultilayer perceptrons and Denoised Auto-encoders is also explored. ANRAT canbe combined with other quasi-Newton training methods, innovative networkvariants, regularization techniques and other specific tricks in DNNs. Otherthan unsupervised pretraining, it provides a new perspective to address thenon-convex optimization problem in DNNs.

Identifying Spatial Relations in Images using Convolutional Neural  Networks

  Traditional approaches to building a large scale knowledge graph have usuallyrelied on extracting information (entities, their properties, and relationsbetween them) from unstructured text (e.g. Dbpedia). Recent advances inConvolutional Neural Networks (CNN) allow us to shift our focus to learningentities and relations from images, as they build robust models that requirelittle or no pre-processing of the images. In this paper, we present anapproach to identify and extract spatial relations (e.g., The girl is standingbehind the table) from images using CNNs. Our research addresses two specificchallenges: providing insight into how spatial relations are learned by thenetwork and which parts of the image are used to predict these relations. Weuse the pre-trained network VGGNet to extract features from an image and traina Multi-layer Perceptron (MLP) on a set of synthetic images and the sun09dataset to extract spatial relations. The MLP predicts spatial relationswithout a bounding box around the objects or the space in the image depictingthe relation. To understand how the spatial relations are represented in thenetwork, a heatmap is overlayed on the image to show the regions that aredeemed important by the network. Also, we analyze the MLP to show therelationship between the activation of consistent groups of nodes and theprediction of a spatial relation. We show how the loss of these groups affectsthe networks ability to identify relations.

