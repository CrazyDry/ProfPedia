Efficiency and Nash Equilibria in a Scrip System for P2P Networks

  A model of providing service in a P2P network is analyzed. It is shown thatby adding a scrip system, a mechanism that admits a reasonable Nash equilibriumthat reduces free riding can be obtained. The effect of varying the totalamount of money (scrip) in the system on efficiency (i.e., social welfare) isanalyzed, and it is shown that by maintaining the appropriate ratio between thetotal amount of money and the number of agents, efficiency is maximized. Thework has implications for many online systems, not only P2P networks but also awide variety of online forums for which scrip systems are popular, but formalanalyses have been lacking.

General Truthfulness Characterizations Via Convex Analysis

  We present a model of truthful elicitation which generalizes and extendsmechanisms, scoring rules, and a number of related settings that do not quitequalify as one or the other. Our main result is a characterization theorem,yielding characterizations for all of these settings, including a newcharacterization of scoring rules for non-convex sets of distributions. Wegeneralize this model to eliciting some property of the agent's privateinformation, and provide the first general characterization for this setting.We also show how this yields a new proof of a result in mechanism design due toSaks and Yu.

The Lotus-Eater Attack

  Many protocols for distributed and peer-to-peer systems have the feature thatnodes will stop providing service for others once they have received a certainamount of service. Examples include BitTorent's unchoking policy, BAR Gossip'sbalanced exchanges, and threshold strategies in scrip systems. An attacker canexploit this by providing service in a targeted way to prevent chosen nodesfrom providing service. While such attacks cannot be prevented, we discusstechniques that can be used to limit the damage they do. These techniquespresume that a certain number of processes will follow the recommendedprotocol, even if they could do better by ``gaming'' the system.

Fixed and Market Pricing for Cloud Services

  We study a model of congestible resources, where pricing and scheduling areintertwined. Motivated by the problem of pricing cloud instances, we model acloud computing service as linked $GI/GI/\cdot$ queuing systems where theprovider chooses to offer a fixed pricing service, a dynamic market basedservice, or a hybrid of both, where jobs can be preempted in the market-basedservice. Users (jobs), who are heterogeneous in both the value they place onservice and their cost for waiting, then choose between the services offered.Combining insights from auction theory with queuing theory we are able tocharacterize user equilibrium behavior, and show its insensitivity to theprecise market design mechanism used. We then provide theoretical andsimulation based evidence suggesting that a fixed price typically, though notalways, generates a higher expected revenue than the hybrid system for theprovider.

Optimizing Scrip Systems: Efficiency, Crashes, Hoarders, and Altruists

  We discuss the design of efficient scrip systems and develop tools forempirically analyzing them. For those interested in the empirical study ofscrip systems, we demonstrate how characteristics of agents in a system can beinferred from the equilibrium distribution of money. From the perspective of asystem designer, we examine the effect of the money supply on social welfareand show that social welfare is maximized by increasing the money supply up tothe point that the system experiences a ``monetary crash,'' where money issufficiently devalued that no agent is willing to perform a service. We alsoexamine the implications of the presence of altruists and hoarders on theperformance of the system. While a small number of altruists may improve socialwelfare, too many can also cause the system to experience a monetary crash,which may be bad for social welfare. Hoarders generally decrease social welfarebut, surprisingly, they also promote system stability by helping preventmonetary crashes. In addition, we provide new technical tools for analyzing andcomputing equilibria by showing that our model exhibits strategiccomplementarities, which implies that there exist equilibria in pure strategiesthat can be computed efficiently.

Truthful Mechanisms for Agents that Value Privacy

  Recent work has constructed economic mechanisms that are both truthful anddifferentially private. In these mechanisms, privacy is treated separately fromthe truthfulness; it is not incorporated in players' utility functions (anddoing so has been shown to lead to non-truthfulness in some cases). In thiswork, we propose a new, general way of modelling privacy in players' utilityfunctions. Specifically, we only assume that if an outcome $o$ has the propertythat any report of player $i$ would have led to $o$ with approximately the sameprobability, then $o$ has small privacy cost to player $i$. We give threemechanisms that are truthful with respect to our modelling of privacy: for anelection between two candidates, for a discrete version of the facilitylocation problem, and for a general social choice problem with discreteutilities (via a VCG-like mechanism). As the number $n$ of players increases,the social welfare achieved by our mechanisms approaches optimal (as a fractionof $n$).

Ranking and Tradeoffs in Sponsored Search Auctions

  In a sponsored search auction, decisions about how to rank ads imposetradeoffs between objectives such as revenue and welfare. In this paper, weexamine how these tradeoffs should be made. We begin by arguing that the mostnatural solution concept to evaluate these tradeoffs is the lowest symmetricNash equilibrium (SNE). As part of this argument, we generalise the well knownconnection between the lowest SNE and the VCG outcome. We then propose a newranking algorithm, loosely based on the revenue-optimal auction, that uses areserve price to order the ads (not just to filter them) and give conditionsunder which it raises more revenue than simply applying that reserve price.Finally, we conduct extensive simulations examining the tradeoffs enabled bydifferent ranking algorithms and show that our proposed algorithm enablessuperior operating points by a variety of metrics.

An Equilibrium Analysis of Scrip Systems

  A game-theoretic model of scrip (artificial currency) systems is analyzed. Itis shown that relative entropy can be used to characterize the distribution ofagent wealth when all agents use threshold strategies---that is, they volunteerto do work iff they have below a threshold amount of money. Monotonicity ofagents' best-reply functions is used to show that scrip systems have purestrategy equilibria where all agents use threshold strategies. An algorithm isgiven that can compute such an equilibrium and the resulting distribution ofwealth.

Multiagent Learning in Large Anonymous Games

  In large systems, it is important for agents to learn to act effectively, butsophisticated multi-agent learning algorithms generally do not scale. Analternative approach is to find restricted classes of games where simple,efficient algorithms converge. It is shown that stage learning efficientlyconverges to Nash equilibria in large anonymous games if best-reply dynamicsconverge. Two features are identified that improve convergence. First, ratherthan making learning more difficult, more agents are actually beneficial inmany settings. Second, providing agents with statistical information about thebehavior of others can significantly reduce the number of observations needed.

Optimal Auctions with Restricted Allocations

  We study the problem of designing optimal auctions under restrictions on theset of permissible allocations. In addition to allowing us to restrict todeterministic mechanisms, we can also indirectly model non-additive valuations.We prove a strong duality result, extending a result due to Daskalakis et al.[2015], that guarantees the existence of a certificate of optimality foroptimal restricted mechanisms. As a corollary of our result, we provide a newcharacterization of the set of allocations that the optimal mechanism mayactually use. To illustrate our result we find and certify optimal mechanismsfor four settings where previous frameworks do not apply, and provide neweconomic intuition about some of the tools that have previously been used tofind optimal mechanisms.

Partial Verification as a Substitute for Money

  Recent work shows that we can use partial verification instead of money toimplement truthful mechanisms. In this paper we develop tools to answer thefollowing question. Given an allocation rule that can be made truthful withpayments, what is the minimal verification needed to make it truthful withoutthem? Our techniques leverage the geometric relationship between the type spaceand the set of possible allocations.

Mix and Match

  Consider a matching problem on a graph where disjoint sets of vertices areprivately owned by self-interested agents. An edge between a pair of verticesindicates compatibility and allows the vertices to match. We seek a mechanismto maximize the number of matches despite self-interest, with agents that eachwant to maximize the number of their own vertices that match. Each agent canchoose to hide some of its vertices, and then privately match the hiddenvertices with any of its own vertices that go unmatched by the mechanism. Aprominent application of this model is to kidney exchange, where agentscorrespond to hospitals and vertices to donor-patient pairs. Here hospitals maygame an exchange by holding back pairs and harm social welfare. In this paperwe seek to design mechanisms that are strategyproof, in the sense that agentscannot benefit from hiding vertices, and approximately maximize efficiency,i.e., produce a matching that is close in cardinality to the maximumcardinality matching. Our main result is the design and analysis of theeponymous Mix-and-Match mechanism; we show that this randomized mechanism isstrategyproof and provides a 2-approximation. Lower bounds establish that themechanism is near optimal.

Optimizing Scrip Systems: Crashes, Altruists, Hoarders, Sybils and  Collusion

  Scrip, or artificial currency, is a useful tool for designing systems thatare robust to selfish behavior by users. However, it also introduces problemsfor a system designer, such as how the amount of money in the system should beset. In this paper, the effect of varying the total amount of money in a scripsystem on efficiency (i.e., social welfare---the total utility of all theagents in the system) is analyzed, and it is shown that by maintaining theappropriate ratio between the total amount of money and the number of agents,efficiency is maximized. This ratio can be found by increasing the money supplyto just below the point that the system would experience a "monetary crash,"where money is sufficiently devalued that no agent is willing to perform aservice. The implications of the presence of altruists, hoarders, sybils, andcollusion on the performance of the system are examined. Approaches arediscussed to identify the strategies and types of agents.

Manipulating Scrip Systems: Sybils and Collusion

  Game-theoretic analyses of distributed and peer-to-peer systems typically usethe Nash equilibrium solution concept, but this explicitly excludes thepossibility of strategic behavior involving more than one agent. We examine theeffects of two types of strategic behavior involving more than one agent,sybils and collusion, in the context of scrip systems where agents provide eachother with service in exchange for scrip. Sybils make an agent more likely tobe chosen to provide service, which generally makes it harder for agentswithout sybils to earn money and decreases social welfare. Surprisingly, incertain circumstances it is possible for sybils to make all agents better off.While collusion is generally bad, in the context of scrip systems it actuallytends to make all agents better off, not merely those who collude. Theseresults also provide insight into the effects of allowing agents to advertiseand loan money. While many extensions of Nash equilibrium have been proposedthat address collusion and other issues relevant to distributed andpeer-to-peer systems, our results show that none of them adequately address theissues raised by sybils and collusion in scrip systems.

Elicitation Complexity of Statistical Properties

  A property, or statistical functional, is said to be elicitable if itminimizes expected loss for some loss function. The study of which propertiesare elicitable sheds light on the capabilities and limits of empirical riskminimization. While several recent papers have asked which properties areelicitable, we instead advocate for a more nuanced question: how manydimensions are required to indirectly elicit a given property? This number iscalled the elicitation complexity of the property. We lay the foundation for ageneral theory of elicitation complexity, including several basic results abouthow elicitation complexity behaves, and the complexity of standard propertiesof interest. Building on this foundation, we establish several upper and lowerbounds for the broad class of Bayes risks. We apply these results by provingtight complexity bounds, with respect to identifiable properties, for variance,financial risk measures, entropy, norms, and new properties of interest. Wethen show how some of these bounds can extend to other practical classes ofproperties, and conclude with a discussion of open directions.

On the Zero-Error Capacity Threshold for Deletion Channels

  We consider the zero-error capacity of deletion channels. Specifically, weconsider the setting where we choose a codebook ${\cal C}$ consisting ofstrings of $n$ bits, and our model of the channel corresponds to an adversarywho may delete up to $pn$ of these bits for a constant $p$. Our goal is todecode correctly without error regardless of the actions of the adversary. Weconsider what values of $p$ allow non-zero capacity in this setting. We suggestmultiple approaches, one of which makes use of the natural connection betweenthis problem and the problem of finding the expected length of the longestcommon subsequence of two random sequences.

Elicitation for Aggregation

  We study the problem of eliciting and aggregating probabilistic informationfrom multiple agents. In order to successfully aggregate the predictions ofagents, the principal needs to elicit some notion of confidence from agents,capturing how much experience or knowledge led to their predictions. Toformalize this, we consider a principal who wishes to elicit predictions abouta random variable from a group of Bayesian agents, each of whom have privatelyobserved some independent samples of the random variable, and hopes toaggregate the predictions as if she had directly observed the samples of allagents. Leveraging techniques from Bayesian statistics, we represent confidenceas the number of samples an agent has observed, which is quantified by ahyperparameter from a conjugate family of prior distributions. This then allowsus to show that if the principal has access to a few samples, she can achieveher aggregation goal by eliciting predictions from agents using proper scoringrules. In particular, if she has access to one sample, she can successfullyaggregate the agents' predictions if and only if every posterior predictivedistribution corresponds to a unique value of the hyperparameter. Furthermore,this uniqueness holds for many common distributions of interest. When thisuniqueness property does not hold, we construct a novel and intuitive mechanismwhere a principal with two samples can elicit and optimally aggregate theagents' predictions.

Simple Pricing Schemes for the Cloud

  The problem of pricing the cloud has attracted much recent attention due tothe widespread use of cloud computing and cloud services. From a theoreticalperspective, several mechanisms that provide strong efficiency or fairnessguarantees and desirable incentive properties have been designed. However,these mechanisms often rely on a rigid model, with several parameters needingto be precisely known in order for the guarantees to hold. In this paper, weconsider a stochastic model and show that it is possible to obtain good welfareand revenue guarantees with simple mechanisms that do not make use of theinformation on some of these parameters. In particular, we prove that amechanism that sets the same price per time step for jobs of any lengthachieves at least 50% of the welfare and revenue obtained by a mechanism thatcan set different prices for jobs of different lengths, and the ratio can beimproved if we have more specific knowledge of some parameters. Similarly, amechanism that sets the same price for all servers even though the servers mayreceive different kinds of jobs can provide a reasonable welfare and revenueapproximation compared to a mechanism that is allowed to set different pricesfor different servers.

Bayesian Admission Policies for Cloud Computing Clusters

  Cloud computing providers must handle heterogeneous customer workloads forresources such as (virtual) CPU or GPU cores. This is particularly challengingif customers, who are already running a job on a cluster, scale their resourceusage up and down over time. The provider therefore has to continuously decidewhether she can add additional workloads to a given cluster or if doing sowould impact existing workloads' ability to scale. Currently, this is oftendone using simple threshold policies to reserve large parts of each cluster,which leads to low average utilization of the cluster. In this paper, wepropose more sophisticated Bayesian policies for controlling admission to acluster and demonstrate that they significantly increase cluster utilization.We first introduce the cluster admission problem and formalize it as aconstrained Partially Observable Markov Decision Problem (POMDP). We then fitthe parameters of the POMDP on a data trace from Microsoft Azure. As it isinfeasible to solve the POMDP optimally, we then systematically designheuristic Bayesian admission policies that estimate moments of each workload'sdistribution of future resource usage. Via simulations we show that ourBayesian admission policies lead to a substantial improvement over the simplethreshold policy. We then evaluate how much further this can be improved withlearned or elicited prior information and how to incentivize users to providethis information.

Optimising Trade-offs Among Stakeholders in Ad Auctions

  We examine trade-offs among stakeholders in ad auctions. Our metrics are therevenue for the utility of the auctioneer, the number of clicks for the utilityof the users and the welfare for the utility of the advertisers. We show how tooptimize linear combinations of the stakeholder utilities, showing that thesecan be tackled through a GSP auction with a per-click reserve price. We thenexamine constrained optimization of stakeholder utilities.  We use simulations and analysis of real-world sponsored search auction datato demonstrate the feasible trade-offs, examining the effect of changing theallowed number of ads on the utilities of the stakeholders. We investigate bothshort term effects, when the players do not have the time to modify theirbehavior, and long term equilibrium conditions.  Finally, we examine a combinatorially richer constrained optimizationproblem, where there are several possible allowed configurations (templates) ofad formats. This model captures richer ad formats, which allow using theavailable screen real estate in various ways. We show that two naturalgeneralizations of the GSP auction rules to this domain are poorly behaved,resulting in not having a symmetric Nash equilibrium or having one with poorwelfare. We also provide positive results for restricted cases.

Decentralised Norm Monitoring in Open Multi-Agent Systems

  We consider the problem of detecting norm violations in open multi-agentsystems (MAS). We show how, using ideas from scrip systems, we can designmechanisms where the agents comprising the MAS are incentivised to monitor theactions of other agents for norm violations. The cost of providing theincentives is not borne by the MAS and does not come from fines charged fornorm violations (fines may be impossible to levy in a system where agents arefree to leave and rejoin again under a different identity). Instead, monitoringincentives come from (scrip) fees for accessing the services provided by theMAS. In some cases, perfect monitoring (and hence enforcement) can be achieved:no norms will be violated in equilibrium. In other cases, we show that, whileit is impossible to achieve perfect enforcement, we can get arbitrarily close;we can make the probability of a norm violation in equilibrium arbitrarilysmall. We show using simulations that our theoretical results hold formulti-agent systems with as few as 1000 agents---the system rapidly convergesto the steady-state distribution of scrip tokens necessary to ensure monitoringand then remains close to the steady state.

