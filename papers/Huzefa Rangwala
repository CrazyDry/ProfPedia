Modeling Precursors for Event Forecasting via Nested Multi-Instance  Learning

  Forecasting events like civil unrest movements, disease outbreaks, financialmarket movements and government elections from open source indicators such asnews feeds and social media streams is an important and challenging problem.From the perspective of human analysts and policy makers, forecastingalgorithms need to provide supporting evidence and identify the causes relatedto the event of interest. We develop a novel multiple instance learning basedapproach that jointly tackles the problem of identifying evidence-basedprecursors and forecasts events into the future. Specifically, given acollection of streaming news articles from multiple sources we develop a nestedmultiple instance learning approach to forecast significant societal eventsacross three countries in Latin America. Our algorithm is able to identify newsarticles considered as precursors for a protest. Our empirical evaluation showsthe strengths of our proposed approaches in filtering candidate precursors,forecasting the occurrence of events with a lead time and predicting thecharacteristics of different events in comparison to several otherformulations. We demonstrate through case studies the effectiveness of ourproposed model in filtering the candidate precursors for inspection by a humananalyst.

Filter based Taxonomy Modification for Improving Hierarchical  Classification

  Hierarchical Classification (HC) is a supervised learning problem whereunlabeled instances are classified into a taxonomy of classes. Several methodsthat utilize the hierarchical structure have been developed to improve the HCperformance. However, in most cases apriori defined hierarchical structure bydomain experts is inconsistent; as a consequence performance improvement is notnoticeable in comparison to flat classification methods. We propose a scalabledata-driven filter based rewiring approach to modify an expert-definedhierarchy. Experimental comparisons of top-down HC with our modified hierarchy,on a wide range of datasets shows classification performance improvement overthe baseline hierarchy (i:e:, defined by expert), clustered hierarchy andflattening based hierarchy modification approaches. In comparison to existingrewiring approaches, our developed method (rewHier) is computationallyefficient, enabling it to scale to datasets with large numbers of classes,instances and features. We also show that our modified hierarchy leads toimproved classification performance for classes with few training samples incomparison to flat and state-of-the-art HC approaches.

Predicting Performance on MOOC Assessments using Multi-Regression Models

  The past few years has seen the rapid growth of data min- ing approaches forthe analysis of data obtained from Mas- sive Open Online Courses (MOOCs). Theobjectives of this study are to develop approaches to predict the scores a stu-dent may achieve on a given grade-related assessment based on information,considered as prior performance or prior ac- tivity in the course. We develop apersonalized linear mul- tiple regression (PLMR) model to predict the grade fora student, prior to attempting the assessment activity. The developed model isreal-time and tracks the participation of a student within a MOOC (viaclick-stream server logs) and predicts the performance of a student on the nextas- sessment within the course offering. We perform a com- prehensive set ofexperiments on data obtained from three openEdX MOOCs via a Stanford Universityinitiative. Our experimental results show the promise of the proposed ap-proach in comparison to baseline approaches and also helps in identification ofkey features that are associated with the study habits and learning behaviorsof students.

Inconsistent Node Flattening for Improving Top-down Hierarchical  Classification

  Large-scale classification of data where classes are structurally organizedin a hierarchy is an important area of research. Top-down approaches thatexploit the hierarchy during the learning and prediction phase are efficientfor large scale hierarchical classification. However, accuracy of top-downapproaches is poor due to error propagation i.e., prediction errors made athigher levels in the hierarchy cannot be corrected at lower levels. One of themain reason behind errors at the higher levels is the presence of inconsistentnodes that are introduced due to the arbitrary process of creating thesehierarchies by domain experts. In this paper, we propose two differentdata-driven approaches (local and global) for hierarchical structuremodification that identifies and flattens inconsistent nodes present within thehierarchy. Our extensive empirical evaluation of the proposed approaches onseveral image and text datasets with varying distribution of features, classesand training instances per class shows improved classification performance overcompeting hierarchical modification approaches. Specifically, we see animprovement upto 7% in Macro-F1 score with our approach over best TD baseline.SOURCE CODE: http://www.cs.gmu.edu/~mlbio/InconsistentNodeFlattening

Embedding Feature Selection for Large-scale Hierarchical Classification

  Large-scale Hierarchical Classification (HC) involves datasets consisting ofthousands of classes and millions of training instances with high-dimensionalfeatures posing several big data challenges. Feature selection that aims toselect the subset of discriminant features is an effective strategy to dealwith large-scale HC problem. It speeds up the training process, reduces theprediction time and minimizes the memory requirements by compressing the totalsize of learned model weight vectors. Majority of the studies have also shownfeature selection to be competent and successful in improving theclassification accuracy by removing irrelevant features. In this work, weinvestigate various filter-based feature selection methods for dimensionalityreduction to solve the large-scale HC problem. Our experimental evaluation ontext and image datasets with varying distribution of features, classes andinstances shows upto 3x order of speed-up on massive datasets and upto 45% lessmemory requirements for storing the weight vectors of learned model without anysignificant loss (improvement for some datasets) in the classificationaccuracy. Source Code: https://cs.gmu.edu/~mlbio/featureselection.

Classifying Documents within Multiple Hierarchical Datasets using  Multi-Task Learning

  Multi-task learning (MTL) is a supervised learning paradigm in which theprediction models for several related tasks are learned jointly to achievebetter generalization performance. When there are only a few training examplesper task, MTL considerably outperforms the traditional Single task learning(STL) in terms of prediction accuracy. In this work we develop an MTL basedapproach for classifying documents that are archived within dual concepthierarchies, namely, DMOZ and Wikipedia. We solve the multi-classclassification problem by defining one-versus-rest binary classification tasksfor each of the different classes across the two hierarchical datasets. Insteadof learning a linear discriminant for each of the different tasksindependently, we use a MTL approach with relationships between the differenttasks across the datasets established using the non-parametric, lazy, nearestneighbor approach. We also develop and evaluate a transfer learning (TL)approach and compare the MTL (and TL) methods against the standard single tasklearning and semi-supervised learning approaches. Our empirical resultsdemonstrate the strength of our developed methods that show an improvementespecially when there are fewer number of training examples per classificationtask.

Multi-Differential Fairness Auditor for Black Box Classifiers

  Machine learning algorithms are increasingly involved in sensitivedecision-making process with adversarial implications on individuals. Thispaper presents mdfa, an approach that identifies the characteristics of thevictims of a classifier's discrimination. We measure discrimination as aviolation of multi-differential fairness. Multi-differential fairness is aguarantee that a black box classifier's outcomes do not leak information on thesensitive attributes of a small group of individuals. We reduce the problem ofidentifying worst-case violations to matching distributions and predictingwhere sensitive attributes and classifier's outcomes coincide. We apply mdfa toa recidivism risk assessment classifier and demonstrate that individualsidentified as African-American with little criminal history are three-timesmore likely to be considered at high risk of violent recidivism than similarindividuals but not African-American.

Next-Term Student Performance Prediction: A Recommender Systems Approach

  An enduring issue in higher education is student retention to successfulgraduation. National statistics indicate that most higher educationinstitutions have four-year degree completion rates around 50 percent, or justhalf of their student populations. While there are prediction models whichilluminate what factors assist with college student success, interventions thatsupport course selections on a semester-to-semester basis have yet to be deeplyunderstood. To further this goal, we develop a system to predict students'grades in the courses they will enroll in during the next enrollment term bylearning patterns from historical transcript data coupled with additionalinformation about students, courses and the instructors teaching them.  We explore a variety of classic and state-of-the-art techniques which haveproven effective for recommendation tasks in the e-commerce domain. In ourexperiments, Factorization Machines (FM), Random Forests (RF), and thePersonalized Multi-Linear Regression model achieve the lowest prediction error.Application of a novel feature selection technique is key to the predictivesuccess and interpretability of the FM. By comparing feature importance acrosspopulations and across models, we uncover strong connections between instructorcharacteristics and student performance. We also discover key differencesbetween transfer and non-transfer students. Ultimately we find that a hybridFM-RF method can be used to accurately predict grades for both new andreturning students taking both new and existing courses. Application of thesetechniques holds promise for student degree planning, instructor interventions,and personalized advising, all of which could improve retention and academicperformance.

Grade Prediction with Temporal Course-wise Influence

  There is a critical need to develop new educational technology applicationsthat analyze the data collected by universities to ensure that studentsgraduate in a timely fashion (4 to 6 years); and they are well prepared forjobs in their respective fields of study. In this paper, we present a novelapproach for analyzing historical educational records from a large, publicuniversity to perform next-term grade prediction; i.e., to estimate the gradesthat a student will get in a course that he/she will enroll in the next term.Accurate next-term grade prediction holds the promise for better student degreeplanning, personalized advising and automated interventions to ensure thatstudents stay on track in their chosen degree program and graduate on time. Wepresent a factorization-based approach called Matrix Factorization withTemporal Course-wise Influence that incorporates course-wise influence effectsand temporal effects for grade prediction. In this model, students and coursesare represented in a latent "knowledge" space. The grade of a student on acourse is modeled as the similarity of their latent representation in the"knowledge" space. Course-wise influence is considered as an additional factorin the grade prediction. Our experimental results show that the proposed methodoutperforms several baseline approaches and infer meaningful patterns betweenpairs of courses within academic programs.

ALE: Additive Latent Effect Models for Grade Prediction

  The past decade has seen a growth in the development and deployment ofeducational technologies for assisting college-going students in choosingmajors, selecting courses and acquiring feedback based on past academicperformance. Grade prediction methods seek to estimate a grade that a studentmay achieve in a course that she may take in the future (e.g., next term).Accurate and timely prediction of students' academic grades is important fordeveloping effective degree planners and early warning systems, and ultimatelyimproving educational outcomes. Existing grade pre- diction methods mostlyfocus on modeling the knowledge components associated with each course andstudent, and often overlook other factors such as the difficulty of eachknowledge component, course instructors, student interest, capabilities andeffort. In this paper, we propose additive latent effect models thatincorporate these factors to predict the student next-term grades.Specifically, the proposed models take into account four factors: (i) student'sacademic level, (ii) course instructors, (iii) student global latent factor,and (iv) latent knowledge factors. We compared the new models with severalstate-of-the-art methods on students of various characteristics (e.g., whethera student transferred in or not). The experimental results demonstrate that theproposed methods significantly outperform the baselines on grade predictionproblem. Moreover, we perform a thorough analysis on the importance ofdifferent factors and how these factors can practically assist students incourse selection, and finally improve their academic performance.

Reliable Deep Grade Prediction with Uncertainty Estimation

  Currently, college-going students are taking longer to graduate than theirparental generations. Further, in the United States, the six-year graduationrate has been 59% for decades. Improving the educational quality by trainingbetter-prepared students who can successfully graduate in a timely manner iscritical. Accurately predicting students' grades in future courses hasattracted much attention as it can help identify at-risk students early so thatpersonalized feedback can be provided to them on time by advisors. Priorresearch on students' grade prediction include shallow linear models; however,students' learning is a highly complex process that involves the accumulationof knowledge across a sequence of courses that can not be sufficiently modeledby these linear models. In addition to that, prior approaches focus onprediction accuracy without considering prediction uncertainty, which isessential for advising and decision making. In this work, we present two typesof Bayesian deep learning models for grade prediction. The MLP ignores thetemporal dynamics of students' knowledge evolution. Hence, we propose RNN forstudents' performance prediction. To evaluate the performance of the proposedmodels, we performed extensive experiments on data collected from a largepublic university. The experimental results show that the proposed modelsachieve better performance than prior state-of-the-art approaches. Besides moreaccurate results, Bayesian deep learning models estimate uncertainty associatedwith the predictions. We explore how uncertainty estimation can be appliedtowards developing a reliable educational early warning system. In addition touncertainty, we also develop an approach to explain the prediction results,which is useful for advisors to provide personalized feedback to students.

