Modeling Precursors for Event Forecasting via Nested Multi-Instance
  Learning

  Forecasting events like civil unrest movements, disease outbreaks, financial
market movements and government elections from open source indicators such as
news feeds and social media streams is an important and challenging problem.
From the perspective of human analysts and policy makers, forecasting
algorithms need to provide supporting evidence and identify the causes related
to the event of interest. We develop a novel multiple instance learning based
approach that jointly tackles the problem of identifying evidence-based
precursors and forecasts events into the future. Specifically, given a
collection of streaming news articles from multiple sources we develop a nested
multiple instance learning approach to forecast significant societal events
across three countries in Latin America. Our algorithm is able to identify news
articles considered as precursors for a protest. Our empirical evaluation shows
the strengths of our proposed approaches in filtering candidate precursors,
forecasting the occurrence of events with a lead time and predicting the
characteristics of different events in comparison to several other
formulations. We demonstrate through case studies the effectiveness of our
proposed model in filtering the candidate precursors for inspection by a human
analyst.


Filter based Taxonomy Modification for Improving Hierarchical
  Classification

  Hierarchical Classification (HC) is a supervised learning problem where
unlabeled instances are classified into a taxonomy of classes. Several methods
that utilize the hierarchical structure have been developed to improve the HC
performance. However, in most cases apriori defined hierarchical structure by
domain experts is inconsistent; as a consequence performance improvement is not
noticeable in comparison to flat classification methods. We propose a scalable
data-driven filter based rewiring approach to modify an expert-defined
hierarchy. Experimental comparisons of top-down HC with our modified hierarchy,
on a wide range of datasets shows classification performance improvement over
the baseline hierarchy (i:e:, defined by expert), clustered hierarchy and
flattening based hierarchy modification approaches. In comparison to existing
rewiring approaches, our developed method (rewHier) is computationally
efficient, enabling it to scale to datasets with large numbers of classes,
instances and features. We also show that our modified hierarchy leads to
improved classification performance for classes with few training samples in
comparison to flat and state-of-the-art HC approaches.


Predicting Performance on MOOC Assessments using Multi-Regression Models

  The past few years has seen the rapid growth of data min- ing approaches for
the analysis of data obtained from Mas- sive Open Online Courses (MOOCs). The
objectives of this study are to develop approaches to predict the scores a stu-
dent may achieve on a given grade-related assessment based on information,
considered as prior performance or prior ac- tivity in the course. We develop a
personalized linear mul- tiple regression (PLMR) model to predict the grade for
a student, prior to attempting the assessment activity. The developed model is
real-time and tracks the participation of a student within a MOOC (via
click-stream server logs) and predicts the performance of a student on the next
as- sessment within the course offering. We perform a com- prehensive set of
experiments on data obtained from three openEdX MOOCs via a Stanford University
initiative. Our experimental results show the promise of the proposed ap-
proach in comparison to baseline approaches and also helps in identification of
key features that are associated with the study habits and learning behaviors
of students.


Inconsistent Node Flattening for Improving Top-down Hierarchical
  Classification

  Large-scale classification of data where classes are structurally organized
in a hierarchy is an important area of research. Top-down approaches that
exploit the hierarchy during the learning and prediction phase are efficient
for large scale hierarchical classification. However, accuracy of top-down
approaches is poor due to error propagation i.e., prediction errors made at
higher levels in the hierarchy cannot be corrected at lower levels. One of the
main reason behind errors at the higher levels is the presence of inconsistent
nodes that are introduced due to the arbitrary process of creating these
hierarchies by domain experts. In this paper, we propose two different
data-driven approaches (local and global) for hierarchical structure
modification that identifies and flattens inconsistent nodes present within the
hierarchy. Our extensive empirical evaluation of the proposed approaches on
several image and text datasets with varying distribution of features, classes
and training instances per class shows improved classification performance over
competing hierarchical modification approaches. Specifically, we see an
improvement upto 7% in Macro-F1 score with our approach over best TD baseline.
SOURCE CODE: http://www.cs.gmu.edu/~mlbio/InconsistentNodeFlattening


Embedding Feature Selection for Large-scale Hierarchical Classification

  Large-scale Hierarchical Classification (HC) involves datasets consisting of
thousands of classes and millions of training instances with high-dimensional
features posing several big data challenges. Feature selection that aims to
select the subset of discriminant features is an effective strategy to deal
with large-scale HC problem. It speeds up the training process, reduces the
prediction time and minimizes the memory requirements by compressing the total
size of learned model weight vectors. Majority of the studies have also shown
feature selection to be competent and successful in improving the
classification accuracy by removing irrelevant features. In this work, we
investigate various filter-based feature selection methods for dimensionality
reduction to solve the large-scale HC problem. Our experimental evaluation on
text and image datasets with varying distribution of features, classes and
instances shows upto 3x order of speed-up on massive datasets and upto 45% less
memory requirements for storing the weight vectors of learned model without any
significant loss (improvement for some datasets) in the classification
accuracy. Source Code: https://cs.gmu.edu/~mlbio/featureselection.


Classifying Documents within Multiple Hierarchical Datasets using
  Multi-Task Learning

  Multi-task learning (MTL) is a supervised learning paradigm in which the
prediction models for several related tasks are learned jointly to achieve
better generalization performance. When there are only a few training examples
per task, MTL considerably outperforms the traditional Single task learning
(STL) in terms of prediction accuracy. In this work we develop an MTL based
approach for classifying documents that are archived within dual concept
hierarchies, namely, DMOZ and Wikipedia. We solve the multi-class
classification problem by defining one-versus-rest binary classification tasks
for each of the different classes across the two hierarchical datasets. Instead
of learning a linear discriminant for each of the different tasks
independently, we use a MTL approach with relationships between the different
tasks across the datasets established using the non-parametric, lazy, nearest
neighbor approach. We also develop and evaluate a transfer learning (TL)
approach and compare the MTL (and TL) methods against the standard single task
learning and semi-supervised learning approaches. Our empirical results
demonstrate the strength of our developed methods that show an improvement
especially when there are fewer number of training examples per classification
task.


Multi-Differential Fairness Auditor for Black Box Classifiers

  Machine learning algorithms are increasingly involved in sensitive
decision-making process with adversarial implications on individuals. This
paper presents mdfa, an approach that identifies the characteristics of the
victims of a classifier's discrimination. We measure discrimination as a
violation of multi-differential fairness. Multi-differential fairness is a
guarantee that a black box classifier's outcomes do not leak information on the
sensitive attributes of a small group of individuals. We reduce the problem of
identifying worst-case violations to matching distributions and predicting
where sensitive attributes and classifier's outcomes coincide. We apply mdfa to
a recidivism risk assessment classifier and demonstrate that individuals
identified as African-American with little criminal history are three-times
more likely to be considered at high risk of violent recidivism than similar
individuals but not African-American.


Next-Term Student Performance Prediction: A Recommender Systems Approach

  An enduring issue in higher education is student retention to successful
graduation. National statistics indicate that most higher education
institutions have four-year degree completion rates around 50 percent, or just
half of their student populations. While there are prediction models which
illuminate what factors assist with college student success, interventions that
support course selections on a semester-to-semester basis have yet to be deeply
understood. To further this goal, we develop a system to predict students'
grades in the courses they will enroll in during the next enrollment term by
learning patterns from historical transcript data coupled with additional
information about students, courses and the instructors teaching them.
  We explore a variety of classic and state-of-the-art techniques which have
proven effective for recommendation tasks in the e-commerce domain. In our
experiments, Factorization Machines (FM), Random Forests (RF), and the
Personalized Multi-Linear Regression model achieve the lowest prediction error.
Application of a novel feature selection technique is key to the predictive
success and interpretability of the FM. By comparing feature importance across
populations and across models, we uncover strong connections between instructor
characteristics and student performance. We also discover key differences
between transfer and non-transfer students. Ultimately we find that a hybrid
FM-RF method can be used to accurately predict grades for both new and
returning students taking both new and existing courses. Application of these
techniques holds promise for student degree planning, instructor interventions,
and personalized advising, all of which could improve retention and academic
performance.


Grade Prediction with Temporal Course-wise Influence

  There is a critical need to develop new educational technology applications
that analyze the data collected by universities to ensure that students
graduate in a timely fashion (4 to 6 years); and they are well prepared for
jobs in their respective fields of study. In this paper, we present a novel
approach for analyzing historical educational records from a large, public
university to perform next-term grade prediction; i.e., to estimate the grades
that a student will get in a course that he/she will enroll in the next term.
Accurate next-term grade prediction holds the promise for better student degree
planning, personalized advising and automated interventions to ensure that
students stay on track in their chosen degree program and graduate on time. We
present a factorization-based approach called Matrix Factorization with
Temporal Course-wise Influence that incorporates course-wise influence effects
and temporal effects for grade prediction. In this model, students and courses
are represented in a latent "knowledge" space. The grade of a student on a
course is modeled as the similarity of their latent representation in the
"knowledge" space. Course-wise influence is considered as an additional factor
in the grade prediction. Our experimental results show that the proposed method
outperforms several baseline approaches and infer meaningful patterns between
pairs of courses within academic programs.


ALE: Additive Latent Effect Models for Grade Prediction

  The past decade has seen a growth in the development and deployment of
educational technologies for assisting college-going students in choosing
majors, selecting courses and acquiring feedback based on past academic
performance. Grade prediction methods seek to estimate a grade that a student
may achieve in a course that she may take in the future (e.g., next term).
Accurate and timely prediction of students' academic grades is important for
developing effective degree planners and early warning systems, and ultimately
improving educational outcomes. Existing grade pre- diction methods mostly
focus on modeling the knowledge components associated with each course and
student, and often overlook other factors such as the difficulty of each
knowledge component, course instructors, student interest, capabilities and
effort. In this paper, we propose additive latent effect models that
incorporate these factors to predict the student next-term grades.
Specifically, the proposed models take into account four factors: (i) student's
academic level, (ii) course instructors, (iii) student global latent factor,
and (iv) latent knowledge factors. We compared the new models with several
state-of-the-art methods on students of various characteristics (e.g., whether
a student transferred in or not). The experimental results demonstrate that the
proposed methods significantly outperform the baselines on grade prediction
problem. Moreover, we perform a thorough analysis on the importance of
different factors and how these factors can practically assist students in
course selection, and finally improve their academic performance.


Reliable Deep Grade Prediction with Uncertainty Estimation

  Currently, college-going students are taking longer to graduate than their
parental generations. Further, in the United States, the six-year graduation
rate has been 59% for decades. Improving the educational quality by training
better-prepared students who can successfully graduate in a timely manner is
critical. Accurately predicting students' grades in future courses has
attracted much attention as it can help identify at-risk students early so that
personalized feedback can be provided to them on time by advisors. Prior
research on students' grade prediction include shallow linear models; however,
students' learning is a highly complex process that involves the accumulation
of knowledge across a sequence of courses that can not be sufficiently modeled
by these linear models. In addition to that, prior approaches focus on
prediction accuracy without considering prediction uncertainty, which is
essential for advising and decision making. In this work, we present two types
of Bayesian deep learning models for grade prediction. The MLP ignores the
temporal dynamics of students' knowledge evolution. Hence, we propose RNN for
students' performance prediction. To evaluate the performance of the proposed
models, we performed extensive experiments on data collected from a large
public university. The experimental results show that the proposed models
achieve better performance than prior state-of-the-art approaches. Besides more
accurate results, Bayesian deep learning models estimate uncertainty associated
with the predictions. We explore how uncertainty estimation can be applied
towards developing a reliable educational early warning system. In addition to
uncertainty, we also develop an approach to explain the prediction results,
which is useful for advisors to provide personalized feedback to students.


