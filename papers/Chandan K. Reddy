TRUST-TECH based Methods for Optimization and Learning

  Many problems that arise in machine learning domain deal with nonlinearity
and quite often demand users to obtain global optimal solutions rather than
local optimal ones. Optimization problems are inherent in machine learning
algorithms and hence many methods in machine learning were inherited from the
optimization literature. Popularly known as the initialization problem, the
ideal set of parameters required will significantly depend on the given
initialization values. The recently developed TRUST-TECH (TRansformation Under
STability-reTaining Equilibria CHaracterization) methodology systematically
explores the subspace of the parameters to obtain a complete set of local
optimal solutions. In this thesis work, we propose TRUST-TECH based methods for
solving several optimization and machine learning problems. Two stages namely,
the local stage and the neighborhood-search stage, are repeated alternatively
in the solution space to achieve improvements in the quality of the solutions.
Our methods were tested on both synthetic and real datasets and the advantages
of using this novel framework are clearly manifested. This framework not only
reduces the sensitivity to initialization, but also allows the flexibility for
the practitioners to use various global and local methods that work well for a
particular problem of interest. Other hierarchical stochastic algorithms like
evolutionary algorithms and smoothing algorithms are also studied and
frameworks for combining these methods with TRUST-TECH have been proposed and
evaluated on several test systems.


A Computationally Efficient and Practically Feasible Two Microphones
  Blind Speech Separation Method

  Traditionally, Blind Speech Separation techniques are computationally
expensive as they update the demixing matrix at every time frame index, making
them impractical to use in many Real-Time applications. In this paper, a robust
data-driven two-microphone sound source localization method is used as a
criterion to reduce the computational complexity of the Independent Vector
Analysis (IVA) Blind Speech Separation (BSS) method. IVA is used to separate
convolutedly mixed speech and noise sources. The practical feasibility of the
proposed method is proved by implementing it on a smartphone device to separate
speech and noise in Real-World scenarios for Hearing-Aid applications. The
experimental results with objective and subjective tests reveal the practical
usability of the developed method in many real-world applications.


An individualized super Gaussian single microphone Speech Enhancement
  for hearing aid users with smartphone as an assistive device

  In this letter, we derive a new super Gaussian Joint Maximum a Posteriori
based single microphone speech enhancement gain function. The developed Speech
Enhancement method is implemented on a smartphone, and this arrangement
functions as an assistive device to hearing aids. We introduce a tradeoff
parameter in the derived gain function that allows the smartphone user to
customize their listening preference, by controlling the amount of noise
suppression and speech distortion in real-time based on their level of hearing
comfort perceived in noisy real world acoustic environment. Objective quality
and intelligibility measures show the effectiveness of the proposed method in
comparison to benchmark techniques considered in this paper. Subjective results
reflect the usefulness of the developed Speech Enhancement application in
real-world noisy conditions at signal to noise ratio levels of 0 dB and 5 dB.


Machine Learning for Survival Analysis: A Survey

  Accurately predicting the time of occurrence of an event of interest is a
critical problem in longitudinal data analysis. One of the main challenges in
this context is the presence of instances whose event outcomes become
unobservable after a certain time point or when some instances do not
experience any event during the monitoring period. Such a phenomenon is called
censoring which can be effectively handled using survival analysis techniques.
Traditionally, statistical approaches have been widely developed in the
literature to overcome this censoring issue. In addition, many machine learning
algorithms are adapted to effectively handle survival data and tackle other
challenging problems that arise in real-world data. In this survey, we provide
a comprehensive and structured review of the representative statistical methods
along with the machine learning techniques used in survival analysis and
provide a detailed taxonomy of the existing methods. We also discuss several
topics that are closely related to survival analysis and illustrate several
successful applications in various real-world application domains. We hope that
this paper will provide a more thorough understanding of the recent advances in
survival analysis and offer some guidelines on applying these approaches to
solve new problems that arise in applications with censored data.


Deep Transfer Reinforcement Learning for Text Summarization

  Deep neural networks are data hungry models and thus face difficulties when
attempting to train on small text datasets. Transfer learning is a potential
solution but their effectiveness in the text domain is not as explored as in
areas such as image analysis. In this paper, we study the problem of transfer
learning for text summarization and discuss why existing state-of-the-art
models fail to generalize well on other (unseen) datasets. We propose a
reinforcement learning framework based on a self-critic policy gradient
approach which achieves good generalization and state-of-the-art results on a
variety of datasets. Through an extensive set of experiments, we also show the
ability of our proposed framework to fine-tune the text summarization model
using only a few training samples. To the best of our knowledge, this is the
first work that studies transfer learning in text summarization and provides a
generic solution that works well on unseen data.


DyLink2Vec: Effective Feature Representation for Link Prediction in
  Dynamic Networks

  The temporal dynamics of a complex system such as a social network or a
communication network can be studied by understanding the patterns of link
appearance and disappearance over time. A critical task along this
understanding is to predict the link state of the network at a future time
given a collection of link states at earlier time points. In existing
literature, this task is known as link prediction in dynamic networks. Solving
this task is more difficult than its counterpart in static networks because an
effective feature representation of node-pair instances for the case of dynamic
network is hard to obtain. To overcome this problem, we propose a novel method
for metric embedding of node-pair instances of a dynamic network. The proposed
method models the metric embedding task as an optimal coding problem where the
objective is to minimize the reconstruction error, and it solves this
optimization task using a gradient descent method. We validate the
effectiveness of the learned feature representation by utilizing it for link
prediction in various real-life dynamic networks. Specifically, we show that
our proposed link prediction model, which uses the extracted feature
representation for the training instances, outperforms several existing methods
that use well-known link prediction features.


Deep Reinforcement Learning For Sequence to Sequence Models

  In recent times, sequence-to-sequence (seq2seq) models have gained a lot of
popularity and provide state-of-the-art performance in a wide variety of tasks
such as machine translation, headline generation, text summarization, speech to
text conversion, and image caption generation. The underlying framework for all
these models is usually a deep neural network comprising an encoder and a
decoder. Although simple encoder-decoder models produce competitive results,
many researchers have proposed additional improvements over these
sequence-to-sequence models, e.g., using an attention-based model over the
input, pointer-generation models, and self-attention models. However, such
seq2seq models suffer from two common problems: 1) exposure bias and 2)
inconsistency between train/test measurement. Recently, a completely novel
point of view has emerged in addressing these two problems in seq2seq models,
leveraging methods from reinforcement learning (RL). In this survey, we
consider seq2seq problems from the RL point of view and provide a formulation
combining the power of RL methods in decision-making with sequence-to-sequence
models that enable remembering long-term memories. We present some of the most
recent frameworks that combine concepts from RL and deep neural networks and
explain how these two areas could benefit from each other in solving complex
seq2seq tasks. Our work aims to provide insights into some of the problems that
inherently arise with current approaches and how we can address them with
better RL models. We also provide the source code for implementing most of the
RL models discussed in this paper to support the complex task of abstractive
text summarization.


Neural Abstractive Text Summarization with Sequence-to-Sequence Models

  In the past few years, neural abstractive text summarization with
sequence-to-sequence (seq2seq) models have gained a lot of popularity. Many
interesting techniques have been proposed to improve the seq2seq models, making
them capable of handling different challenges, such as saliency, fluency and
human readability, and generate high-quality summaries. Generally speaking,
most of these techniques differ in one of these three categories: network
structure, parameter inference, and decoding/generation. There are also other
concerns, such as efficiency and parallelism for training a model. In this
paper, we provide a comprehensive literature and technical survey on different
seq2seq models for abstractive text summarization from viewpoint of network
structures, training strategies, and summary generation algorithms. Many models
were first proposed for language modeling and generation tasks, such as machine
translation, and later applied to abstractive text summarization. Therefore, we
also provide a brief review of these models. As part of this survey, we also
develop an open source library, namely Neural Abstractive Text Summarizer
(NATS) toolkit, for the abstractive text summarization. An extensive set of
experiments have been conducted on the widely used CNN/Daily Mail dataset to
examine the effectiveness of several different neural network components.
Finally, we benchmark two models implemented in NATS on two recently released
datasets, i.e., Newsroom and Bytecup.


