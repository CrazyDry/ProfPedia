TRUST-TECH based Methods for Optimization and Learning

  Many problems that arise in machine learning domain deal with nonlinearityand quite often demand users to obtain global optimal solutions rather thanlocal optimal ones. Optimization problems are inherent in machine learningalgorithms and hence many methods in machine learning were inherited from theoptimization literature. Popularly known as the initialization problem, theideal set of parameters required will significantly depend on the giveninitialization values. The recently developed TRUST-TECH (TRansformation UnderSTability-reTaining Equilibria CHaracterization) methodology systematicallyexplores the subspace of the parameters to obtain a complete set of localoptimal solutions. In this thesis work, we propose TRUST-TECH based methods forsolving several optimization and machine learning problems. Two stages namely,the local stage and the neighborhood-search stage, are repeated alternativelyin the solution space to achieve improvements in the quality of the solutions.Our methods were tested on both synthetic and real datasets and the advantagesof using this novel framework are clearly manifested. This framework not onlyreduces the sensitivity to initialization, but also allows the flexibility forthe practitioners to use various global and local methods that work well for aparticular problem of interest. Other hierarchical stochastic algorithms likeevolutionary algorithms and smoothing algorithms are also studied andframeworks for combining these methods with TRUST-TECH have been proposed andevaluated on several test systems.

A Computationally Efficient and Practically Feasible Two Microphones  Blind Speech Separation Method

  Traditionally, Blind Speech Separation techniques are computationallyexpensive as they update the demixing matrix at every time frame index, makingthem impractical to use in many Real-Time applications. In this paper, a robustdata-driven two-microphone sound source localization method is used as acriterion to reduce the computational complexity of the Independent VectorAnalysis (IVA) Blind Speech Separation (BSS) method. IVA is used to separateconvolutedly mixed speech and noise sources. The practical feasibility of theproposed method is proved by implementing it on a smartphone device to separatespeech and noise in Real-World scenarios for Hearing-Aid applications. Theexperimental results with objective and subjective tests reveal the practicalusability of the developed method in many real-world applications.

An individualized super Gaussian single microphone Speech Enhancement  for hearing aid users with smartphone as an assistive device

  In this letter, we derive a new super Gaussian Joint Maximum a Posterioribased single microphone speech enhancement gain function. The developed SpeechEnhancement method is implemented on a smartphone, and this arrangementfunctions as an assistive device to hearing aids. We introduce a tradeoffparameter in the derived gain function that allows the smartphone user tocustomize their listening preference, by controlling the amount of noisesuppression and speech distortion in real-time based on their level of hearingcomfort perceived in noisy real world acoustic environment. Objective qualityand intelligibility measures show the effectiveness of the proposed method incomparison to benchmark techniques considered in this paper. Subjective resultsreflect the usefulness of the developed Speech Enhancement application inreal-world noisy conditions at signal to noise ratio levels of 0 dB and 5 dB.

Machine Learning for Survival Analysis: A Survey

  Accurately predicting the time of occurrence of an event of interest is acritical problem in longitudinal data analysis. One of the main challenges inthis context is the presence of instances whose event outcomes becomeunobservable after a certain time point or when some instances do notexperience any event during the monitoring period. Such a phenomenon is calledcensoring which can be effectively handled using survival analysis techniques.Traditionally, statistical approaches have been widely developed in theliterature to overcome this censoring issue. In addition, many machine learningalgorithms are adapted to effectively handle survival data and tackle otherchallenging problems that arise in real-world data. In this survey, we providea comprehensive and structured review of the representative statistical methodsalong with the machine learning techniques used in survival analysis andprovide a detailed taxonomy of the existing methods. We also discuss severaltopics that are closely related to survival analysis and illustrate severalsuccessful applications in various real-world application domains. We hope thatthis paper will provide a more thorough understanding of the recent advances insurvival analysis and offer some guidelines on applying these approaches tosolve new problems that arise in applications with censored data.

Deep Transfer Reinforcement Learning for Text Summarization

  Deep neural networks are data hungry models and thus face difficulties whenattempting to train on small text datasets. Transfer learning is a potentialsolution but their effectiveness in the text domain is not as explored as inareas such as image analysis. In this paper, we study the problem of transferlearning for text summarization and discuss why existing state-of-the-artmodels fail to generalize well on other (unseen) datasets. We propose areinforcement learning framework based on a self-critic policy gradientapproach which achieves good generalization and state-of-the-art results on avariety of datasets. Through an extensive set of experiments, we also show theability of our proposed framework to fine-tune the text summarization modelusing only a few training samples. To the best of our knowledge, this is thefirst work that studies transfer learning in text summarization and provides ageneric solution that works well on unseen data.

DyLink2Vec: Effective Feature Representation for Link Prediction in  Dynamic Networks

  The temporal dynamics of a complex system such as a social network or acommunication network can be studied by understanding the patterns of linkappearance and disappearance over time. A critical task along thisunderstanding is to predict the link state of the network at a future timegiven a collection of link states at earlier time points. In existingliterature, this task is known as link prediction in dynamic networks. Solvingthis task is more difficult than its counterpart in static networks because aneffective feature representation of node-pair instances for the case of dynamicnetwork is hard to obtain. To overcome this problem, we propose a novel methodfor metric embedding of node-pair instances of a dynamic network. The proposedmethod models the metric embedding task as an optimal coding problem where theobjective is to minimize the reconstruction error, and it solves thisoptimization task using a gradient descent method. We validate theeffectiveness of the learned feature representation by utilizing it for linkprediction in various real-life dynamic networks. Specifically, we show thatour proposed link prediction model, which uses the extracted featurerepresentation for the training instances, outperforms several existing methodsthat use well-known link prediction features.

Deep Reinforcement Learning For Sequence to Sequence Models

  In recent times, sequence-to-sequence (seq2seq) models have gained a lot ofpopularity and provide state-of-the-art performance in a wide variety of taskssuch as machine translation, headline generation, text summarization, speech totext conversion, and image caption generation. The underlying framework for allthese models is usually a deep neural network comprising an encoder and adecoder. Although simple encoder-decoder models produce competitive results,many researchers have proposed additional improvements over thesesequence-to-sequence models, e.g., using an attention-based model over theinput, pointer-generation models, and self-attention models. However, suchseq2seq models suffer from two common problems: 1) exposure bias and 2)inconsistency between train/test measurement. Recently, a completely novelpoint of view has emerged in addressing these two problems in seq2seq models,leveraging methods from reinforcement learning (RL). In this survey, weconsider seq2seq problems from the RL point of view and provide a formulationcombining the power of RL methods in decision-making with sequence-to-sequencemodels that enable remembering long-term memories. We present some of the mostrecent frameworks that combine concepts from RL and deep neural networks andexplain how these two areas could benefit from each other in solving complexseq2seq tasks. Our work aims to provide insights into some of the problems thatinherently arise with current approaches and how we can address them withbetter RL models. We also provide the source code for implementing most of theRL models discussed in this paper to support the complex task of abstractivetext summarization.

Neural Abstractive Text Summarization with Sequence-to-Sequence Models

  In the past few years, neural abstractive text summarization withsequence-to-sequence (seq2seq) models have gained a lot of popularity. Manyinteresting techniques have been proposed to improve the seq2seq models, makingthem capable of handling different challenges, such as saliency, fluency andhuman readability, and generate high-quality summaries. Generally speaking,most of these techniques differ in one of these three categories: networkstructure, parameter inference, and decoding/generation. There are also otherconcerns, such as efficiency and parallelism for training a model. In thispaper, we provide a comprehensive literature and technical survey on differentseq2seq models for abstractive text summarization from viewpoint of networkstructures, training strategies, and summary generation algorithms. Many modelswere first proposed for language modeling and generation tasks, such as machinetranslation, and later applied to abstractive text summarization. Therefore, wealso provide a brief review of these models. As part of this survey, we alsodevelop an open source library, namely Neural Abstractive Text Summarizer(NATS) toolkit, for the abstractive text summarization. An extensive set ofexperiments have been conducted on the widely used CNN/Daily Mail dataset toexamine the effectiveness of several different neural network components.Finally, we benchmark two models implemented in NATS on two recently releaseddatasets, i.e., Newsroom and Bytecup.

