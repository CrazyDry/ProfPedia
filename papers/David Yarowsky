Decision Lists for Lexical Ambiguity Resolution: Application to Accent
  Restoration in Spanish and French

  This paper presents a statistical decision procedure for lexical ambiguity
resolution. The algorithm exploits both local syntactic patterns and more
distant collocational evidence, generating an efficient, effective, and highly
perspicuous recipe for resolving a given ambiguity. By identifying and
utilizing only the single best disambiguating evidence in a target context, the
algorithm avoids the problematic complex modeling of statistical dependencies.
Although directly applicable to a wide class of ambiguities, the algorithm is
described and evaluated in a realistic case study, the problem of restoring
missing accents in Spanish and French text.


Dynamic Nonlocal Language Modeling via Hierarchical Topic-Based
  Adaptation

  This paper presents a novel method of generating and applying hierarchical,
dynamic topic-based language models. It proposes and evaluates new cluster
generation, hierarchical smoothing and adaptive topic-probability estimation
techniques. These combined models help capture long-distance lexical
dependencies. Experiments on the Broadcast News corpus show significant
improvement in perplexity (10.5% overall and 33.5% on target vocabulary).


Rule Writing or Annotation: Cost-efficient Resource Usage for Base Noun
  Phrase Chunking

  This paper presents a comprehensive empirical comparison between two
approaches for developing a base noun phrase chunker: human rule writing and
active learning using interactive real-time human annotation. Several novel
variations on active learning are investigated, and underlying cost models for
cross-modal machine learning comparison are presented and explored. Results
show that it is more efficient and more successful by several measures to train
a system using active learning annotation rather than hand-crafted rule writing
at a comparable level of human labor investment.


Paradigm Completion for Derivational Morphology

  The generation of complex derived word forms has been an overlooked problem
in NLP; we fill this gap by applying neural sequence-to-sequence models to the
task. We overview the theoretical motivation for a paradigmatic treatment of
derivational morphology, and introduce the task of derivational paradigm
completion as a parallel to inflectional paradigm completion. State-of-the-art
neural models, adapted from the inflection task, are able to learn a range of
derivation patterns, and outperform a non-neural baseline by 16.4%. However,
due to semantic, historical, and lexical considerations involved in
derivational morphology, future work will be needed to achieve performance
parity with inflection-generating systems.


Massively Multilingual Adversarial Speech Recognition

  We report on adaptation of multilingual end-to-end speech recognition models
trained on as many as 100 languages. Our findings shed light on the relative
importance of similarity between the target and pretraining languages along the
dimensions of phonetics, phonology, language family, geographical location, and
orthography. In this context, experiments demonstrate the effectiveness of two
additional pretraining objectives in encouraging language-independent encoder
representations: a context-independent phoneme objective paired with a
language-adversarial classification objective.


Decision Lists for English and Basque

  In this paper we describe the systems we developed for the English (lexical
and all-words) and Basque tasks. They were all supervised systems based on
Yarowsky's Decision Lists. We used Semcor for training in the English all-words
task. We defined different feature sets for each language. For Basque, in order
to extract all the information from the text, we defined features that have not
been used before in the literature, using a morphological analyzer. We also
implemented systems that selected automatically good features and were able to
obtain a prefixed precision (85%) at the cost of coverage. The systems that
used all the features were identified as BCU-ehu-dlist-all and the systems that
selected some features as BCU-ehu-dlist-best.


Marrying Universal Dependencies and Universal Morphology

  The Universal Dependencies (UD) and Universal Morphology (UniMorph) projects
each present schemata for annotating the morphosyntactic details of language.
Each project also provides corpora of annotated text in many languages - UD at
the token level and UniMorph at the type level. As each corpus is built by
different annotators, language-specific decisions hinder the goal of universal
schemata. With compatibility of tags, each project's annotations could be used
to validate the other's. Additionally, the availability of both type- and
token-level resources would be a boon to tasks such as parsing and homograph
disambiguation. To ease this interoperability, we present a deterministic
mapping from Universal Dependencies v2 features into the UniMorph schema. We
validate our approach by lookup in the UniMorph corpora and find a
macro-average of 64.13% recall. We also note incompatibilities due to paucity
of data on either side. Finally, we present a critical evaluation of the
foundations, strengths, and weaknesses of the two annotation projects.


UniMorph 2.0: Universal Morphology

  The Universal Morphology UniMorph project is a collaborative effort to
improve how NLP handles complex morphology across the world's languages. The
project releases annotated morphological data using a universal tagset, the
UniMorph schema. Each inflected form is associated with a lemma, which
typically carries its underlying lexical meaning, and a bundle of morphological
features from our schema. Additional supporting data and tools are also
released on a per-language basis when available. UniMorph is based at the
Center for Language and Speech Processing (CLSP) at Johns Hopkins University in
Baltimore, Maryland and is sponsored by the DARPA LORELEI program. This paper
details advances made to the collection, annotation, and dissemination of
project resources since the initial UniMorph release described at LREC 2016.
lexical resources} }


CoNLL-SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection
  in 52 Languages

  The CoNLL-SIGMORPHON 2017 shared task on supervised morphological generation
required systems to be trained and tested in each of 52 typologically diverse
languages. In sub-task 1, submitted systems were asked to predict a specific
inflected form of a given lemma. In sub-task 2, systems were given a lemma and
some of its specific inflected forms, and asked to complete the inflectional
paradigm by predicting all of the remaining inflected forms. Both sub-tasks
included high, medium, and low-resource conditions. Sub-task 1 received 24
system submissions, while sub-task 2 received 3 system submissions. Following
the success of neural sequence-to-sequence models in the SIGMORPHON 2016 shared
task, all but one of the submissions included a neural component. The results
show that high performance can be achieved with small training datasets, so
long as models have appropriate inductive bias or make use of additional
unlabeled data or synthetic data. However, different biasing and data
augmentation resulted in disjoint sets of inflected forms being predicted
correctly, suggesting that there is room for future improvement.


The CoNLL--SIGMORPHON 2018 Shared Task: Universal Morphological
  Reinflection

  The CoNLL--SIGMORPHON 2018 shared task on supervised learning of
morphological generation featured data sets from 103 typologically diverse
languages. Apart from extending the number of languages involved in earlier
supervised tasks of generating inflected forms, this year the shared task also
featured a new second task which asked participants to inflect words in
sentential context, similar to a cloze task. This second task featured seven
languages. Task 1 received 27 submissions and task 2 received 6 submissions.
Both tasks featured a low, medium, and high data condition. Nearly all
submissions featured a neural component and built on highly-ranked systems from
the earlier 2017 shared task. In the inflection task (task 1), 41 of the 52
languages present in last year's inflection task showed improvement by the best
systems in the low-resource setting. The cloze task (task 2) proved to be
difficult, and few submissions managed to consistently improve upon both a
simple neural baseline system and a lemma-repeating baseline.


