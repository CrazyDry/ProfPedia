Semi-Automatically Extracting FAQs to Improve Accessibility of Software
  Development Knowledge

  Frequently asked questions (FAQs) are a popular way to document software
development knowledge. As creating such documents is expensive, this paper
presents an approach for automatically extracting FAQs from sources of software
development discussion, such as mailing lists and Internet forums, by combining
techniques of text mining and natural language processing. We apply the
approach to popular mailing lists and carry out a survey among software
developers to show that it is able to extract high-quality FAQs that may be
further improved by experts.


On Functional Aggregate Queries with Additive Inequalities

  Motivated by fundamental applications in databases and relational machine
learning, we formulate and study the problem of answering functional aggregate
queries (FAQ) in which some of the input factors are defined by a collection of
additive inequalities between variables. We refer to these queries as FAQ-AI
for short.
  To answer FAQ-AI in the Boolean semiring, we define relaxed tree
decompositions and relaxed submodular and fractional hypertree width
parameters. We show that an extension of the InsideOut algorithm using
Chazelle's geometric data structure for solving the semigroup range search
problem can answer Boolean FAQ-AI in time given by these new width parameters.
This new algorithm achieves lower complexity than known solutions for FAQ-AI.
It also recovers some known results in database query answering.
  Our second contribution is a relaxation of the set of polymatroids that gives
rise to the counting version of the submodular width, denoted by #subw. This
new width is sandwiched between the submodular and the fractional hypertree
widths. Any FAQ and FAQ-AI over one semiring can be answered in time
proportional to #subw and respectively to the relaxed version of #subw.
  We present three applications of our FAQ-AI framework to relational machine
learning: k-means clustering, training linear support vector machines, and
training models using non-polynomial loss. These optimization problems can be
solved over a database asymptotically faster than computing the join of the
database relations.


FAQ about the "contextual objectivity" point of view

  We discuss some Frequently Asked Questions about the ``contextual
objectivity" point of view on quantum mechanics introduced in two previous
preprints quant-ph/0012122 and quant-ph/0111154.


FAQ: Questions Asked Frequently

  We define and study the Functional Aggregate Query (FAQ) problem, which
encompasses many frequently asked questions in constraint satisfaction,
databases, matrix operations, probabilistic graphical models and logic. This is
our main conceptual contribution.
  We then present a simple algorithm called "InsideOut" to solve this general
problem. InsideOut is a variation of the traditional dynamic programming
approach for constraint programming based on variable elimination. Our
variation adds a couple of simple twists to basic variable elimination in order
to deal with the generality of FAQ, to take full advantage of Grohe and Marx's
fractional edge cover framework, and of the analysis of recent worst-case
optimal relational join algorithms.
  As is the case with constraint programming and graphical model inference, to
make InsideOut run efficiently we need to solve an optimization problem to
compute an appropriate 'variable ordering'. The main technical contribution of
this work is a precise characterization of when a variable ordering is
'semantically equivalent' to the variable ordering given by the input FAQ
expression. Then, we design an approximation algorithm to find an equivalent
variable ordering that has the best 'fractional FAQ-width'. Our results imply a
host of known and a few new results in graphical model inference, matrix
operations, relational joins, and logic.
  We also briefly explain how recent algorithms on beyond worst-case analysis
for joins and those for solving SAT and #SAT can be viewed as variable
elimination to solve FAQ over compactly represented input functions.


The FIRST-APM QSOs Survey in the SBS sky region

  The main goal of the FIRST-APM QSO Survey (FAQS) survey is to compile the
most complete sample of Bright QSOs, located in the well optically investigated
area of the sky covered by the Second Byurakan Survey (SBS). We do that through
the combination of both radio and optical surveys, down to the magnitude limit
B<18.5. We report here the first results of our ongoing study, that is based
upon the cross-identification of the FIRST radio catalog and the Automated
Plate Measuring Machine (APM) optical catalog. The overlapping sky area between
the FIRST and the SBS surveys is about 700 sq. deg. Our compiled list of
sources for this overlapping region contains ~400 quasar candidates brighter
than B=18.5. Of which, about 90 objects are already spectroscopically
classified. These objects have been discovered maynly by the SBS survey. During
1999, we have carried out spectroscopic observations for more than 100 FAQS
objects with the 2.1m telescope of the Guillermo Haro Astrophysical Observatory
(GHO). So far, in the studied subsample, we have found 33 new QSOs, 2 Seyfert
Galaxies, 15 emission line galaxies, 1 BL Lac, and 45 high galactic latitude
stars. Amongst the 33 QSOs, we have found two broad absorption line (BAL) QSOs,
namely, FAQS 151113.7+490557 and FAQS 161744.4+515054. These two BAL QSOs are
radio-loud, and have radio-to-optical flux ratios (log R) with values of 1.1
and 2.5 respectively. The last object being the brightest radio-loud BAL QSO
known, with a flux density of 99.8 mJy at 1.4 Ghz.


Details of the photoemission spectra analysis

  Here we present some details of the self-consistent procedure of the
photoemission spectra analysis suggested in [Phys. Rev. B 71, 214513 (2005);
cond-mat/0405696; cond-mat/0409483] and answer some of the most frequently
asked questions concerning this analysis.


CLUBB-SILHS: A parameterization of subgrid variability in the atmosphere

  This document provides a detailed overview of the CLUBB-SILHS cloud and
turbulence parameterization, including theoretical background, model equations,
closure assumptions, simulation results, comparison with other parameterization
methods, FAQs, and source code documentation.


The FIRST-APM QSO survey (FAQS) in the SBS Region. Preliminary Results

  The main goal of the FIRST-APM QSO Survey (FAQS) survey is to compile the
most complete sample of Bright QSOs, located in the area covered by the Second
Byurakan Survey (SBS). Here we report the first results of an ongoing study
based on the cross-identification of the FIRST radio catalog and the APM
optical catalog. The overlapping sky area between FIRST and SBS is about 700
deg$^{2}$. The compiled list of sources for this overlapping region contains
$\sim 400$ quasar candidates brighter than $B=18\fm5$. About 90 objects were
already spectroscopically classified. During 1999-2000, we observed
spectroscopically more than 150 FAQS objects with the 2.1m telescope of the
Guillermo Haro Observatory (GHO).We have found 51 new QSOs (4 BAL QSOs), 13
Seyfert Galaxies (5 NLSy1's), 23 emission line galaxies, 3 BL Lac objects and
57 stars.


Frozen time in hyperbolic spacetime motion

  According to the Lorentz transformation and clearly seen from the Minkowski
diagram, hyperbolic spacetime motion of a test object relative to a stationary
reference frame can be performed in a specific way such that time becomes
frozen in the moving frame of the test object. In that case, time can be
arranged to become frozen even at moderate relativistic velocities, in contrast
to the minute traditional relativistic time dilation at such velocities. An
appendix gives a simple illustration in Minkowski form of how time in a frame
in hyperbolic motion can become frozen to a complete standstill relative to a
stationary frame. (Published in Phys. Scr. 84 (2011) 035004)
  In addition to the paper, the arXiv file also contains a discussion of
Frequently Asked Questions from readers. Further questions not adequately dealt
with in the existing FAQ are welcome.


Tractable Graph Matching via Soft Seeding

  The graph matching problem aims to discover a latent correspondence between
the vertex sets of two observed graphs. This problem has proven to be quite
challenging, with few satisfying methods that are computationally tractable and
widely applicable. The FAQ algorithm has proven to have good performance on
benchmark problems and works with a indefinite relaxation of the problem. Due
to the indefinite relaxation, FAQ is not guaranteed to find the global maximum.
However, if prior information is known about the true correspondence, this can
be leveraged to initialize the algorithm near the truth. We show that given
certain properties of this initial matrix, with high probability the FAQ
algorithm will converge in two steps to the truth under a flexible model for
pairs of random graphs. Importantly, this result implies that there will be no
local optima near the global optima, providing a method to assess performance.


Juggling Functions Inside a Database

  We define and study the Functional Aggregate Query (FAQ) problem, which
captures common computational tasks across a very wide range of domains
including relational databases, logic, matrix and tensor computation,
probabilistic graphical models, constraint satisfaction, and signal processing.
Simply put, an FAQ is a declarative way of defining a new function from a
database of input functions.
  We present "InsideOut", a dynamic programming algorithm, to evaluate an FAQ.
The algorithm rewrites the input query into a set of easier-to-compute FAQ
sub-queries. Each sub-query is then evaluated using a worst-case optimal
relational join algorithm. The topic of designing algorithms to optimally
evaluate the classic multiway join problem has seen exciting developments in
the past few years. Our framework tightly connects these new ideas in database
theory with a vast number of application areas in a coherent manner, showing
potentially that a good database engine can be a general-purpose constraint
solver, relational data store, graphical model inference engine, and
matrix/tensor computation processor all at once.
  The InsideOut algorithm is very simple, as shall be described in this paper.
Yet, in spite of solving an extremely general problem, its runtime either is as
good as or improves upon the best known algorithm for the applications that FAQ
specializes to. These corollaries include computational tasks in graphical
model inference, matrix/tensor operations, relational joins, and logic. Better
yet, InsideOut can be used within any database engine, because it is basically
a principled way of rewriting queries. Indeed, it is already part of the
LogicBlox database engine, helping efficiently answer traditional database
queries, graphical model inference queries, and train a large class of machine
learning models inside the database itself.


Fast Approximate Quadratic Programming for Large (Brain) Graph Matching

  Quadratic assignment problems (QAPs) arise in a wide variety of domains,
ranging from operations research to graph theory to computer vision to
neuroscience. In the age of big data, graph valued data is becoming more
prominent, and with it, a desire to run algorithms on ever larger graphs.
Because QAP is NP-hard, exact algorithms are intractable. Approximate
algorithms necessarily employ an accuracy/efficiency trade-off. We developed a
fast approximate quadratic assignment algorithm (FAQ). FAQ finds a local optima
in (worst case) time cubic in the number of vertices, similar to other
approximate QAP algorithms. We demonstrate empirically that our algorithm is
faster and achieves a lower objective value on over 80% of the suite of QAP
benchmarks, compared with the previous state-of-the-art. Applying the
algorithms to our motivating example, matching C. elegans connectomes
(brain-graphs), we find that FAQ achieves the optimal performance in record
time, whereas none of the others even find the optimum.


An introduction to SDE simulation

  We outline the basic ideas and techniques underpinning the simulation of
stochastic differential equations. In particular we focus on strong simulation
and its context. We also provide illustratory examples and sample matlab
algorithms for the reader to use and follow. Our target audience is advanced
undergraduate and graduate students interested in learning about simulating
stochastic differential equations. We try to address the FAQs we have
encountered.


'Which Multiverse?': Some FAQ

  Recently, we pointed out the possible inconsistency in the very foundations
of the Everett MWI (or a Multiverse) theory. Here, we place some emphasis on
the very basic notions underlying our conclusion yet motivated by certain,
recently raised clever observations in this regard.


FAQ-based Question Answering via Word Alignment

  In this paper, we propose a novel word-alignment-based method to solve the
FAQ-based question answering task. First, we employ a neural network model to
calculate question similarity, where the word alignment between two questions
is used for extracting features. Second, we design a bootstrap-based feature
extraction method to extract a small set of effective lexical features. Third,
we propose a learning-to-rank algorithm to train parameters more suitable for
the ranking tasks. Experimental results, conducted on three languages (English,
Spanish and Japanese), demonstrate that the question similarity model is more
effective than baseline systems, the sparse features bring 5% improvements on
top-1 accuracy, and the learning-to-rank algorithm works significantly better
than the traditional method. We further evaluate our method on the answer
sentence selection task. Our method outperforms all the previous systems on the
standard TREC data set.


Mass of perfect fluid black shells

  The spherically symmetric singular perfect fluid shells are considered for
the case of their radii being equal to the event horizon (the black shells). We
study their observable masses, depending at least on the three parameters,
viz., the square speed of sound in the shell, instantaneous radial velocity of
the shell at a moment when it reaches the horizon, and integration constant
related to surface mass density. We discuss the features of black shells
depending on an equation of state.


Target Space Duality II: Applications

  We apply the framework developed in Target Space Duality I: General Theory.
We show that both nonabelian duality and Poisson-Lie duality are examples of
the general theory. We propose how the formalism leads to a systematic study of
duality by studying few scenarios that lead to open questions in the theory of
Lie algebras. We present evidence that there are probably new examples of
irreducible target space duality.


Frequently Asked Questions for: The Atoms of Neural Computation

  Based on a survey of the literature, we attempt to answer Frequently Asked
Questions on issues of cortical uniformity vs. non-uniformity, the neural
mechanisms of symbolic variable binding, and other issues highlighted in
(Marcus, Marblestone and Dean. "The Atoms of Neural Computation". Science. 31
October 2014. Vol 346. Issue 6209).


Counterparty Risk FAQ: Credit VaR, PFE, CVA, DVA, Closeout, Netting,
  Collateral, Re-hypothecation, WWR, Basel, Funding, CCDS and Margin Lending

  We present a dialogue on Counterparty Credit Risk touching on Credit Value at
Risk (Credit VaR), Potential Future Exposure (PFE), Expected Exposure (EE),
Expected Positive Exposure (EPE), Credit Valuation Adjustment (CVA), Debit
Valuation Adjustment (DVA), DVA Hedging, Closeout conventions, Netting clauses,
Collateral modeling, Gap Risk, Re-hypothecation, Wrong Way Risk, Basel III,
inclusion of Funding costs, First to Default risk, Contingent Credit Default
Swaps (CCDS) and CVA restructuring possibilities through margin lending. The
dialogue is in the form of a Q&A between a CVA expert and a newly hired
colleague.


Ten questions on Group Field Theory (and their tentative answers)

  We provide a short and non-technical summary of our current knowledge and
some possible perspectives on the group field theory formalism for quantum
gravity, in the form of a (partial) FAQ (with answers). Some of the questions
and answers relate to aspects of the formalism that concern loop quantum
gravity. This summary also aims at giving a brief, rough guide to the recent
literature on group field theory (and tensor models).


Preprint Déjà Vu: an FAQ

  I give a brief overview of arXiv history, and describe the current state of
arXiv practice, both technical and sociological. This commentary originally
appeared in the EMBO Journal, 19 Oct 2016. It was intended as an update on
comments from the late 1990s regarding use of preprints by biologists (or lack
thereof), but may be of interest to practitioners of other disciplines. It is
based largely on a keynote presentation I gave to the ASAPbio inaugural meeting
in Feb 2016, and responds as well to some follow-up questions.


CCPs, Central Clearing, CSA, Credit Collateral and Funding Costs
  Valuation FAQ: Re-hypothecation, CVA, Closeout, Netting, WWR, Gap-Risk,
  Initial and Variation Margins, Multiple Discount Curves, FVA?

  We present a dialogue on Funding Costs and Counterparty Credit Risk modeling,
inclusive of collateral, wrong way risk, gap risk and possible Central Clearing
implementation through CCPs. This framework is important following the fact
that derivatives valuation and risk analysis has moved from exotic derivatives
managed on simple single asset classes to simple derivatives embedding the new
or previously neglected types of complex and interconnected nonlinear risks we
address here. This dialogue is the continuation of the "Counterparty Risk,
Collateral and Funding FAQ" by Brigo (2011). In this dialogue we focus more on
funding costs for the hedging strategy of a portfolio of trades, on the
non-linearities emerging from assuming borrowing and lending rates to be
different, on the resulting aggregation-dependent valuation process and its
operational challenges, on the implications of the onset of central clearing,
on the macro and micro effects on valuation and risk of the onset of CCPs, on
initial and variation margins impact on valuation, and on multiple discount
curves. Through questions and answers (Q&A) between a senior expert and a
junior colleague, and by referring to the growing body of literature on the
subject, we present a unified view of valuation (and risk) that takes all such
aspects into account.


Caenorhabditis elegans and the network control framework - FAQs

  Control is essential to the functioning of any neural system. Indeed, under
healthy conditions the brain must be able to continuously maintain a tight
functional control between the system's inputs and outputs. One may therefore
hypothesise that the brain's wiring is predetermined by the need to maintain
control across multiple scales, maintaining the stability of key internal
variables, and producing behaviour in response to environmental cues. Recent
advances in network control have offered a powerful mathematical framework to
explore the structure-function relationship in complex biological, social, and
technological networks, and are beginning to yield important and precise
insights for neuronal systems. The network control paradigm promises a
predictive, quantitative framework to unite the distinct datasets necessary to
fully describe a nervous system, and provide mechanistic explanations for the
observed structure and function relationships. Here, we provide a thorough
review of the network control framework as applied to C. elegans, in the style
of a FAQ. We present the theoretical, computational, and experimental aspects
of network control, and discuss its current capabilities and limitations,
together with the next likely advances and improvements. We further present the
Python code to enable exploration of control principles in a manner specific to
this prototypical organism.


Proof of Riemann's zeta-hypothesis

  Make an exponential transformation in the integral formulation of Riemann's
zeta-function zeta(s) for Re(s) > 0. Separately, in addition make the
substitution s -> 1 - s and then transform back to s again using the functional
equation. Using residue calculus, we can in this way get two alternative,
equivalent series expansions for zeta(s) of order N, both valid inside the
"critical strip", i e for 0 < Re(s) < 1. Together, these two expansions embody
important characteristics of the zeta-function in this range, and their
detailed behavior as N tends to infinity can be used to prove Riemann's
zeta-hypothesis that the nontrivial zeros of the zeta-function must all have
real part 1/2.
  In addition to the preprint, the arXiv file also contains a discussion of
some forty Frequently Asked Questions from readers. Further questions not
adequately dealt with in the existing FAQ are welcome.


Brout-Englert-Higgs physics: From foundations to phenomenology

  The aim of this review is to describe the field-theoretical foundations of
Brout-Englert-Higgs (BEH) physics, and to show how the usual phenomenology
arises from it. This requires to give a precise and gauge-invariant meaning to
the underlying physics. This is complicated by the fact that concepts like the
Higgs vacuum expectation value or the separation between confinement and the
BEH effect loose their meaning beyond perturbation theory. This is addressed by
carefully constructing the corresponding theory space and the quantum phase
diagram. The physical spectrum needs then to be also given in terms of
gauge-invariant, i. e. composite, states. Using gauge-invariant perturbation
theory, as developed by Froehlich, Morchio, and Strocchi, it is possible to
rederive conventional perturbation theory. This derivation explicitly shows why
the description of the standard model in terms of the unphysical,
gauge-dependent, elementary states of the Higgs and W-bosons and Z-boson, but
also of the elementary fermions, is adequate and successful. These are
unavoidable consequences of the field theory underlying the standard model,
from which the usual picture emerges. The validity of this emergence can only
be tested non-perturbatively. Such tests, in particular using lattice gauge
theory, will be reviewed as well. They fully confirm the underlying mechanisms.
It will be seen that the structure of the standard model is very special, and
qualitative changes occur beyond it. The extension beyond the standard model
will therefore also be reviewed. Particular attention will be given to
structural differences arising for phenomenology. Again, non-perturbative tests
of these results will be reviewed. Finally, to make this review self-contained
a brief discussion of issues like the triviality and hierarchy problem, and how
they fit into a fundamental field-theoretical formulation, is included.


Target Space Duality I: General Theory

  We develop a systematic framework for studying target space duality at the
classical level. We show that target space duality between manifolds M and
Mtilde arises because of the existence of a very special symplectic manifold.
This manifold locally looks like M x Mtilde and admits a double fibration. We
analyze the local geometric requirements necessary for target space duality and
prove that both manifolds must admit flat orthogonal connections. We show how
abelian duality, nonabelian duality and Poisson-Lie duality are all special
cases of a more general framework. As an example we exhibit new (nonlinear)
dualities in the case M = Mtilde = R^n.


No extension of quantum theory can have improved predictive power

  According to quantum theory, measurements generate random outcomes, in stark
contrast with classical mechanics. This raises the question of whether there
could exist an extension of the theory which removes this indeterminism, as
suspected by Einstein, Podolsky and Rosen (EPR). Although this has been shown
to be impossible, existing results do not imply that the current theory is
maximally informative. Here we ask the more general question of whether any
improved predictions can be achieved by any extension of quantum theory. Under
the assumption that measurements can be chosen freely, we answer this question
in the negative: no extension of quantum theory can give more information about
the outcomes of future measurements than quantum theory itself. Our result has
significance for the foundations of quantum mechanics, as well as applications
to tasks that exploit the inherent randomness in quantum theory, such as
quantum cryptography.


Seeded Graph Matching

  Given two graphs, the graph matching problem is to align the two vertex sets
so as to minimize the number of adjacency disagreements between the two graphs.
The seeded graph matching problem is the graph matching problem when we are
first given a partial alignment that we are tasked with completing. In this
paper, we modify the state-of-the-art approximate graph matching algorithm
"FAQ" of Vogelstein et al. (2015) to make it a fast approximate seeded graph
matching algorithm, adapt its applicability to include graphs with differently
sized vertex sets, and extend the algorithm so as to provide, for each
individual vertex, a nomination list of likely matches. We demonstrate the
effectiveness of our algorithm via simulation and real data experiments;
indeed, knowledge of even a few seeds can be extremely effective when our
seeded graph matching algorithm is used to recover a naturally existing
alignment that is only partially observed.


Toward incremental FIB aggregation with quick selections (FAQS)

  Several approaches to mitigating the Forwarding Information Base (FIB)
overflow problem were developed and software solutions using FIB aggregation
are of particular interest. One of the greatest concerns to deploy these
algorithms to real networks is their high running time and heavy computational
overhead to handle thousands of FIB updates every second. In this work, we
manage to use a single tree traversal to implement faster aggregation and
update handling algorithm with much lower memory footprint than other existing
work. We utilize 6-year realistic IPv4 and IPv6 routing tables from 2011 to
2016 to evaluate the performance of our algorithm with various metrics. To the
best of our knowledge, it is the first time that IPv6 FIB aggregation has been
performed. Our new solution is 2.53 and 1.75 times as fast as
the-state-of-the-art FIB aggregation algorithm for IPv4 and IPv6 FIBs,
respectively, while achieving a near-optimal FIB aggregation ratio.


Excitons in soliton and bipolaron lattice states of doped Peierls
  systems

  Exciton effects on soliton and bipolaron lattice states are investigated
using an electron-lattice Peierls model with long-range Coulomb interactions.
The Hartree-Fock (HF) approximation and the single-excitation
configuration-interaction (single-CI) method are used to obtain optical
absorption spectra. We discuss the following properties: (1) The attraction
between the excited electron and the remaining hole makes the excitation energy
smaller when the correlations are taken into account by the single-CI. The
oscillator strengths of the lower excited states become relatively larger than
in the HF calculations. (2) We look at variations of relative oscillator
strengths of two or three kinds of excitons described by the single-CI. While
the excess-electron concentration is small, the ratio of the oscillator
strengths of the exciton with the lowest energy, which is calculated against
the total electronic excitation oscillator strengths, increases almost
linearly. The oscillator strengths accumulate at this exciton as the
concentration increases.


Lorentz-covariant quantum transport and the origin of dark energy

  A possible explanation for the enigma of dark energy, responsible for about
76 % of the mass-energy of the universe, is obtained by requiring only that the
rigorous continuity equation (the Boltzmann transport equation) for quanta
propagating through space should have the form of a Lorentz-covariant and
dispersion-free wave equation. This requirement implies (i) properties of
space-time which an observer would describe as uniform expansion in agreement
with Hubble's law, and (ii) that the quantum transport behaves like in a
multiplicative medium with multiplication factor = 2. This inherent,
essentially explosive multiplicity of vacuum, thus caused by the requirement of
Lorentz-covariance, is suggested as a potential origin of dark energy. In
addition, it is shown (iii) that this requirement of Lorentz-covariant quantum
transport leads to an apparent accelerated expansion of the universe.
  In addition to the updated manuscript for Phys. Scr., the arXiv file also
contains a discussion of about a dozen Frequently Asked Questions from readers.
Further questions not adequately dealt with in the existing FAQ are welcome.


A Cancer Biotherapy Resource

  Cancer Biotherapy (CB), as opposed to cancer chemotherapy, is the use of
macromolecular, biological agents instead of organic chemicals or drugs to
treat cancer. Biological agents usually have higher selectivity and have less
toxic side effects than chemical agents. The I.S.B.T.C., being the only major
information database for CB, seems lacking in some crucial information on
various cancer biotherapy regimens. It is thus necessary to have a
comprehensive curated CB database. The database accessible to cancer patients
and also should be a sounding board for scientific ideas by cancer researchers.
The database/web server has information about main families of cancer
biotherapy regimens to date, namely, Protein Kinase Inhibitors, Ras Pathway
Inhibitors, Cell-Cycle Active Agents, MAbs (monoclonal antibodies), ADEPT
(Antibody-Directed Enzyme Pro-Drug Therapy), Cytokines, Anti-Angiogenesis
Agents, Cancer Vaccines, Cell-based Immunotherapeutics, Gene Therapy,
Hematopoietic Growth Factors, Retinoids, and CAAT. For each biotherapy regimen,
we will extract the following attributes in populating the database: Cancer
type, Gene/s and gene product/s involved, Gene sequence, Organs affected,
Reference papers, Clinical phase/stage, Survival rate, Clinical test center
locations, Cost, Patient blogs, Researcher blogs, and Future work. The database
will be accessible to public through a website and had FAQs for making it
understandable to the laymen and discussion page for researchers to express
their views and ideas. In addition to information about the biotherapy
regimens, the website will link to other biologically significant databases
like structural proteomics, metabolomics, glycomics, and lipidomics databases,
as well as to news around the world regarding cancer therapy results. The
database attributes would be regularly updated for novel attributes as
discoveries are made.


Quantum Multiverses

  A quantum theory of the universe consists of a theory of its quantum dynamics
and a theory of its quantum state The theory predicts quantum multiverses in
the form of decoherent sets of alternative histories describing the evolution
of the universe's spacetime geometry and matter content. These consequences
follow: (a) The universe generally exhibits different quantum multiverses at
different levels and kinds of coarse graining. (b) Quantum multiverses are not
a choice or an assumption but are consequences of the theory or not. (c)
Quantum multiverses are generic for simple theories (d) Anthropic selection is
automatic because observers are physical systems within the universe not
somehow outside it. (e) Quantum multiverses can provide different mechanisms
for the variation constants in effective theories (like the cosmological
constant) enabling anthropic selection. (f) Different levels of coarse grained
multiverses provide different routes to calculation as a consequence of
decoherence. We support these conclusions by analyzing the quantum multiverses
of a variety of quantum cosmological models aimed at the prediction of
observable properties of our universe. In particular we show how the example of
a multiverse consisting of a vast classical spacetime containing many pocket
universes arises automatically as part of a quantum multiverse describing an
eternally inflating false vacuum that decays by the quantum nucleation of true
vacuum bubbles. In a FAQ we argue that the quantum multiverses of the universe
are scientific, real, testable, falsifiable, and similar to those in other
areas of science even if they are not directly observable on arbitrarily large
scales.


