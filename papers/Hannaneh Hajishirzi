Reasoning about RoboCup Soccer Narratives

  This paper presents an approach for learning to translate simple narratives,
i.e., texts (sequences of sentences) describing dynamic systems, into coherent
sequences of events without the need for labeled training data. Our approach
incorporates domain knowledge in the form of preconditions and effects of
events, and we show that it outperforms state-of-the-art supervised learning
systems on the task of reconstructing RoboCup soccer games from their
commentaries.


Sampling First Order Logical Particles

  Approximate inference in dynamic systems is the problem of estimating the
state of the system given a sequence of actions and partial observations. High
precision estimation is fundamental in many applications like diagnosis,
natural language processing, tracking, planning, and robotics. In this paper we
present an algorithm that samples possible deterministic executions of a
probabilistic sequence. The algorithm takes advantage of a compact
representation (using first order logic) for actions and world states to
improve the precision of its estimation. Theoretical and empirical results show
that the algorithm's expected error is smaller than propositional sampling and
Sequential Monte Carlo (SMC) sampling techniques.


Data-Driven Methods for Solving Algebra Word Problems

  We explore contemporary, data-driven techniques for solving math word
problems over recent large-scale datasets. We show that well-tuned neural
equation classifiers can outperform more sophisticated models such as sequence
to sequence and self-attention across these datasets. Our error analysis
indicates that, while fully data driven models show some promise, semantic and
world knowledge is necessary for further advances.


Semantic Understanding of Professional Soccer Commentaries

  This paper presents a novel approach to the problem of semantic parsing via
learning the correspondences between complex sentences and rich sets of events.
Our main intuition is that correct correspondences tend to occur more
frequently. Our model benefits from a discriminative notion of similarity to
learn the correspondence between sentence and an event and a ranking machinery
that scores the popularity of each correspondence. Our method can discover a
group of events (called macro-events) that best describes a sentence. We
evaluate our method on our novel dataset of professional soccer commentaries.
The empirical results show that our method significantly outperforms the
state-of-theart.


Talking to the crowd: What do people react to in online discussions?

  This paper addresses the question of how language use affects community
reaction to comments in online discussion forums, and the relative importance
of the message vs. the messenger. A new comment ranking task is proposed based
on community annotated karma in Reddit discussions, which controls for topic
and timing of comments. Experimental work with discussion threads from six
subreddits shows that the importance of different types of language features
varies with the community of interest.


Scientific Information Extraction with Semi-supervised Neural Tagging

  This paper addresses the problem of extracting keyphrases from scientific
articles and categorizing them as corresponding to a task, process, or
material. We cast the problem as sequence tagging and introduce semi-supervised
methods to a neural tagging model, which builds on recent advances in named
entity recognition. Since annotated training data is scarce in this domain, we
introduce a graph-based semi-supervised algorithm together with a data
selection scheme to leverage unannotated articles. Both inductive and
transductive semi-supervised learning strategies outperform state-of-the-art
information extraction performance on the 2017 SemEval Task 10 ScienceIE task.


Semi-Supervised Event Extraction with Paraphrase Clusters

  Supervised event extraction systems are limited in their accuracy due to the
lack of available training data. We present a method for self-training event
extraction systems by bootstrapping additional training data. This is done by
taking advantage of the occurrence of multiple mentions of the same event
instances across newswire articles from multiple sources. If our system can
make a highconfidence extraction of some mentions in such a cluster, it can
then acquire diverse training examples by adding the other mentions as well.
Our experiments show significant performance improvements on multiple event
extractors over ACE 2005 and TAC-KBP 2015 datasets.


Scientific Relation Extraction with Selectively Incorporated Concept
  Embeddings

  This paper describes our submission for the SemEval 2018 Task 7 shared task
on semantic relation extraction and classification in scientific papers. We
extend the end-to-end relation extraction model of (Miwa and Bansal) with
enhancements such as a character-level encoding attention mechanism on
selecting pretrained concept candidate embeddings. Our official submission
ranked the second in relation classification task (Subtask 1.1 and Subtask 2
Senerio 2), and the first in the relation extraction task (Subtask 2 Scenario
1).


Multi-Task Identification of Entities, Relations, and Coreference for
  Scientific Knowledge Graph Construction

  We introduce a multi-task setup of identifying and classifying entities,
relations, and coreference clusters in scientific articles. We create SciERC, a
dataset that includes annotations for all three tasks and develop a unified
framework called Scientific Information Extractor (SciIE) for with shared span
representations. The multi-task setup reduces cascading errors between tasks
and leverages cross-sentence relations through coreference links. Experiments
show that our multi-task model outperforms previous models in scientific
information extraction without using any domain-specific features. We further
show that the framework supports construction of a scientific knowledge graph,
which we use to analyze information in scientific literature.


Are Elephants Bigger than Butterflies? Reasoning about Sizes of Objects

  Human vision greatly benefits from the information about sizes of objects.
The role of size in several visual reasoning tasks has been thoroughly explored
in human perception and cognition. However, the impact of the information about
sizes of objects is yet to be determined in AI. We postulate that this is
mainly attributed to the lack of a comprehensive repository of size
information. In this paper, we introduce a method to automatically infer object
sizes, leveraging visual and textual information from web. By maximizing the
joint likelihood of textual and visual observations, our method learns reliable
relative size estimates, with no explicit human supervision. We introduce the
relative size dataset and show that our method outperforms competitive textual
and visual baselines in reasoning about size comparisons.


Query-Reduction Networks for Question Answering

  In this paper, we study the problem of question answering when reasoning over
multiple facts is required. We propose Query-Reduction Network (QRN), a variant
of Recurrent Neural Network (RNN) that effectively handles both short-term
(local) and long-term (global) sequential dependencies to reason over multiple
facts. QRN considers the context sentences as a sequence of state-changing
triggers, and reduces the original query to a more informed query as it
observes each trigger (context sentence) through time. Our experiments show
that QRN produces the state-of-the-art results in bAbI QA and dialog tasks, and
in a real goal-oriented dialog dataset. In addition, QRN formulation allows
parallelization on RNN's time axis, saving an order of magnitude in time
complexity for training and inference.


View-Driven Deduplication with Active Learning

  Visual analytics systems such as Tableau are increasingly popular for
interactive data exploration. These tools, however, do not currently assist
users with detecting or resolving potential data quality problems including the
well-known deduplication problem. Recent approaches for deduplication focus on
cleaning entire datasets and commonly require hundreds to thousands of user
labels. In this paper, we address the problem of deduplication in the context
of visual data analytics. We present a new approach for record deduplication
that strives to produce the cleanest view possible with a limited budget for
data labeling. The key idea behind our approach is to consider the impact that
individual tuples have on a visualization and to monitor how the view changes
during cleaning. With experiments on nine different visualizations for two
real-world datasets, we show that our approach produces significantly cleaner
views for small labeling budgets than state-of-the-art alternatives and that it
also stops the cleaning process after requesting fewer labels.


A Diagram Is Worth A Dozen Images

  Diagrams are common tools for representing complex concepts, relationships
and events, often when it would be difficult to portray the same information
with natural images. Understanding natural images has been extensively studied
in computer vision, while diagram understanding has received little attention.
In this paper, we study the problem of diagram interpretation and reasoning,
the challenging task of identifying the structure of a diagram and the
semantics of its constituents and their relationships. We introduce Diagram
Parse Graphs (DPG) as our representation to model the structure of diagrams. We
define syntactic parsing of diagrams as learning to infer DPGs for diagrams and
study semantic interpretation and reasoning of diagrams in the context of
diagram question answering. We devise an LSTM-based method for syntactic
parsing of diagrams and introduce a DPG-based attention model for diagram
question answering. We compile a new dataset of diagrams with exhaustive
annotations of constituents and relationships for over 5,000 diagrams and
15,000 questions and answers. Our results show the significance of our models
for syntactic parsing and question answering in diagrams using DPGs.


Disfluency Detection using a Bidirectional LSTM

  We introduce a new approach for disfluency detection using a Bidirectional
Long-Short Term Memory neural network (BLSTM). In addition to the word
sequence, the model takes as input pattern match features that were developed
to reduce sensitivity to vocabulary size in training, which lead to improved
performance over the word sequence alone. The BLSTM takes advantage of explicit
repair states in addition to the standard reparandum states. The final output
leverages integer linear programming to incorporate constraints of disfluency
structure. In experiments on the Switchboard corpus, the model achieves
state-of-the-art performance for both the standard disfluency detection task
and the correction detection task. Analysis shows that the model has better
detection of non-repetition disfluencies, which tend to be much harder to
detect.


A Theme-Rewriting Approach for Generating Algebra Word Problems

  Texts present coherent stories that have a particular theme or overall
setting, for example science fiction or western. In this paper, we present a
text generation method called {\it rewriting} that edits existing
human-authored narratives to change their theme without changing the underlying
story. We apply the approach to math word problems, where it might help
students stay more engaged by quickly transforming all of their homework
assignments to the theme of their favorite movie without changing the math
concepts that are being taught. Our rewriting method uses a two-stage decoding
process, which proposes new words from the target theme and scores the
resulting stories according to a number of factors defining aspects of
syntactic, semantic, and thematic coherence. Experiments demonstrate that the
final stories typically represent the new theme well while still testing the
original math concepts, outperforming a number of baselines. We also release a
new dataset of human-authored rewrites of math word problems in several themes.


Bidirectional Attention Flow for Machine Comprehension

  Machine comprehension (MC), answering a query about a given context
paragraph, requires modeling complex interactions between the context and the
query. Recently, attention mechanisms have been successfully extended to MC.
Typically these methods use attention to focus on a small portion of the
context and summarize it with a fixed-size vector, couple attentions
temporally, and/or often form a uni-directional attention. In this paper we
introduce the Bi-Directional Attention Flow (BIDAF) network, a multi-stage
hierarchical process that represents the context at different levels of
granularity and uses bi-directional attention flow mechanism to obtain a
query-aware context representation without early summarization. Our
experimental evaluations show that our model achieves the state-of-the-art
results in Stanford Question Answering Dataset (SQuAD) and CNN/DailyMail cloze
test.


Question Answering through Transfer Learning from Large Fine-grained
  Supervision Data

  We show that the task of question answering (QA) can significantly benefit
from the transfer learning of models trained on a different large, fine-grained
QA dataset. We achieve the state of the art in two well-studied QA datasets,
WikiQA and SemEval-2016 (Task 3A), through a basic transfer learning technique
from SQuAD. For WikiQA, our model outperforms the previous best model by more
than 8%. We demonstrate that finer supervision provides better guidance for
learning lexical and syntactic information than coarser supervision, through
quantitative results and visual analysis. We also show that a similar transfer
learning procedure achieves the state of the art on an entailment task.


Neural Speed Reading via Skim-RNN

  Inspired by the principles of speed reading, we introduce Skim-RNN, a
recurrent neural network (RNN) that dynamically decides to update only a small
fraction of the hidden state for relatively unimportant input tokens. Skim-RNN
gives computational advantage over an RNN that always updates the entire hidden
state. Skim-RNN uses the same input and output interfaces as a standard RNN and
can be easily used instead of RNNs in existing models. In our experiments, we
show that Skim-RNN can achieve significantly reduced computational cost without
losing accuracy compared to standard RNNs across five different natural
language tasks. In addition, we demonstrate that the trade-off between accuracy
and speed of Skim-RNN can be dynamically controlled during inference time in a
stable manner. Our analysis also shows that Skim-RNN running on a single CPU
offers lower latency compared to standard RNNs on GPUs.


Identifying Most Walkable Direction for Navigation in an Outdoor
  Environment

  We present an approach for identifying the most walkable direction for
navigation using a hand-held camera. Our approach extracts semantically rich
contextual information from the scene using a custom encoder-decoder
architecture for semantic segmentation and models the spatial and temporal
behavior of objects in the scene using a spatio-temporal graph. The system
learns to minimize a cost function over the spatial and temporal object
attributes to identify the most walkable direction. We construct a new
annotated navigation dataset collected using a hand-held mobile camera in an
unconstrained outdoor environment, which includes challenging settings such as
highly dynamic scenes, occlusion between objects, and distortions. Our system
achieves an accuracy of 84% on predicting a safe direction. We also show that
our custom segmentation network is both fast and accurate, achieving mIOU (mean
intersection over union) scores of 81 and 44.7 on the PASCAL VOC and the PASCAL
Context datasets, respectively, while running at about 21 frames per second.


ESPNet: Efficient Spatial Pyramid of Dilated Convolutions for Semantic
  Segmentation

  We introduce a fast and efficient convolutional neural network, ESPNet, for
semantic segmentation of high resolution images under resource constraints.
ESPNet is based on a new convolutional module, efficient spatial pyramid (ESP),
which is efficient in terms of computation, memory, and power. ESPNet is 22
times faster (on a standard GPU) and 180 times smaller than the
state-of-the-art semantic segmentation network PSPNet, while its category-wise
accuracy is only 8% less. We evaluated ESPNet on a variety of semantic
segmentation datasets including Cityscapes, PASCAL VOC, and a breast biopsy
whole slide image dataset. Under the same constraints on memory and
computation, ESPNet outperforms all the current efficient CNN networks such as
MobileNet, ShuffleNet, and ENet on both standard metrics and our newly
introduced performance metrics that measure efficiency on edge devices. Our
network can process high resolution images at a rate of 112 and 9 frames per
second on a standard GPU and edge device, respectively.


Phrase-Indexed Question Answering: A New Challenge for Scalable Document
  Comprehension

  We formalize a new modular variant of current question answering tasks by
enforcing complete independence of the document encoder from the question
encoder. This formulation addresses a key challenge in machine comprehension by
requiring a standalone representation of the document discourse. It
additionally leads to a significant scalability advantage since the encoding of
the answer candidate phrases in the document can be pre-computed and indexed
offline for efficient retrieval. We experiment with baseline models for the new
task, which achieve a reasonable accuracy but significantly underperform
unconstrained QA models. We invite the QA research community to engage in
Phrase-Indexed Question Answering (PIQA, pika) for closing the gap. The
leaderboard is at: nlp.cs.washington.edu/piqa


Pyramidal Recurrent Unit for Language Modeling

  LSTMs are powerful tools for modeling contextual information, as evidenced by
their success at the task of language modeling. However, modeling contexts in
very high dimensional space can lead to poor generalizability. We introduce the
Pyramidal Recurrent Unit (PRU), which enables learning representations in high
dimensional space with more generalization power and fewer parameters. PRUs
replace the linear transformation in LSTMs with more sophisticated interactions
including pyramidal and grouped linear transformations. This architecture gives
strong results on word-level language modeling while reducing the number of
parameters significantly. In particular, PRU improves the perplexity of a
recent state-of-the-art language model Merity et al. (2018) by up to 1.3 points
while learning 15-20% fewer parameters. For similar number of model parameters,
PRU outperforms all previous RNN models that exploit different gating
mechanisms and transformations. We provide a detailed examination of the PRU
and its behavior on the language modeling tasks. Our code is open-source and
available at https://sacmehta.github.io/PRU/


ESPNetv2: A Light-weight, Power Efficient, and General Purpose
  Convolutional Neural Network

  We introduce a light-weight, power efficient, and general purpose
convolutional neural network, ESPNetv2, for modeling visual and sequential
data. Our network uses group point-wise and depth-wise dilated separable
convolutions to learn representations from a large effective receptive field
with fewer FLOPs and parameters. The performance of our network is evaluated on
four different tasks: (1) object classification, (2) semantic segmentation, (3)
object detection, and (4) language modeling. Experiments on these tasks,
including image classification on the ImageNet and language modeling on the
PenTree bank dataset, demonstrate the superior performance of our method over
the state-of-the-art methods. Our network outperforms ESPNet by 4-5% and has
2-4x fewer FLOPs on the PASCAL VOC and the Cityscapes dataset. Compared to
YOLOv2 on the MS-COCO object detection, ESPNetv2 delivers 4.4% higher accuracy
with 6x fewer FLOPs. Our experiments show that ESPNetv2 is much more power
efficient than existing state-of-the-art efficient methods including
ShuffleNets and MobileNets. Our code is open-source and available at
https://github.com/sacmehta/ESPNetv2


Text Generation from Knowledge Graphs with Graph Transformers

  Generating texts which express complex ideas spanning multiple sentences
requires a structured representation of their content (document plan), but
these representations are prohibitively expensive to manually produce. In this
work, we address the problem of generating coherent multi-sentence texts from
the output of an information extraction system, and in particular a knowledge
graph. Graphical knowledge representations are ubiquitous in computing, but
pose a significant challenge for text generation techniques due to their
non-hierarchical nature, collapsing of long-distance dependencies, and
structural variety. We introduce a novel graph transforming encoder which can
leverage the relational structure of such knowledge graphs without imposing
linearization or hierarchical constraints. Incorporated into an encoder-decoder
setup, we provide an end-to-end trainable system for graph-to-text generation
that we apply to the domain of scientific text. Automatic and human evaluations
show that our technique produces more informative texts which exhibit better
document structure than competitive encoder-decoder methods.


A General Framework for Information Extraction using Dynamic Span Graphs

  We introduce a general framework for several information extraction tasks
that share span representations using dynamically constructed span graphs. The
graphs are constructed by selecting the most confident entity spans and linking
these nodes with confidence-weighted relation types and coreferences. The
dynamic span graph allows coreference and relation type confidences to
propagate through the graph to iteratively refine the span representations.
This is unlike previous multi-task frameworks for information extraction in
which the only interaction between tasks is in the shared first-layer LSTM. Our
framework significantly outperforms the state-of-the-art on multiple
information extraction tasks across multiple datasets reflecting different
domains. We further observe that the span enumeration approach is good at
detecting nested span entities, with significant F1 score improvement on the
ACE dataset.


