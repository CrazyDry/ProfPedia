Combining Multiple Knowledge Sources for Discourse Segmentation

  We predict discourse segment boundaries from linguistic features of
utterances, using a corpus of spoken narratives as data. We present two methods
for developing segmentation algorithms from training data: hand tuning and
machine learning. When multiple types of features are used, results approach
human performance on an independent test set (both methods), and using
cross-validation (machine learning).


OmniGraph: Rich Representation and Graph Kernel Learning

  OmniGraph, a novel representation to support a range of NLP classification
tasks, integrates lexical items, syntactic dependencies and frame semantic
parses into graphs. Feature engineering is folded into the learning through
convolution graph kernel learning to explore different extents of the graph. A
high-dimensional space of features includes individual nodes as well as complex
subgraphs. In experiments on a text-forecasting problem that predicts stock
price change from news for company mentions, OmniGraph beats several benchmarks
based on bag-of-words, syntactic dependencies, and semantic trees. The highly
expressive features OmniGraph discovers provide insights into the semantics
across distinct market sectors. To demonstrate the method's generality, we also
report its high performance results on a fine-grained sentiment corpus.


Integrating Gricean and Attentional Constraints

  This paper concerns how to generate and understand discourse anaphoric noun
phrases. I present the results of an analysis of all discourse anaphoric noun
phrases (N=1,233) in a corpus of ten narrative monologues, where the choice
between a definite pronoun or phrasal NP conforms largely to Gricean
constraints on informativeness. I discuss Dale and Reiter's [To appear] recent
model and show how it can be augmented for understanding as well as generating
the range of data presented here. I argue that integrating centering [Grosz et
al., 1983] [Kameyama, 1985] with this model can be applied uniformly to
discourse anaphoric pronouns and phrasal NPs. I conclude with a hypothesis for
addressing the interaction between local and global discourse processing.


Applying Reliability Metrics to Co-Reference Annotation

  Studies of the contextual and linguistic factors that constrain discourse
phenomena such as reference are coming to depend increasingly on annotated
language corpora. In preparing the corpora, it is important to evaluate the
reliability of the annotation, but methods for doing so have not been readily
available. In this report, I present a method for computing reliability of
coreference annotation. First I review a method for applying the information
retrieval metrics of recall and precision to coreference annotation proposed by
Marc Vilain and his collaborators. I show how this method makes it possible to
construct contingency tables for computing Cohen's Kappa, a familiar
reliability metric. By comparing recall and precision to reliability on the
same data sets, I also show that recall and precision can be misleadingly high.
Because Kappa factors out chance agreement among coders, it is a preferable
measure for developing annotated corpora where no pre-existing target
annotation exists.


Intention-based Segmentation: Human Reliability and Correlation with
  Linguistic Cues

  Certain spans of utterances in a discourse, referred to here as segments, are
widely assumed to form coherent units. Further, the segmental structure of
discourse has been claimed to constrain and be constrained by many phenomena.
However, there is weak consensus on the nature of segments and the criteria for
recognizing or generating them. We present quantitative results of a two part
study using a corpus of spontaneous, narrative monologues. The first part
evaluates the statistical reliability of human segmentation of our corpus,
where speaker intention is the segmentation criterion. We then use the
subjects' segmentations to evaluate the correlation of discourse segmentation
with three linguistic cues (referential noun phrases, cue words, and pauses),
using information retrieval metrics.


Abstractive Multi-Document Summarization via Phrase Selection and
  Merging

  We propose an abstraction-based multi-document summarization framework that
can construct new sentences by exploring more fine-grained syntactic units than
sentences, namely, noun/verb phrases. Different from existing abstraction-based
approaches, our method first constructs a pool of concepts and facts
represented by phrases from the input documents. Then new sentences are
generated by selecting and merging informative phrases to maximize the salience
of phrases and meanwhile satisfy the sentence construction constraints. We
employ integer linear optimization for conducting phrase selection and merging
simultaneously in order to achieve the global optimal solution for a summary.
Experimental results on the benchmark data set TAC 2011 show that our framework
outperforms the state-of-the-art models under automated pyramid evaluation
metric, and achieves reasonably well results on manual linguistic quality
evaluation.


