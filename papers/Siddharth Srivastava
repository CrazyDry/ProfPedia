Benchmarking KAZE and MCM for Multiclass Classification

  In this paper, we propose a novel approach for feature generation by
appropriately fusing KAZE and SIFT features. We then use this feature set along
with Minimal Complexity Machine(MCM) for object classification. We show that
KAZE and SIFT features are complementary. Experimental results indicate that an
elementary integration of these techniques can outperform the state-of-the-art
approaches.


SIFT Vs SURF: Quantifying the Variation in Transformations

  This paper studies the robustness of SIFT and SURF against different image
transforms (rigid body, similarity, affine and projective) by quantitatively
analyzing the variations in the extent of transformations. Previous studies
have been comparing the two techniques on absolute transformations rather than
the specific amount of deformation caused by the transformation. The paper
establishes an exhaustive empirical analysis of such deformations and matching
capability of SIFT and SURF with variations in matching parameters and the
amount of tolerance. This is helpful in choosing the specific use case for
applying these techniques.


Object Classification using Ensemble of Local and Deep Features

  In this paper we propose an ensemble of local and deep features for object
classification. We also compare and contrast effectiveness of feature
representation capability of various layers of convolutional neural network. We
demonstrate with extensive experiments for object classification that the
representation capability of features from deep networks can be complemented
with information captured from local features. We also find out that features
from various deep convolutional networks encode distinctive characteristic
information. We establish that, as opposed to conventional practice,
intermediate layers of deep networks can augment the classification
capabilities of features obtained from fully connected layers.


Enhanced Characterness for Text Detection in the Wild

  Text spotting is an interesting research problem as text may appear at any
random place and may occur in various forms. Moreover, ability to detect text
opens the horizons for improving many advanced computer vision problems. In
this paper, we propose a novel language agnostic text detection method
utilizing edge enhanced Maximally Stable Extremal Regions in natural scenes by
defining strong characterness measures. We show that a simple combination of
characterness cues help in rejecting the non text regions. These regions are
further fine-tuned for rejecting the non-textual neighbor regions.
Comprehensive evaluation of the proposed scheme shows that it provides
comparative to better generalization performance to the traditional methods for
this task.


Electronic Health Records and Cloud based Generic Medical Equipment
  Interface

  Now-a-days Health Care industry is well equipped with Medical Equipments to
provide accurate and timely reports of investigation and examination results.
Medical Equipments available in market are made for specific tests suited for a
particular laboratory leading to a wide variety of devices. The result viewing
experience on console of these devices is not only cumborsome for medical staff
but inefficient. Therefore, Medical Equipment Interfaces act as backbone of any
Hospital Management Information System assisting in better management and
delivery of test results. It also acts as a mode to collect data for further
research and analysis. These equipments communicate via a fixed data format but
compatibility among these formats is a major issue being faced in modern and
legacy medical equipments. In this paper, we present a case study of designing
and implementing a cloud based Generic Medical Equipment Interface(GMEI) along
with the state of the art in such systems. This solution removes the burden of
reentry of patient details into the Electronic Health Record(EHR) and thrives
for accelerating EMR initiative in the country


Large Scale Novel Object Discovery in 3D

  We present a method for discovering never-seen-before objects in 3D point
clouds obtained from sensors like Microsoft Kinect. We generate supervoxels
directly from the point cloud data and use them with a Siamese network, built
on a recently proposed 3D convolutional neural network architecture. We use
known objects to train a non-linear embedding of supervoxels, by optimizing the
criteria that supervoxels which fall on the same object should be closer than
those which fall on different objects, in the embedding space. We test on
unknown objects, which were not seen during training, and perform clustering in
the learned embedding space of supervoxels to effectively perform novel object
discovery. We validate the method with extensive experiments, quantitatively
showing that it can discover numerous unseen objects while being trained on
only a few dense 3D models. We also show very good qualitative results of
object discovery in point cloud data when the test objects, either specific
instances or even categories, were never seen during training.


3D Binary Signatures

  In this paper, we propose a novel binary descriptor for 3D point clouds. The
proposed descriptor termed as 3D Binary Signature (3DBS) is motivated from the
matching efficiency of the binary descriptors for 2D images. 3DBS describes
keypoints from point clouds with a binary vector resulting in extremely fast
matching. The method uses keypoints from standard keypoint detectors. The
descriptor is built by constructing a Local Reference Frame and aligning a
local surface patch accordingly. The local surface patch constitutes of
identifying nearest neighbours based upon an angular constraint among them. The
points are ordered with respect to the distance from the keypoints. The normals
of the ordered pairs of these keypoints are projected on the axes and the
relative magnitude is used to assign a binary digit. The vector thus
constituted is used as a signature for representing the keypoints. The matching
is done by using hamming distance. We show that 3DBS outperforms state of the
art descriptors on various evaluation metrics.


Drought Stress Classification using 3D Plant Models

  Quantification of physiological changes in plants can capture different
drought mechanisms and assist in selection of tolerant varieties in a high
throughput manner. In this context, an accurate 3D model of plant canopy
provides a reliable representation for drought stress characterization in
contrast to using 2D images. In this paper, we propose a novel end-to-end
pipeline including 3D reconstruction, segmentation and feature extraction,
leveraging deep neural networks at various stages, for drought stress study. To
overcome the high degree of self-similarities and self-occlusions in plant
canopy, prior knowledge of leaf shape based on features from deep siamese
network are used to construct an accurate 3D model using structure from motion
on wheat plants. The drought stress is characterized with a deep network based
feature aggregation. We compare the proposed methodology on several
descriptors, and show that the network outperforms conventional methods.


An Anytime Algorithm for Task and Motion MDPs

  Integrated task and motion planning has emerged as a challenging problem in
sequential decision making, where a robot needs to compute high-level strategy
and low-level motion plans for solving complex tasks. While high-level
strategies require decision making over longer time-horizons and scales, their
feasibility depends on low-level constraints based upon the geometries and
continuous dynamics of the environment. The hybrid nature of this problem makes
it difficult to scale; most existing approaches focus on deterministic, fully
observable scenarios. We present a new approach where the high-level decision
problem occurs in a stochastic setting and can be modeled as a Markov decision
process. In contrast to prior efforts, we show that complete MDP policies, or
contingent behaviors, can be computed effectively in an anytime fashion. Our
algorithm continuously improves the quality of the solution and is guaranteed
to be probabilistically complete. We evaluate the performance of our approach
on a challenging, realistic test problem: autonomous aircraft inspection. Our
results show that we can effectively compute consistent task and motion
policies for the most likely execution-time outcomes using only a fraction of
the computation required to develop the complete task and motion policy.


DeepPoint3D: Learning Discriminative Local Descriptors using Deep Metric
  Learning on 3D Point Clouds

  Learning local descriptors is an important problem in computer vision. While
there are many techniques for learning local patch descriptors for 2D images,
recently efforts have been made for learning local descriptors for 3D points.
The recent progress towards solving this problem in 3D leverages the strong
feature representation capability of image based convolutional neural networks
by utilizing RGB-D or multi-view representations. However, in this paper, we
propose to learn 3D local descriptors by directly processing unstructured 3D
point clouds without needing any intermediate representation. The method
constitutes a deep network for learning permutation invariant representation of
3D points. To learn the local descriptors, we use a multi-margin contrastive
loss which discriminates between similar and dissimilar points on a surface
while also leveraging the extent of dissimilarity among the negative samples at
the time of training. With comprehensive evaluation against strong baselines,
we show that the proposed method outperforms state-of-the-art methods for
matching points in 3D point clouds. Further, we demonstrate the effectiveness
of the proposed method on various applications achieving state-of-the-art
results.


Brain Computer Interfaces for Mobile Apps: State-of-the-art and Future
  Directions

  In recent times, there have been significant advancements in utilizing the
sensing capabilities of mobile devices for developing applications. The primary
objective has been to enhance the way a user interacts with the application by
making it effortless and convenient. This paper explores the capabilities of
using Brain Computer Interfaces (BCI), an evolving subset of Human Computer
Interaction (HCI) paradigms, to control mobile devices. We present a
comprehensive survey of the state-of-the-art in this area, discussing the
challenges and limitations in using BCI for mobile applications. Further we
propose possible modalities that in future can benefit with BCI applications.
This paper consolidates research directions being pursued in this domain, and
draws conclusions on feasibility and benefits of using BCI systems effectively
augmented to the mobile application development domain.


Simulating reachability using first-order logic with applications to
  verification of linked data structures

  This paper shows how to harness existing theorem provers for first-order
logic to automatically verify safety properties of imperative programs that
perform dynamic storage allocation and destructive updating of pointer-valued
structure fields. One of the main obstacles is specifying and proving the
(absence) of reachability properties among dynamically allocated cells.
  The main technical contributions are methods for simulating reachability in a
conservative way using first-order formulas--the formulas describe a superset
of the set of program states that would be specified if one had a precise way
to express reachability. These methods are employed for semi-automatic program
verification (i.e., using programmer-supplied loop invariants) on programs such
as mark-and-sweep garbage collection and destructive reversal of a singly
linked list. (The mark-and-sweep example has been previously reported as being
beyond the capabilities of ESC/Java.)


On the smoothness of multi-M2 brane horizons

  We calculate the degree of horizon smoothness of multi- $M2$-brane solution
with branes along a common axis. We find that the metric is generically only
thrice continuously differentiable at any of the horizons. The four-form field
strength is found to be only twice continuously differentiable. We work with
Gaussian null-like co-ordinates which are obtained by solving geodesic
equations for multi-$M2$ brane geometry. We also find different, exact
co-ordinate transformations which take the metric from isotropic co-ordinates
to co-ordinates in which metric is thrice differentiable at the horizon. Both
methods give the same result that the multi-$M2$ brane metric is only thrice
continuously differentiable at the horizon.


An ROS-based Shared Communication Middleware for Plug & Play Modular
  Intelligent Design of Smart Systems

  Centralized architectures for systems such as smart offices and homes are
rapidly becoming obsolete due to inherent inflexibility in their design and
management. This is because such systems should not only be easily
re-configurable with the addition of newer capabilities over time but should
also have the ability to adapt to multiple points of failure. Fully harnessing
the capabilities of these massively integrated systems requires higher level
reasoning engines that allow them to plan for and achieve diverse long-term
goals, rather than being limited to a few predefined tasks. In this paper, we
propose a set of properties that will accommodate such capabilities, and
develop a general architecture for integrating automated planning components
into smart systems. We show how the reasoning capabilities are embedded in the
design and operation of the system and demonstrate the same on a real-world
implementation of a smart office.


Learning Generalized Reactive Policies using Deep Neural Networks

  We present a new approach to learning for planning, where knowledge acquired
while solving a given set of planning problems is used to plan faster in
related, but new problem instances. We show that a deep neural network can be
used to learn and represent a \emph{generalized reactive policy} (GRP) that
maps a problem instance and a state to an action, and that the learned GRPs
efficiently solve large classes of challenging problem instances. In contrast
to prior efforts in this direction, our approach significantly reduces the
dependence of learning on handcrafted domain knowledge or feature selection.
Instead, the GRP is trained from scratch using a set of successful execution
traces. We show that our approach can also be used to automatically learn a
heuristic function that can be used in directed search algorithms. We evaluate
our approach using an extensive suite of experiments on two challenging
planning problem domains and show that our approach facilitates learning
complex decision making policies and powerful heuristic functions with minimal
human input. Videos of our results are available at goo.gl/Hpy4e3.


Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior
  Explanations

  There is a growing interest within the AI research community to develop
autonomous systems capable of explaining their behavior to users. One aspect of
the explanation generation problem that has yet to receive much attention is
the task of explaining plans to users whose level of expertise differ from that
of the explainer. We propose an approach for addressing this problem by
representing the user's model as an abstraction of the domain model that the
planner uses. We present algorithms for generating minimal explanations in
cases where this abstract human model is not known. We reduce the problem of
generating explanation to a search over the space of abstract models and
investigate possible greedy approximations for minimal explanations. We also
empirically show that our approach can efficiently compute explanations for a
variety of problems.


Discrete-Continuous Mixtures in Probabilistic Programming: Generalized
  Semantics and Inference Algorithms

  Despite the recent successes of probabilistic programming languages (PPLs) in
AI applications, PPLs offer only limited support for random variables whose
distributions combine discrete and continuous elements. We develop the notion
of measure-theoretic Bayesian networks (MTBNs) and use it to provide more
general semantics for PPLs with arbitrarily many random variables defined over
arbitrary measure spaces. We develop two new general sampling algorithms that
are provably correct under the MTBN framework: the lexicographic likelihood
weighting (LLW) for general MTBNs and the lexicographic particle filter (LPF),
a specialized algorithm for state-space models. We further integrate MTBNs into
a widely used PPL system, BLOG, and verify the effectiveness of the new
inference algorithms through representative examples.


Identifying Critical Regions for Motion Planning using Auto-Generated
  Saliency Labels with Convolutional Neural Networks

  In this paper, we present a new approach to learning for motion planning (MP)
where critical regions of an environment with low probability measure are
learned from a given set of motion plans and used to improve performance on new
problem instances. We show that a convolutional neural network (CNN) can be
used to identify critical regions for motion plans. We also introduce a new
sampling-based motion planner, Learn and Link (LLP). LLP leverages critical
region locations identified by our CNN to overcome the limitations of uniform
sampling, while still maintaining guarantees of correctness inherent to
sampling-based algorithms. We evaluate our planner using an extensive suite of
experiments on challenging navigation planning problems and compare its
performance against planners from the Open Motion Planning Library (OMPL). We
show that our approach requires the creation of far fewer states than the
existing sampling-based planners.


Why Couldn't You do that? Explaining Unsolvability of Classical Planning
  Problems in the Presence of Plan Advice

  Explainable planning is widely accepted as a prerequisite for autonomous
agents to successfully work with humans. While there has been a lot of research
on generating explanations of solutions to planning problems, explaining the
absence of solutions remains an open and under-studied problem, even though
such situations can be the hardest to understand or debug. In this paper, we
show that hierarchical abstractions can be used to efficiently generate reasons
for unsolvability of planning problems. In contrast to related work on
computing certificates of unsolvability, we show that these methods can
generate compact, human-understandable reasons for unsolvability. Empirical
analysis and user studies show the validity of our methods as well as their
computational efficacy on a number of benchmark planning domains.


A Unified Framework for Planning in Adversarial and Cooperative
  Environments

  Users of AI systems may rely upon them to produce plans for achieving desired
objectives. Such AI systems should be able to compute obfuscated plans whose
execution in adversarial situations protects privacy, as well as legible plans
which are easy for team members to understand in cooperative situations. We
develop a unified framework that addresses these dual problems by computing
plans with a desired level of comprehensibility from the point of view of a
partially informed observer. For adversarial settings, our approach produces
obfuscated plans with observations that are consistent with at least k goals
from a set of decoy goals. By slightly varying our framework, we present an
approach for goal legibility in cooperative settings which produces plans that
achieve a goal while being consistent with at most j goals from a set of
confounding goals. In addition, we show how the observability of the observer
can be controlled to either obfuscate or clarify the next actions in a plan
when the goal is known to the observer. We present theoretical results on the
complexity analysis of our problems. We demonstrate the execution of obfuscated
and legible plans in a cooking domain using a physical robot Fetch. We also
provide an empirical evaluation to show the feasibility and usefulness of our
approaches using IPC domains.


Large-Scale 3D Shape Reconstruction and Segmentation from ShapeNet
  Core55

  We introduce a large-scale 3D shape understanding benchmark using data and
annotation from ShapeNet 3D object database. The benchmark consists of two
tasks: part-level segmentation of 3D shapes and 3D reconstruction from single
view images. Ten teams have participated in the challenge and the best
performing teams have outperformed state-of-the-art approaches on both tasks. A
few novel deep learning architectures have been proposed on various 3D
representations on both tasks. We report the techniques used by each team and
the corresponding performances. In addition, we summarize the major discoveries
from the reported results and possible trends for the future work in the field.


