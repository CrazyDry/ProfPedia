Holographic Dark Energy with Cosmological Constant

  Inspired by the multiverse scenario, we study a heterotic dark energy model
in which there are two parts, the first being the cosmological constant and the
second being the holographic dark energy, thus this model is named the
$\Lambda$HDE model. By studying the $\Lambda$HDE model theoretically, we find
that the parameters $d$ and $\Omega_{hde}$ are divided into a few domains in
which the fate of the universe is quite different. We investigate dynamical
behaviors of this model, and especially the future evolution of the universe.
We perform fitting analysis on the cosmological parameters in the $\Lambda$HDE
model by using the recent observational data. We find the model yields
$\chi^2_{\rm min}=426.27$ when constrained by $\rm Planck+SNLS3+BAO+HST$,
comparable to the results of the HDE model (428.20) and the concordant
$\Lambda$CDM model (431.35). At 68.3\% CL, we obtain
$-0.07<\Omega_{\Lambda0}<0.68$ and correspondingly $0.04<\Omega_{hde0}<0.79$,
implying at present there is considerable degeneracy between the holographic
dark energy and cosmological constant components in the $\Lambda$HDE model.


Cosmological constraints on the new holographic dark energy model with
  action principle

  Recently, a New HDE model with action principle was proposed (Li and Miao,
arXiv:1210.0966). This model completely solves the causality and circular
problems in the original HDE model, and is similar to the original model except
a new term that can be interpreted as dark radiation. In this paper, we make
further investigations on this model from the aspect of cosmological
observations. Numerically, we confirm that the equations of motion force the
$L(z=-1)=0$, making the cut-off $aL$ exactly the future event horizon. We also
perform detailed analysis on the dynamical properties of the model, divided
into the $c<6$ and $c\geq6$ cases ($c$ is a dimensionless parameter which
should be decided by the data). From a combination of the present
Union2.1+BAO+CMB+$H_0$ data, we find the model yields $\chi^2_{\rm
min}=548.798$ (in a non-flat Universe), comparable to the results of the
original HDE model (549.461) and the concordant $\Lambda$CDM model (550.354).
At 95.4% CL, we get $1.41<c<3.09$ and correspondingly $-2.25<w(z=-1)<-1.39$,
implying the Big Rip fate of the Universe at a high confidence level. Besides,
for the constraints on dark radiation, we also get a rough estimation $N_{\rm
\rm eff}=3.54^{+0.32+0.67}_{\rm -0.45-0.76}$, with the central value slightly
larger than the standard value 3.046.


Investigating the Possibility of a Turning Point in the Dark Energy
  Equation of State

  We investigate a second order $parabolic$ parametrization,
$w(a)=w_t+w_a(a_t-a)^2$, which is a direct characterization of a possible
$turning$ in $w$. The cosmological consequence of this parametrization is
explored by using the observational data of the SNLS3 type Ia supernovae
sample, the CMB measurements from WMAP9 and Planck, the Hubble parameter
measurement from HST, and the baryon acoustic oscillation (BAO) measurements
from 6dFGS, BOSS DR11 and improved WiggleZ. We found the existence of a turning
point in $w$ at $a\sim0.7$ is favored at 1$\sigma$ CL. In the epoch $0.55< a<
0.9$, $w<-1$ is favored at 1$\sigma$ CL, and this significance increases near
$a=0.8$, reaching a 2$\sigma$ CL. The parabolic parametrization achieve
equivalent performance to the $\Lambda$CDM and Chevallier-Polarski-Linder (CPL)
models when the Akaike information criterion was used to assess them. Our
analysis shows the value of considering high order parametrizations when
studying the cosmological constraints on $w$.


Semantic Exploration of Traffic Dynamics

  Given a large collection of urban datasets, how can we find their hidden
correlations? For example, New York City (NYC) provides open access to taxi
data from year 2012 to 2015 with about half million taxi trips generated per
day. In the meantime, we have a rich set of urban data in NYC including
points-of-interest (POIs), geo-tagged tweets, weather, vehicle collisions, etc.
Is it possible that these ubiquitous datasets can be used to explain the city
traffic? Understanding the hidden correlation between external data and traffic
data would allow us to answer many important questions in urban computing such
as: If we observe a high traffic volume at Madison Square Garden (MSG) in NYC,
is it because of the regular peak hour or a big event being held at MSG? If a
disaster weather such as a hurricane or a snow storm hits the city, how would
the traffic be affected?
  While existing studies may utilize external datasets for prediction task,
they do not explicitly seek for direct explanations from the external datasets.
In this paper, we present our results in attempts to understand taxi traffic
dynamics in NYC from multiple external data sources. We use four real-world
ubiquitous urban datasets, including POI, weather, geo-tagged tweet, and
collision records. To address the heterogeneity of ubiquitous urban data, we
present carefully-designed feature representations for various datasets.
Extensive experiments on real data demonstrate the explanatory power on taxi
traffic by using external datasets. More specifically, our analysis suggests
that POIs can well describe the regular traffic patterns. At the same time,
geo-tagged tweets can explain irregular traffic caused by big events and
weather can explain the abnormal traffic drop.


Revisit of the Interaction between Holographic Dark Energy and Dark
  Matter

  In this paper we investigate the possible direct, non-gravitational
interaction between holographic dark energy (HDE) and dark matter. Firstly, we
start with two simple models with the interaction terms $Q \propto \rho_{dm}$
and $Q \propto \rho_{de}$, and then we move on to the general form $Q \propto
\rho_m^\alpha\rho_{de}^\beta$. The cosmological constraints of the models are
obtained from the joint analysis of the present Union2.1+BAO+CMB+$H_0$ data. We
find that the data slightly favor an energy flow from dark matter to dark
energy, although the original HDE model still lies in the 95.4% confidence
level (CL) region. For all models we find $c<1$ at the 95.4% CL. We show that
compared with the cosmic expansion, the effect of interaction on the evolution
of $\rho_{dm}$ and $\rho_{de}$ is smaller, and the relative increment
(decrement) amount of the energy in the dark matter component is constrained to
be less than 9% (15%) at the 95.4% CL. By introducing the interaction, we find
that even when $c<1$ the big rip still can be avoided due to the existence of a
de Sitter solution at $z\rightarrow-1$. We show that this solution can not be
accomplished in the two simple models, while for the general model such a
solution can be achieved with a large $\beta$, and the big rip may be avoided
at the 95.4% CL.


Generalized Fisher Score for Feature Selection

  Fisher score is one of the most widely used supervised feature selection
methods. However, it selects each feature independently according to their
scores under the Fisher criterion, which leads to a suboptimal subset of
features. In this paper, we present a generalized Fisher score to jointly
select features. It aims at finding an subset of features, which maximize the
lower bound of traditional Fisher score. The resulting feature selection
problem is a mixed integer programming, which can be reformulated as a
quadratically constrained linear programming (QCLP). It is solved by cutting
plane algorithm, in each iteration of which a multiple kernel learning problem
is solved alternatively by multivariate ridge regression and projected gradient
descent. Experiments on benchmark data sets indicate that the proposed method
outperforms Fisher score as well as many other state-of-the-art feature
selection methods.


A Simple Baseline for Travel Time Estimation using Large-Scale Trip Data

  The increased availability of large-scale trajectory data around the world
provides rich information for the study of urban dynamics. For example, New
York City Taxi Limousine Commission regularly releases source-destination
information about trips in the taxis they regulate. Taxi data provide
information about traffic patterns, and thus enable the study of urban flow --
what will traffic between two locations look like at a certain date and time in
the future? Existing big data methods try to outdo each other in terms of
complexity and algorithmic sophistication. In the spirit of "big data beats
algorithms", we present a very simple baseline which outperforms
state-of-the-art approaches, including Bing Maps and Baidu Maps (whose APIs
permit large scale experimentation). Such a travel time estimation baseline has
several important uses, such as navigation (fast travel time estimates can
serve as approximate heuristics for A search variants for path finding) and
trip planning (which uses operating hours for popular destinations along with
travel time estimates to create an itinerary).


Single-Carrier Modulation for Large-Scale Antenna Systems

  Large-scale antenna (LSA) has gained a lot of attention due to its great
potential to significantly improve system throughput. In most existing works on
LSA systems, orthogonal frequency division multiplexing (OFDM) is presumed to
deal with frequency selectivity of wireless channels. Although LSA-OFDM is a
natural evolution from multiple-input multiple-output OFDM (MIMO-OFDM), the
drawbacks of LSA-OFDM are inevitable, especially when used for the uplink. In
this paper, we investigate single-carrier (SC) modulation for the uplink
transmission in LSA systems based on a novel waveform recovery theory, where
the receiver is designed to recover the transmit waveform while the
information-bearing symbols can be recovered by directly sampling the recovered
waveform. The waveform recovery adopts the assumption that the antenna number
is infinite and the channels at different antennas are independent. In
practical environments, however, the antenna number is always finite and the
channels at different antennas are also correlated when placing hundreds of
antennas in a small area. Therefore, we will also analyze the impacts of such
non-ideal environments.


Detecting Outliers in Data with Correlated Measures

  Advances in sensor technology have enabled the collection of large-scale
datasets. Such datasets can be extremely noisy and often contain a significant
amount of outliers that result from sensor malfunction or human operation
faults. In order to utilize such data for real-world applications, it is
critical to detect outliers so that models built from these datasets will not
be skewed by outliers.
  In this paper, we propose a new outlier detection method that utilizes the
correlations in the data (e.g., taxi trip distance vs. trip time). Different
from existing outlier detection methods, we build a robust regression model
that explicitly models the outliers and detects outliers simultaneously with
the model fitting.
  We validate our approach on real-world datasets against methods specifically
designed for each dataset as well as the state of the art outlier detectors.
Our outlier detection method achieves better performances, demonstrating the
robustness and generality of our method. Last, we report interesting case
studies on some outliers that result from atypical events.


Generalized Holographic Dark Energy and its Observational Constraints

  In the original holographic dark energy (HDE) model, the dark energy density
is proposed to be $\rho_{de} = 3c^2M^2_{pl}L^{-2}$, with $c$ is a dimensionless
constant characterizing the properties of the HDE. In this work, we propose the
generalized holographic dark energy (GHDE) model by considering the parameter
$c$ as a redshift-dependent function $c(z)$. We derive all the physical
quantities of the GHDE model analytically, and fit the $c(z)$ by trying four
kinds of parametrizations. The cosmological constraints of the $c(z)$ are
obtained from the joint analysis of the present SNLS3+BAO+CMB+$H_0$ data. We
find that, compared with the original HDE model, the GHDE models can provide a
better fit to the data. For example, the GHDE model with JBP-type $c(z)$ can
reduce the $\chi^2_{min}$ of the HDE model by 2.16. We also find that, unlike
the original HDE model with a phantom-like behavior in the future, the GHDE
models can present many more different possibilities, i.e., it allows the GHDE
in the future to be either quintessence like, cosmological constant like, or
phantom like, depending on the forms of $c(z)$.


Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for
  Traffic Prediction

  Traffic prediction has drawn increasing attention in AI research field due to
the increasing availability of large-scale traffic data and its importance in
the real world. For example, an accurate taxi demand prediction can assist taxi
companies in pre-allocating taxis. The key challenge of traffic prediction lies
in how to model the complex spatial dependencies and temporal dynamics.
Although both factors have been considered in modeling, existing works make
strong assumptions about spatial dependence and temporal dynamics, i.e.,
spatial dependence is stationary in time, and temporal dynamics is strictly
periodical. However, in practice, the spatial dependence could be dynamic
(i.e., changing from time to time), and the temporal dynamics could have some
perturbation from one period to another period. In this paper, we make two
important observations: (1) the spatial dependencies between locations are
dynamic; and (2) the temporal dependency follows daily and weekly pattern but
it is not strictly periodic for its dynamic temporal shifting. To address these
two issues, we propose a novel Spatial-Temporal Dynamic Network (STDN), in
which a flow gating mechanism is introduced to learn the dynamic similarity
between locations, and a periodically shifted attention mechanism is designed
to handle long-term periodic temporal shifting. To the best of our knowledge,
this is the first work that tackles both issues in a unified framework. Our
experimental results on real-world traffic datasets verify the effectiveness of
the proposed method.


Test $Λ$CDM model with High Redshift data from Baryon Acoustic
  Oscillations

  The Baryon Acoustic Oscillations (BAO) provide a standard ruler for studying
cosmic expansion. The recent observations of BAO in SDSS DR9 and DR11 take
measurements of $H(z)$ at several different redshifts. It is argued that the
behavior of dark energy could be constrained more effectively by adding
high-redshift Hubble parameter data, such as the SDSS DR11 measurement of $H(z)
= 222\pm7$ km/sec/Mpc at z = 2.34. In this paper, we investigate the
significance of these BAO data in the flat $\Lambda$CDM model, by combining
them with the recent observational data of the Hubble constant from local
distance ladder and the Cosmic Microwave Background (CMB) measurements from
Planck+WP. We perform a detailed data analysis on these datasets and find that
the recent observations of BAO in SDSS DR9 and DR11 have considerable tension
with the Planck + WP measurements in the framework of the standard $\Lambda$CDM
model. The fitting results show that the main contribution to the tension comes
from the Hubble parameter measurement at redshift of $z=2.34$. But there is no
visible tension once the joint data analysis by combining the datasets of SDSS
and Planck+WP is performed. Thus in order to see whether dark energy does
evolve, we need more independent measurements of the Hubble parameter at high
redshifts.


Learning from Multiple Cities: A Meta-Learning Approach for
  Spatial-Temporal Prediction

  Spatial-temporal prediction is a fundamental problem for constructing smart
city, which is useful for tasks such as traffic control, taxi dispatching, and
environmental policy making. Due to data collection mechanism, it is common to
see data collection with unbalanced spatial distributions. For example, some
cities may release taxi data for multiple years while others only release a few
days of data; some regions may have constant water quality data monitored by
sensors whereas some regions only have a small collection of water samples. In
this paper, we tackle the problem of spatial-temporal prediction for the cities
with only a short period of data collection. We aim to utilize the long-period
data from other cities via transfer learning. Different from previous studies
that transfer knowledge from one single source city to a target city, we are
the first to leverage information from multiple cities to increase the
stability of transfer. Specifically, our proposed model is designed as a
spatial-temporal network with a meta-learning paradigm. The meta-learning
paradigm learns a well-generalized initialization of the spatial-temporal
network, which can be effectively adapted to target cities. In addition, a
pattern-based spatial-temporal memory is designed to distill long-term temporal
information (i.e., periodicity). We conduct extensive experiments on two tasks:
traffic (taxi and bike) prediction and water quality prediction. The
experiments demonstrate the effectiveness of our proposed model over several
competitive baseline models.


Planck Constraints on Holographic Dark Energy

  We perform a detailed investigation on the cosmological constraints on the
holographic dark energy (HDE) model by using the Planck data. HDE can provide a
good fit to Planck high-l (l>40) temperature power spectrum, while the
discrepancy at l=20-40 found in LCDM remains unsolved in HDE. The Planck data
alone can lead to strong and reliable constraint on the HDE parameter c. At 68%
CL, we get c=0.508+-0.207 with Planck+WP+lensing, favoring the present phantom
HDE at > 2sigma CL. Comparably, by using WMAP9 alone we cannot get interesting
constraint on c. By combining Planck+WP with the BAO measurements from
6dFGS+SDSS DR7(R)+BOSS DR9, the H0 measurement from HST, the SNLS3 and Union2.1
SNIa data sets, we get 68% CL constraints c=0.484+-0.070, 0.474+-0.049,
0.594+-0.051 and 0.642+-0.066. Constraints can be improved by 2%-15% if we
further add the Planck lensing data. Compared with the WMAP9 results, the
Planck results reduce the error by 30%-60%, and prefer a phantom-like HDE at
higher CL. We find no evident tension between Planck and BAO/HST. Especially,
the strong correlation between Omegam h^3 and dark energy parameters is helpful
in relieving the tension between Planck and HST. The residual
chi^2_{Planck+WP+HST}-chi^2_{Planck+WP} is 7.8 in LCDM, and is reduced to 1.0
or 0.3 if we switch dark energy to the w model or the holographic model. We
find SNLS3 is in tension with all other data sets; for Planck+WP, WMAP9 and
BAO+HST, the corresponding Delta chi^2 is 6.4, 3.5 and 4.1, respectively.
Comparably, Union2.1 is consistent with these data sets, but the combination
Union2.1+BAO+HST is in tension with Planck+WP+lensing, corresponding to a Delta
chi^2 8.6 (1.4% probability). Thus, it is not reasonable to perform an
all-combined (CMB+SNIa+BAO+HST) analysis for HDE when using the Planck data.
Our tightest self-consistent constraint is c=0.495+-0.039 obtained from
Planck+WP+BAO+HST+lensing.


Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction

  Taxi demand prediction is an important building block to enabling intelligent
transportation systems in a smart city. An accurate prediction model can help
the city pre-allocate resources to meet travel demand and to reduce empty taxis
on streets which waste energy and worsen the traffic congestion. With the
increasing popularity of taxi requesting services such as Uber and Didi Chuxing
(in China), we are able to collect large-scale taxi demand data continuously.
How to utilize such big data to improve the demand prediction is an interesting
and critical real-world problem. Traditional demand prediction methods mostly
rely on time series forecasting techniques, which fail to model the complex
non-linear spatial and temporal relations. Recent advances in deep learning
have shown superior performance on traditionally challenging tasks such as
image classification by learning the complex features and correlations from
large-scale data. This breakthrough has inspired researchers to explore deep
learning techniques on traffic prediction problems. However, existing methods
on traffic prediction have only considered spatial relation (e.g., using CNN)
or temporal relation (e.g., using LSTM) independently. We propose a Deep
Multi-View Spatial-Temporal Network (DMVST-Net) framework to model both spatial
and temporal relations. Specifically, our proposed model consists of three
views: temporal view (modeling correlations between future demand values with
near time points via LSTM), spatial view (modeling local spatial correlation
via local CNN), and semantic view (modeling correlations among regions sharing
similar temporal patterns). Experiments on large-scale real taxi demand data
demonstrate effectiveness of our approach over state-of-the-art methods.


