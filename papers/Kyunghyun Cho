Can neural machine translation do simultaneous translation?

  We investigate the potential of attention-based neural machine translation in
simultaneous translation. We introduce a novel decoding algorithm, called
simultaneous greedy decoding, that allows an existing neural machine
translation model to begin translating before a full source sentence is
received. This approach is unique from previous works on simultaneous
translation in that segmentation and translation are done jointly to maximize
the translation quality and that translating each segment is strongly
conditioned on all the previous segments. This paper presents a first step
toward building a full simultaneous translation system based on neural machine
translation.


Natural Language Understanding with Distributed Representation

  This is a lecture note for the course DS-GA 3001 <Natural Language
Understanding with Distributed Representation> at the Center for Data Science ,
New York University in Fall, 2015. As the name of the course suggests, this
lecture note introduces readers to a neural network based approach to natural
language understanding/processing. In order to make it as self-contained as
possible, I spend much time on describing basics of machine learning and neural
networks, only after which how they are used for natural languages is
introduced. On the language front, I almost solely focus on language modelling
and machine translation, two of which I personally find most fascinating and
most fundamental to natural language understanding.


Strawman: an Ensemble of Deep Bag-of-Ngrams for Sentiment Analysis

  This paper describes a builder entry, named "strawman", to the sentence-level
sentiment analysis task of the "Build It, Break It" shared task of the First
Workshop on Building Linguistically Generalizable NLP Systems. The goal of a
builder is to provide an automated sentiment analyzer that would serve as a
target for breakers whose goal is to find pairs of minimally-differing
sentences that break the analyzer.


Overcoming the Curse of Sentence Length for Neural Machine Translation
  using Automatic Segmentation

  The authors of (Cho et al., 2014a) have shown that the recently introduced
neural network translation systems suffer from a significant drop in
translation quality when translating long sentences, unlike existing
phrase-based translation systems. In this paper, we propose a way to address
this issue by automatically segmenting an input sentence into phrases that can
be easily translated by the neural network translation model. Once each segment
has been independently translated by the neural machine translation model, the
translated clauses are concatenated to form a final translation. Empirical
results show a significant improvement in translation quality for long
sentences.


Understanding Dropout: Training Multi-Layer Perceptrons with Auxiliary
  Independent Stochastic Neurons

  In this paper, a simple, general method of adding auxiliary stochastic
neurons to a multi-layer perceptron is proposed. It is shown that the proposed
method is a generalization of recently successful methods of dropout (Hinton et
al., 2012), explicit noise injection (Vincent et al., 2010; Bishop, 1995) and
semantic hashing (Salakhutdinov & Hinton, 2009). Under the proposed framework,
an extension of dropout which allows using separate dropping probabilities for
different hidden neurons, or layers, is found to be available. The use of
different dropping probabilities for hidden layers separately is empirically
investigated.


Classifying and Visualizing Motion Capture Sequences using Deep Neural
  Networks

  The gesture recognition using motion capture data and depth sensors has
recently drawn more attention in vision recognition. Currently most systems
only classify dataset with a couple of dozens different actions. Moreover,
feature extraction from the data is often computational complex. In this paper,
we propose a novel system to recognize the actions from skeleton data with
simple, but effective, features using deep neural networks. Features are
extracted for each frame based on the relative positions of joints (PO),
temporal differences (TD), and normalized trajectories of motion (NT). Given
these features a hybrid multi-layer perceptron is trained, which simultaneously
classifies and reconstructs input data. We use deep autoencoder to visualize
learnt features, and the experiments show that deep neural networks can capture
more discriminative information than, for instance, principal component
analysis can. We test our system on a public database with 65 classes and more
than 2,000 motion sequences. We obtain an accuracy above 95% which is, to our
knowledge, the state of the art result for such a large dataset.


Boltzmann Machines and Denoising Autoencoders for Image Denoising

  Image denoising based on a probabilistic model of local image patches has
been employed by various researchers, and recently a deep (denoising)
autoencoder has been proposed by Burger et al. [2012] and Xie et al. [2012] as
a good model for this. In this paper, we propose that another popular family of
models in the field of deep learning, called Boltzmann machines, can perform
image denoising as well as, or in certain cases of high level of noise, better
than denoising autoencoders. We empirically evaluate the two models on three
different sets of images with different types and levels of noise. Throughout
the experiments we also examine the effect of the depth of the models. The
experiments confirmed our claim and revealed that the performance can be
improved by adding more hidden layers, especially when the level of noise is
high.


On the Properties of Neural Machine Translation: Encoder-Decoder
  Approaches

  Neural machine translation is a relatively new approach to statistical
machine translation based purely on neural networks. The neural machine
translation models often consist of an encoder and a decoder. The encoder
extracts a fixed-length representation from a variable-length input sentence,
and the decoder generates a correct translation from this representation. In
this paper, we focus on analyzing the properties of the neural machine
translation using two models; RNN Encoder--Decoder and a newly proposed gated
recursive convolutional neural network. We show that the neural machine
translation performs relatively well on short sentences without unknown words,
but its performance degrades rapidly as the length of the sentence and the
number of unknown words increase. Furthermore, we find that the proposed gated
recursive convolutional network learns a grammatical structure of a sentence
automatically.


On Using Very Large Target Vocabulary for Neural Machine Translation

  Neural machine translation, a recently proposed approach to machine
translation based purely on neural networks, has shown promising results
compared to the existing approaches such as phrase-based statistical machine
translation. Despite its recent success, neural machine translation has its
limitation in handling a larger vocabulary, as training complexity as well as
decoding complexity increase proportionally to the number of target words. In
this paper, we propose a method that allows us to use a very large target
vocabulary without increasing training complexity, based on importance
sampling. We show that decoding can be efficiently done even with the model
having a very large target vocabulary by selecting only a small subset of the
whole target vocabulary. The models trained by the proposed approach are
empirically found to outperform the baseline models with a small vocabulary as
well as the LSTM-based neural machine translation models. Furthermore, when we
use the ensemble of a few models with very large target vocabularies, we
achieve the state-of-the-art translation performance (measured by BLEU) on the
English->German translation and almost as high performance as state-of-the-art
English->French translation system.


Learning Phrase Representations using RNN Encoder-Decoder for
  Statistical Machine Translation

  In this paper, we propose a novel neural network model called RNN
Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN
encodes a sequence of symbols into a fixed-length vector representation, and
the other decodes the representation into another sequence of symbols. The
encoder and decoder of the proposed model are jointly trained to maximize the
conditional probability of a target sequence given a source sequence. The
performance of a statistical machine translation system is empirically found to
improve by using the conditional probabilities of phrase pairs computed by the
RNN Encoder-Decoder as an additional feature in the existing log-linear model.
Qualitatively, we show that the proposed model learns a semantically and
syntactically meaningful representation of linguistic phrases.


First Step toward Model-Free, Anonymous Object Tracking with Recurrent
  Neural Networks

  In this paper, we propose and study a novel visual object tracking approach
based on convolutional networks and recurrent networks. The proposed approach
is distinct from the existing approaches to visual object tracking, such as
filtering-based ones and tracking-by-detection ones, in the sense that the
tracking system is explicitly trained off-line to track anonymous objects in a
noisy environment. The proposed visual tracking model is end-to-end trainable,
minimizing any adversarial effect from mismatches in object representation and
between the true underlying dynamics and learning dynamics. We empirically show
that the proposed tracking approach works well in various scenarios by
generating artificial video sequences with varying conditions; the number of
objects, amount of noise and the match between the training shapes and test
shapes.


On the Number of Linear Regions of Deep Neural Networks

  We study the complexity of functions computable by deep feedforward neural
networks with piecewise linear activations in terms of the symmetries and the
number of linear regions that they have. Deep networks are able to sequentially
map portions of each layer's input-space to the same output. In this way, deep
models compute functions that react equally to complicated patterns of
different inputs. The compositional structure of these functions enables them
to re-use pieces of computation exponentially often in terms of the network's
depth. This paper investigates the complexity of such compositional maps and
contributes new theoretical results regarding the advantage of depth for neural
networks with piecewise linear activation functions. In particular, our
analysis is not specific to a single family of models, and as an example, we
employ it for rectifier and maxout networks. We improve complexity bounds from
pre-existing work and investigate the behavior of units in higher layers.


Describing Multimedia Content using Attention-based Encoder--Decoder
  Networks

  Whereas deep neural networks were first mostly used for classification tasks,
they are rapidly expanding in the realm of structured output problems, where
the observed target is composed of multiple random variables that have a rich
joint distribution, given the input. We focus in this paper on the case where
the input also has a rich structure and the input and output structures are
somehow related. We describe systems that learn to attend to different places
in the input, for each element of the output, for a variety of tasks: machine
translation, image caption generation, video clip description and speech
recognition. All these systems are based on a shared set of building blocks:
gated recurrent neural networks and convolutional neural networks, along with
trained attention mechanisms. We report on experimental results with these
systems, showing impressively good performance and the advantage of the
attention mechanism.


Noisy Parallel Approximate Decoding for Conditional Recurrent Language
  Model

  Recent advances in conditional recurrent language modelling have mainly
focused on network architectures (e.g., attention mechanism), learning
algorithms (e.g., scheduled sampling and sequence-level training) and novel
applications (e.g., image/video description generation, speech recognition,
etc.) On the other hand, we notice that decoding algorithms/strategies have not
been investigated as much, and it has become standard to use greedy or beam
search. In this paper, we propose a novel decoding strategy motivated by an
earlier observation that nonlinear hidden layers of a deep neural network
stretch the data manifold. The proposed strategy is embarrassingly
parallelizable without any communication overhead, while improving an existing
decoding algorithm. We extensively evaluate it with attention-based neural
machine translation on the task of En->Cz translation.


Emergent Linguistic Phenomena in Multi-Agent Communication Games

  In this work, we propose a computational framework in which agents equipped
with communication capabilities simultaneously play a series of referential
games, where agents are trained using deep reinforcement learning. We
demonstrate that the framework mirrors linguistic phenomena observed in natural
language: i) the outcome of contact between communities is a function of inter-
and intra-group connectivity; ii) linguistic contact either converges to the
majority protocol, or in balanced cases leads to novel creole languages of
lower complexity; and iii) a linguistic continuum emerges where neighboring
languages are more mutually intelligible than farther removed languages. We
conclude that intricate properties of language evolution need not depend on
complex evolved linguistic capabilities, but can emerge from simple social
exchanges between perceptually-enabled agents playing communication games.


Not All Neural Embeddings are Born Equal

  Neural language models learn word representations that capture rich
linguistic and conceptual information. Here we investigate the embeddings
learned by neural machine translation models. We show that translation-based
embeddings outperform those learned by cutting-edge monolingual models at
single-language tasks requiring knowledge of conceptual similarity and/or
syntactic role. The findings suggest that, while monolingual models learn
information about how concepts are related, neural-translation models better
capture their true ontological status.


Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
  Modeling

  In this paper we compare different types of recurrent units in recurrent
neural networks (RNNs). Especially, we focus on more sophisticated units that
implement a gating mechanism, such as a long short-term memory (LSTM) unit and
a recently proposed gated recurrent unit (GRU). We evaluate these recurrent
units on the tasks of polyphonic music modeling and speech signal modeling. Our
experiments revealed that these advanced recurrent units are indeed better than
more traditional recurrent units such as tanh units. Also, we found GRU to be
comparable to LSTM.


Efficient Character-level Document Classification by Combining
  Convolution and Recurrent Layers

  Document classification tasks were primarily tackled at word level. Recent
research that works with character-level inputs shows several benefits over
word-level approaches such as natural incorporation of morphemes and better
handling of rare words. We propose a neural network architecture that utilizes
both convolution and recurrent layers to efficiently encode character inputs.
We validate the proposed model on eight large scale document classification
tasks and compare with character-level convolution-only models. It achieves
comparable performances with much less parameters.


Learning Distributed Representations of Sentences from Unlabelled Data

  Unsupervised methods for learning distributed representations of words are
ubiquitous in today's NLP research, but far less is known about the best ways
to learn distributed phrase or sentence representations from unlabelled data.
This paper is a systematic comparison of models that learn such
representations. We find that the optimal approach depends critically on the
intended application. Deeper, more complex models are preferable for
representations to be used in supervised systems, but shallow log-linear models
work best for building representation spaces that can be decoded with simple
spatial distance metrics. We also propose two new unsupervised
representation-learning objectives designed to optimise the trade-off between
training time, domain portability and performance.


Zero-Resource Translation with Multi-Lingual Neural Machine Translation

  In this paper, we propose a novel finetuning algorithm for the recently
introduced multi-way, mulitlingual neural machine translate that enables
zero-resource machine translation. When used together with novel many-to-one
translation strategies, we empirically show that this finetuning algorithm
allows the multi-way, multilingual model to translate a zero-resource language
pair (1) as well as a single-pair neural translation model trained with up to
1M direct parallel sentences of the same language pair and (2) better than
pivot-based translation strategy, while keeping only one additional copy of
attention-related parameters.


Multi-Way, Multilingual Neural Machine Translation with a Shared
  Attention Mechanism

  We propose multi-way, multilingual neural machine translation. The proposed
approach enables a single neural translation model to translate between
multiple languages, with a number of parameters that grows only linearly with
the number of languages. This is made possible by having a single attention
mechanism that is shared across all language pairs. We train the proposed
multi-way, multilingual model on ten language pairs from WMT'15 simultaneously
and observe clear performance improvements over models trained on only one
language pair. In particular, we observe that the proposed model significantly
improves the translation quality of low-resource language pairs.


Does Neural Machine Translation Benefit from Larger Context?

  We propose a neural machine translation architecture that models the
surrounding text in addition to the source sentence. These models lead to
better performance, both in terms of general translation quality and pronoun
prediction, when trained on small corpora, although this improvement largely
disappears when trained with a larger corpus. We also discover that
attention-based neural machine translation is well suited for pronoun
prediction and compares favorably with other approaches that were specifically
designed for this task.


Towards Music Captioning: Generating Music Playlist Descriptions

  Descriptions are often provided along with recommendations to help users'
discovery. Recommending automatically generated music playlists (e.g.
personalised playlists) introduces the problem of generating descriptions. In
this paper, we propose a method for generating music playlist descriptions,
which is called as music captioning. In the proposed method, audio content
analysis and natural language processing are adopted to utilise the information
of each track.


Learning to Parse and Translate Improves Neural Machine Translation

  There has been relatively little attention to incorporating linguistic prior
to neural machine translation. Much of the previous work was further
constrained to considering linguistic prior on the source side. In this paper,
we propose a hybrid model, called NMT+RNNG, that learns to parse and translate
by combining the recurrent neural network grammar into the attention-based
neural machine translation. Our approach encourages the neural machine
translation model to incorporate linguistic prior during training, and lets it
translate on its own afterward. Extensive experiments with four language pairs
show the effectiveness of the proposed NMT+RNNG.


Nematus: a Toolkit for Neural Machine Translation

  We present Nematus, a toolkit for Neural Machine Translation. The toolkit
prioritizes high translation accuracy, usability, and extensibility. Nematus
has been used to build top-performing submissions to shared translation tasks
at WMT and IWSLT, and has been used to train systems for production
environments.


A Comparison of Audio Signal Preprocessing Methods for Deep Neural
  Networks on Music Tagging

  In this paper, we empirically investigate the effect of audio preprocessing
on music tagging with deep neural networks. We perform comprehensive
experiments involving audio preprocessing using different time-frequency
representations, logarithmic magnitude compression, frequency weighting, and
scaling. We show that many commonly used input preprocessing techniques are
redundant except magnitude compression.


Attention-based Mixture Density Recurrent Networks for History-based
  Recommendation

  The goal of personalized history-based recommendation is to automatically
output a distribution over all the items given a sequence of previous purchases
of a user. In this work, we present a novel approach that uses a recurrent
network for summarizing the history of purchases, continuous vectors
representing items for scalability, and a novel attention-based recurrent
mixture density network, which outputs each component in a mixture
sequentially, for modelling a multi-modal conditional distribution. We evaluate
the proposed approach on two publicly available datasets, MovieLens-20M and
RecSys15. The experiments show that the proposed approach, which explicitly
models the multi-modal nature of the predictive distribution, is able to
improve the performance over various baselines in terms of precision, recall
and nDCG.


Graph Convolutional Networks for Classification with a Structured Label
  Space

  It is a usual practice to ignore any structural information underlying
classes in multi-class classification. In this paper, we propose a graph
convolutional network (GCN) augmented neural network classifier to exploit a
known, underlying graph structure of labels. The proposed approach resembles an
(approximate) inference procedure in, for instance, a conditional random field
(CRF). We evaluate the proposed approach on document classification and object
recognition and report both accuracies and graph-theoretic metrics that
correspond to the consistency of the model's prediction. The experiment results
reveal that the proposed model outperforms a baseline method which ignores the
graph structures of a label space in terms of graph-theoretic metrics.


Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative
  Refinement

  We propose a conditional non-autoregressive neural sequence model based on
iterative refinement. The proposed model is designed based on the principles of
latent variable models and denoising autoencoders, and is generally applicable
to any sequence generation task. We extensively evaluate the proposed model on
machine translation (En-De and En-Ro) and image caption generation, and observe
that it significantly speeds up decoding while maintaining the generation
quality comparable to the autoregressive counterpart.


Retrieval-Augmented Convolutional Neural Networks for Improved
  Robustness against Adversarial Examples

  We propose a retrieval-augmented convolutional network and propose to train
it with local mixup, a novel variant of the recently proposed mixup algorithm.
The proposed hybrid architecture combining a convolutional network and an
off-the-shelf retrieval engine was designed to mitigate the adverse effect of
off-manifold adversarial examples, while the proposed local mixup addresses
on-manifold ones by explicitly encouraging the classifier to locally behave
linearly on the data manifold. Our evaluation of the proposed approach against
five readily-available adversarial attacks on three datasets--CIFAR-10, SVHN
and ImageNet--demonstrate the improved robustness compared to the vanilla
convolutional network.


Vehicle Communication Strategies for Simulated Highway Driving

  Interest in emergent communication has recently surged in Machine Learning.
The focus of this interest has largely been either on investigating the
properties of the learned protocol or on utilizing emergent communication to
better solve problems that already have a viable solution. Here, we consider
self-driving cars coordinating with each other and focus on how communication
influences the agents' collective behavior. Our main result is that
communication helps (most) with adverse conditions.


Dynamic Meta-Embeddings for Improved Sentence Representations

  While one of the first steps in many NLP systems is selecting what
pre-trained word embeddings to use, we argue that such a step is better left
for neural networks to figure out by themselves. To that end, we introduce
dynamic meta-embeddings, a simple yet effective method for the supervised
learning of embedding ensembles, which leads to state-of-the-art performance
within the same model class on a variety of tasks. We subsequently show how the
technique can be used to shed new light on the usage of word embeddings in NLP
systems.


Classifier-agnostic saliency map extraction

  Extracting saliency maps, which indicate parts of the image important to
classification, requires many tricks to achieve satisfactory performance when
using classifier-dependent methods. Instead, we propose classifier-agnostic
saliency map extraction, which finds all parts of the image that any classifier
could use, not just one given in advance. We observe that the proposed approach
extracts higher quality saliency maps and outperforms existing
weakly-supervised localization techniques, setting the new state of the art
result on the ImageNet dataset. We made our code publicly available at
https://github.com/kondiz/casme .


Pommerman: A Multi-Agent Playground

  We present Pommerman, a multi-agent environment based on the classic console
game Bomberman. Pommerman consists of a set of scenarios, each having at least
four players and containing both cooperative and competitive aspects. We
believe that success in Pommerman will require a diverse set of tools and
methods, including planning, opponent/teammate modeling, game theory, and
communication, and consequently can serve well as a multi-agent benchmark. To
date, we have already hosted one competition, and our next one will be featured
in the NIPS 2018 competition track.


Dialogue Natural Language Inference

  Consistency is a long standing issue faced by dialogue models. In this paper,
we frame the consistency of dialogue agents as natural language inference (NLI)
and create a new natural language inference dataset called Dialogue NLI. We
propose a method which demonstrates that a model trained on Dialogue NLI can be
used to improve the consistency of a dialogue model, and evaluate the method
with human evaluation and with automatic metrics on a suite of evaluation sets
designed to measure a dialogue model's consistency.


BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field
  Language Model

  We show that BERT (Devlin et al., 2018) is a Markov random field language
model. This formulation gives way to a natural procedure to sample sentences
from BERT. We generate from BERT and find that it can produce high-quality,
fluent generations. Compared to the generations of a traditional left-to-right
language model, BERT generates sentences that are more diverse but of slightly
worse quality.


Context-Aware Learning for Neural Machine Translation

  Interest in larger-context neural machine translation, including
document-level and multi-modal translation, has been growing. Multiple works
have proposed new network architectures or evaluation schemes, but potentially
helpful context is still sometimes ignored by larger-context translation
models. In this paper, we propose a novel learning algorithm that explicitly
encourages a neural translation model to take into account additional context
using a multilevel pair-wise ranking loss. We evaluate the proposed learning
algorithm with a transformer-based larger-context translation system on
document-level translation. By comparing performance using actual and random
contexts, we show that a model trained with the proposed algorithm is more
sensitive to the additional context.


On the Equivalence Between Deep NADE and Generative Stochastic Networks

  Neural Autoregressive Distribution Estimators (NADEs) have recently been
shown as successful alternatives for modeling high dimensional multimodal
distributions. One issue associated with NADEs is that they rely on a
particular order of factorization for $P(\mathbf{x})$. This issue has been
recently addressed by a variant of NADE called Orderless NADEs and its deeper
version, Deep Orderless NADE. Orderless NADEs are trained based on a criterion
that stochastically maximizes $P(\mathbf{x})$ with all possible orders of
factorizations. Unfortunately, ancestral sampling from deep NADE is very
expensive, corresponding to running through a neural net separately predicting
each of the visible variables given some others. This work makes a connection
between this criterion and the training criterion for Generative Stochastic
Networks (GSNs). It shows that training NADEs in this way also trains a GSN,
which defines a Markov chain associated with the NADE model. Based on this
connection, we show an alternative way to sample from a trained Orderless NADE
that allows to trade-off computing time and quality of the samples: a 3 to
10-fold speedup (taking into account the waste due to correlations between
consecutive samples of the chain) can be obtained without noticeably reducing
the quality of the samples. This is achieved using a novel sampling procedure
for GSNs called annealed GSN sampling, similar to tempering methods that
combines fast mixing (obtained thanks to steps at high noise levels) with
accurate samples (obtained thanks to steps at low noise levels).


Identifying and attacking the saddle point problem in high-dimensional
  non-convex optimization

  A central challenge to many fields of science and engineering involves
minimizing non-convex error functions over continuous, high dimensional spaces.
Gradient descent or quasi-Newton methods are almost ubiquitously used to
perform such minimizations, and it is often thought that a main source of
difficulty for these local methods to find the global minimum is the
proliferation of local minima with much higher error than the global minimum.
Here we argue, based on results from statistical physics, random matrix theory,
neural network theory, and empirical evidence, that a deeper and more profound
difficulty originates from the proliferation of saddle points, not local
minima, especially in high dimensional problems of practical interest. Such
saddle points are surrounded by high error plateaus that can dramatically slow
down learning, and give the illusory impression of the existence of a local
minimum. Motivated by these arguments, we propose a new approach to
second-order optimization, the saddle-free Newton method, that can rapidly
escape high dimensional saddle points, unlike gradient descent and quasi-Newton
methods. We apply this algorithm to deep or recurrent neural network training,
and provide numerical evidence for its superior optimization performance.


Exponentially Increasing the Capacity-to-Computation Ratio for
  Conditional Computation in Deep Learning

  Many state-of-the-art results obtained with deep networks are achieved with
the largest models that could be trained, and if more computation power was
available, we might be able to exploit much larger datasets in order to improve
generalization ability. Whereas in learning algorithms such as decision trees
the ratio of capacity (e.g., the number of parameters) to computation is very
favorable (up to exponentially more parameters than computation), the ratio is
essentially 1 for deep neural networks. Conditional computation has been
proposed as a way to increase the capacity of a deep neural network without
increasing the amount of computation required, by activating some parameters
and computation "on-demand", on a per-example basis. In this note, we propose a
novel parametrization of weight matrices in neural networks which has the
potential to increase up to exponentially the ratio of the number of parameters
to computation. The proposed approach is based on turning on some parameters
(weight matrices) when specific bit patterns of hidden unit activations are
obtained. In order to better control for the overfitting that might result, we
propose a parametrization that is tree-structured, where each node of the tree
corresponds to a prefix of a sequence of sign bits, or gating units, associated
with hidden units.


How to Construct Deep Recurrent Neural Networks

  In this paper, we explore different ways to extend a recurrent neural network
(RNN) to a \textit{deep} RNN. We start by arguing that the concept of depth in
an RNN is not as clear as it is in feedforward neural networks. By carefully
analyzing and understanding the architecture of an RNN, however, we find three
points of an RNN which may be made deeper; (1) input-to-hidden function, (2)
hidden-to-hidden transition and (3) hidden-to-output function. Based on this
observation, we propose two novel architectures of a deep RNN which are
orthogonal to an earlier attempt of stacking multiple recurrent layers to build
a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an
alternative interpretation of these deep RNNs using a novel framework based on
neural operators. The proposed deep RNNs are empirically evaluated on the tasks
of polyphonic music prediction and language modeling. The experimental result
supports our claim that the proposed deep RNNs benefit from the depth and
outperform the conventional, shallow RNNs.


Learned-Norm Pooling for Deep Feedforward and Recurrent Neural Networks

  In this paper we propose and investigate a novel nonlinear unit, called $L_p$
unit, for deep neural networks. The proposed $L_p$ unit receives signals from
several projections of a subset of units in the layer below and computes a
normalized $L_p$ norm. We notice two interesting interpretations of the $L_p$
unit. First, the proposed unit can be understood as a generalization of a
number of conventional pooling operators such as average, root-mean-square and
max pooling widely used in, for instance, convolutional neural networks (CNN),
HMAX models and neocognitrons. Furthermore, the $L_p$ unit is, to a certain
degree, similar to the recently proposed maxout unit (Goodfellow et al., 2013)
which achieved the state-of-the-art object recognition results on a number of
benchmark datasets. Secondly, we provide a geometrical interpretation of the
activation function based on which we argue that the $L_p$ unit is more
efficient at representing complex, nonlinear separating boundaries. Each $L_p$
unit defines a superelliptic boundary, with its exact shape defined by the
order $p$. We claim that this makes it possible to model arbitrarily shaped,
curved boundaries more efficiently by combining a few $L_p$ units of different
orders. This insight justifies the need for learning different orders for each
unit in the model. We empirically evaluate the proposed $L_p$ units on a number
of datasets and show that multilayer perceptrons (MLP) consisting of the $L_p$
units achieve the state-of-the-art results on a number of benchmark datasets.
Furthermore, we evaluate the proposed $L_p$ unit on the recently proposed deep
recurrent neural networks (RNN).


End-to-end Continuous Speech Recognition using Attention-based Recurrent
  NN: First Results

  We replace the Hidden Markov Model (HMM) which is traditionally used in in
continuous speech recognition with a bi-directional recurrent neural network
encoder coupled to a recurrent neural network decoder that directly emits a
stream of phonemes. The alignment between the input and output sequences is
established using an attention mechanism: the decoder emits each symbol based
on a context created with a subset of input symbols elected by the attention
mechanism. We report initial results demonstrating that this new approach
achieves phoneme error rates that are comparable to the state-of-the-art
HMM-based decoders, on the TIMIT dataset.


Learning to Understand Phrases by Embedding the Dictionary

  Distributional models that learn rich semantic word representations are a
success story of recent NLP research. However, developing models that learn
useful representations of phrases and sentences has proved far harder. We
propose using the definitions found in everyday dictionaries as a means of
bridging this gap between lexical and phrasal semantics. Neural language
embedding models can be effectively trained to map dictionary definitions
(phrases) to (lexical) representations of the words defined by those
definitions. We present two applications of these architectures: "reverse
dictionaries" that return the name of a concept given a definition or
description and general-knowledge crossword question answerers. On both tasks,
neural language embedding models trained on definitions from a handful of
freely-available lexical resources perform as well or better than existing
commercial systems that rely on significant task-specific engineering. The
results highlight the effectiveness of both neural embedding architectures and
definition-based training for developing models that understand phrases and
sentences.


ReNet: A Recurrent Neural Network Based Alternative to Convolutional
  Networks

  In this paper, we propose a deep neural network architecture for object
recognition based on recurrent neural networks. The proposed network, called
ReNet, replaces the ubiquitous convolution+pooling layer of the deep
convolutional neural network with four recurrent neural networks that sweep
horizontally and vertically in both directions across the image. We evaluate
the proposed ReNet on three widely-used benchmark datasets; MNIST, CIFAR-10 and
SVHN. The result suggests that ReNet is a viable alternative to the deep
convolutional neural network, and that further investigation is needed.


Bounding the Test Log-Likelihood of Generative Models

  Several interesting generative learning algorithms involve a complex
probability distribution over many random variables, involving intractable
normalization constants or latent variable normalization. Some of them may even
not have an analytic expression for the unnormalized probability function and
no tractable approximation. This makes it difficult to estimate the quality of
these models, once they have been trained, or to monitor their quality (e.g.
for early stopping) while training. A previously proposed method is based on
constructing a non-parametric density estimator of the model's probability
function from samples generated by the model. We revisit this idea, propose a
more efficient estimator, and prove that it provides a lower bound on the true
test log-likelihood, and an unbiased estimator as the number of generated
samples goes to infinity, although one that incorporates the effect of poor
mixing. We further propose a biased variant of the estimator that can be used
reliably with a finite number of samples for the purpose of model comparison.


Iterative Neural Autoregressive Distribution Estimator (NADE-k)

  Training of the neural autoregressive density estimator (NADE) can be viewed
as doing one step of probabilistic inference on missing values in data. We
propose a new model that extends this inference scheme to multiple steps,
arguing that it is easier to learn to improve a reconstruction in $k$ steps
rather than to learn to reconstruct in a single inference step. The proposed
model is an unsupervised building block for deep learning that combines the
desirable properties of NADE and multi-predictive training: (1) Its test
likelihood can be computed analytically, (2) it is easy to generate independent
samples from it, and (3) it uses an inference engine that is a superset of
variational inference for Boltzmann machines. The proposed NADE-k is
competitive with the state-of-the-art in density estimation on the two datasets
tested.


Gated Word-Character Recurrent Language Model

  We introduce a recurrent neural network language model (RNN-LM) with long
short-term memory (LSTM) units that utilizes both character-level and
word-level inputs. Our model has a gate that adaptively finds the optimal
mixture of the character-level and word-level inputs. The gate creates the
final vector representation of a word by combining two distinct representations
of the word. The character-level inputs are converted into vector
representations of words using a bidirectional LSTM. The word-level inputs are
projected into another high-dimensional space by a word lookup table. The final
vector representations of words are used in the LSTM language model which
predicts the next word given all the preceding words. Our model with the gating
mechanism effectively utilizes the character-level inputs for rare and
out-of-vocabulary words and outperforms word-level language models on several
English corpora.


Recurrent Neural Networks for Multivariate Time Series with Missing
  Values

  Multivariate time series data in practical applications, such as health care,
geoscience, and biology, are characterized by a variety of missing values. In
time series prediction and other related tasks, it has been noted that missing
values and their missing patterns are often correlated with the target labels,
a.k.a., informative missingness. There is very limited work on exploiting the
missing patterns for effective imputation and improving prediction performance.
In this paper, we develop novel deep learning models, namely GRU-D, as one of
the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a
state-of-the-art recurrent neural network. It takes two representations of
missing patterns, i.e., masking and time interval, and effectively incorporates
them into a deep model architecture so that it not only captures the long-term
temporal dependencies in time series, but also utilizes the missing patterns to
achieve better prediction results. Experiments of time series classification
tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic
datasets demonstrate that our models achieve state-of-the-art performance and
provides useful insights for better understanding and utilization of missing
values in time series analysis.


First Result on Arabic Neural Machine Translation

  Neural machine translation has become a major alternative to widely used
phrase-based statistical machine translation. We notice however that much of
research on neural machine translation has focused on European languages
despite its language agnostic nature. In this paper, we apply neural machine
translation to the task of Arabic translation (Ar<->En) and compare it against
a standard phrase-based translation system. We run extensive comparison using
various configurations in preprocessing Arabic script and show that the
phrase-based and neural translation systems perform comparably to each other
and that proper preprocessing of Arabic script has a similar effect on both of
the systems. We however observe that the neural machine translation
significantly outperform the phrase-based system on an out-of-domain test set,
making it attractive for real-world deployment.


