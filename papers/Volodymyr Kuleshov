Simultaneous diagonalization: the asymmetric, low-rank, and noisy
  settings

  Simultaneous matrix diagonalization is used as a subroutine in many machine
learning problems, including blind source separation and paramater estimation
in latent variable models. Here, we extend algorithms for performing joint
diagonalization to low-rank and asymmetric matrices, and we also provide
extensions to the perturbation analysis of these methods. Our results allow
joint diagonalization to be applied in several new settings.


Estimating Uncertainty Online Against an Adversary

  Assessing uncertainty is an important step towards ensuring the safety and
reliability of machine learning systems. Existing uncertainty estimation
techniques may fail when their modeling assumptions are not met, e.g. when the
data distribution differs from the one seen at training time. Here, we propose
techniques that assess a classification algorithm's uncertainty via calibrated
probabilities (i.e. probabilities that match empirical outcome frequencies in
the long run) and which are guaranteed to be reliable (i.e. accurate and
calibrated) on out-of-distribution input, including input generated by an
adversary. This represents an extension of classical online learning that
handles uncertainty in addition to guaranteeing accuracy under adversarial
assumptions. We establish formal guarantees for our methods, and we validate
them on two real-world problems: question answering and medical diagnosis from
genomic data.


Audio Super Resolution using Neural Networks

  We introduce a new audio processing technique that increases the sampling
rate of signals such as speech or music using deep convolutional neural
networks. Our model is trained on pairs of low and high-quality audio examples;
at test-time, it predicts missing samples within a low-resolution signal in an
interpolation process similar to image super-resolution. Our method is simple
and does not involve specialized audio processing techniques; in our
experiments, it outperforms baselines on standard speech and music benchmarks
at upscaling ratios of 2x, 4x, and 6x. The method has practical applications in
telephony, compression, and text-to-speech generation; it demonstrates the
effectiveness of feed-forward convolutional architectures on an audio
generation task.


Neural Variational Inference and Learning in Undirected Graphical Models

  Many problems in machine learning are naturally expressed in the language of
undirected graphical models. Here, we propose black-box learning and inference
algorithms for undirected models that optimize a variational approximation to
the log-likelihood of the model. Central to our approach is an upper bound on
the log-partition function parametrized by a function q that we express as a
flexible neural network. Our bound makes it possible to track the partition
function during learning, to speed-up sampling, and to train a broad class of
hybrid directed/undirected models via a unified variational inference
framework. We empirically demonstrate the effectiveness of our method on
several popular generative modeling datasets.


Accurate Uncertainties for Deep Learning Using Calibrated Regression

  Methods for reasoning under uncertainty are a key building block of accurate
and reliable machine learning systems. Bayesian methods provide a general
framework to quantify uncertainty. However, because of model misspecification
and the use of approximate inference, Bayesian uncertainty estimates are often
inaccurate -- for example, a 90% credible interval may not contain the true
outcome 90% of the time. Here, we propose a simple procedure for calibrating
any regression algorithm; when applied to Bayesian and probabilistic models, it
is guaranteed to produce calibrated uncertainty estimates given enough data.
Our procedure is inspired by Platt scaling and extends previous work on
classification. We evaluate this approach on Bayesian linear regression,
feedforward, and recurrent neural networks, and find that it consistently
outputs well-calibrated credible intervals while improving performance on time
series forecasting and model-based reinforcement learning tasks.


Algorithms for multi-armed bandit problems

  Although many algorithms for the multi-armed bandit problem are
well-understood theoretically, empirical confirmation of their effectiveness is
generally scarce. This paper presents a thorough empirical study of the most
popular multi-armed bandit algorithms. Three important observations can be made
from our results. Firstly, simple heuristics such as epsilon-greedy and
Boltzmann exploration outperform theoretically sound algorithms on most
settings by a significant margin. Secondly, the performance of most algorithms
varies dramatically with the parameters of the bandit problem. Our study
identifies for each algorithm the settings where it performs well, and the
settings where it performs poorly. Thirdly, the algorithms' performance
relative each to other is affected only by the number of bandit arms and the
variance of the rewards. This finding may guide the design of subsequent
empirical evaluations. In the second part of the paper, we turn our attention
to an important area of application of bandit algorithms: clinical trials.
Although the design of clinical trials has been one of the principal practical
problems motivating research on multi-armed bandits, bandit algorithms have
never been evaluated as potential treatment allocation strategies. Using data
from a real study, we simulate the outcome that a 2001-2002 clinical trial
would have had if bandit algorithms had been used to allocate patients to
treatments. We find that an adaptive trial would have successfully treated at
least 50% more patients, while significantly reducing the number of adverse
effects and increasing patient retention. At the end of the trial, the best
treatment could have still been identified with a high level of statistical
confidence. Our findings demonstrate that bandit algorithms are attractive
alternatives to current adaptive treatment allocation strategies.


Tensor Factorization via Matrix Factorization

  Tensor factorization arises in many machine learning applications, such
knowledge base modeling and parameter estimation in latent variable models.
However, numerical methods for tensor factorization have not reached the level
of maturity of matrix factorization methods. In this paper, we propose a new
method for CP tensor factorization that uses random projections to reduce the
problem to simultaneous matrix diagonalization. Our method is conceptually
simple and also applies to non-orthogonal and asymmetric tensors of arbitrary
order. We prove that a small number random projections essentially preserves
the spectral information in the tensor, allowing us to remove the dependence on
the eigengap that plagued earlier tensor-to-matrix reductions. Experimentally,
our method outperforms existing tensor factorization methods on both simulated
data and two real datasets.


Adversarial Constraint Learning for Structured Prediction

  Constraint-based learning reduces the burden of collecting labels by having
users specify general properties of structured outputs, such as constraints
imposed by physical laws. We propose a novel framework for simultaneously
learning these constraints and using them for supervision, bypassing the
difficulty of using domain expertise to manually specify constraints. Learning
requires a black-box simulator of structured outputs, which generates valid
labels, but need not model their corresponding inputs or the input-label
relationship. At training time, we constrain the model to produce outputs that
cannot be distinguished from simulated labels by adversarial training.
Providing our framework with a small number of labeled inputs gives rise to a
new semi-supervised structured prediction model; we evaluate this model on
multiple tasks --- tracking, pose estimation and time series prediction --- and
find that it achieves high accuracy with only a small number of labeled inputs.
In some cases, no labels are required at all.


