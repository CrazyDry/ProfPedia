On the Universality of Online Mirror Descent

  We show that for a general class of convex online learning problems, MirrorDescent can always achieve a (nearly) optimal regret guarantee.

Optimistic Rates for Learning with a Smooth Loss

  We establish an excess risk bound of O(H R_n^2 + R_n \sqrt{H L*}) forempirical risk minimization with an H-smooth loss function and a hypothesisclass with Rademacher complexity R_n, where L* is the best risk achievable bythe hypothesis class. For typical hypothesis classes where R_n = \sqrt{R/n},this translates to a learning rate of O(RH/n) in the separable (L*=0) case andO(RH/n + \sqrt{L^* RH/n}) more generally. We also provide similar guaranteesfor online and stochastic convex optimization with a smooth non-negativeobjective.

Better Mini-Batch Algorithms via Accelerated Gradient Methods

  Mini-batch algorithms have been proposed as a way to speed-up stochasticconvex optimization problems. We study how such algorithms can be improvedusing accelerated gradient methods. We provide a novel analysis, which showshow standard gradient methods may sometimes be insufficient to obtain asignificant speed-up and propose a novel accelerated gradient algorithm, whichdeals with this deficiency, enjoys a uniformly superior guarantee and workswell in practice.

Minimizing The Misclassification Error Rate Using a Surrogate Convex  Loss

  We carefully study how well minimizing convex surrogate loss functions,corresponds to minimizing the misclassification error rate for the problem ofbinary classification with linear predictors. In particular, we show thatamongst all convex surrogate losses, the hinge loss gives essentially the bestpossible bound, of all convex loss functions, for the misclassification errorrate of the resulting linear predictor in terms of the best possible marginerror rate. We also provide lower bounds for specific convex surrogates thatshow how different commonly used losses qualitatively differ from each other.

Learning From An Optimization Viewpoint

  In this dissertation we study statistical and online learning problems froman optimization viewpoint.The dissertation is divided into two parts :  I. We first consider the question of learnability for statistical learningproblems in the general learning setting. The question of learnability is wellstudied and fully characterized for binary classification and for real valuedsupervised learning problems using the theory of uniform convergence. Howeverwe show that for the general learning setting uniform convergence theory failsto characterize learnability. To fill this void we use stability of learningalgorithms to fully characterize statistical learnability in the generalsetting. Next we consider the problem of online learning. Unlike thestatistical learning framework there is a dearth of generic tools that can beused to establish learnability and rates for online learning problems ingeneral. We provide online analogs to classical tools from statistical learningtheory like Rademacher complexity, covering numbers, etc. We further use thesetools to fully characterize learnability for online supervised learningproblems.  II. In the second part, for general classes of convex learning problems, weprovide appropriate mirror descent (MD) updates for online and statisticallearning of these problems. Further, we show that the the MD is near optimalfor online convex learning and for most cases, is also near optimal forstatistical convex learning. We next consider the problem of convexoptimization and show that oracle complexity can be lower bounded by the socalled fat-shattering dimension of the associated linear class. Thus weestablish a strong connection between offline convex optimization problems andstatistical learning problems. We also show that for a large class of highdimensional optimization problems, MD is in fact near optimal even for convexoptimization.

Online Learning: Beyond Regret

  We study online learnability of a wide class of problems, extending theresults of (Rakhlin, Sridharan, Tewari, 2010) to general notions of performancemeasure well beyond external regret. Our framework simultaneously captures suchwell-known notions as internal and general Phi-regret, learning withnon-additive global cost functions, Blackwell's approachability, calibration offorecasters, adaptive regret, and more. We show that learnability in all thesesituations is due to control of the same three quantities: a martingaleconvergence term, a term describing the ability to perform well if future isknown, and a generalization of sequential Rademacher complexity, studied in(Rakhlin, Sridharan, Tewari, 2010). Since we directly study complexity of theproblem instead of focusing on efficient algorithms, we are able to improve andextend many known results which have been previously derived via an algorithmicconstruction.

Online Nonparametric Regression

  We establish optimal rates for online regression for arbitrary classes ofregression functions in terms of the sequential entropy introduced in (Rakhlin,Sridharan, Tewari, 2010). The optimal rates are shown to exhibit a phasetransition analogous to the i.i.d./statistical learning case, studied in(Rakhlin, Sridharan, Tsybakov 2013). In the frequently encountered situationwhen sequential entropy and i.i.d. empirical entropy match, our results pointto the interesting phenomenon that the rates for statistical learning withsquared loss and online nonparametric regression are the same.  In addition to a non-algorithmic study of minimax regret, we exhibit ageneric forecaster that enjoys the established optimal rates. We also provide arecipe for designing online regression algorithms that can be computationallyefficient. We illustrate the techniques by deriving existing and newforecasters for the case of finite experts and for online linear regression.

Learning Exponential Families in High-Dimensions: Strong Convexity and  Sparsity

  The versatility of exponential families, along with their attendant convexityproperties, make them a popular and effective statistical model. A centralissue is learning these models in high-dimensions, such as when there is somesparsity pattern of the optimal parameter. This work characterizes a certainstrong convexity property of general exponential families, which allow theirgeneralization ability to be quantified. In particular, we show how thisproperty can be used to analyze generic exponential families under L_1regularization.

Online Learning via Sequential Complexities

  We consider the problem of sequential prediction and provide tools to studythe minimax value of the associated game. Classical statistical learning theoryprovides several useful complexity measures to study learning with i.i.d. data.Our proposed sequential complexities can be seen as extensions of thesemeasures to the sequential setting. The developed theory is shown to yieldprecise learning guarantees for the problem of sequential prediction. Inparticular, we show necessary and sufficient conditions for online learnabilityin the setting of supervised learning. Several examples show the utility of ourframework: we can establish learnability without having to exhibit an explicitonline learning algorithm.

Competing With Strategies

  We study the problem of online learning with a notion of regret defined withrespect to a set of strategies. We develop tools for analyzing the minimaxrates and for deriving regret-minimization algorithms in this scenario. Whilethe standard methods for minimizing the usual notion of regret fail, throughour analysis we demonstrate existence of regret-minimization methods thatcompete with such sets of strategies as: autoregressive algorithms, strategiesbased on statistical models, regularized least squares, and follow theregularized leader strategies. In several cases we also derive efficientlearning algorithms.

Hypothesis Set Stability and Generalization

  We present an extensive study of generalization for data-dependent hypothesissets. We give a general learning guarantee for data-dependent hypothesis setsbased on a notion of transductive Rademacher complexity. Our main results aretwo generalization bounds for data-dependent hypothesis sets expressed in termsof a notion of hypothesis set stability and a notion of Rademacher complexityfor data-dependent hypothesis sets that we introduce. These bounds admit asspecial cases both standard Rademacher complexity bounds andalgorithm-dependent uniform stability bounds. We also illustrate the use ofthese learning bounds in the analysis of several scenarios.

Sequential Probability Assignment with Binary Alphabets and Large  Classes of Experts

  We analyze the problem of sequential probability assignment for binaryoutcomes with side information and logarithmic loss, where regret---or,redundancy---is measured with respect to a (possibly infinite) class ofexperts. We provide upper and lower bounds for minimax regret in terms ofsequential complexities of the class. These complexities were recently shown togive matching (up to logarithmic factors) upper and lower bounds for sequentialprediction with general convex Lipschitz loss functions (Rakhlin and Sridharan,2015). To deal with unbounded gradients of the logarithmic loss, we present anew analysis that employs a sequential chaining technique with a Bernstein-typebound. The introduced complexities are intrinsic to the problem of sequentialprobability assignment, as illustrated by our lower bound.  We also consider an example of a large class of experts parametrized byvectors in a high-dimensional Euclidean ball (or a Hilbert ball). The typicaldiscretization approach fails, while our techniques give a non-trivial bound.For this problem we also present an algorithm based on regularization with aself-concordant barrier. This algorithm is of an independent interest, as itrequires a bound on the function values rather than gradients.

Learning Kernel-Based Halfspaces with the Zero-One Loss

  We describe and analyze a new algorithm for agnostically learningkernel-based halfspaces with respect to the \emph{zero-one} loss function.Unlike most previous formulations which rely on surrogate convex loss functions(e.g. hinge-loss in SVM and log-loss in logistic regression), we provide finitetime/sample guarantees with respect to the more natural zero-one loss function.The proposed algorithm can learn kernel-based halfspaces in worst-case time$\poly(\exp(L\log(L/\epsilon)))$, for $\emph{any}$ distribution, where $L$ is aLipschitz constant (which can be thought of as the reciprocal of the margin),and the learned classifier is worse than the optimal halfspace by at most$\epsilon$. We also prove a hardness result, showing that under a certaincryptographic assumption, no algorithm can learn kernel-based halfspaces intime polynomial in $L$.

Relax and Localize: From Value to Algorithms

  We show a principled way of deriving online learning algorithms from aminimax analysis. Various upper bounds on the minimax value, previously thoughtto be non-constructive, are shown to yield algorithms. This allows us toseamlessly recover known methods and to derive new ones. Our framework alsocaptures such "unorthodox" methods as Follow the Perturbed Leader and the R^2forecaster. We emphasize that understanding the inherent complexity of thelearning problem leads to the development of algorithms.  We define local sequential Rademacher complexities and associated algorithmsthat allow us to obtain faster rates in online learning, similarly tostatistical learning theory. Based on these localized complexities we build ageneral adaptive method that can take advantage of the suboptimality of theobserved sequence.  We present a number of new algorithms, including a family of randomizedmethods that use the idea of a "random playout". Several new versions of theFollow-the-Perturbed-Leader algorithms are presented, as well as methods basedon the Littlestone's dimension, efficient methods for matrix completion withtrace norm, and algorithms for the problems of transductive learning andprediction with static experts.

Online Learning with Predictable Sequences

  We present methods for online linear optimization that take advantage ofbenign (as opposed to worst-case) sequences. Specifically if the sequenceencountered by the learner is described well by a known "predictable process",the algorithms presented enjoy tighter bounds as compared to the typical worstcase bounds. Additionally, the methods achieve the usual worst-case regretbounds if the sequence is not benign. Our approach can be seen as a way ofadding prior knowledge about the sequence within the paradigm of onlinelearning. The setting is shown to encompass partial and side information.Variance and path-length bounds can be seen as particular examples of onlinelearning with simple predictable sequences.  We further extend our methods and results to include competing with a set ofpossible predictable processes (models), that is "learning" the predictableprocess itself concurrently with using it to obtain better regret guarantees.We show that such model selection is possible under various assumptions on theavailable feedback. Our results suggest a promising direction of furtherresearch with potential applications to stock market and time seriesprediction.

Optimization, Learning, and Games with Predictable Sequences

  We provide several applications of Optimistic Mirror Descent, an onlinelearning algorithm based on the idea of predictable sequences. First, werecover the Mirror Prox algorithm for offline optimization, prove an extensionto Holder-smooth functions, and apply the results to saddle-point typeproblems. Next, we prove that a version of Optimistic Mirror Descent (which hasa close relation to the Exponential Weights algorithm) can be used by twostrongly-uncoupled players in a finite zero-sum matrix game to converge to theminimax equilibrium at the rate of O((log T)/T). This addresses a question ofDaskalakis et al 2011. Further, we consider a partial information version ofthe problem. We then apply the results to convex programming and exhibit asimple algorithm for the approximate Max Flow problem.

Online Optimization : Competing with Dynamic Comparators

  Recent literature on online learning has focused on developing adaptivealgorithms that take advantage of a regularity of the sequence of observations,yet retain worst-case performance guarantees. A complementary direction is todevelop prediction methods that perform well against complex benchmarks. Inthis paper, we address these two directions together. We present a fullyadaptive method that competes with dynamic benchmarks in which regret guaranteescales with regularity of the sequence of cost functions and comparators.Notably, the regret bound adapts to the smaller complexity measure in theproblem environment. Finally, we apply our results to drifting zero-sum,two-player games where both players achieve no regret guarantees against bestsequences of actions in hindsight.

Online Nonparametric Regression with General Loss Functions

  This paper establishes minimax rates for online regression with arbitraryclasses of functions and general losses. We show that below a certain thresholdfor the complexity of the function class, the minimax rates depend on both thecurvature of the loss function and the sequential complexities of the class.Above this threshold, the curvature of the loss does not affect the rates.Furthermore, for the case of square loss, our results point to the interestingphenomenon: whenever sequential and i.i.d. empirical entropies match, the ratesfor statistical and online learning are the same.  In addition to the study of minimax regret, we derive a generic forecasterthat enjoys the established optimal rates. We also provide a recipe fordesigning online prediction algorithms that can be computationally efficientfor certain problems. We illustrate the techniques by deriving existing and newforecasters for the case of finite experts and for online linear regression.

Learning with Square Loss: Localization through Offset Rademacher  Complexity

  We consider regression with square loss and general classes of functionswithout the boundedness assumption. We introduce a notion of offset Rademachercomplexity that provides a transparent way to study localization both inexpectation and in high probability. For any (possibly non-convex) class, theexcess loss of a two-step estimator is shown to be upper bounded by this offsetcomplexity through a novel geometric inequality. In the convex case, theestimator reduces to an empirical risk minimizer. The method recovers theresults of \citep{RakSriTsy15} for the bounded case while also providingguarantees without the boundedness assumption.

Hierarchies of Relaxations for Online Prediction Problems with Evolving  Constraints

  We study online prediction where regret of the algorithm is measured againsta benchmark defined via evolving constraints. This framework captures onlineprediction on graphs, as well as other prediction problems with combinatorialstructure. A key aspect here is that finding the optimal benchmark predictor(even in hindsight, given all the data) might be computationally hard due tothe combinatorial nature of the constraints. Despite this, we providepolynomial-time \emph{prediction} algorithms that achieve low regret againstcombinatorial benchmark sets. We do so by building improper learning algorithmsbased on two ideas that work together. The first is to alleviate part of thecomputational burden through random playout, and the second is to employLasserre semidefinite hierarchies to approximate the resulting integer program.Interestingly, for our prediction algorithms, we only need to compute thevalues of the semidefinite programs and not the rounded solutions. However, theintegrality gap for Lasserre hierarchy \emph{does} enter the generic regretbound in terms of Rademacher complexity of the benchmark set. This establishesa trade-off between the computation time and the regret bound of the algorithm.

Adaptive Online Learning

  We propose a general framework for studying adaptive regret bounds in theonline learning framework, including model selection bounds and data-dependentbounds. Given a data- or model-dependent bound we ask, "Does there exist somealgorithm achieving this bound?" We show that modifications to recentlyintroduced sequential complexity measures can be used to answer this questionby providing sufficient conditions under which adaptive rates can be achieved.In particular each adaptive rate induces a set of so-called offset complexitymeasures, and obtaining small upper bounds on these quantities is sufficient todemonstrate achievability. A cornerstone of our analysis technique is the useof one-sided tail inequalities to bound suprema of offset random processes.  Our framework recovers and improves a wide variety of adaptive boundsincluding quantile bounds, second-order data-dependent bounds, and small lossbounds. In addition we derive a new type of adaptive bound for online linearoptimization based on the spectral norm, as well as a new online PAC-Bayestheorem that holds for countably infinite sets.

On Equivalence of Martingale Tail Bounds and Deterministic Regret  Inequalities

  We study an equivalence of (i) deterministic pathwise statements appearing inthe online learning literature (termed \emph{regret bounds}), (ii)high-probability tail bounds for the supremum of a collection of martingales(of a specific form arising from uniform laws of large numbers formartingales), and (iii) in-expectation bounds for the supremum. By virtue ofthe equivalence, we prove exponential tail bounds for norms of Banach spacevalued martingales via deterministic regret bounds for the online mirrordescent algorithm with an adaptive step size. We extend these results beyondthe linear structure of the Banach space: we define a notion of\emph{martingale type} for general classes of real-valued functions and showits equivalence (up to a logarithmic factor) to various sequential complexitiesof the class (in particular, the sequential Rademacher complexity and itsoffset version). For classes with the general martingale type 2, we exhibit afiner notion of variation that allows partial adaptation to the functionindexing the martingale. Our proof technique rests on sequential symmetrizationand on certifying the \emph{existence} of regret minimization strategies forcertain online prediction problems.

Private Causal Inference

  Causal inference deals with identifying which random variables "cause" orcontrol other random variables. Recent advances on the topic of causalinference based on tools from statistical estimation and machine learning haveresulted in practical algorithms for causal inference. Causal inference has thepotential to have significant impact on medical research, prevention andcontrol of diseases, and identifying factors that impact economic changes toname just a few. However, these promising applications for causal inference areoften ones that involve sensitive or personal data of users that need to bekept private (e.g., medical records, personal finances, etc). Therefore, thereis a need for the development of causal inference methods that preserve dataprivacy. We study the problem of inferring causality using the current, popularcausal inference framework, the additive noise model (ANM) while simultaneouslyensuring privacy of the users. Our framework provides differential privacyguarantees for a variety of ANM variants. We run extensive experiments, anddemonstrate that our techniques are practical and easy to implement.

Exploiting the Structure: Stochastic Gradient Methods Using Raw Clusters

  The amount of data available in the world is growing faster than our abilityto deal with it. However, if we take advantage of the internal\emph{structure}, data may become much smaller for machine learning purposes.In this paper we focus on one of the fundamental machine learning tasks,empirical risk minimization (ERM), and provide faster algorithms with the helpfrom the clustering structure of the data.  We introduce a simple notion of raw clustering that can be efficientlycomputed from the data, and propose two algorithms based on clusteringinformation. Our accelerated algorithm ClusterACDM is built on a novel Haartransformation applied to the dual space of the ERM problem, and ourvariance-reduction based algorithm ClusterSVRG introduces a new gradientestimator using clustering. Our algorithms outperform their classicalcounterparts ACDM and SVRG respectively.

BISTRO: An Efficient Relaxation-Based Method for Contextual Bandits

  We present efficient algorithms for the problem of contextual bandits withi.i.d. covariates, an arbitrary sequence of rewards, and an arbitrary class ofpolicies. Our algorithm BISTRO requires d calls to the empirical riskminimization (ERM) oracle per round, where d is the number of actions. Themethod uses unlabeled data to make the problem computationally simple. When theERM problem itself is computationally hard, we extend the approach by employingmultiplicative approximation algorithms for the ERM. The integrality gap of therelaxation only enters in the regret bound rather than the benchmark. Finally,we show that the adversarial version of the contextual bandit problem islearnable (and efficient) whenever the full-information supervised onlinelearning problem has a non-trivial regret guarantee (and efficient).

A Tutorial on Online Supervised Learning with Applications to Node  Classification in Social Networks

  We revisit the elegant observation of T. Cover '65 which, perhaps, is not aswell-known to the broader community as it should be. The first goal of thetutorial is to explain---through the prism of this elementary result---how tosolve certain sequence prediction problems by modeling sets of solutions ratherthan the unknown data-generating mechanism. We extend Cover's observation inseveral directions and focus on computational aspects of the proposedalgorithms. The applicability of the methods is illustrated on severalexamples, including node classification in a network.  The second aim of this tutorial is to demonstrate the following phenomenon:it is possible to predict as well as a combinatorial "benchmark" for which wehave a certain multiplicative approximation algorithm, even if the exactcomputation of the benchmark given all the data is NP-hard. The proposedprediction methods, therefore, circumvent some of the computationaldifficulties associated with finding the best model given the data. Thesedifficulties arise rather quickly when one attempts to develop a probabilisticmodel for graph-based or other problems with a combinatorial structure.

Parameter-free online learning via model selection

  We introduce an efficient algorithmic framework for model selection in onlinelearning, also known as parameter-free online learning. Departing from previouswork, which has focused on highly structured function classes such as nestedballs in Hilbert space, we propose a generic meta-algorithm framework thatachieves online model selection oracle inequalities under minimal structuralassumptions. We give the first computationally efficient parameter-freealgorithms that work in arbitrary Banach spaces under mild smoothnessassumptions; previous results applied only to Hilbert spaces. We further derivenew oracle inequalities for matrix classes, non-nested convex sets, and$\mathbb{R}^{d}$ with generic regularizers. Finally, we generalize theseresults by providing oracle inequalities for arbitrary non-linear classes inthe online supervised learning model. These results are all derived through aunified meta-algorithm scheme using a novel "multi-scale" algorithm forprediction with expert advice based on random playout, which may be ofindependent interest.

Online Learning: Sufficient Statistics and the Burkholder Method

  We uncover a fairly general principle in online learning: If regret can be(approximately) expressed as a function of certain "sufficient statistics" forthe data sequence, then there exists a special Burkholder function that 1) canbe used algorithmically to achieve the regret bound and 2) only depends onthese sufficient statistics, not the entire data sequence, so that the onlinestrategy is only required to keep the sufficient statistics in memory. Thischaracterization is achieved by bringing the full power of the BurkholderMethod --- originally developed for certifying probabilistic martingaleinequalities --- to bear on the online learning setting.  To demonstrate the scope and effectiveness of the Burkholder method, wedevelop a novel online strategy for matrix prediction that attains a regretbound corresponding to the variance term in matrix concentration inequalities.We also present a linear-time/space prediction strategy for parameter freesupervised learning with linear classes and general smooth norms.

Training Well-Generalizing Classifiers for Fairness Metrics and Other  Data-Dependent Constraints

  Classifiers can be trained with data-dependent constraints to satisfyfairness goals, reduce churn, achieve a targeted false positive rate, or otherpolicy goals. We study the generalization performance for such constrainedoptimization problems, in terms of how well the constraints are satisfied atevaluation time, given that they are satisfied at training time. To improvegeneralization performance, we frame the problem as a two-player game where oneplayer optimizes the model parameters on a training dataset, and the otherplayer enforces the constraints on an independent validation dataset. We buildon recent work in two-player constrained optimization to show that if one usesthis two-dataset approach, then constraint generalization can be significantlyimproved. As we illustrate experimentally, this approach works not only intheory, but also in practice.

Online Learning: Stochastic and Constrained Adversaries

  Learning theory has largely focused on two main learning scenarios. The firstis the classical statistical setting where instances are drawn i.i.d. from afixed distribution and the second scenario is the online learning, completelyadversarial scenario where adversary at every time step picks the worstinstance to provide the learner with. It can be argued that in the real worldneither of these assumptions are reasonable. It is therefore important to studyproblems with a range of assumptions on data. Unfortunately, theoreticalresults in this area are scarce, possibly due to absence of general tools foranalysis. Focusing on the regret formulation, we define the minimax value of agame where the adversary is restricted in his moves. The framework capturesstochastic and non-stochastic assumptions on data. Building on the sequentialsymmetrization approach, we define a notion of distribution-dependentRademacher complexity for the spectrum of problems ranging from i.i.d. toworst-case. The bounds let us immediately deduce variation-type bounds. We thenconsider the i.i.d. adversary and show equivalence of online and batchlearnability. In the supervised setting, we consider various hybrid assumptionson the way that x and y variables are chosen. Finally, we consider smoothedlearning problems and show that half-spaces are online learnable in thesmoothed model. In fact, exponentially small noise added to adversary'sdecisions turns this problem with infinite Littlestone's dimension into alearnable problem.

Making Gradient Descent Optimal for Strongly Convex Stochastic  Optimization

  Stochastic gradient descent (SGD) is a simple and popular method to solvestochastic optimization problems which arise in machine learning. For stronglyconvex problems, its convergence rate was known to be O(\log(T)/T), by runningSGD for T iterations and returning the average point. However, recent resultsshowed that using a different algorithm, one can get an optimal O(1/T) rate.This might lead one to believe that standard SGD is suboptimal, and maybeshould even be replaced as a method of choice. In this paper, we investigatethe optimality of SGD in a stochastic setting. We show that for smoothproblems, the algorithm attains the optimal O(1/T) rate. However, fornon-smooth problems, the convergence rate with averaging might really be\Omega(\log(T)/T), and this is not just an artifact of the analysis. On theflip side, we show that a simple modification of the averaging step suffices torecover the O(1/T) rate, and no other change of the algorithm is necessary. Wealso present experimental results which support our findings, and point outopen problems.

Inference in Sparse Graphs with Pairwise Measurements and Side  Information

  We consider the statistical problem of recovering a hidden "ground truth"binary labeling for the vertices of a graph up to low Hamming error from noisyedge and vertex measurements. We present new algorithms and a sharpfinite-sample analysis for this problem on trees and sparse graphs with poorexpansion properties such as hypergrids and ring lattices. Our methodgeneralizes and improves over that of Globerson et al. (2015), who introducedthe problem for two-dimensional grid lattices.  For trees we provide a simple, efficient, algorithm that infers the groundtruth with optimal Hamming error has optimal sample complexity and impliesrecovery results for all connected graphs. Here, the presence of sideinformation is critical to obtain a non-trivial recovery rate. We then show howto adapt this algorithm to tree decompositions of edge-subgraphs of certaingraph families such as lattices, resulting in optimal recovery error rates thatcan be obtained efficiently  The thrust of our analysis is to 1) use the tree decomposition along withedge measurements to produce a small class of viable vertex labelings and 2)apply an analysis influenced by statistical learning theory to show that we caninfer the ground truth from this class using vertex measurements. We show thepower of our method in several examples including hypergrids, ring lattices,and the Newman-Watts model for small world graphs. For two-dimensional grids,our results improve over Globerson et al. (2015) by obtaining optimal recoveryin the constant-height regime.

ZigZag: A new approach to adaptive online learning

  We develop a novel family of algorithms for the online learning setting withregret against any data sequence bounded by the empirical Rademacher complexityof that sequence. To develop a general theory of when this type of adaptiveregret bound is achievable we establish a connection to the theory ofdecoupling inequalities for martingales in Banach spaces. When the hypothesisclass is a set of linear functions bounded in some norm, such a regret bound isachievable if and only if the norm satisfies certain decoupling inequalitiesfor martingales. Donald Burkholder's celebrated geometric characterization ofdecoupling inequalities (1984) states that such an inequality holds if and onlyif there exists a special function called a Burkholder function satisfyingcertain restricted concavity properties. Our online learning algorithms areefficient in terms of queries to this function.  We realize our general theory by giving novel efficient algorithms forclasses including lp norms, Schatten p-norms, group norms, and reproducingkernel Hilbert spaces. The empirical Rademacher complexity regret bound implies--- when used in the i.i.d. setting --- a data-dependent complexity bound forexcess risk after online-to-batch conversion. To showcase the power of theempirical Rademacher complexity regret bound, we derive improved rates for asupervised learning generalization of the online learning with low rank expertstask and for the online matrix prediction task.  In addition to obtaining tight data-dependent regret bounds, our algorithmsenjoy improved efficiency over previous techniques based on Rademachercomplexity, automatically work in the infinite horizon setting, and arescale-free. To obtain such adaptive methods, we introduce novel machinery, andthe resulting algorithms are not based on the standard tools of online convexoptimization.

Small-loss bounds for online learning with partial information

  We consider the problem of adversarial (non-stochastic) online learning withpartial information feedback, where at each round, a decision maker selects anaction from a finite set of alternatives. We develop a black-box approach forsuch problems where the learner observes as feedback only losses of a subset ofthe actions that includes the selected action. When losses of actions arenon-negative, under the graph-based feedback model introduced by Mannor andShamir, we offer algorithms that attain the so called "small-loss" $o(\alphaL^{\star})$ regret bounds with high probability, where $\alpha$ is theindependence number of the graph, and $L^{\star}$ is the loss of the bestaction. Prior to our work, there was no data-dependent guarantee for generalfeedback graphs even for pseudo-regret (without dependence on the number ofactions, i.e. utilizing the increased information feedback). Taking advantageof the black-box nature of our technique, we extend our results to many otherapplications such as semi-bandits (including routing in networks), contextualbandits (even with an infinite comparator class), as well as learning withslowly changing (shifting) comparators.  In the special case of classical bandit and semi-bandit problems, we provideoptimal small-loss, high-probability guarantees of$\tilde{O}(\sqrt{dL^{\star}})$ for actual regret, where $d$ is the number ofactions, answering open questions of Neu. Previous bounds for bandits andsemi-bandits were known only for pseudo-regret and only in expectation. We alsooffer an optimal $\tilde{O}(\sqrt{\kappa L^{\star}})$ regret guarantee forfixed feedback graphs with clique-partition number at most $\kappa$.

Two-Player Games for Efficient Non-Convex Constrained Optimization

  In recent years, constrained optimization has become increasingly relevant tothe machine learning community, with applications including Neyman-Pearsonclassification, robust optimization, and fair machine learning. A naturalapproach to constrained optimization is to optimize the Lagrangian, but this isnot guaranteed to work in the non-convex setting, and, if using a first-ordermethod, cannot cope with non-differentiable constraints (e.g. constraints onrates or proportions).  The Lagrangian can be interpreted as a two-player game played between aplayer who seeks to optimize over the model parameters, and a player who wishesto maximize over the Lagrange multipliers. We propose a non-zero-sum variant ofthe Lagrangian formulation that can cope with non-differentiable--evendiscontinuous--constraints, which we call the "proxy-Lagrangian". The firstplayer minimizes external regret in terms of easy-to-optimize "proxyconstraints", while the second player enforces the original constraints byminimizing swap regret.  For this new formulation, as for the Lagrangian in the non-convex setting,the result is a stochastic classifier. For both the proxy-Lagrangian andLagrangian formulations, however, we prove that this classifier, instead ofhaving unbounded size, can be taken to be a distribution over no more than m+1models (where m is the number of constraints). This is a significantimprovement in practical terms.

Optimization with Non-Differentiable Constraints with Applications to  Fairness, Recall, Churn, and Other Goals

  We show that many machine learning goals, such as improved fairness metrics,can be expressed as constraints on the model's predictions, which we call rateconstraints. We study the problem of training non-convex models subject tothese rate constraints (or any non-convex and non-differentiable constraints).In the non-convex setting, the standard approach of Lagrange multipliers mayfail. Furthermore, if the constraints are non-differentiable, then one cannotoptimize the Lagrangian with gradient-based methods. To solve these issues, weintroduce the proxy-Lagrangian formulation. This new formulation leads to analgorithm that produces a stochastic classifier by playing a two-playernon-zero-sum game solving for what we call a semi-coarse correlatedequilibrium, which in turn corresponds to an approximately optimal and feasiblesolution to the constrained optimization problem. We then give a procedurewhich shrinks the randomized solution down to one that is a mixture of at most$m+1$ deterministic solutions, given $m$ constraints. This culminates inalgorithms that can solve non-convex constrained optimization problems withpossibly non-differentiable and non-convex constraints with theoreticalguarantees. We provide extensive experimental results enforcing a wide range ofpolicy goals including different fairness metrics, and other goals on accuracy,coverage, recall, and churn.

Uniform Convergence of Gradients for Non-Convex Learning and  Optimization

  We investigate 1) the rate at which refined properties of the empiricalrisk---in particular, gradients---converge to their population counterparts instandard non-convex learning tasks, and 2) the consequences of this convergencefor optimization. Our analysis follows the tradition of norm-based capacitycontrol. We propose vector-valued Rademacher complexities as a simple,composable, and user-friendly tool to derive dimension-free uniform convergencebounds for gradients in non-convex learning problems. As an application of ourtechniques, we give a new analysis of batch gradient descent methods fornon-convex generalized linear models and non-convex robust regression, showinghow to use any algorithm that finds approximate stationary points to obtainoptimal sample complexity, even when dimension is high or possibly infinite andmultiple passes over the dataset are allowed.  Moving to non-smooth models we show----in contrast to the smooth case---thateven for a single ReLU it is not possible to obtain dimension-independentconvergence rates for gradients in the worst case. On the positive side, it isstill possible to obtain dimension-independent rates under a new type ofdistributional assumption.

The Complexity of Making the Gradient Small in Stochastic Convex  Optimization

  We give nearly matching upper and lower bounds on the oracle complexity offinding $\epsilon$-stationary points ($\| \nabla F(x) \| \leq\epsilon$) instochastic convex optimization. We jointly analyze the oracle complexity inboth the local stochastic oracle model and the global oracle (or, statisticallearning) model. This allows us to decompose the complexity of findingnear-stationary points into optimization complexity and sample complexity, andreveals some surprising differences between the complexity of stochasticoptimization versus learning. Notably, we show that in the globaloracle/statistical learning model, only logarithmic dependence on smoothness isrequired to find a near-stationary point, whereas polynomial dependence onsmoothness is necessary in the local stochastic oracle model. In other words,the separation in complexity between the two models can be exponential, andthat the folklore understanding that smoothness is required to find stationarypoints is only weakly true for statistical learning.  Our upper bounds are based on extensions of a recent "recursiveregularization" technique proposed by Allen-Zhu (2018). We show how to extendthe technique to achieve near-optimal rates, and in particular show how toleverage the extra information available in the global oracle model. Ouralgorithm for the global model can be implemented efficiently through finitesum methods, and suggests an interesting new computational-statisticaltradeoff.

Distributed Learning with Sublinear Communication

  In distributed statistical learning, $N$ samples are split across $m$machines and a learner wishes to use minimal communication to learn as well asif the examples were on a single machine. This model has received substantialinterest in machine learning due to its scalability and potential for parallelspeedup. However, in high-dimensional settings, where the number examples issmaller than the number of features ("dimension"), the speedup afforded bydistributed learning may be overshadowed by the cost of communicating a singleexample. This paper investigates the following question: When is it possible tolearn a $d$-dimensional model in the distributed setting with totalcommunication sublinear in $d$?  Starting with a negative result, we show that for learning $\ell_1$-boundedor sparse linear models, no algorithm can obtain optimal error untilcommunication is linear in dimension. Our main result is that that by slightlyrelaxing the standard boundedness assumptions for linear models, we can obtaindistributed algorithms that enjoy optimal error with communication logarithmicin dimension. This result is based on a family of algorithms that combinemirror descent with randomized sparsification/quantization of iterates, andextends to the general stochastic convex optimization model.

Empirical entropy, minimax regret and minimax risk

  We consider the random design regression model with square loss. We propose amethod that aggregates empirical minimizers (ERM) over appropriately chosenrandom subsets and reduces to ERM in the extreme case, and we establish sharporacle inequalities for its risk. We show that, under the $\varepsilon^{-p}$growth of the empirical $\varepsilon$-entropy, the excess risk of the proposedmethod attains the rate $n^{-2/(2+p)}$ for $p\in(0,2)$ and $n^{-1/p}$ for $p>2$where $n$ is the sample size. Furthermore, for $p\in(0,2)$, the excess riskrate matches the behavior of the minimax risk of function estimation inregression problems under the well-specified model. This yields a conclusionthat the rates of statistical estimation in well-specified models (minimaxrisk) and in misspecified models (minimax regret) are equivalent in the regime$p\in(0,2)$. In other words, for $p\in(0,2)$ the problem of statisticallearning enjoys the same minimax rate as the problem of statistical estimation.On the contrary, for $p>2$ we show that the rates of the minimax regret are, ingeneral, slower than for the minimax risk. Our oracle inequalities also implythe $v\log(n/v)/n$ rates for Vapnik-Chervonenkis type classes of dimension $v$without the usual convexity assumption on the class; we show that these ratesare optimal. Finally, for a slightly modified method, we derive a bound on theexcess risk of $s$-sparse convex aggregation improving that of Lounici [Math.Methods Statist. 16 (2007) 246-259] and providing the optimal rate.

Learning in Games: Robustness of Fast Convergence

  We show that learning algorithms satisfying a $\textit{low approximateregret}$ property experience fast convergence to approximate optimality in alarge class of repeated games. Our property, which simply requires that eachlearner has small regret compared to a $(1+\epsilon)$-multiplicativeapproximation to the best action in hindsight, is ubiquitous among learningalgorithms; it is satisfied even by the vanilla Hedge forecaster. Our resultsimprove upon recent work of Syrgkanis et al. [SALS15] in a number of ways. Werequire only that players observe payoffs under other players' realizedactions, as opposed to expected payoffs. We further show that convergenceoccurs with high probability, and show convergence under bandit feedback.Finally, we improve upon the speed of convergence by a factor of $n$, thenumber of players. Both the scope of settings and the class of algorithms forwhich our analysis provides fast convergence are considerably broader than inprevious work.  Our framework applies to dynamic population games via a low approximateregret property for shifting experts. Here we strengthen the results ofLykouris et al. [LST16] in two ways: We allow players to select learningalgorithms from a larger class, which includes a minor variant of the basicHedge algorithm, and we increase the maximum churn in players for whichapproximate optimality is achieved.  In the bandit setting we present a new algorithm which provides a "smallloss"-type bound with improved dependence on the number of actions in utilitysettings, and is both simple and efficient. This result may be of independentinterest.

Mixed Precision Training of Convolutional Neural Networks using Integer  Operations

  The state-of-the-art (SOTA) for mixed precision training is dominated byvariants of low precision floating point operations, and in particular, FP16accumulating into FP32 Micikevicius et al. (2017). On the other hand, while alot of research has also happened in the domain of low and mixed-precisionInteger training, these works either present results for non-SOTA networks (forinstance only AlexNet for ImageNet-1K), or relatively small datasets (likeCIFAR-10). In this work, we train state-of-the-art visual understanding neuralnetworks on the ImageNet-1K dataset, with Integer operations on General Purpose(GP) hardware. In particular, we focus on Integer Fused-Multiply-and-Accumulate(FMA) operations which take two pairs of INT16 operands and accumulate resultsinto an INT32 output.We propose a shared exponent representation of tensors anddevelop a Dynamic Fixed Point (DFP) scheme suitable for common neural networkoperations. The nuances of developing an efficient integer convolution kernelis examined, including methods to handle overflow of the INT32 accumulator. Weimplement CNN training for ResNet-50, GoogLeNet-v1, VGG-16 and AlexNet; andthese networks achieve or exceed SOTA accuracy within the same number ofiterations as their FP32 counterparts without any change in hyper-parametersand with a 1.8X improvement in end-to-end training throughput. To the best ofour knowledge these results represent the first INT16 training results on GPhardware for ImageNet-1K dataset using SOTA CNNs and achieve highest reportedaccuracy using half-precision

Logistic Regression: The Importance of Being Improper

  Learning linear predictors with the logistic loss---both in stochastic andonline settings---is a fundamental task in machine learning and statistics,with direct connections to classification and boosting. Existing "fast rates"for this setting exhibit exponential dependence on the predictor norm, andHazan et al. (2014) showed that this is unfortunately unimprovable. Startingwith the simple observation that the logistic loss is $1$-mixable, we design anew efficient improper learning algorithm for online logistic regression thatcircumvents the aforementioned lower bound with a regret bound exhibiting adoubly-exponential improvement in dependence on the predictor norm. Thisprovides a positive resolution to a variant of the COLT 2012 open problem ofMcMahan and Streeter (2012) when improper learning is allowed. This improvementis obtained both in the online setting and, with some extra work, in the batchstatistical setting with high probability. We also show that the improveddependence on predictor norm is near-optimal.  Leveraging this improved dependency on the predictor norm yields thefollowing applications: (a) we give algorithms for online bandit multiclasslearning with the logistic loss with an $\tilde{O}(\sqrt{n})$ relative mistakebound across essentially all parameter ranges, thus providing a solution to theCOLT 2009 open problem of Abernethy and Rakhlin (2009), and (b) we give anadaptive algorithm for online multiclass boosting with optimal samplecomplexity, thus partially resolving an open problem of Beygelzimer et al.(2015) and Jung et al. (2017). Finally, we give information-theoretic bounds onthe optimal rates for improper logistic regression with general functionclasses, thereby characterizing the extent to which our improvement for linearclasses extends to other parametric and even nonparametric settings.

