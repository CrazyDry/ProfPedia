The Complexity of Plan Existence and Evaluation in Probabilistic Domains

  We examine the computational complexity of testing and finding small plans in
probabilistic planning domains with succinct representations. We find that many
problems of interest are complete for a variety of complexity classes: NP,
co-NP, PP, NP^PP, co-NP^PP, and PSPACE. Of these, the probabilistic classes PP
and NP^PP are likely to be of special interest in the field of uncertainty in
artificial intelligence and are deserving of additional study. These results
suggest a fruitful direction of future algorithmic development.


The Computational Complexity of Dominance and Consistency in CP-Nets

  We investigate the computational complexity of testing dominance and
consistency in CP-nets. Previously, the complexity of dominance has been
determined for restricted classes in which the dependency graph of the CP-net
is acyclic. However, there are preferences of interest that define cyclic
dependency graphs; these are modeled with general CP-nets. In our main results,
we show here that both dominance and consistency for general CP-nets are
PSPACE-complete. We then consider the concept of strong dominance, dominance
equivalence and dominance incomparability, and several notions of optimality,
and identify the complexity of the corresponding decision problems. The
reductions used in the proofs are from STRIPS planning, and thus reinforce the
earlier established connections between both areas.


Tally NP Sets and Easy Census Functions

  We study the question of whether every P set has an easy (i.e.,
polynomial-time computable) census function. We characterize this question in
terms of unlikely collapses of language and function classes such as the
containment of #P_1 in FP, where #P_1 is the class of functions that count the
witnesses for tally NP sets. We prove that every #P_{1}^{PH} function can be
computed in FP^{#P_{1}^{#P_{1}}}. Consequently, every P set has an easy census
function if and only if every set in the polynomial hierarchy does. We show
that the assumption of #P_1 being contained in FP implies P = BPP and that PH
is contained in MOD_{k}P for each k \geq 2, which provides further evidence
that not all sets in P have an easy census function. We also relate a set's
property of having an easy census function to other well-studied properties of
sets, such as rankability and scalability (the closure of the rankable sets
under P-isomorphisms). Finally, we prove that it is no more likely that the
census function of any set in P can be approximated (more precisely, can be
n^{\alpha}-enumerated in time n^{\beta} for fixed \alpha and \beta) than that
it can be precisely computed in polynomial time.


The Complexity of Probabilistic Lobbying

  We propose models for lobbying in a probabilistic environment, in which an
actor (called "The Lobby") seeks to influence voters' preferences of voting for
or against multiple issues when the voters' preferences are represented in
terms of probabilities. In particular, we provide two evaluation criteria and
two bribery methods to formally describe these models, and we consider the
resulting forms of lobbying with and without issue weighting. We provide a
formal analysis for these problems of lobbying in a stochastic environment, and
determine their classical and parameterized complexity depending on the given
bribery/evaluation criteria and on various natural parameterizations.
Specifically, we show that some of these problems can be solved in polynomial
time, some are NP-complete but fixed-parameter tractable, and some are
W[2]-complete. Finally, we provide approximability and inapproximability
results for these problems and several variants.


Approximation of Lorenz-Optimal Solutions in Multiobjective Markov
  Decision Processes

  This paper is devoted to fair optimization in Multiobjective Markov Decision
Processes (MOMDPs). A MOMDP is an extension of the MDP model for planning under
uncertainty while trying to optimize several reward functions simultaneously.
This applies to multiagent problems when rewards define individual utility
functions, or in multicriteria problems when rewards refer to different
features. In this setting, we study the determination of policies leading to
Lorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Pareto
dominance that was introduced in Social Choice for the measurement of
inequalities. In this paper, we introduce methods to efficiently approximate
the sets of Lorenz-non-dominated solutions of infinite-horizon, discounted
MOMDPs. The approximations are polynomial-sized subsets of those solutions.


Lessons Learned from Development of a Software Tool to Support Academic
  Advising

  We detail some lessons learned while designing and testing a
decision-theoretic advising support tool for undergraduates at a large state
university. Between 2009 and 2011 we conducted two surveys of over 500 students
in multiple majors and colleges. These surveys asked students detailed
questions about their preferences concerning course selection, advising, and
career paths. We present data from this study which may be helpful for faculty
and staff who advise undergraduate students. We find that advising support
software tools can augment the student-advisor relationship, particularly in
terms of course planning, but cannot and should not replace in-person advising.


Ethical Considerations in Artificial Intelligence Courses

  The recent surge in interest in ethics in artificial intelligence may leave
many educators wondering how to address moral, ethical, and philosophical
issues in their AI courses. As instructors we want to develop curriculum that
not only prepares students to be artificial intelligence practitioners, but
also to understand the moral, ethical, and philosophical impacts that
artificial intelligence will have on society. In this article we provide
practical case studies and links to resources for use by AI educators. We also
provide concrete suggestions on how to integrate AI ethics into a general
artificial intelligence course and how to teach a stand-alone artificial
intelligence ethics course.


The Complexity of Campaigning

  In "The Logic of Campaigning", Dean and Parikh consider a candidate making
campaign statements to appeal to the voters. They model these statements as
Boolean formulas over variables that represent stances on the issues, and study
optimal candidate strategies under three proposed models of voter preferences
based on the assignments that satisfy these formulas. We prove that voter
utility evaluation is computationally hard under these preference models (in
one case, #P-hard), along with certain problems related to candidate strategic
reasoning. Our results raise questions about the desirable characteristics of a
voter preference model and to what extent a polynomial-time-evaluable function
can capture them.


My Brain is Full: When More Memory Helps

  We consider the problem of finding good finite-horizon policies for POMDPs
under the expected reward metric. The policies considered are {em free
finite-memory policies with limited memory}; a policy is a mapping from the
space of observation-memory pairs to the space of action-memeory pairs (the
policy updates the memory as it goes), and the number of possible memory states
is a parameter of the input to the policy-finding algorithms. The algorithms
considered here are preliminary implementations of three search heuristics:
local search, simulated annealing, and genetic algorithms. We compare their
outcomes to each other and to the optimal policies for each instance. We
compare run times of each policy and of a dynamic programming algorithm for
POMDPs developed by Hansen that iteratively improves a finite-state controller
--- the previous state of the art for finite memory policies. The value of the
best policy can only improve as the amount of memory increases, up to the
amount needed for an optimal finite-memory policy. Our most surprising finding
is that more memory helps in another way: given more memory than is needed for
an optimal policy, the algorithms are more likely to converge to optimal-valued
policies.


Topological Value Iteration Algorithms

  Value iteration is a powerful yet inefficient algorithm for Markov decision
processes (MDPs) because it puts the majority of its effort into backing up the
entire state space, which turns out to be unnecessary in many cases. In order
to overcome this problem, many approaches have been proposed. Among them, ILAO*
and variants of RTDP are state-of-the-art ones. These methods use reachability
analysis and heuristic search to avoid some unnecessary backups. However, none
of these approaches build the graphical structure of the state transitions in a
pre-processing step or use the structural information to systematically
decompose a problem, whereby generating an intelligent backup sequence of the
state space. In this paper, we present two optimal MDP algorithms. The first
algorithm, topological value iteration (TVI), detects the structure of MDPs and
backs up states based on topological sequences. It (1) divides an MDP into
strongly-connected components (SCCs), and (2) solves these components
sequentially. TVI outperforms VI and other state-of-the-art algorithms vastly
when an MDP has multiple, close-to-equal-sized SCCs. The second algorithm,
focused topological value iteration (FTVI), is an extension of TVI. FTVI
restricts its attention to connected components that are relevant for solving
the MDP. Specifically, it uses a small amount of heuristic search to eliminate
provably sub-optimal actions; this pruning allows FTVI to find smaller
connected components, thus running faster. We demonstrate that FTVI outperforms
TVI by an order of magnitude, averaged across several domains. Surprisingly,
FTVI also significantly outperforms popular heuristically-informed MDP
algorithms such as ILAO*, LRTDP, BRTDP and Bayesian-RTDP in many domains,
sometimes by as much as two orders of magnitude. Finally, we characterize the
type of domains where FTVI excels --- suggesting a way to an informed choice of
solver.


