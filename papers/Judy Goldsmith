The Complexity of Plan Existence and Evaluation in Probabilistic Domains

  We examine the computational complexity of testing and finding small plans inprobabilistic planning domains with succinct representations. We find that manyproblems of interest are complete for a variety of complexity classes: NP,co-NP, PP, NP^PP, co-NP^PP, and PSPACE. Of these, the probabilistic classes PPand NP^PP are likely to be of special interest in the field of uncertainty inartificial intelligence and are deserving of additional study. These resultssuggest a fruitful direction of future algorithmic development.

The Computational Complexity of Dominance and Consistency in CP-Nets

  We investigate the computational complexity of testing dominance andconsistency in CP-nets. Previously, the complexity of dominance has beendetermined for restricted classes in which the dependency graph of the CP-netis acyclic. However, there are preferences of interest that define cyclicdependency graphs; these are modeled with general CP-nets. In our main results,we show here that both dominance and consistency for general CP-nets arePSPACE-complete. We then consider the concept of strong dominance, dominanceequivalence and dominance incomparability, and several notions of optimality,and identify the complexity of the corresponding decision problems. Thereductions used in the proofs are from STRIPS planning, and thus reinforce theearlier established connections between both areas.

Tally NP Sets and Easy Census Functions

  We study the question of whether every P set has an easy (i.e.,polynomial-time computable) census function. We characterize this question interms of unlikely collapses of language and function classes such as thecontainment of #P_1 in FP, where #P_1 is the class of functions that count thewitnesses for tally NP sets. We prove that every #P_{1}^{PH} function can becomputed in FP^{#P_{1}^{#P_{1}}}. Consequently, every P set has an easy censusfunction if and only if every set in the polynomial hierarchy does. We showthat the assumption of #P_1 being contained in FP implies P = BPP and that PHis contained in MOD_{k}P for each k \geq 2, which provides further evidencethat not all sets in P have an easy census function. We also relate a set'sproperty of having an easy census function to other well-studied properties ofsets, such as rankability and scalability (the closure of the rankable setsunder P-isomorphisms). Finally, we prove that it is no more likely that thecensus function of any set in P can be approximated (more precisely, can ben^{\alpha}-enumerated in time n^{\beta} for fixed \alpha and \beta) than thatit can be precisely computed in polynomial time.

The Complexity of Probabilistic Lobbying

  We propose models for lobbying in a probabilistic environment, in which anactor (called "The Lobby") seeks to influence voters' preferences of voting foror against multiple issues when the voters' preferences are represented interms of probabilities. In particular, we provide two evaluation criteria andtwo bribery methods to formally describe these models, and we consider theresulting forms of lobbying with and without issue weighting. We provide aformal analysis for these problems of lobbying in a stochastic environment, anddetermine their classical and parameterized complexity depending on the givenbribery/evaluation criteria and on various natural parameterizations.Specifically, we show that some of these problems can be solved in polynomialtime, some are NP-complete but fixed-parameter tractable, and some areW[2]-complete. Finally, we provide approximability and inapproximabilityresults for these problems and several variants.

Approximation of Lorenz-Optimal Solutions in Multiobjective Markov  Decision Processes

  This paper is devoted to fair optimization in Multiobjective Markov DecisionProcesses (MOMDPs). A MOMDP is an extension of the MDP model for planning underuncertainty while trying to optimize several reward functions simultaneously.This applies to multiagent problems when rewards define individual utilityfunctions, or in multicriteria problems when rewards refer to differentfeatures. In this setting, we study the determination of policies leading toLorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Paretodominance that was introduced in Social Choice for the measurement ofinequalities. In this paper, we introduce methods to efficiently approximatethe sets of Lorenz-non-dominated solutions of infinite-horizon, discountedMOMDPs. The approximations are polynomial-sized subsets of those solutions.

Lessons Learned from Development of a Software Tool to Support Academic  Advising

  We detail some lessons learned while designing and testing adecision-theoretic advising support tool for undergraduates at a large stateuniversity. Between 2009 and 2011 we conducted two surveys of over 500 studentsin multiple majors and colleges. These surveys asked students detailedquestions about their preferences concerning course selection, advising, andcareer paths. We present data from this study which may be helpful for facultyand staff who advise undergraduate students. We find that advising supportsoftware tools can augment the student-advisor relationship, particularly interms of course planning, but cannot and should not replace in-person advising.

Ethical Considerations in Artificial Intelligence Courses

  The recent surge in interest in ethics in artificial intelligence may leavemany educators wondering how to address moral, ethical, and philosophicalissues in their AI courses. As instructors we want to develop curriculum thatnot only prepares students to be artificial intelligence practitioners, butalso to understand the moral, ethical, and philosophical impacts thatartificial intelligence will have on society. In this article we providepractical case studies and links to resources for use by AI educators. We alsoprovide concrete suggestions on how to integrate AI ethics into a generalartificial intelligence course and how to teach a stand-alone artificialintelligence ethics course.

The Complexity of Campaigning

  In "The Logic of Campaigning", Dean and Parikh consider a candidate makingcampaign statements to appeal to the voters. They model these statements asBoolean formulas over variables that represent stances on the issues, and studyoptimal candidate strategies under three proposed models of voter preferencesbased on the assignments that satisfy these formulas. We prove that voterutility evaluation is computationally hard under these preference models (inone case, #P-hard), along with certain problems related to candidate strategicreasoning. Our results raise questions about the desirable characteristics of avoter preference model and to what extent a polynomial-time-evaluable functioncan capture them.

My Brain is Full: When More Memory Helps

  We consider the problem of finding good finite-horizon policies for POMDPsunder the expected reward metric. The policies considered are {em freefinite-memory policies with limited memory}; a policy is a mapping from thespace of observation-memory pairs to the space of action-memeory pairs (thepolicy updates the memory as it goes), and the number of possible memory statesis a parameter of the input to the policy-finding algorithms. The algorithmsconsidered here are preliminary implementations of three search heuristics:local search, simulated annealing, and genetic algorithms. We compare theiroutcomes to each other and to the optimal policies for each instance. Wecompare run times of each policy and of a dynamic programming algorithm forPOMDPs developed by Hansen that iteratively improves a finite-state controller--- the previous state of the art for finite memory policies. The value of thebest policy can only improve as the amount of memory increases, up to theamount needed for an optimal finite-memory policy. Our most surprising findingis that more memory helps in another way: given more memory than is needed foran optimal policy, the algorithms are more likely to converge to optimal-valuedpolicies.

Topological Value Iteration Algorithms

  Value iteration is a powerful yet inefficient algorithm for Markov decisionprocesses (MDPs) because it puts the majority of its effort into backing up theentire state space, which turns out to be unnecessary in many cases. In orderto overcome this problem, many approaches have been proposed. Among them, ILAO*and variants of RTDP are state-of-the-art ones. These methods use reachabilityanalysis and heuristic search to avoid some unnecessary backups. However, noneof these approaches build the graphical structure of the state transitions in apre-processing step or use the structural information to systematicallydecompose a problem, whereby generating an intelligent backup sequence of thestate space. In this paper, we present two optimal MDP algorithms. The firstalgorithm, topological value iteration (TVI), detects the structure of MDPs andbacks up states based on topological sequences. It (1) divides an MDP intostrongly-connected components (SCCs), and (2) solves these componentssequentially. TVI outperforms VI and other state-of-the-art algorithms vastlywhen an MDP has multiple, close-to-equal-sized SCCs. The second algorithm,focused topological value iteration (FTVI), is an extension of TVI. FTVIrestricts its attention to connected components that are relevant for solvingthe MDP. Specifically, it uses a small amount of heuristic search to eliminateprovably sub-optimal actions; this pruning allows FTVI to find smallerconnected components, thus running faster. We demonstrate that FTVI outperformsTVI by an order of magnitude, averaged across several domains. Surprisingly,FTVI also significantly outperforms popular heuristically-informed MDPalgorithms such as ILAO*, LRTDP, BRTDP and Bayesian-RTDP in many domains,sometimes by as much as two orders of magnitude. Finally, we characterize thetype of domains where FTVI excels --- suggesting a way to an informed choice ofsolver.

