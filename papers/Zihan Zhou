Modeling Photographic Composition via Triangles

  The capacity of automatically modeling photographic composition is valuable
for many real-world machine vision applications such as digital photography,
image retrieval, image understanding, and image aesthetics assessment. The
triangle technique is among those indispensable composition methods on which
professional photographers often rely. This paper proposes a system that can
identify prominent triangle arrangements in two major categories of
photographs: natural or urban scenes, and portraits. For the natural or urban
scene pictures, the focus is on the effect of linear perspective. For
portraits, we carefully examine the positioning of human subjects in a photo.
We show that line analysis is highly advantageous for modeling composition in
both categories. Based on the detected triangles, new mathematical descriptors
for composition are formulated and used to retrieve similar images. Leveraging
the rich source of high aesthetics photos online, similar approaches can
potentially be incorporated in future smart cameras to enhance a person's photo
composition skills.


Detecting Dominant Vanishing Points in Natural Scenes with Application
  to Composition-Sensitive Image Retrieval

  Linear perspective is widely used in landscape photography to create the
impression of depth on a 2D photo. Automated understanding of linear
perspective in landscape photography has several real-world applications,
including aesthetics assessment, image retrieval, and on-site feedback for
photo composition, yet adequate automated understanding has been elusive. We
address this problem by detecting the dominant vanishing point and the
associated line structures in a photo. However, natural landscape scenes pose
great technical challenges because often the inadequate number of strong edges
converging to the dominant vanishing point is inadequate. To overcome this
difficulty, we propose a novel vanishing point detection method that exploits
global structures in the scene via contour detection. We show that our method
significantly outperforms state-of-the-art methods on a public ground truth
landscape image dataset that we have created. Based on the detection results,
we further demonstrate how our approach to linear perspective understanding
provides on-site guidance to amateur photographers on their work through a
novel viewpoint-specific image retrieval system.


Image Based Review Text Generation with Emotional Guidance

  In the current field of computer vision, automatically generating texts from
given images has been a fully worked technique. Up till now, most works of this
area focus on image content describing, namely image-captioning. However, rare
researches focus on generating product review texts, which is ubiquitous in the
online shopping malls and is crucial for online shopping selection and
evaluation. Different from content describing, review texts include more
subjective information of customers, which may bring difference to the results.
Therefore, we aimed at a new field concerning generating review text from
customers based on images together with the ratings of online shopping
products, which appear as non-image attributes. We made several adjustments to
the existing image-captioning model to fit our task, in which we should also
take non-image features into consideration. We also did experiments based on
our model and get effective primary results.


Sparsity and Robustness in Face Recognition

  This report concerns the use of techniques for sparse signal representation
and sparse error correction for automatic face recognition. Much of the recent
interest in these techniques comes from the paper "Robust Face Recognition via
Sparse Representation" by Wright et al. (2009), which showed how, under certain
technical conditions, one could cast the face recognition problem as one of
seeking a sparse representation of a given input face image in terms of a
"dictionary" of training images and images of individual pixels. In this
report, we have attempted to clarify some frequently encountered questions
about this work and particularly, on the validity of using sparse
representation techniques for face recognition.


Stable Principal Component Pursuit

  In this paper, we study the problem of recovering a low-rank matrix (the
principal components) from a high-dimensional data matrix despite both small
entry-wise noise and gross sparse errors. Recently, it has been shown that a
convex program, named Principal Component Pursuit (PCP), can recover the
low-rank matrix when the data matrix is corrupted by gross sparse errors. We
further prove that the solution to a related convex program (a relaxed PCP)
gives an estimate of the low-rank matrix that is simultaneously stable to small
entrywise noise and robust to gross sparse errors. More precisely, our result
shows that the proposed convex program recovers the low-rank matrix even though
a positive fraction of its entries are arbitrarily corrupted, with an error
bound proportional to the noise level. We present simulation results to support
our result and demonstrate that the new convex program accurately recovers the
principal components (the low-rank matrix) under quite broad conditions. To our
knowledge, this is the first result that shows the classical Principal
Component Analysis (PCA), optimal for small i.i.d. noise, can be made robust to
gross sparse errors; or the first that shows the newly proposed PCP can be made
stable to small entry-wise perturbations.


Self-Charged Graphene Battery Harvests Electricity from Thermal Energy
  of the Environment

  The energy of ionic thermal motion presents universally, which is as high as
4 kJ\bullet kg-1\bullet K-1 in aqueous solution, where thermal velocity of ions
is in the order of hundreds of meters per second at room temperature1,2.
Moreover, the thermal velocity of ions can be maintained by the external
environment, which means it is unlimited. However, little study has been
reported on converting the ionic thermal energy into electricity. Here we
present a graphene device with asymmetric electrodes configuration to capture
such ionic thermal energy and convert it into electricity. An output voltage
around 0.35 V was generated when the device was dipped into saturated CuCl2
solution, in which this value lasted over twenty days. A positive correlation
between the open-circuit voltage and the temperature, as well as the cation
concentration, was observed. Furthermore, we demonstrated that this finding is
of practical value by lighting a commercial light-emitting diode up with six of
such graphene devices connected in series. This finding provides a new way to
understand the behavior of graphene at molecular scale and represents a huge
breakthrough for the research of self-powered technology. Moreover, the finding
will benefit quite a few applications, such as artificial organs, clean
renewable energy and portable electronics.


Robust Influence Maximization

  In this paper, we address the important issue of uncertainty in the edge
influence probability estimates for the well studied influence maximization
problem --- the task of finding $k$ seed nodes in a social network to maximize
the influence spread. We propose the problem of robust influence maximization,
which maximizes the worst-case ratio between the influence spread of the chosen
seed set and the optimal seed set, given the uncertainty of the parameter
input. We design an algorithm that solves this problem with a
solution-dependent bound. We further study uniform sampling and adaptive
sampling methods to effectively reduce the uncertainty on parameters and
improve the robustness of the influence maximization task. Our empirical
results show that parameter uncertainty may greatly affect influence
maximization performance and prior studies that learned influence probabilities
could lead to poor performance in robust influence maximization due to
relatively large uncertainty in parameter estimates, and information cascade
based adaptive sampling method may be an effective way to improve the
robustness of influence maximization.


Smart Library: Identifying Books in a Library using Richly Supervised
  Deep Scene Text Reading

  Physical library collections are valuable and long standing resources for
knowledge and learning. However, managing books in a large bookshelf and
finding books on it often leads to tedious manual work, especially for large
book collections where books might be missing or misplaced. Recently, deep
neural models, such as Convolutional Neural Networks (CNN) and Recurrent Neural
Networks (RNN) have achieved great success for scene text detection and
recognition. Motivated by these recent successes, we aim to investigate their
viability in facilitating book management, a task that introduces further
challenges including large amounts of cluttered scene text, distortion, and
varied lighting conditions. In this paper, we present a library inventory
building and retrieval system based on scene text reading methods. We
specifically design our scene text recognition model using rich supervision to
accelerate training and achieve state-of-the-art performance on several
benchmark datasets. Our proposed system has the potential to greatly reduce the
amount of human labor required in managing book inventories as well as the
space needed to store book information.


Fast L1-Minimization Algorithms For Robust Face Recognition

  L1-minimization refers to finding the minimum L1-norm solution to an
underdetermined linear system b=Ax. Under certain conditions as described in
compressive sensing theory, the minimum L1-norm solution is also the sparsest
solution. In this paper, our study addresses the speed and scalability of its
algorithms. In particular, we focus on the numerical implementation of a
sparsity-based classification framework in robust face recognition, where
sparse representation is sought to recover human identities from very
high-dimensional facial images that may be corrupted by illumination, facial
disguise, and pose variation. Although the underlying numerical problem is a
linear program, traditional algorithms are known to suffer poor scalability for
large-scale applications. We investigate a new solution based on a classical
convex optimization framework, known as Augmented Lagrangian Methods (ALM). The
new convex solvers provide a viable solution to real-world, time-critical
applications such as face recognition. We conduct extensive experiments to
validate and compare the performance of the ALM algorithms against several
popular L1-minimization solvers, including interior-point method, Homotopy,
FISTA, SESOP-PCD, approximate message passing (AMP) and TFOCS. To aid peer
evaluation, the code for all the algorithms has been made publicly available.


Graph Construction with Label Information for Semi-Supervised Learning

  In the literature, most existing graph-based semi-supervised learning (SSL)
methods only use the label information of observed samples in the label
propagation stage, while ignoring such valuable information when learning the
graph. In this paper, we argue that it is beneficial to consider the label
information in the graph learning stage. Specifically, by enforcing the weight
of edges between labeled samples of different classes to be zero, we explicitly
incorporate the label information into the state-of-the-art graph learning
methods, such as the Low-Rank Representation (LRR), and propose a novel
semi-supervised graph learning method called Semi-Supervised Low-Rank
Representation (SSLRR). This results in a convex optimization problem with
linear constraints, which can be solved by the linearized alternating direction
method. Though we take LRR as an example, our proposed method is in fact very
general and can be applied to any self-representation graph learning methods.
Experiment results on both synthetic and real datasets demonstrate that the
proposed graph learning method can better capture the global geometric
structure of the data, and therefore is more effective for semi-supervised
learning tasks.


Single-Image Piece-wise Planar 3D Reconstruction via Associative
  Embedding

  Single-image piece-wise planar 3D reconstruction aims to simultaneously
segment plane instances and recover 3D plane parameters from an image. Most
recent approaches leverage convolutional neural networks (CNNs) and achieve
promising results. However, these methods are limited to detecting a fixed
number of planes with certain learned order. To tackle this problem, we propose
a novel two-stage method based on associative embedding, inspired by its recent
success in instance segmentation. In the first stage, we train a CNN to map
each pixel to an embedding space where pixels from the same plane instance have
similar embeddings. Then, the plane instances are obtained by grouping the
embedding vectors in planar regions via an efficient mean shift clustering
algorithm. In the second stage, we estimate the parameter for each plane
instance by considering both pixel-level and instance-level consistencies. With
the proposed method, we are able to detect an arbitrary number of planes.
Extensive experiments on public datasets validate the effectiveness and
efficiency of our method. Furthermore, our method runs at 30 fps at the testing
time, thus could facilitate many real-time applications such as visual SLAM and
human-robot interaction. Code is available at
https://github.com/svip-lab/PlanarReconstruction.


