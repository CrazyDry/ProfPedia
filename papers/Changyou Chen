A Remark on Nonlinear Dirac Equations

  For a $n$-dimensional spin manifold $M$ with a fixed spin structure and aspinor bundle $\Sigma M$, we prove an $\epsilon$-regularity theorem for weaksolutions to the nonlinear Dirac equation of cubic nonlinearity. This, inparticular, answers a regularity question raised by Chen-Jost-Wang when $n=2$.

Dependent Hierarchical Normalized Random Measures for Dynamic Topic  Modeling

  We develop dependent hierarchical normalized random measures and apply themto dynamic topic modeling. The dependency arises via superposition, subsamplingand point transition on the underlying Poisson processes of these measures. Themeasures used include normalised generalised Gamma processes that demonstratepower law properties, unlike Dirichlet processes used previously in dynamictopic modeling. Inference for the model includes adapting a recently developedslice sampler to directly manipulate the underlying Poisson process.Experiments performed on news, blogs, academic and Twitter collectionsdemonstrate the technique gives superior perplexity over a number of previousmodels.

Second-Order Adversarial Attack and Certifiable Robustness

  We propose a powerful second-order attack method that outperforms existingattack methods on reducing the accuracy of state-of-the-art defense modelsbased on adversarial training. The effectiveness of our attack method motivatesan investigation of provable robustness of a defense model. To this end, weintroduce a framework that allows one to obtain a certifiable lower bound onthe prediction accuracy against adversarial examples. We conduct experiments toshow the effectiveness of our attack method. At the same time, our defensemodels obtain higher accuracies compared to previous works under our proposedattack.

Mechanism of cellular effect directly induced by magnetic nanoparticles  under magnetic fields

  The interaction of magnetic nanoparticles (MNPs) with various magnetic fieldscould directly induce cellular effects. Many scattered investigations have gotinvolved in these cellular effects, analyzed their relative mechanisms andextended their biomedical uses in magnetic hyperthermia and cell regulation.This review reports these cellular effects and their important applications inbiomedical area. More importantly, we highlight the underlying mechanismsbehind these direct cellular effects in the review from the thermal energy andmechanical force. Recently, some physical analyses showed that the mechanismsof heat and mechanical force in cellular effects are controversial. Althoughthe physical principle plays an important role in these cellular effects, somechemical reactions such as free radical reaction also existed in theinteraction of MNPs with magnetic fields, which provides the possibleexplanation for the current controversy. It's anticipated that the review herecould provide readers a deeper understanding of mechanisms of how MNPscontribute to the direct cellular effects and thus their biomedicalapplications under various magnetic fields.

Continuous-Time Flows for Efficient Inference and Density Estimation

  Two fundamental problems in unsupervised learning are efficient inference forlatent-variable models and robust density estimation based on large amounts ofunlabeled data. Algorithms for the two tasks, such as normalizing flows andgenerative adversarial networks (GANs), are often developed independently. Inthis paper, we propose the concept of {\em continuous-time flows} (CTFs), afamily of diffusion-based methods that are able to asymptotically approach atarget distribution. Distinct from normalizing flows and GANs, CTFs can beadopted to achieve the above two goals in one framework, with theoreticalguarantees. Our framework includes distilling knowledge from a CTF forefficient inference, and learning an explicit energy-based distribution withCTFs for density estimation. Both tasks rely on a new technique fordistribution matching within amortized learning. Experiments on various tasksdemonstrate promising performance of the proposed CTF framework, compared torelated techniques.

A Unified Particle-Optimization Framework for Scalable Bayesian Sampling

  There has been recent interest in developing scalable Bayesian samplingmethods such as stochastic gradient MCMC (SG-MCMC) and Stein variationalgradient descent (SVGD) for big-data analysis. A standard SG-MCMC algorithmsimulates samples from a discrete-time Markov chain to approximate a targetdistribution, thus samples could be highly correlated, an undesired propertyfor SG-MCMC. In contrary, SVGD directly optimizes a set of particles toapproximate a target distribution, and thus is able to obtain goodapproximations with relatively much fewer samples. In this paper, we propose aprinciple particle-optimization framework based on Wasserstein gradient flowsto unify SG-MCMC and SVGD, and to allow new algorithms to be developed. Ourframework interprets SG-MCMC as particle optimization on the space ofprobability measures, revealing a strong connection between SG-MCMC and SVGD.The key component of our framework is several particle-approximate techniquesto efficiently solve the original partial differential equations on the spaceof probability measures. Extensive experiments on both synthetic data and deepneural networks demonstrate the effectiveness and efficiency of our frameworkfor scalable Bayesian sampling.

Bridging the Gap between Stochastic Gradient MCMC and Stochastic  Optimization

  Stochastic gradient Markov chain Monte Carlo (SG-MCMC) methods are Bayesiananalogs to popular stochastic optimization methods; however, this connection isnot well studied. We explore this relationship by applying simulated annealingto an SGMCMC algorithm. Furthermore, we extend recent SG-MCMC methods with twokey components: i) adaptive preconditioners (as in ADAgrad or RMSprop), and ii)adaptive element-wise momentum weights. The zero-temperature limit gives anovel stochastic optimization method with adaptive element-wise momentumweights, while conventional optimization methods only have a shared, staticmomentum weight. Under certain assumptions, our theoretical analysis suggeststhe proposed simulated annealing approach converges close to the global optima.Experiments on several deep neural network models show state-of-the-art resultscompared to related stochastic optimization algorithms.

Stochastic Gradient MCMC with Stale Gradients

  Stochastic gradient MCMC (SG-MCMC) has played an important role inlarge-scale Bayesian learning, with well-developed theoretical convergenceproperties. In such applications of SG-MCMC, it is becoming increasinglypopular to employ distributed systems, where stochastic gradients are computedbased on some outdated parameters, yielding what are termed stale gradients.While stale gradients could be directly used in SG-MCMC, their impact onconvergence properties has not been well studied. In this paper we developtheory to show that while the bias and MSE of an SG-MCMC algorithm depend onthe staleness of stochastic gradients, its estimation variance (relative to theexpected estimate, based on a prescribed number of samples) is independent ofit. In a simple Bayesian distributed system with SG-MCMC, where stale gradientsare computed asynchronously by a set of workers, our theory indicates a linearspeedup on the decrease of estimation variance w.r.t. the number of workers.Experiments on synthetic data and deep neural networks validate our theory,demonstrating the effectiveness and scalability of SG-MCMC with stalegradients.

On the Convergence of Stochastic Gradient MCMC Algorithms with  High-Order Integrators

  Recent advances in Bayesian learning with large-scale data have witnessedemergence of stochastic gradient MCMC algorithms (SG-MCMC), such as stochasticgradient Langevin dynamics (SGLD), stochastic gradient Hamiltonian MCMC(SGHMC), and the stochastic gradient thermostat. While finite-time convergenceproperties of the SGLD with a 1st-order Euler integrator have recently beenstudied, corresponding theory for general SG-MCMCs has not been explored. Inthis paper we consider general SG-MCMCs with high-order integrators, anddevelop theory to analyze finite-time convergence properties and theirasymptotic invariant measures. Our theoretical results show faster convergencerates and more accurate invariant measures for SG-MCMCs with higher-orderintegrators. For example, with the proposed efficient 2nd-order symmetricsplitting integrator, the {\em mean square error} (MSE) of the posterioraverage for the SGHMC achieves an optimal convergence rate of $L^{-4/5}$ at $L$iterations, compared to $L^{-2/3}$ for the SGHMC and SGLD with 1st-order Eulerintegrators. Furthermore, convergence results of decreasing-step-size SG-MCMCsare also developed, with the same convergence rates as their fixed-step-sizecounterparts for a specific decreasing sequence. Experiments on both syntheticand real datasets verify our theory, and show advantages of the proposed methodin two large-scale real applications.

A Convergence Analysis for A Class of Practical Variance-Reduction  Stochastic Gradient MCMC

  Stochastic gradient Markov Chain Monte Carlo (SG-MCMC) has been developed asa flexible family of scalable Bayesian sampling algorithms. However, there hasbeen little theoretical analysis of the impact of minibatch size to thealgorithm's convergence rate. In this paper, we prove that under a limitedcomputational budget/time, a larger minibatch size leads to a faster decreaseof the mean squared error bound (thus the fastest one corresponds to using fullgradients), which motivates the necessity of variance reduction in SG-MCMC.Consequently, by borrowing ideas from stochastic optimization, we propose apractical variance-reduction technique for SG-MCMC, that is efficient in bothcomputation and storage. We develop theory to prove that our algorithm inducesa faster convergence rate than standard SG-MCMC. A number of large-scaleexperiments, ranging from Bayesian learning of logistic regression to deepneural networks, validate the theory and demonstrate the superiority of theproposed variance-reduction SG-MCMC framework.

Particle Optimization in Stochastic Gradient MCMC

  Stochastic gradient Markov chain Monte Carlo (SG-MCMC) has been increasinglypopular in Bayesian learning due to its ability to deal with large data. Astandard SG-MCMC algorithm simulates samples from a discretized-time Markovchain to approximate a target distribution. However, the samples are typicallyhighly correlated due to the sequential generation process, an undesiredproperty in SG-MCMC. In contrary, Stein variational gradient descent (SVGD)directly optimizes a set of particles, and it is able to approximate a targetdistribution with much fewer samples. In this paper, we propose a novel methodto directly optimize particles (or samples) in SG-MCMC from scratch.Specifically, we propose efficient methods to solve the correspondingFokker-Planck equation on the space of probability distributions, whosesolution (i.e., a distribution) is approximated by particles. Through ourframework, we are able to show connections of SG-MCMC to SVGD, as well as theseemly unrelated generative-adversarial-net framework. Under certainrelaxations, particle optimization in SG-MCMC can be interpreted as anextension of standard SVGD with momentum.

Stochastic Particle-Optimization Sampling and the Non-Asymptotic  Convergence Theory

  Particle-optimization sampling (POS) is a recently developed technique togenerate high-quality samples from a target distribution by iterativelyupdating a set of interactive particles. A representative algorithm is theStein variational gradient descent (SVGD). Though obtaining significantempirical success, the {\em non-asymptotic} convergence behavior of SVGDremains unknown. In this paper, we generalize POS to a stochasticity setting byinjecting random noise in particle updates, called stochasticparticle-optimization sampling (SPOS). Standard SVGD can be regarded as aspecial case of our framework. Notably, for the first time, we developnon-asymptotic convergence theory for the SPOS framework (which includes SVGD),characterizing the bias of a sample approximation w.r.t. the numbers ofparticles and iterations under both convex- and noncovex-energy-functionsettings. Remarkably, we provide theoretical understand of a pitfall of SVGDthat can be avoided in the proposed SPOS framework, i.e., particles tent tocollapse to a local mode in SVGD under some particular conditions. Our theoryis based on the analysis of nonlinear stochastic differential equations, whichserves as an extension and a complemented development to the asymptoticconvergence theory for SVGD such as [Liu17].

Variance Reduction in Stochastic Particle-Optimization Sampling

  Stochastic particle-optimization sampling (SPOS) is a recently-developedscalable Bayesian sampling framework that unifies stochastic gradient MCMC(SG-MCMC) and Stein variational gradient descent (SVGD) algorithms based onWasserstein gradient flows. With a rigorous non-asymptotic convergence theorydeveloped recently, SPOS avoids the particle-collapsing pitfall of SVGD.Nevertheless, variance reduction in SPOS has never been studied. In this paper,we bridge the gap by presenting several variance-reduction techniques for SPOS.Specifically, we propose three variants of variance-reduced SPOS, called SAGAparticle-optimization sampling (SAGA-POS), SVRG particle-optimization sampling(SVRG-POS) and a variant of SVRG-POS which avoids full gradient computations,denoted as SVRG-POS$^+$. Importantly, we provide non-asymptotic convergenceguarantees for these algorithms in terms of 2-Wasserstein metric and analyzetheir complexities. Remarkably, the results show our algorithms yield betterconvergence rates than existing variance-reduced variants of stochasticLangevin dynamics, even though more space is required to store the particles intraining. Our theory well aligns with experimental results on both syntheticand real datasets.

Self-Adversarially Learned Bayesian Sampling

  Scalable Bayesian sampling is playing an important role in modern machinelearning, especially in the fast-developed unsupervised-(deep)-learning models.While tremendous progresses have been achieved via scalable Bayesian samplingsuch as stochastic gradient MCMC (SG-MCMC) and Stein variational gradientdescent (SVGD), the generated samples are typically highly correlated.Moreover, their sample-generation processes are often criticized to beinefficient. In this paper, we propose a novel self-adversarial learningframework that automatically learns a conditional generator to mimic thebehavior of a Markov kernel (transition kernel). High-quality samples can beefficiently generated by direct forward passes though a learned generator. Mostimportantly, the learning process adopts a self-learning paradigm, requiring noinformation on existing Markov kernels, e.g., knowledge of how to draw samplesfrom them. Specifically, our framework learns to use current samples, eitherfrom the generator or pre-provided training data, to update the generator suchthat the generated samples progressively approach a target distribution, thusit is called self-learning. Experiments on both synthetic and real datasetsverify advantages of our framework, outperforming related methods in terms ofboth sampling efficiency and sample quality.

Adversarial Learning of a Sampler Based on an Unnormalized Distribution

  We investigate adversarial learning in the case when only an unnormalizedform of the density can be accessed, rather than samples. With insights sogarnered, adversarial learning is extended to the case for which one has accessto an unnormalized form u(x) of the target density function, but no samples.Further, new concepts in GAN regularization are developed, based on learningfrom samples or from u(x). The proposed method is compared to alternativeapproaches, with encouraging results demonstrated across a range ofapplications, including deep soft Q-learning.

Improving Sequence-to-Sequence Learning via Optimal Transport

  Sequence-to-sequence models are commonly trained via maximum likelihoodestimation (MLE). However, standard MLE training considers a word-levelobjective, predicting the next word given the previous ground-truth partialsentence. This procedure focuses on modeling local syntactic patterns, and mayfail to capture long-range semantic structure. We present a novel solution toalleviate these issues. Our approach imposes global sequence-level guidance vianew supervision based on optimal transport, enabling the overallcharacterization and preservation of semantic features. We further show thatthis method can be understood as a Wasserstein gradient flow trying to matchour model to the ground truth sequence distribution. Extensive experiments areconducted to validate the utility of the proposed approach, showing consistentimprovements over a wide variety of NLP tasks, including machine translation,abstractive text summarization, and image captioning.

ALICE: Towards Understanding Adversarial Learning for Joint Distribution  Matching

  We investigate the non-identifiability issues associated with bidirectionaladversarial training for joint distribution matching. Within a framework ofconditional entropy, we propose both adversarial and non-adversarial approachesto learn desirable matched joint distributions for unsupervised and supervisedtasks. We unify a broad family of adversarial models as joint distributionmatching problems. Our approach stabilizes learning of unsupervisedbidirectional adversarial learning methods. Further, we introduce an extensionfor semi-supervised learning tasks. Theoretical results are validated insynthetic data and real-world applications.

Sequence Generation with Guider Network

  Sequence generation with reinforcement learning (RL) has received significantattention recently. However, a challenge with such methods is the sparse-rewardproblem in the RL training process, in which a scalar guiding signal is oftenonly available after an entire sequence has been generated. This type of sparsereward tends to ignore the global structural information of a sequence, causinggeneration of sequences that are semantically inconsistent. In this paper, wepresent a model-based RL approach to overcome this issue. Specifically, wepropose a novel guider network to model the sequence-generation environment,which can assist next-word prediction and provide intermediate rewards forgenerator optimization. Extensive experiments show that the proposed methodleads to improved performance for both unconditional and conditionalsequence-generation tasks.

Theory of Dependent Hierarchical Normalized Random Measures

  This paper presents theory for Normalized Random Measures (NRMs), NormalizedGeneralized Gammas (NGGs), a particular kind of NRM, and Dependent HierarchicalNRMs which allow networks of dependent NRMs to be analysed. These have beenused, for instance, for time-dependent topic modelling. In this paper, we firstintroduce some mathematical background of completely random measures (CRMs) andtheir construction from Poisson processes, and then introduce NRMs and NGGs.Slice sampling is also introduced for posterior inference. The dependencyoperators in Poisson processes and for the corresponding CRMs and NRMs is thenintroduced and Posterior inference for the NGG presented. Finally, we givedependency and composition results when applying these operators to NRMs sothey can be used in a network with hierarchical and dependent relations.

Scalable Bayesian Non-Negative Tensor Factorization for Massive Count  Data

  We present a Bayesian non-negative tensor factorization model forcount-valued tensor data, and develop scalable inference algorithms (both batchand online) for dealing with massive tensors. Our generative model can handleoverdispersed counts as well as infer the rank of the decomposition. Moreover,leveraging a reparameterization of the Poisson distribution as a multinomialfacilitates conjugacy in the model and enables simple and efficient Gibbssampling and variational Bayes (VB) inference updates, with a computationalcost that only depends on the number of nonzeros in the tensor. The model alsoprovides a nice interpretability for the factors; in our model, each factorcorresponds to a "topic". We develop a set of online inference algorithms thatallow further scaling up the model to massive tensors, for which batchinference methods may be infeasible. We apply our framework on diversereal-world applications, such as \emph{multiway} topic modeling on a scientificpublications database, analyzing a political science data set, and analyzing amassive household transactions data set.

High-Order Stochastic Gradient Thermostats for Bayesian Learning of Deep  Models

  Learning in deep models using Bayesian methods has generated significantattention recently. This is largely because of the feasibility of modernBayesian methods to yield scalable learning and inference, while maintaining ameasure of uncertainty in the model parameters. Stochastic gradient MCMCalgorithms (SG-MCMC) are a family of diffusion-based sampling methods forlarge-scale Bayesian learning. In SG-MCMC, multivariate stochastic gradientthermostats (mSGNHT) augment each parameter of interest, with a momentum and athermostat variable to maintain stationary distributions as target posteriordistributions. As the number of variables in a continuous-time diffusionincreases, its numerical approximation error becomes a practical bottleneck, sobetter use of a numerical integrator is desirable. To this end, we propose useof an efficient symmetric splitting integrator in mSGNHT, instead of thetraditional Euler integrator. We demonstrate that the proposed scheme is moreaccurate, robust, and converges faster. These properties are demonstrated to bedesirable in Bayesian deep learning. Extensive experiments on two canonicalmodels and their deep extensions demonstrate that the proposed scheme improvesgeneral Bayesian posterior sampling, particularly for deep models.

Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural  Networks

  Effective training of deep neural networks suffers from two main issues. Thefirst is that the parameter spaces of these models exhibit pathologicalcurvature. Recent methods address this problem by using adaptivepreconditioning for Stochastic Gradient Descent (SGD). These methods improveconvergence by adapting to the local geometry of parameter space. A secondissue is overfitting, which is typically addressed by early stopping. However,recent work has demonstrated that Bayesian model averaging mitigates thisproblem. The posterior can be sampled by using Stochastic Gradient LangevinDynamics (SGLD). However, the rapidly changing curvature renders default SGLDmethods inefficient. Here, we propose combining adaptive preconditioners withSGLD. In support of this idea, we give theoretical properties on asymptoticconvergence and predictive risk. We also provide empirical results for LogisticRegression, Feedforward Neural Nets, and Convolutional Neural Nets,demonstrating that our preconditioned SGLD method gives state-of-the-artperformance on these models.

Towards Unifying Hamiltonian Monte Carlo and Slice Sampling

  We unify slice sampling and Hamiltonian Monte Carlo (HMC) sampling,demonstrating their connection via the Hamiltonian-Jacobi equation fromHamiltonian mechanics. This insight enables extension of HMC and slice samplingto a broader family of samplers, called Monomial Gamma Samplers (MGS). Weprovide a theoretical analysis of the mixing performance of such samplers,proving that in the limit of a single parameter, the MGS draws decorrelatedsamples from the desired target distribution. We further show that as thisparameter tends toward this limit, performance gains are achieved at a cost ofincreasing numerical difficulty and some practical convergence issues. Ourtheoretical results are validated with synthetic data and real-worldapplications.

Nonlinear Statistical Learning with Truncated Gaussian Graphical Models

  We introduce the truncated Gaussian graphical model (TGGM) as a novelframework for designing statistical models for nonlinear learning. A TGGM is aGaussian graphical model (GGM) with a subset of variables truncated to benonnegative. The truncated variables are assumed latent and integrated out toinduce a marginal model. We show that the variables in the marginal model arenon-Gaussian distributed and their expected relations are nonlinear. We useexpectation-maximization to break the inference of the nonlinear model into asequence of TGGM inference problems, each of which is efficiently solved byusing the properties and numerical methods of multivariate Gaussiandistributions. We use the TGGM to design models for nonlinear regression andclassification, with the performances of these models demonstrated on extensivebenchmark datasets and compared to state-of-the-art competing results.

Nonparametric Bayesian Topic Modelling with the Hierarchical Pitman-Yor  Processes

  The Dirichlet process and its extension, the Pitman-Yor process, arestochastic processes that take probability distributions as a parameter. Theseprocesses can be stacked up to form a hierarchical nonparametric Bayesianmodel. In this article, we present efficient methods for the use of theseprocesses in this hierarchical context, and apply them to latent variablemodels for text analytics. In particular, we propose a general framework fordesigning these Bayesian models, which are called topic models in the computerscience community. We then propose a specific nonparametric Bayesian topicmodel for modelling text from social media. We focus on tweets (posts onTwitter) in this article due to their ease of access. We find that ournonparametric model performs better than existing parametric models in bothgoodness of fit and real world applications.

Twitter-Network Topic Model: A Full Bayesian Treatment for Social  Network and Text Modeling

  Twitter data is extremely noisy -- each tweet is short, unstructured and withinformal language, a challenge for current topic modeling. On the other hand,tweets are accompanied by extra information such as authorship, hashtags andthe user-follower network. Exploiting this additional information, we proposethe Twitter-Network (TN) topic model to jointly model the text and the socialnetwork in a full Bayesian nonparametric way. The TN topic model employs thehierarchical Poisson-Dirichlet processes (PDP) for text modeling and a Gaussianprocess random function model for social network modeling. We show that the TNtopic model significantly outperforms several existing nonparametric models dueto its flexibility. Moreover, the TN topic model enables additional informativeinference such as authors' interests, hashtag analysis, as well as leading tofurther applications such as author recommendation, automatic topic labelingand hashtag suggestion. Note our general inference framework can readily beapplied to other topic models with embedded PDP nodes.

Scalable Bayesian Learning of Recurrent Neural Networks for Language  Modeling

  Recurrent neural networks (RNNs) have shown promising performance forlanguage modeling. However, traditional training of RNNs using back-propagationthrough time often suffers from overfitting. One reason for this is thatstochastic optimization (used for large training sets) does not provide goodestimates of model uncertainty. This paper leverages recent advances instochastic gradient Markov Chain Monte Carlo (also appropriate for largetraining sets) to learn weight uncertainty in RNNs. It yields a principledBayesian learning algorithm, adding gradient noise during training (enhancingexploration of the model-parameter space) and model averaging when testing.Extensive experiments on various RNN models and across a broad range ofapplications demonstrate the superiority of the proposed approach overstochastic optimization.

Stochastic Gradient Monomial Gamma Sampler

  Recent advances in stochastic gradient techniques have made it possible toestimate posterior distributions from large datasets via Markov Chain MonteCarlo (MCMC). However, when the target posterior is multimodal, mixingperformance is often poor. This results in inadequate exploration of theposterior distribution. A framework is proposed to improve the samplingefficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. Ageneralized kinetic function is leveraged, delivering superior stationarymixing, especially for multimodal distributions. Techniques are also discussedto overcome the practical issues introduced by this generalization. It is shownthat the proposed approach is better at exploring complex multimodal posteriordistributions, as demonstrated on multiple applications and in comparison withother stochastic gradient MCMC methods.

On Connecting Stochastic Gradient MCMC and Differential Privacy

  Significant success has been realized recently on applying machine learningto real-world applications. There have also been corresponding concerns on theprivacy of training data, which relates to data security and confidentialityissues. Differential privacy provides a principled and rigorous privacyguarantee on machine learning models. While it is common to design a modelsatisfying a required differential-privacy property by injecting noise, it isgenerally hard to balance the trade-off between privacy and utility. We showthat stochastic gradient Markov chain Monte Carlo (SG-MCMC) -- a class ofscalable Bayesian posterior sampling algorithms proposed recently -- satisfiesstrong differential privacy with carefully chosen step sizes. We develop theoryon the performance of the proposed differentially-private SG-MCMC method. Weconduct experiments to support our analysis and show that a standard SG-MCMCsampler without any modification (under a default setting) can reachstate-of-the-art performance in terms of both privacy and utility on Bayesianlearning.

Learning Structural Weight Uncertainty for Sequential Decision-Making

  Learning probability distributions on the weights of neural networks (NNs)has recently proven beneficial in many applications. Bayesian methods, such asStein variational gradient descent (SVGD), offer an elegant framework to reasonabout NN model uncertainty. However, by assuming independent Gaussian priorsfor the individual NN weights (as often applied), SVGD does not impose priorknowledge that there is often structural information (dependence) amongweights. We propose efficient posterior learning of structural weightuncertainty, within an SVGD framework, by employing matrix variate Gaussianpriors on NN parameters. We further investigate the learned structuraluncertainty in sequential decision-making problems, including contextualbandits and reinforcement learning. Experiments on several synthetic and realdatasets indicate the superiority of our model, compared with state-of-the-artmethods.

Policy Optimization as Wasserstein Gradient Flows

  Policy optimization is a core component of reinforcement learning (RL), andmost existing RL methods directly optimize parameters of a policy based onmaximizing the expected total reward, or its surrogate. Though often achievingencouraging empirical success, its underlying mathematical principle on {\empolicy-distribution} optimization is unclear. We place policy optimization intothe space of probability measures, and interpret it as Wasserstein gradientflows. On the probability-measure space, under specified circumstances, policyoptimization becomes a convex problem in terms of distribution optimization. Tomake optimization feasible, we develop efficient algorithms by numericallysolving the corresponding discrete gradient flows. Our technique is applicableto several RL settings, and is related to many state-of-the-artpolicy-optimization algorithms. Empirical results verify the effectiveness ofour framework, often obtaining better performance compared to relatedalgorithms.

Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning

  The posteriors over neural network weights are high dimensional andmultimodal. Each mode typically characterizes a meaningfully differentrepresentation of the data. We develop Cyclical Stochastic Gradient MCMC(SG-MCMC) to automatically explore such distributions. In particular, wepropose a cyclical stepsize schedule, where larger steps discover new modes,and smaller steps characterize each mode. We prove that our proposed learningrate schedule provides faster convergence to samples from a stationarydistribution than SG-MCMC with standard decaying schedules. Moreover, weprovide extensive experimental results to demonstrate the effectiveness ofcyclical SG-MCMC in learning complex multimodal distributions, especially forfully Bayesian inference with modern deep neural networks.

Scalable Thompson Sampling via Optimal Transport

  Thompson sampling (TS) is a class of algorithms for sequentialdecision-making, which requires maintaining a posterior distribution over amodel. However, calculating exact posterior distributions is intractable forall but the simplest models. Consequently, efficient computation of anapproximate posterior distribution is a crucial problem for scalable TS withcomplex models, such as neural networks. In this paper, we use distributionoptimization techniques to approximate the posterior distribution, solved viaWasserstein gradient flows. Based on the framework, a principledparticle-optimization algorithm is developed for TS to approximate theposterior efficiently. Our approach is scalable and does not make explicitdistribution assumptions on posterior approximations. Extensive experiments onboth synthetic data and real large-scale data demonstrate the superiorperformance of the proposed methods.

Topic-Guided Variational Autoencoders for Text Generation

  We propose a topic-guided variational autoencoder (TGVAE) model for textgeneration. Distinct from existing variational autoencoder (VAE) basedapproaches, which assume a simple Gaussian prior for the latent code, our modelspecifies the prior as a Gaussian mixture model (GMM) parametrized by a neuraltopic module. Each mixture component corresponds to a latent topic, whichprovides guidance to generate sentences under the topic. The neural topicmodule and the VAE-based neural sequence module in our model are learnedjointly. In particular, a sequence of invertible Householder transformations isapplied to endow the approximate posterior of the latent code with highflexibility during model inference. Experimental results show that our TGVAEoutperforms alternative approaches on both unconditional and conditional textgeneration, which can generate semantically-meaningful sentences with varioustopics.

Earliness-Aware Deep Convolutional Networks for Early Time Series  Classification

  We present Earliness-Aware Deep Convolutional Networks (EA-ConvNets), anend-to-end deep learning framework, for early classification of time seriesdata. Unlike most existing methods for early classification of time seriesdata, that are designed to solve this problem under the assumption of theavailability of a good set of pre-defined (often hand-crafted) features, ourframework can jointly perform feature learning (by learning a deep hierarchy of\emph{shapelets} capturing the salient characteristics in each time series),along with a dynamic truncation model to help our deep feature learningarchitecture focus on the early parts of each time series. Consequently, ourframework is able to make highly reliable early predictions, outperformingvarious state-of-the-art methods for early time series classification, whilealso being competitive when compared to the state-of-the-art time seriesclassification algorithms that work with \emph{fully observed} time seriesdata. To the best of our knowledge, the proposed framework is the first toperform data-driven (deep) feature learning in the context of earlyclassification of time series data. We perform a comprehensive set ofexperiments, on several benchmark data sets, which demonstrate that our methodyields significantly better predictions than various state-of-the-art methodsdesigned for early time series classification. In addition to obtaining highaccuracies, our experiments also show that the learned deep shapelets basedfeatures are also highly interpretable and can help gain better understandingof the underlying characteristics of time series data.

Zero-Shot Learning via Class-Conditioned Deep Generative Models

  We present a deep generative model for learning to predict classes not seenat training time. Unlike most existing methods for this problem, that representeach class as a point (via a semantic embedding), we represent each seen/unseenclass using a class-specific latent-space distribution, conditioned on classattributes. We use these latent-space distributions as a prior for a supervisedvariational autoencoder (VAE), which also facilitates learning highlydiscriminative feature representations for the inputs. The entire framework islearned end-to-end using only the seen-class training data. The model inferscorresponding attributes of a test image by maximizing the VAE lower bound; theinferred attributes may be linked to labels not seen when training. We furtherextend our model to a (1) semi-supervised/transductive setting by leveragingunlabeled unseen-class data via an unsupervised learning module, and (2)few-shot learning where we also have a small number of labeled inputs from theunseen classes. We compare our model with several state-of-the-art methodsthrough a comprehensive set of experiments on a variety of benchmark data sets.

Distributionally Adversarial Attack

  Recent work on adversarial attack has shown that Projected Gradient Descent(PGD) Adversary is a universal first-order adversary, and the classifieradversarially trained by PGD is robust against a wide range of first-orderattacks. It is worth noting that the original objective of an attack/defensemodel relies on a data distribution $p(\mathbf{x})$, typically in the form ofrisk maximization/minimization, e.g.,$\max/\min\mathbb{E}_{p(\mathbf(x))}\mathcal{L}(\mathbf{x})$ with$p(\mathbf{x})$ some unknown data distribution and $\mathcal{L}(\cdot)$ a lossfunction. However, since PGD generates attack samples independently for eachdata sample based on $\mathcal{L}(\cdot)$, the procedure does not necessarilylead to good generalization in terms of risk optimization. In this paper, weachieve the goal by proposing distributionally adversarial attack (DAA), aframework to solve an optimal {\em adversarial-data distribution}, a perturbeddistribution that satisfies the $L_\infty$ constraint but deviates from theoriginal data distribution to increase the generalization risk maximally.Algorithmically, DAA performs optimization on the space of potential datadistributions, which introduces direct dependency between all data points whengenerating adversarial samples. DAA is evaluated by attacking state-of-the-artdefense models, including the adversarially-trained models provided by {\em MITMadryLab}. Notably, DAA ranks {\em the first place} on MadryLab's white-boxleaderboards, reducing the accuracy of their secret MNIST model to $88.79\%$(with $l_\infty$ perturbations of $\epsilon = 0.3$) and the accuracy of theirsecret CIFAR model to $44.71\%$ (with $l_\infty$ perturbations of $\epsilon =8.0$). Code for the experiments is released on\url{https://github.com/tianzheng4/Distributionally-Adversarial-Attack}.

PointCloud Saliency Maps

  3D point-cloud recognition with PointNet and its variants has receivedremarkable progress. A missing ingredient, however, is the ability toautomatically evaluate point-wise importance w.r.t.\! classificationperformance, which is usually reflected by a saliency map. A saliency map is animportant tool as it allows one to perform further processes on point-clouddata. In this paper, we propose a novel way of characterizing critical pointsand segments to build point-cloud saliency maps. Our method assigns each pointa score reflecting its contribution to the model-recognition loss. The saliencymap explicitly explains which points are the key for model recognition.Furthermore, aggregations of highly-scored points indicate importantsegments/subsets in a point-cloud. Our motivation for constructing a saliencymap is by point dropping, which is a non-differentiable operator. To overcomethis issue, we approximate point-dropping with a differentiable procedure ofshifting points towards the cloud centroid. Consequently, each saliency scorecan be efficiently measured by the corresponding gradient of the loss w.r.t thepoint under the spherical coordinates. Extensive evaluations on severalstate-of-the-art point-cloud recognition models, including PointNet, PointNet++and DGCNN, demonstrate the veracity and generality of our proposed saliencymap. Code for experiments is released on\url{https://github.com/tianzheng4/PointCloud-Saliency-Maps}.

Is PGD-Adversarial Training Necessary? Alternative Training via a  Soft-Quantization Network with Noisy-Natural Samples Only

  Recent work on adversarial attack and defense suggests that PGD is auniversal $l_\infty$ first-order attack, and PGD adversarial training cansignificantly improve network robustness against a wide range of first-order$l_\infty$-bounded attacks, represented as the state-of-the-art defense method.However, an obvious weakness of PGD adversarial training is itshighly-computational cost in generating adversarial samples, making itcomputationally infeasible for large and high-resolution real datasets such asthe ImageNet dataset. In addition, recent work also has suggested a simple"close-form" solution to a robust model on MNIST. Therefore, a natural questionraised is that is PGD adversarial training really necessary for robust defense?In this paper, we give a negative answer by proposing a training paradigm thatis comparable to PGD adversarial training on several standard datasets, whileonly using noisy-natural samples. Specifically, we reformulate the min-maxobjective in PGD adversarial training by a problem to minimize the originalnetwork loss plus $l_1$ norms of its gradients w.r.t. the inputs. For the$l_1$-norm loss, we propose a computationally-feasible solution by embedding adifferentiable soft-quantization layer after the network input layer. We showformally that the soft-quantization layer trained with noisy-natural samples isan alternative approach to minimizing the $l_1$-gradient norms as in PGDadversarial training. Extensive empirical evaluations on standard datasets showthat our proposed models are comparable to PGD-adversarially-trained modelsunder PGD and BPDA attacks. Remarkably, our method achieves a 24X speed-up onMNIST while maintaining a comparable defensive ability, and for the first timefine-tunes a robust Imagenet model within only two days. Code is provided on\url{https://github.com/tianzheng4/Noisy-Training-Soft-Quantization}

Band gap and band alignment prediction of nitride based semiconductors  using machine learning

  Nitride has been drawing much attention due to its wide range of applicationsin optoelectronics and remains plenty of room for materials design anddiscovery. Here, a large set of nitrides have been designed, with their bandgap and alignment being studied by first-principles calculations combined withmachine learning. Band gap and band offset against wurtzite GaN accuratelycalculated by the combination of screened hybrid functional of HSE and DFT-PBEwere used to train and test machine learning models. After comparison amongdifferent techniques of machine learning, when elemental properties are takenas features, support vector regression (SVR) with radial kernel performs bestfor predicting both band gap and band offset with prediction root mean squareerror (RMSE) of 0.298 eV and 0.183 eV, respectively. The former is within HSEcalculation uncertainty and the latter is small enough to provide reliablepredictions. Additionally, when band gap calculated by DFT-PBE was added intothe feature space, band gap prediction RMSE decreases to 0.099 eV. Through afeature engineering algorithm, elemental feature space based band gapprediction RMSE further drops by around 0.005 eV and the relative importance ofelemental properties for band gap prediction was revealed. Finally, band gapand band offset of all designed nitrides were predicted and two trends werenoticed that as the number of cation types increases, band gap tends to narrowdown while band offset tends to go up. The predicted results will be a usefulguidance for precise investigation on nitride engineering.

