A Remark on Nonlinear Dirac Equations

  For a $n$-dimensional spin manifold $M$ with a fixed spin structure and a
spinor bundle $\Sigma M$, we prove an $\epsilon$-regularity theorem for weak
solutions to the nonlinear Dirac equation of cubic nonlinearity. This, in
particular, answers a regularity question raised by Chen-Jost-Wang when $n=2$.


Dependent Hierarchical Normalized Random Measures for Dynamic Topic
  Modeling

  We develop dependent hierarchical normalized random measures and apply them
to dynamic topic modeling. The dependency arises via superposition, subsampling
and point transition on the underlying Poisson processes of these measures. The
measures used include normalised generalised Gamma processes that demonstrate
power law properties, unlike Dirichlet processes used previously in dynamic
topic modeling. Inference for the model includes adapting a recently developed
slice sampler to directly manipulate the underlying Poisson process.
Experiments performed on news, blogs, academic and Twitter collections
demonstrate the technique gives superior perplexity over a number of previous
models.


Second-Order Adversarial Attack and Certifiable Robustness

  We propose a powerful second-order attack method that outperforms existing
attack methods on reducing the accuracy of state-of-the-art defense models
based on adversarial training. The effectiveness of our attack method motivates
an investigation of provable robustness of a defense model. To this end, we
introduce a framework that allows one to obtain a certifiable lower bound on
the prediction accuracy against adversarial examples. We conduct experiments to
show the effectiveness of our attack method. At the same time, our defense
models obtain higher accuracies compared to previous works under our proposed
attack.


Mechanism of cellular effect directly induced by magnetic nanoparticles
  under magnetic fields

  The interaction of magnetic nanoparticles (MNPs) with various magnetic fields
could directly induce cellular effects. Many scattered investigations have got
involved in these cellular effects, analyzed their relative mechanisms and
extended their biomedical uses in magnetic hyperthermia and cell regulation.
This review reports these cellular effects and their important applications in
biomedical area. More importantly, we highlight the underlying mechanisms
behind these direct cellular effects in the review from the thermal energy and
mechanical force. Recently, some physical analyses showed that the mechanisms
of heat and mechanical force in cellular effects are controversial. Although
the physical principle plays an important role in these cellular effects, some
chemical reactions such as free radical reaction also existed in the
interaction of MNPs with magnetic fields, which provides the possible
explanation for the current controversy. It's anticipated that the review here
could provide readers a deeper understanding of mechanisms of how MNPs
contribute to the direct cellular effects and thus their biomedical
applications under various magnetic fields.


Continuous-Time Flows for Efficient Inference and Density Estimation

  Two fundamental problems in unsupervised learning are efficient inference for
latent-variable models and robust density estimation based on large amounts of
unlabeled data. Algorithms for the two tasks, such as normalizing flows and
generative adversarial networks (GANs), are often developed independently. In
this paper, we propose the concept of {\em continuous-time flows} (CTFs), a
family of diffusion-based methods that are able to asymptotically approach a
target distribution. Distinct from normalizing flows and GANs, CTFs can be
adopted to achieve the above two goals in one framework, with theoretical
guarantees. Our framework includes distilling knowledge from a CTF for
efficient inference, and learning an explicit energy-based distribution with
CTFs for density estimation. Both tasks rely on a new technique for
distribution matching within amortized learning. Experiments on various tasks
demonstrate promising performance of the proposed CTF framework, compared to
related techniques.


A Unified Particle-Optimization Framework for Scalable Bayesian Sampling

  There has been recent interest in developing scalable Bayesian sampling
methods such as stochastic gradient MCMC (SG-MCMC) and Stein variational
gradient descent (SVGD) for big-data analysis. A standard SG-MCMC algorithm
simulates samples from a discrete-time Markov chain to approximate a target
distribution, thus samples could be highly correlated, an undesired property
for SG-MCMC. In contrary, SVGD directly optimizes a set of particles to
approximate a target distribution, and thus is able to obtain good
approximations with relatively much fewer samples. In this paper, we propose a
principle particle-optimization framework based on Wasserstein gradient flows
to unify SG-MCMC and SVGD, and to allow new algorithms to be developed. Our
framework interprets SG-MCMC as particle optimization on the space of
probability measures, revealing a strong connection between SG-MCMC and SVGD.
The key component of our framework is several particle-approximate techniques
to efficiently solve the original partial differential equations on the space
of probability measures. Extensive experiments on both synthetic data and deep
neural networks demonstrate the effectiveness and efficiency of our framework
for scalable Bayesian sampling.


Bridging the Gap between Stochastic Gradient MCMC and Stochastic
  Optimization

  Stochastic gradient Markov chain Monte Carlo (SG-MCMC) methods are Bayesian
analogs to popular stochastic optimization methods; however, this connection is
not well studied. We explore this relationship by applying simulated annealing
to an SGMCMC algorithm. Furthermore, we extend recent SG-MCMC methods with two
key components: i) adaptive preconditioners (as in ADAgrad or RMSprop), and ii)
adaptive element-wise momentum weights. The zero-temperature limit gives a
novel stochastic optimization method with adaptive element-wise momentum
weights, while conventional optimization methods only have a shared, static
momentum weight. Under certain assumptions, our theoretical analysis suggests
the proposed simulated annealing approach converges close to the global optima.
Experiments on several deep neural network models show state-of-the-art results
compared to related stochastic optimization algorithms.


Stochastic Gradient MCMC with Stale Gradients

  Stochastic gradient MCMC (SG-MCMC) has played an important role in
large-scale Bayesian learning, with well-developed theoretical convergence
properties. In such applications of SG-MCMC, it is becoming increasingly
popular to employ distributed systems, where stochastic gradients are computed
based on some outdated parameters, yielding what are termed stale gradients.
While stale gradients could be directly used in SG-MCMC, their impact on
convergence properties has not been well studied. In this paper we develop
theory to show that while the bias and MSE of an SG-MCMC algorithm depend on
the staleness of stochastic gradients, its estimation variance (relative to the
expected estimate, based on a prescribed number of samples) is independent of
it. In a simple Bayesian distributed system with SG-MCMC, where stale gradients
are computed asynchronously by a set of workers, our theory indicates a linear
speedup on the decrease of estimation variance w.r.t. the number of workers.
Experiments on synthetic data and deep neural networks validate our theory,
demonstrating the effectiveness and scalability of SG-MCMC with stale
gradients.


On the Convergence of Stochastic Gradient MCMC Algorithms with
  High-Order Integrators

  Recent advances in Bayesian learning with large-scale data have witnessed
emergence of stochastic gradient MCMC algorithms (SG-MCMC), such as stochastic
gradient Langevin dynamics (SGLD), stochastic gradient Hamiltonian MCMC
(SGHMC), and the stochastic gradient thermostat. While finite-time convergence
properties of the SGLD with a 1st-order Euler integrator have recently been
studied, corresponding theory for general SG-MCMCs has not been explored. In
this paper we consider general SG-MCMCs with high-order integrators, and
develop theory to analyze finite-time convergence properties and their
asymptotic invariant measures. Our theoretical results show faster convergence
rates and more accurate invariant measures for SG-MCMCs with higher-order
integrators. For example, with the proposed efficient 2nd-order symmetric
splitting integrator, the {\em mean square error} (MSE) of the posterior
average for the SGHMC achieves an optimal convergence rate of $L^{-4/5}$ at $L$
iterations, compared to $L^{-2/3}$ for the SGHMC and SGLD with 1st-order Euler
integrators. Furthermore, convergence results of decreasing-step-size SG-MCMCs
are also developed, with the same convergence rates as their fixed-step-size
counterparts for a specific decreasing sequence. Experiments on both synthetic
and real datasets verify our theory, and show advantages of the proposed method
in two large-scale real applications.


A Convergence Analysis for A Class of Practical Variance-Reduction
  Stochastic Gradient MCMC

  Stochastic gradient Markov Chain Monte Carlo (SG-MCMC) has been developed as
a flexible family of scalable Bayesian sampling algorithms. However, there has
been little theoretical analysis of the impact of minibatch size to the
algorithm's convergence rate. In this paper, we prove that under a limited
computational budget/time, a larger minibatch size leads to a faster decrease
of the mean squared error bound (thus the fastest one corresponds to using full
gradients), which motivates the necessity of variance reduction in SG-MCMC.
Consequently, by borrowing ideas from stochastic optimization, we propose a
practical variance-reduction technique for SG-MCMC, that is efficient in both
computation and storage. We develop theory to prove that our algorithm induces
a faster convergence rate than standard SG-MCMC. A number of large-scale
experiments, ranging from Bayesian learning of logistic regression to deep
neural networks, validate the theory and demonstrate the superiority of the
proposed variance-reduction SG-MCMC framework.


Particle Optimization in Stochastic Gradient MCMC

  Stochastic gradient Markov chain Monte Carlo (SG-MCMC) has been increasingly
popular in Bayesian learning due to its ability to deal with large data. A
standard SG-MCMC algorithm simulates samples from a discretized-time Markov
chain to approximate a target distribution. However, the samples are typically
highly correlated due to the sequential generation process, an undesired
property in SG-MCMC. In contrary, Stein variational gradient descent (SVGD)
directly optimizes a set of particles, and it is able to approximate a target
distribution with much fewer samples. In this paper, we propose a novel method
to directly optimize particles (or samples) in SG-MCMC from scratch.
Specifically, we propose efficient methods to solve the corresponding
Fokker-Planck equation on the space of probability distributions, whose
solution (i.e., a distribution) is approximated by particles. Through our
framework, we are able to show connections of SG-MCMC to SVGD, as well as the
seemly unrelated generative-adversarial-net framework. Under certain
relaxations, particle optimization in SG-MCMC can be interpreted as an
extension of standard SVGD with momentum.


Stochastic Particle-Optimization Sampling and the Non-Asymptotic
  Convergence Theory

  Particle-optimization sampling (POS) is a recently developed technique to
generate high-quality samples from a target distribution by iteratively
updating a set of interactive particles. A representative algorithm is the
Stein variational gradient descent (SVGD). Though obtaining significant
empirical success, the {\em non-asymptotic} convergence behavior of SVGD
remains unknown. In this paper, we generalize POS to a stochasticity setting by
injecting random noise in particle updates, called stochastic
particle-optimization sampling (SPOS). Standard SVGD can be regarded as a
special case of our framework. Notably, for the first time, we develop
non-asymptotic convergence theory for the SPOS framework (which includes SVGD),
characterizing the bias of a sample approximation w.r.t. the numbers of
particles and iterations under both convex- and noncovex-energy-function
settings. Remarkably, we provide theoretical understand of a pitfall of SVGD
that can be avoided in the proposed SPOS framework, i.e., particles tent to
collapse to a local mode in SVGD under some particular conditions. Our theory
is based on the analysis of nonlinear stochastic differential equations, which
serves as an extension and a complemented development to the asymptotic
convergence theory for SVGD such as [Liu17].


Variance Reduction in Stochastic Particle-Optimization Sampling

  Stochastic particle-optimization sampling (SPOS) is a recently-developed
scalable Bayesian sampling framework that unifies stochastic gradient MCMC
(SG-MCMC) and Stein variational gradient descent (SVGD) algorithms based on
Wasserstein gradient flows. With a rigorous non-asymptotic convergence theory
developed recently, SPOS avoids the particle-collapsing pitfall of SVGD.
Nevertheless, variance reduction in SPOS has never been studied. In this paper,
we bridge the gap by presenting several variance-reduction techniques for SPOS.
Specifically, we propose three variants of variance-reduced SPOS, called SAGA
particle-optimization sampling (SAGA-POS), SVRG particle-optimization sampling
(SVRG-POS) and a variant of SVRG-POS which avoids full gradient computations,
denoted as SVRG-POS$^+$. Importantly, we provide non-asymptotic convergence
guarantees for these algorithms in terms of 2-Wasserstein metric and analyze
their complexities. Remarkably, the results show our algorithms yield better
convergence rates than existing variance-reduced variants of stochastic
Langevin dynamics, even though more space is required to store the particles in
training. Our theory well aligns with experimental results on both synthetic
and real datasets.


Self-Adversarially Learned Bayesian Sampling

  Scalable Bayesian sampling is playing an important role in modern machine
learning, especially in the fast-developed unsupervised-(deep)-learning models.
While tremendous progresses have been achieved via scalable Bayesian sampling
such as stochastic gradient MCMC (SG-MCMC) and Stein variational gradient
descent (SVGD), the generated samples are typically highly correlated.
Moreover, their sample-generation processes are often criticized to be
inefficient. In this paper, we propose a novel self-adversarial learning
framework that automatically learns a conditional generator to mimic the
behavior of a Markov kernel (transition kernel). High-quality samples can be
efficiently generated by direct forward passes though a learned generator. Most
importantly, the learning process adopts a self-learning paradigm, requiring no
information on existing Markov kernels, e.g., knowledge of how to draw samples
from them. Specifically, our framework learns to use current samples, either
from the generator or pre-provided training data, to update the generator such
that the generated samples progressively approach a target distribution, thus
it is called self-learning. Experiments on both synthetic and real datasets
verify advantages of our framework, outperforming related methods in terms of
both sampling efficiency and sample quality.


Adversarial Learning of a Sampler Based on an Unnormalized Distribution

  We investigate adversarial learning in the case when only an unnormalized
form of the density can be accessed, rather than samples. With insights so
garnered, adversarial learning is extended to the case for which one has access
to an unnormalized form u(x) of the target density function, but no samples.
Further, new concepts in GAN regularization are developed, based on learning
from samples or from u(x). The proposed method is compared to alternative
approaches, with encouraging results demonstrated across a range of
applications, including deep soft Q-learning.


Improving Sequence-to-Sequence Learning via Optimal Transport

  Sequence-to-sequence models are commonly trained via maximum likelihood
estimation (MLE). However, standard MLE training considers a word-level
objective, predicting the next word given the previous ground-truth partial
sentence. This procedure focuses on modeling local syntactic patterns, and may
fail to capture long-range semantic structure. We present a novel solution to
alleviate these issues. Our approach imposes global sequence-level guidance via
new supervision based on optimal transport, enabling the overall
characterization and preservation of semantic features. We further show that
this method can be understood as a Wasserstein gradient flow trying to match
our model to the ground truth sequence distribution. Extensive experiments are
conducted to validate the utility of the proposed approach, showing consistent
improvements over a wide variety of NLP tasks, including machine translation,
abstractive text summarization, and image captioning.


ALICE: Towards Understanding Adversarial Learning for Joint Distribution
  Matching

  We investigate the non-identifiability issues associated with bidirectional
adversarial training for joint distribution matching. Within a framework of
conditional entropy, we propose both adversarial and non-adversarial approaches
to learn desirable matched joint distributions for unsupervised and supervised
tasks. We unify a broad family of adversarial models as joint distribution
matching problems. Our approach stabilizes learning of unsupervised
bidirectional adversarial learning methods. Further, we introduce an extension
for semi-supervised learning tasks. Theoretical results are validated in
synthetic data and real-world applications.


Sequence Generation with Guider Network

  Sequence generation with reinforcement learning (RL) has received significant
attention recently. However, a challenge with such methods is the sparse-reward
problem in the RL training process, in which a scalar guiding signal is often
only available after an entire sequence has been generated. This type of sparse
reward tends to ignore the global structural information of a sequence, causing
generation of sequences that are semantically inconsistent. In this paper, we
present a model-based RL approach to overcome this issue. Specifically, we
propose a novel guider network to model the sequence-generation environment,
which can assist next-word prediction and provide intermediate rewards for
generator optimization. Extensive experiments show that the proposed method
leads to improved performance for both unconditional and conditional
sequence-generation tasks.


Theory of Dependent Hierarchical Normalized Random Measures

  This paper presents theory for Normalized Random Measures (NRMs), Normalized
Generalized Gammas (NGGs), a particular kind of NRM, and Dependent Hierarchical
NRMs which allow networks of dependent NRMs to be analysed. These have been
used, for instance, for time-dependent topic modelling. In this paper, we first
introduce some mathematical background of completely random measures (CRMs) and
their construction from Poisson processes, and then introduce NRMs and NGGs.
Slice sampling is also introduced for posterior inference. The dependency
operators in Poisson processes and for the corresponding CRMs and NRMs is then
introduced and Posterior inference for the NGG presented. Finally, we give
dependency and composition results when applying these operators to NRMs so
they can be used in a network with hierarchical and dependent relations.


High-Order Stochastic Gradient Thermostats for Bayesian Learning of Deep
  Models

  Learning in deep models using Bayesian methods has generated significant
attention recently. This is largely because of the feasibility of modern
Bayesian methods to yield scalable learning and inference, while maintaining a
measure of uncertainty in the model parameters. Stochastic gradient MCMC
algorithms (SG-MCMC) are a family of diffusion-based sampling methods for
large-scale Bayesian learning. In SG-MCMC, multivariate stochastic gradient
thermostats (mSGNHT) augment each parameter of interest, with a momentum and a
thermostat variable to maintain stationary distributions as target posterior
distributions. As the number of variables in a continuous-time diffusion
increases, its numerical approximation error becomes a practical bottleneck, so
better use of a numerical integrator is desirable. To this end, we propose use
of an efficient symmetric splitting integrator in mSGNHT, instead of the
traditional Euler integrator. We demonstrate that the proposed scheme is more
accurate, robust, and converges faster. These properties are demonstrated to be
desirable in Bayesian deep learning. Extensive experiments on two canonical
models and their deep extensions demonstrate that the proposed scheme improves
general Bayesian posterior sampling, particularly for deep models.


Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural
  Networks

  Effective training of deep neural networks suffers from two main issues. The
first is that the parameter spaces of these models exhibit pathological
curvature. Recent methods address this problem by using adaptive
preconditioning for Stochastic Gradient Descent (SGD). These methods improve
convergence by adapting to the local geometry of parameter space. A second
issue is overfitting, which is typically addressed by early stopping. However,
recent work has demonstrated that Bayesian model averaging mitigates this
problem. The posterior can be sampled by using Stochastic Gradient Langevin
Dynamics (SGLD). However, the rapidly changing curvature renders default SGLD
methods inefficient. Here, we propose combining adaptive preconditioners with
SGLD. In support of this idea, we give theoretical properties on asymptotic
convergence and predictive risk. We also provide empirical results for Logistic
Regression, Feedforward Neural Nets, and Convolutional Neural Nets,
demonstrating that our preconditioned SGLD method gives state-of-the-art
performance on these models.


Towards Unifying Hamiltonian Monte Carlo and Slice Sampling

  We unify slice sampling and Hamiltonian Monte Carlo (HMC) sampling,
demonstrating their connection via the Hamiltonian-Jacobi equation from
Hamiltonian mechanics. This insight enables extension of HMC and slice sampling
to a broader family of samplers, called Monomial Gamma Samplers (MGS). We
provide a theoretical analysis of the mixing performance of such samplers,
proving that in the limit of a single parameter, the MGS draws decorrelated
samples from the desired target distribution. We further show that as this
parameter tends toward this limit, performance gains are achieved at a cost of
increasing numerical difficulty and some practical convergence issues. Our
theoretical results are validated with synthetic data and real-world
applications.


Nonlinear Statistical Learning with Truncated Gaussian Graphical Models

  We introduce the truncated Gaussian graphical model (TGGM) as a novel
framework for designing statistical models for nonlinear learning. A TGGM is a
Gaussian graphical model (GGM) with a subset of variables truncated to be
nonnegative. The truncated variables are assumed latent and integrated out to
induce a marginal model. We show that the variables in the marginal model are
non-Gaussian distributed and their expected relations are nonlinear. We use
expectation-maximization to break the inference of the nonlinear model into a
sequence of TGGM inference problems, each of which is efficiently solved by
using the properties and numerical methods of multivariate Gaussian
distributions. We use the TGGM to design models for nonlinear regression and
classification, with the performances of these models demonstrated on extensive
benchmark datasets and compared to state-of-the-art competing results.


Scalable Bayesian Non-Negative Tensor Factorization for Massive Count
  Data

  We present a Bayesian non-negative tensor factorization model for
count-valued tensor data, and develop scalable inference algorithms (both batch
and online) for dealing with massive tensors. Our generative model can handle
overdispersed counts as well as infer the rank of the decomposition. Moreover,
leveraging a reparameterization of the Poisson distribution as a multinomial
facilitates conjugacy in the model and enables simple and efficient Gibbs
sampling and variational Bayes (VB) inference updates, with a computational
cost that only depends on the number of nonzeros in the tensor. The model also
provides a nice interpretability for the factors; in our model, each factor
corresponds to a "topic". We develop a set of online inference algorithms that
allow further scaling up the model to massive tensors, for which batch
inference methods may be infeasible. We apply our framework on diverse
real-world applications, such as \emph{multiway} topic modeling on a scientific
publications database, analyzing a political science data set, and analyzing a
massive household transactions data set.


Nonparametric Bayesian Topic Modelling with the Hierarchical Pitman-Yor
  Processes

  The Dirichlet process and its extension, the Pitman-Yor process, are
stochastic processes that take probability distributions as a parameter. These
processes can be stacked up to form a hierarchical nonparametric Bayesian
model. In this article, we present efficient methods for the use of these
processes in this hierarchical context, and apply them to latent variable
models for text analytics. In particular, we propose a general framework for
designing these Bayesian models, which are called topic models in the computer
science community. We then propose a specific nonparametric Bayesian topic
model for modelling text from social media. We focus on tweets (posts on
Twitter) in this article due to their ease of access. We find that our
nonparametric model performs better than existing parametric models in both
goodness of fit and real world applications.


Twitter-Network Topic Model: A Full Bayesian Treatment for Social
  Network and Text Modeling

  Twitter data is extremely noisy -- each tweet is short, unstructured and with
informal language, a challenge for current topic modeling. On the other hand,
tweets are accompanied by extra information such as authorship, hashtags and
the user-follower network. Exploiting this additional information, we propose
the Twitter-Network (TN) topic model to jointly model the text and the social
network in a full Bayesian nonparametric way. The TN topic model employs the
hierarchical Poisson-Dirichlet processes (PDP) for text modeling and a Gaussian
process random function model for social network modeling. We show that the TN
topic model significantly outperforms several existing nonparametric models due
to its flexibility. Moreover, the TN topic model enables additional informative
inference such as authors' interests, hashtag analysis, as well as leading to
further applications such as author recommendation, automatic topic labeling
and hashtag suggestion. Note our general inference framework can readily be
applied to other topic models with embedded PDP nodes.


Scalable Bayesian Learning of Recurrent Neural Networks for Language
  Modeling

  Recurrent neural networks (RNNs) have shown promising performance for
language modeling. However, traditional training of RNNs using back-propagation
through time often suffers from overfitting. One reason for this is that
stochastic optimization (used for large training sets) does not provide good
estimates of model uncertainty. This paper leverages recent advances in
stochastic gradient Markov Chain Monte Carlo (also appropriate for large
training sets) to learn weight uncertainty in RNNs. It yields a principled
Bayesian learning algorithm, adding gradient noise during training (enhancing
exploration of the model-parameter space) and model averaging when testing.
Extensive experiments on various RNN models and across a broad range of
applications demonstrate the superiority of the proposed approach over
stochastic optimization.


Stochastic Gradient Monomial Gamma Sampler

  Recent advances in stochastic gradient techniques have made it possible to
estimate posterior distributions from large datasets via Markov Chain Monte
Carlo (MCMC). However, when the target posterior is multimodal, mixing
performance is often poor. This results in inadequate exploration of the
posterior distribution. A framework is proposed to improve the sampling
efficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. A
generalized kinetic function is leveraged, delivering superior stationary
mixing, especially for multimodal distributions. Techniques are also discussed
to overcome the practical issues introduced by this generalization. It is shown
that the proposed approach is better at exploring complex multimodal posterior
distributions, as demonstrated on multiple applications and in comparison with
other stochastic gradient MCMC methods.


On Connecting Stochastic Gradient MCMC and Differential Privacy

  Significant success has been realized recently on applying machine learning
to real-world applications. There have also been corresponding concerns on the
privacy of training data, which relates to data security and confidentiality
issues. Differential privacy provides a principled and rigorous privacy
guarantee on machine learning models. While it is common to design a model
satisfying a required differential-privacy property by injecting noise, it is
generally hard to balance the trade-off between privacy and utility. We show
that stochastic gradient Markov chain Monte Carlo (SG-MCMC) -- a class of
scalable Bayesian posterior sampling algorithms proposed recently -- satisfies
strong differential privacy with carefully chosen step sizes. We develop theory
on the performance of the proposed differentially-private SG-MCMC method. We
conduct experiments to support our analysis and show that a standard SG-MCMC
sampler without any modification (under a default setting) can reach
state-of-the-art performance in terms of both privacy and utility on Bayesian
learning.


Learning Structural Weight Uncertainty for Sequential Decision-Making

  Learning probability distributions on the weights of neural networks (NNs)
has recently proven beneficial in many applications. Bayesian methods, such as
Stein variational gradient descent (SVGD), offer an elegant framework to reason
about NN model uncertainty. However, by assuming independent Gaussian priors
for the individual NN weights (as often applied), SVGD does not impose prior
knowledge that there is often structural information (dependence) among
weights. We propose efficient posterior learning of structural weight
uncertainty, within an SVGD framework, by employing matrix variate Gaussian
priors on NN parameters. We further investigate the learned structural
uncertainty in sequential decision-making problems, including contextual
bandits and reinforcement learning. Experiments on several synthetic and real
datasets indicate the superiority of our model, compared with state-of-the-art
methods.


Policy Optimization as Wasserstein Gradient Flows

  Policy optimization is a core component of reinforcement learning (RL), and
most existing RL methods directly optimize parameters of a policy based on
maximizing the expected total reward, or its surrogate. Though often achieving
encouraging empirical success, its underlying mathematical principle on {\em
policy-distribution} optimization is unclear. We place policy optimization into
the space of probability measures, and interpret it as Wasserstein gradient
flows. On the probability-measure space, under specified circumstances, policy
optimization becomes a convex problem in terms of distribution optimization. To
make optimization feasible, we develop efficient algorithms by numerically
solving the corresponding discrete gradient flows. Our technique is applicable
to several RL settings, and is related to many state-of-the-art
policy-optimization algorithms. Empirical results verify the effectiveness of
our framework, often obtaining better performance compared to related
algorithms.


Cyclical Stochastic Gradient MCMC for Bayesian Deep Learning

  The posteriors over neural network weights are high dimensional and
multimodal. Each mode typically characterizes a meaningfully different
representation of the data. We develop Cyclical Stochastic Gradient MCMC
(SG-MCMC) to automatically explore such distributions. In particular, we
propose a cyclical stepsize schedule, where larger steps discover new modes,
and smaller steps characterize each mode. We prove that our proposed learning
rate schedule provides faster convergence to samples from a stationary
distribution than SG-MCMC with standard decaying schedules. Moreover, we
provide extensive experimental results to demonstrate the effectiveness of
cyclical SG-MCMC in learning complex multimodal distributions, especially for
fully Bayesian inference with modern deep neural networks.


Scalable Thompson Sampling via Optimal Transport

  Thompson sampling (TS) is a class of algorithms for sequential
decision-making, which requires maintaining a posterior distribution over a
model. However, calculating exact posterior distributions is intractable for
all but the simplest models. Consequently, efficient computation of an
approximate posterior distribution is a crucial problem for scalable TS with
complex models, such as neural networks. In this paper, we use distribution
optimization techniques to approximate the posterior distribution, solved via
Wasserstein gradient flows. Based on the framework, a principled
particle-optimization algorithm is developed for TS to approximate the
posterior efficiently. Our approach is scalable and does not make explicit
distribution assumptions on posterior approximations. Extensive experiments on
both synthetic data and real large-scale data demonstrate the superior
performance of the proposed methods.


Topic-Guided Variational Autoencoders for Text Generation

  We propose a topic-guided variational autoencoder (TGVAE) model for text
generation. Distinct from existing variational autoencoder (VAE) based
approaches, which assume a simple Gaussian prior for the latent code, our model
specifies the prior as a Gaussian mixture model (GMM) parametrized by a neural
topic module. Each mixture component corresponds to a latent topic, which
provides guidance to generate sentences under the topic. The neural topic
module and the VAE-based neural sequence module in our model are learned
jointly. In particular, a sequence of invertible Householder transformations is
applied to endow the approximate posterior of the latent code with high
flexibility during model inference. Experimental results show that our TGVAE
outperforms alternative approaches on both unconditional and conditional text
generation, which can generate semantically-meaningful sentences with various
topics.


Earliness-Aware Deep Convolutional Networks for Early Time Series
  Classification

  We present Earliness-Aware Deep Convolutional Networks (EA-ConvNets), an
end-to-end deep learning framework, for early classification of time series
data. Unlike most existing methods for early classification of time series
data, that are designed to solve this problem under the assumption of the
availability of a good set of pre-defined (often hand-crafted) features, our
framework can jointly perform feature learning (by learning a deep hierarchy of
\emph{shapelets} capturing the salient characteristics in each time series),
along with a dynamic truncation model to help our deep feature learning
architecture focus on the early parts of each time series. Consequently, our
framework is able to make highly reliable early predictions, outperforming
various state-of-the-art methods for early time series classification, while
also being competitive when compared to the state-of-the-art time series
classification algorithms that work with \emph{fully observed} time series
data. To the best of our knowledge, the proposed framework is the first to
perform data-driven (deep) feature learning in the context of early
classification of time series data. We perform a comprehensive set of
experiments, on several benchmark data sets, which demonstrate that our method
yields significantly better predictions than various state-of-the-art methods
designed for early time series classification. In addition to obtaining high
accuracies, our experiments also show that the learned deep shapelets based
features are also highly interpretable and can help gain better understanding
of the underlying characteristics of time series data.


Zero-Shot Learning via Class-Conditioned Deep Generative Models

  We present a deep generative model for learning to predict classes not seen
at training time. Unlike most existing methods for this problem, that represent
each class as a point (via a semantic embedding), we represent each seen/unseen
class using a class-specific latent-space distribution, conditioned on class
attributes. We use these latent-space distributions as a prior for a supervised
variational autoencoder (VAE), which also facilitates learning highly
discriminative feature representations for the inputs. The entire framework is
learned end-to-end using only the seen-class training data. The model infers
corresponding attributes of a test image by maximizing the VAE lower bound; the
inferred attributes may be linked to labels not seen when training. We further
extend our model to a (1) semi-supervised/transductive setting by leveraging
unlabeled unseen-class data via an unsupervised learning module, and (2)
few-shot learning where we also have a small number of labeled inputs from the
unseen classes. We compare our model with several state-of-the-art methods
through a comprehensive set of experiments on a variety of benchmark data sets.


Distributionally Adversarial Attack

  Recent work on adversarial attack has shown that Projected Gradient Descent
(PGD) Adversary is a universal first-order adversary, and the classifier
adversarially trained by PGD is robust against a wide range of first-order
attacks. It is worth noting that the original objective of an attack/defense
model relies on a data distribution $p(\mathbf{x})$, typically in the form of
risk maximization/minimization, e.g.,
$\max/\min\mathbb{E}_{p(\mathbf(x))}\mathcal{L}(\mathbf{x})$ with
$p(\mathbf{x})$ some unknown data distribution and $\mathcal{L}(\cdot)$ a loss
function. However, since PGD generates attack samples independently for each
data sample based on $\mathcal{L}(\cdot)$, the procedure does not necessarily
lead to good generalization in terms of risk optimization. In this paper, we
achieve the goal by proposing distributionally adversarial attack (DAA), a
framework to solve an optimal {\em adversarial-data distribution}, a perturbed
distribution that satisfies the $L_\infty$ constraint but deviates from the
original data distribution to increase the generalization risk maximally.
Algorithmically, DAA performs optimization on the space of potential data
distributions, which introduces direct dependency between all data points when
generating adversarial samples. DAA is evaluated by attacking state-of-the-art
defense models, including the adversarially-trained models provided by {\em MIT
MadryLab}. Notably, DAA ranks {\em the first place} on MadryLab's white-box
leaderboards, reducing the accuracy of their secret MNIST model to $88.79\%$
(with $l_\infty$ perturbations of $\epsilon = 0.3$) and the accuracy of their
secret CIFAR model to $44.71\%$ (with $l_\infty$ perturbations of $\epsilon =
8.0$). Code for the experiments is released on
\url{https://github.com/tianzheng4/Distributionally-Adversarial-Attack}.


PointCloud Saliency Maps

  3D point-cloud recognition with PointNet and its variants has received
remarkable progress. A missing ingredient, however, is the ability to
automatically evaluate point-wise importance w.r.t.\! classification
performance, which is usually reflected by a saliency map. A saliency map is an
important tool as it allows one to perform further processes on point-cloud
data. In this paper, we propose a novel way of characterizing critical points
and segments to build point-cloud saliency maps. Our method assigns each point
a score reflecting its contribution to the model-recognition loss. The saliency
map explicitly explains which points are the key for model recognition.
Furthermore, aggregations of highly-scored points indicate important
segments/subsets in a point-cloud. Our motivation for constructing a saliency
map is by point dropping, which is a non-differentiable operator. To overcome
this issue, we approximate point-dropping with a differentiable procedure of
shifting points towards the cloud centroid. Consequently, each saliency score
can be efficiently measured by the corresponding gradient of the loss w.r.t the
point under the spherical coordinates. Extensive evaluations on several
state-of-the-art point-cloud recognition models, including PointNet, PointNet++
and DGCNN, demonstrate the veracity and generality of our proposed saliency
map. Code for experiments is released on
\url{https://github.com/tianzheng4/PointCloud-Saliency-Maps}.


Is PGD-Adversarial Training Necessary? Alternative Training via a
  Soft-Quantization Network with Noisy-Natural Samples Only

  Recent work on adversarial attack and defense suggests that PGD is a
universal $l_\infty$ first-order attack, and PGD adversarial training can
significantly improve network robustness against a wide range of first-order
$l_\infty$-bounded attacks, represented as the state-of-the-art defense method.
However, an obvious weakness of PGD adversarial training is its
highly-computational cost in generating adversarial samples, making it
computationally infeasible for large and high-resolution real datasets such as
the ImageNet dataset. In addition, recent work also has suggested a simple
"close-form" solution to a robust model on MNIST. Therefore, a natural question
raised is that is PGD adversarial training really necessary for robust defense?
In this paper, we give a negative answer by proposing a training paradigm that
is comparable to PGD adversarial training on several standard datasets, while
only using noisy-natural samples. Specifically, we reformulate the min-max
objective in PGD adversarial training by a problem to minimize the original
network loss plus $l_1$ norms of its gradients w.r.t. the inputs. For the
$l_1$-norm loss, we propose a computationally-feasible solution by embedding a
differentiable soft-quantization layer after the network input layer. We show
formally that the soft-quantization layer trained with noisy-natural samples is
an alternative approach to minimizing the $l_1$-gradient norms as in PGD
adversarial training. Extensive empirical evaluations on standard datasets show
that our proposed models are comparable to PGD-adversarially-trained models
under PGD and BPDA attacks. Remarkably, our method achieves a 24X speed-up on
MNIST while maintaining a comparable defensive ability, and for the first time
fine-tunes a robust Imagenet model within only two days. Code is provided on
\url{https://github.com/tianzheng4/Noisy-Training-Soft-Quantization}


Band gap and band alignment prediction of nitride based semiconductors
  using machine learning

  Nitride has been drawing much attention due to its wide range of applications
in optoelectronics and remains plenty of room for materials design and
discovery. Here, a large set of nitrides have been designed, with their band
gap and alignment being studied by first-principles calculations combined with
machine learning. Band gap and band offset against wurtzite GaN accurately
calculated by the combination of screened hybrid functional of HSE and DFT-PBE
were used to train and test machine learning models. After comparison among
different techniques of machine learning, when elemental properties are taken
as features, support vector regression (SVR) with radial kernel performs best
for predicting both band gap and band offset with prediction root mean square
error (RMSE) of 0.298 eV and 0.183 eV, respectively. The former is within HSE
calculation uncertainty and the latter is small enough to provide reliable
predictions. Additionally, when band gap calculated by DFT-PBE was added into
the feature space, band gap prediction RMSE decreases to 0.099 eV. Through a
feature engineering algorithm, elemental feature space based band gap
prediction RMSE further drops by around 0.005 eV and the relative importance of
elemental properties for band gap prediction was revealed. Finally, band gap
and band offset of all designed nitrides were predicted and two trends were
noticed that as the number of cation types increases, band gap tends to narrow
down while band offset tends to go up. The predicted results will be a useful
guidance for precise investigation on nitride engineering.


