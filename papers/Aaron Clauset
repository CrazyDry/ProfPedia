Rejoinder of "Estimating the historical and future probabilities of
  large terrorist events" by Aaron Clauset and Ryan Woodard

  Rejoinder of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Discussion of "Estimating the historical and future probabilities of
  large terrorist events" by Aaron Clauset and Ryan Woodard

  Discussion of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Discussion of "Estimating the historical and future probabilities of
  large terrorist event" by Aaron Clauset and Ryan Woodard

  Discussion of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Discussion of "Estimating the historical and future probabilities of
  large terrorist events" by Aaron Clauset and Ryan Woodard

  Discussion of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Discussion of "Estimating the historical and future probabilities of
  large terrorist events" by Aaron Clauset and Ryan Woodard

  Discussion of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Discussion of "Estimating the historical and future probabilities of
  large terrorist events" by Aaron Clauset and Ryan Woodard

  Discussion of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Discussion of "Estimating the historical and future probabilities of
  large terrorist events" by Aaron Clauset and Ryan Woodard

  Discussion of "Estimating the historical and future probabilities of large
terrorist events" by Aaron Clauset and Ryan Woodard [arXiv:1209.0089].


Evolutionary Model of Species Body Mass Diversification

  We present a quantitative model for the biological evolution of species body
masses within large groups of related species, e.g., terrestrial mammals, in
which body mass M evolves according to branching (speciation), multiplicative
diffusion, and an extinction probability that increases logarithmically with
mass. We describe this evolution in terms of a convection-diffusion-reaction
equation for ln M. The steady-state behavior is in good agreement with
empirical data on recent terrestrial mammals, and the time-dependent behavior
also agrees with data on extinct mammal species between 95 - 50 Myr ago.


On the frequency and severity of interstate wars

  Lewis Fry Richardson argued that the frequency and severity of deadly
conflicts of all kinds, from homicides to interstate wars and everything in
between, followed universal statistical patterns: their frequency followed a
simple Poisson arrival process and their severity followed a simple power-law
distribution. Although his methods and data in the mid-20th century were
neither rigorous nor comprehensive, his insights about violent conflicts have
endured. In this chapter, using modern statistical methods and data, we show
that Richardson's original claims appear largely correct, with a few caveats.
These facts place important constraints on our understanding of the underlying
mechanisms that produce individual wars and periods of peace, and shed light on
the persistent debate about trends in conflict.


How Do Networks Become Navigable?

  Networks created and maintained by social processes, such as the human
friendship network and the World Wide Web, appear to exhibit the property of
navigability: namely, not only do short paths exist between any pair of nodes,
but such paths can easily be found using only local information. It has been
shown that for networks with an underlying metric, algorithms using only local
information perform extremely well if there is a power-law distribution of link
lengths. However, it is not clear why or how real networks might develop this
distribution. In this paper we define a decentralized ``rewiring'' process,
inspired by surfers on the Web, in which each surfer attempts to travel from
their home page to a random destination, and updates the outgoing link from
their home page if this journey takes too long. We show that this process does
indeed cause the link length distribution to converge to a power law, achieving
a routing time of O(log^2 n) on networks of size n. We also study finite-size
effects on the optimal exponent, and show that it converges polylogarithmically
slowly as the lattice size goes to infinity.


Traceroute sampling makes random graphs appear to have power law degree
  distributions

  The topology of the Internet has typically been measured by sampling
traceroutes, which are roughly shortest paths from sources to destinations. The
resulting measurements have been used to infer that the Internet's degree
distribution is scale-free; however, many of these measurements have relied on
sampling traceroutes from a small number of sources. It was recently argued
that sampling in this way can introduce a fundamental bias in the degree
distribution, for instance, causing random (Erdos-Renyi) graphs to appear to
have power law degree distributions. We explain this phenomenon analytically
using differential equations to model the growth of a breadth-first tree in a
random graph G(n,p=c/n) of average degree c, and show that sampling from a
single source gives an apparent power law degree distribution P(k) ~ 1/k for k
< c.


Why Mapping the Internet is Hard

  Despite great effort spent measuring topological features of large networks
like the Internet, it was recently argued that sampling based on taking paths
through the network (e.g., traceroutes) introduces a fundamental bias in the
observed degree distribution. We examine this bias analytically and
experimentally. For classic random graphs with mean degree c, we show
analytically that traceroute sampling gives an observed degree distribution
P(k) ~ 1/k for k < c, even though the underlying degree distribution is
Poisson. For graphs whose degree distributions have power-law tails P(k) ~
k^-alpha, the accuracy of traceroute sampling is highly sensitive to the
population of low-degree vertices. In particular, when the graph has a large
excess (i.e., many more edges than vertices), traceroute sampling can
significantly misestimate alpha.


Accuracy and Scaling Phenomena in Internet Mapping

  A great deal of effort has been spent measuring topological features of the
Internet. However, it was recently argued that sampling based on taking paths
or traceroutes through the network from a small number of sources introduces a
fundamental bias in the observed degree distribution. We examine this bias
analytically and experimentally. For Erdos-Renyi random graphs with mean degree
c, we show analytically that traceroute sampling gives an observed degree
distribution P(k) ~ 1/k for k < c, even though the underlying degree
distribution is Poisson. For graphs whose degree distributions have power-law
tails P(k) ~ k^-alpha, traceroute sampling from a small number of sources can
significantly underestimate the value of \alpha when the graph has a large
excess (i.e., many more edges than vertices). We find that in order to obtain a
good estimate of alpha it is necessary to use a number of sources which grows
linearly in the average degree of the underlying graph. Based on these
observations we comment on the accuracy of the published values of alpha for
the Internet.


Scale Invariance in Global Terrorism

  Traditional analyses of international terrorism have not sought to explain
the emergence of rare but extremely severe events. Using the tools of extremal
statistics to analyze the set of terrorist attacks worldwide between 1968 and
2004, as compiled by the National Memorial Institute for the Prevention of
Terrorism (MIPT), we find that the relationship between the frequency and
severity of terrorist attacks exhibits the ``scale-free'' property with an
exponent of close to two. This property is robust, even when we restrict our
analysis to events from a single type of weapon or events within major
industrialized nations. We also find that the distribution of event sizes has
changed very little over the past 37 years, suggesting that scale invariance is
an inherent feature of global terrorism.


Finding local community structure in networks

  Although the inference of global community structure in networks has recently
become a topic of great interest in the physics community, all such algorithms
require that the graph be completely known. Here, we define both a measure of
local community structure and an algorithm that infers the hierarchy of
communities that enclose a given vertex by exploring the graph one vertex at a
time. This algorithm runs in time O(d*k^2) for general graphs when $d$ is the
mean degree and k is the number of vertices to be explored. For graphs where
exploring a new vertex is time-consuming, the running time is linear, O(k). We
show that on computer-generated graphs this technique compares favorably to
algorithms that require global knowledge. We also use this algorithm to extract
meaningful local clustering information in the large recommender network of an
online retailer and show the existence of mesoscopic structure.


Scale Invariance in Road Networks

  We study the topological and geographic structure of the national road
networks of the United States, England and Denmark. By transforming these
networks into their dual representation, where roads are vertices and an edge
connects two vertices if the corresponding roads ever intersect, we show that
they exhibit both topological and geographic scale invariance. That is, we show
that for sufficiently large geographic areas, the dual degree distribution
follows a power law with exponent 2.2 < alpha < 2.4, and that journeys,
regardless of their length, have a largely identical structure. To explain
these properties, we introduce and analyze a simple fractal model of road
placement that reproduces the observed structure, and suggests a testable
connection between the scaling exponent alpha and the fractal dimensions
governing the placement of roads and intersections.


On the Frequency of Severe Terrorist Events

  In the spirit of Richardson's original (1948) study of the statistics of
deadly conflicts, we study the frequency and severity of terrorist attacks
worldwide since 1968. We show that these events are uniformly characterized by
the phenomenon of scale invariance, i.e., the frequency scales as an inverse
power of the severity, P(x) ~ x^-alpha. We find that this property is a robust
feature of terrorism, persisting when we control for economic development of
the target country, the type of weapon used, and even for short time-scales.
Further, we show that the center of the distribution oscillates slightly with a
period of roughly tau ~ 13 years, that there exist significant temporal
correlations in the frequency of severe events, and that current models of
event incidence cannot account for these variations or the scale invariance
property of global terrorism. Finally, we describe a simple toy model for the
generation of these statistics, and briefly discuss its implications.


Structural Inference of Hierarchies in Networks

  One property of networks that has received comparatively little attention is
hierarchy, i.e., the property of having vertices that cluster together in
groups, which then join to form groups of groups, and so forth, up through all
levels of organization in the network. Here, we give a precise definition of
hierarchical structure, give a generic model for generating arbitrary
hierarchical structure in a random graph, and describe a statistically
principled way to learn the set of hierarchical features that most plausibly
explain a particular real-world network. By applying this approach to two
example networks, we demonstrate its advantages for the interpretation of
network data, the annotation of graphs with edge, vertex and community
properties, and the generation of generic null models for further hypothesis
testing.


How many species have mass M?

  Within large taxonomic assemblages, the number of species with adult body
mass M is characterized by a broad but asymmetric distribution, with the
largest mass being orders of magnitude larger than the typical mass. This
canonical shape can be explained by cladogenetic diffusion that is bounded
below by a hard limit on viable species mass and above by extinction risks that
increase weakly with mass. Here we introduce and analytically solve a
simplified cladogenetic diffusion model. When appropriately parameterized, the
diffusion-reaction equation predicts mass distributions that are in good
agreement with data on 4002 terrestrial mammal from the late Quaternary and
8617 extant bird species. Under this model, we show that a specific tradeoff
between the strength of within-lineage drift toward larger masses (Cope's rule)
and the increased risk of extinction from increased mass is necessary to
produce realistic mass distributions for both taxa. We then make several
predictions about the evolution of avian species masses.


The evolution and distribution of species body size

  The distribution of species body size within taxonomic groups exhibits a
heavy right-tail extending over many orders of magnitude, where most species
are significantly larger than the smallest species. We provide a simple model
of cladogenetic diffusion over evolutionary time that omits explicit mechanisms
for inter-specific competition and other microevolutionary processes yet fully
explains the shape of this distribution. We estimate the model's parameters
from fossil data and find that it robustly reproduces the distribution of 4002
mammal species from the late Quaternary. The observed fit suggests that the
asymmetric distribution arises from a fundamental tradeoff between the
short-term selective advantages (Cope's rule) and long-term selective risks of
increased species body size, in the presence of a taxon-specific lower limit on
body size.


Comment on Yu et al., "High Quality Binary Protein Interaction Map of
  the Yeast Interactome Network." Science 322, 104 (2008)

  We test the claim by Yu et al. -- presented in Science 322, 104 (2008) --
that the degree distribution of the yeast (Saccharomyces cerevisiae)
protein-interaction network is best approximated by a power law. Yu et al.
consider three versions of this network. In all three cases, however, we find
the most likely power-law model of the data is distinct from and incompatible
with the one given by Yu et al. Only one network admits good statistical
support for any power law, and in that case, the power law explains only the
distribution of the upper 10% of node degrees. These results imply that there
is considerably more structure present in the yeast interactome than suggested
by Yu et al., and that these networks should probably not be called "scale
free."


A generalized aggregation-disintegration model for the frequency of
  severe terrorist attacks

  We present and analyze a model of the frequency of severe terrorist attacks,
which generalizes the recently proposed model of Johnson et al. This model,
which is based on the notion of self-organized criticality and which describes
how terrorist cells might aggregate and disintegrate over time, predicts that
the distribution of attack severities should follow a power-law form with an
exponent of alpha=5/2. This prediction is in good agreement with current
empirical estimates for terrorist attacks worldwide, which give alpha=2.4 \pm
0.2, and which we show is independent of certain details of the model. We close
by discussing the utility of this model for understanding terrorism and the
behavior of terrorist organizations, and mention several productive ways it
could be extended mathematically or tested empirically.


The developmental dynamics of terrorist organizations

  We identify robust statistical patterns in the frequency and severity of
violent attacks by terrorist organizations as they grow and age. Using
group-level static and dynamic analyses of terrorist events worldwide from
1968-2008 and a simulation model of organizational dynamics, we show that the
production of violent events tends to accelerate with increasing size and
experience. This coupling of frequency, experience and size arises from a
fundamental positive feedback loop in which attacks lead to growth which leads
to increased production of new attacks. In contrast, event severity is
independent of both size and experience. Thus larger, more experienced
organizations are more deadly because they attack more frequently, not because
their attacks are more deadly, and large events are equally likely to come from
large and small organizations. These results hold across political ideologies
and time, suggesting that the frequency and severity of terrorism may be
constrained by fundamental processes.


Persistence and periodicity in a dynamic proximity network

  The topology of social networks can be understood as being inherently
dynamic, with edges having a distinct position in time. Most characterizations
of dynamic networks discretize time by converting temporal information into a
sequence of network "snapshots" for further analysis. Here we study a highly
resolved data set of a dynamic proximity network of 66 individuals. We show
that the topology of this network evolves over a very broad distribution of
time scales, that its behavior is characterized by strong periodicities driven
by external calendar cycles, and that the conversion of inherently
continuous-time data into a sequence of snapshots can produce highly biased
estimates of network structure. We suggest that dynamic social networks exhibit
a natural time scale \Delta_{nat}, and that the best conversion of such dynamic
data to a discrete sequence of networks is done at this natural rate.


Scoring dynamics across professional team sports: tempo, balance and
  predictability

  Despite growing interest in quantifying and modeling the scoring dynamics
within professional sports games, relative little is known about what patterns
or principles, if any, cut across different sports. Using a comprehensive data
set of scoring events in nearly a dozen consecutive seasons of college and
professional (American) football, professional hockey, and professional
basketball, we identify several common patterns in scoring dynamics. Across
these sports, scoring tempo---when scoring events occur---closely follows a
common Poisson process, with a sport-specific rate. Similarly, scoring
balance---how often a team wins an event---follows a common Bernoulli process,
with a parameter that effectively varies with the size of the lead. Combining
these processes within a generative model of gameplay, we find they both
reproduce the observed dynamics in all four sports and accurately predict game
outcomes. These results demonstrate common dynamical patterns underlying
within-game scoring dynamics across professional team sports, and suggest
specific mechanisms for driving them. We close with a brief discussion of the
implications of our results for several popular hypotheses about sports
dynamics.


Friends FTW! Friendship, Collaboration and Competition in Halo: Reach

  How important are friendships in determining success by individuals and teams
in complex collaborative environments? By combining a novel data set containing
the dynamics of millions of ad hoc teams from the popular multiplayer online
first person shooter Halo: Reach with survey data on player demographics, play
style, psychometrics and friendships derived from an anonymous online survey,
we investigate the impact of friendship on collaborative and competitive
performance. In addition to finding significant differences in player behavior
across these variables, we find that friendships exert a strong influence,
leading to both improved individual and team performance--even after
controlling for the overall expertise of the team--and increased pro-social
behaviors. Players also structure their in-game activities around social
opportunities, and as a result hidden friendship ties can be accurately
inferred directly from behavioral time series. Virtual environments that enable
such friendship effects will thus likely see improved collaboration and
competition.


Detectability thresholds and optimal algorithms for community structure
  in dynamic networks

  We study the fundamental limits on learning latent community structure in
dynamic networks. Specifically, we study dynamic stochastic block models where
nodes change their community membership over time, but where edges are
generated independently at each time step. In this setting (which is a special
case of several existing models), we are able to derive the detectability
threshold exactly, as a function of the rate of change and the strength of the
communities. Below this threshold, we claim that no algorithm can identify the
communities better than chance. We then give two algorithms that are optimal in
the sense that they succeed all the way down to this limit. The first uses
belief propagation (BP), which gives asymptotically optimal accuracy, and the
second is a fast spectral clustering algorithm, based on linearizing the BP
equations. We verify our analytic and algorithmic results via numerical
simulation, and close with a brief discussion of extensions and open questions.


Power-law distributions in empirical data

  Power-law distributions occur in many situations of scientific interest and
have significant consequences for our understanding of natural and man-made
phenomena. Unfortunately, the detection and characterization of power laws is
complicated by the large fluctuations that occur in the tail of the
distribution -- the part of the distribution representing large but rare events
-- and by the difficulty of identifying the range over which power-law behavior
holds. Commonly used methods for analyzing power-law data, such as
least-squares fitting, can produce substantially inaccurate estimates of
parameters for power-law distributions, and even in cases where such methods
return accurate answers they are still unsatisfactory because they give no
indication of whether the data obey a power law at all. Here we present a
principled statistical framework for discerning and quantifying power-law
behavior in empirical data. Our approach combines maximum-likelihood fitting
methods with goodness-of-fit tests based on the Kolmogorov-Smirnov statistic
and likelihood ratios. We evaluate the effectiveness of the approach with tests
on synthetic data and give critical comparisons to previous approaches. We also
apply the proposed methods to twenty-four real-world data sets from a range of
different disciplines, each of which has been conjectured to follow a power-law
distribution. In some cases we find these conjectures to be consistent with the
data while in others the power law is ruled out.


Hierarchical structure and the prediction of missing links in networks

  Networks have in recent years emerged as an invaluable tool for describing
and quantifying complex systems in many branches of science. Recent studies
suggest that networks often exhibit hierarchical organization, where vertices
divide into groups that further subdivide into groups of groups, and so forth
over multiple scales. In many cases these groups are found to correspond to
known functional units, such as ecological niches in food webs, modules in
biochemical networks (protein interaction networks, metabolic networks, or
genetic regulatory networks), or communities in social networks. Here we
present a general technique for inferring hierarchical structure from network
data and demonstrate that the existence of hierarchy can simultaneously explain
and quantitatively reproduce many commonly observed topological properties of
networks, such as right-skewed degree distributions, high clustering
coefficients, and short path lengths. We further show that knowledge of
hierarchical structure can be used to predict missing connections in partially
known networks with high accuracy, and for more general network structures than
competing techniques. Taken together, our results suggest that hierarchy is a
central organizing principle of complex networks, capable of offering insight
into many network phenomena.


The performance of modularity maximization in practical contexts

  Although widely used in practice, the behavior and accuracy of the popular
module identification technique called modularity maximization is not well
understood in practical contexts. Here, we present a broad characterization of
its performance in such situations. First, we revisit and clarify the
resolution limit phenomenon for modularity maximization. Second, we show that
the modularity function Q exhibits extreme degeneracies: it typically admits an
exponential number of distinct high-scoring solutions and typically lacks a
clear global maximum. Third, we derive the limiting behavior of the maximum
modularity Q_max for one model of infinitely modular networks, showing that it
depends strongly both on the size of the network and on the number of modules
it contains. Finally, using three real-world metabolic networks as examples, we
show that the degenerate solutions can fundamentally disagree on many, but not
all, partition properties such as the composition of the largest modules and
the distribution of module sizes. These results imply that the output of any
modularity maximization procedure should be interpreted cautiously in
scientific contexts. They also explain why many heuristics are often successful
at finding high-scoring partitions in practice and why different heuristics can
disagree on the modular structure of the same network. We conclude by
discussing avenues for mitigating some of these behaviors, such as combining
information from many degenerate solutions or using generative models.


Estimating the historical and future probabilities of large terrorist
  events

  Quantities with right-skewed distributions are ubiquitous in complex social
systems, including political conflict, economics and social networks, and these
systems sometimes produce extremely large events. For instance, the 9/11
terrorist events produced nearly 3000 fatalities, nearly six times more than
the next largest event. But, was this enormous loss of life statistically
unlikely given modern terrorism's historical record? Accurately estimating the
probability of such an event is complicated by the large fluctuations in the
empirical distribution's upper tail. We present a generic statistical algorithm
for making such estimates, which combines semi-parametric models of tail
behavior and a nonparametric bootstrap. Applied to a global database of
terrorist events, we estimate the worldwide historical probability of observing
at least one 9/11-sized or larger event since 1968 to be 11-35%. These results
are robust to conditioning on global variations in economic development,
domestic versus international events, the type of weapon used and a truncated
history that stops at 1998. We then use this procedure to make a data-driven
statistical forecast of at least one similar event over the next decade.


How large should whales be?

  The evolution and distribution of species body sizes for terrestrial mammals
is well-explained by a macroevolutionary tradeoff between short-term selective
advantages and long-term extinction risks from increased species body size,
unfolding above the 2g minimum size induced by thermoregulation in air. Here,
we consider whether this same tradeoff, formalized as a constrained
convection-reaction-diffusion system, can also explain the sizes of fully
aquatic mammals, which have not previously been considered. By replacing the
terrestrial minimum with a pelagic one, at roughly 7000g, the terrestrial
mammal tradeoff model accurately predicts, with no tunable parameters, the
observed body masses of all extant cetacean species, including the 175,000,000g
Blue Whale. This strong agreement between theory and data suggests that a
universal macroevolutionary tradeoff governs body size evolution for all
mammals, regardless of their habitat. The dramatic sizes of cetaceans can thus
be attributed mainly to the increased convective heat loss is water, which
shifts the species size distribution upward and pushes its right tail into
ranges inaccessible to terrestrial mammals. Under this macroevolutionary
tradeoff, the largest expected species occurs where the rate at which
smaller-bodied species move up into large-bodied niches approximately equals
the rate at which extinction removes them.


Structure and inference in annotated networks

  For many networks of scientific interest we know both the connections of the
network and information about the network nodes, such as the age or gender of
individuals in a social network, geographic location of nodes in the Internet,
or cellular function of nodes in a gene regulatory network. Here we demonstrate
how this "metadata" can be used to improve our analysis and understanding of
network structure. We focus in particular on the problem of community detection
in networks and develop a mathematically principled approach that combines a
network and its metadata to detect communities more accurately than can be done
with either alone. Crucially, the method does not assume that the metadata are
correlated with the communities we are trying to find. Instead the method
learns whether a correlation exists and correctly uses or ignores the metadata
depending on whether they contain useful information. The learned correlations
are also of interest in their own right, allowing us to make predictions about
the community membership of nodes whose network connections are unknown. We
demonstrate our method on synthetic networks with known structure and on
real-world networks, large and small, drawn from social, biological, and
technological domains.


Power-law distributions in binned empirical data

  Many man-made and natural phenomena, including the intensity of earthquakes,
population of cities and size of international wars, are believed to follow
power-law distributions. The accurate identification of power-law patterns has
significant consequences for correctly understanding and modeling complex
systems. However, statistical evidence for or against the power-law hypothesis
is complicated by large fluctuations in the empirical distribution's tail, and
these are worsened when information is lost from binning the data. We adapt the
statistically principled framework for testing the power-law hypothesis,
developed by Clauset, Shalizi and Newman, to the case of binned data. This
approach includes maximum-likelihood fitting, a hypothesis test based on the
Kolmogorov--Smirnov goodness-of-fit statistic and likelihood ratio tests for
comparing against alternative explanations. We evaluate the effectiveness of
these methods on synthetic binned data with known structure, quantify the loss
of statistical power due to binning, and apply the methods to twelve real-world
binned data sets with heavy-tailed patterns.


Characterizing the structural diversity of complex networks across
  domains

  The structure of complex networks has been of interest in many scientific and
engineering disciplines over the decades. A number of studies in the field have
been focused on finding the common properties among different kinds of networks
such as heavy-tail degree distribution, small-worldness and modular structure
and they have tried to establish a theory of structural universality in complex
networks. However, there is no comprehensive study of network structure across
a diverse set of domains in order to explain the structural diversity we
observe in the real-world networks. In this paper, we study 986 real-world
networks of diverse domains ranging from ecological food webs to online social
networks along with 575 networks generated from four popular network models.
Our study utilizes a number of machine learning techniques such as random
forest and confusion matrix in order to show the relationships among network
domains in terms of network structure. Our results indicate that there are some
partitions of network categories in which networks are hard to distinguish
based purely on network structure. We have found that these partitions of
network categories tend to have similar underlying functions, constraints
and/or generative mechanisms of networks even though networks in the same
partition have different origins, e.g., biological processes, results of
engineering by human being, etc. This suggests that the origin of a network,
whether it's biological, technological or social, may not necessarily be a
decisive factor of the formation of similar network structure. Our findings
shed light on the possible direction along which we could uncover the hidden
principles for the structural diversity of complex networks.


Finding community structure in very large networks

  The discovery and analysis of community structure in networks is a topic of
considerable recent interest within the physics community, but most methods
proposed so far are unsuitable for very large networks because of their
computational cost. Here we present a hierarchical agglomeration algorithm for
detecting community structure which is faster than many competing algorithms:
its running time on a network with n vertices and m edges is O(m d log n) where
d is the depth of the dendrogram describing the community structure. Many
real-world networks are sparse and hierarchical, with m ~ n and d ~ log n, in
which case our algorithm runs in essentially linear time, O(n log^2 n). As an
example of the application of this algorithm we use it to analyze a network of
items for sale on the web-site of a large online retailer, items in the network
being linked if they are frequently purchased by the same buyer. The network
has more than 400,000 vertices and 2 million edges. We show that our algorithm
can extract meaningful communities from this network, revealing large-scale
patterns present in the purchasing habits of customers.


Adapting to Non-stationarity with Growing Expert Ensembles

  When dealing with time series with complex non-stationarities, low
retrospective regret on individual realizations is a more appropriate goal than
low prospective risk in expectation. Online learning algorithms provide
powerful guarantees of this form, and have often been proposed for use with
non-stationary processes because of their ability to switch between different
forecasters or ``experts''. However, existing methods assume that the set of
experts whose forecasts are to be combined are all given at the start, which is
not plausible when dealing with a genuinely historical or evolutionary system.
We show how to modify the ``fixed shares'' algorithm for tracking the best
expert to cope with a steadily growing set of experts, obtained by fitting new
models to new data as it becomes available, and obtain regret bounds for the
growing ensemble.


Environmental structure and competitive scoring advantages in team
  competitions

  In most professional sports, the structure of the environment is kept neutral
so that scoring imbalances may be attributed to differences in team skill. It
thus remains unknown what impact structural heterogeneities can have on scoring
dynamics and producing competitive advantages. Applying a generative model of
scoring dynamics to roughly 10 million team competitions drawn from an online
game, we quantify the relationship between a competition's structure and its
scoring dynamics. Despite wide structural variations, we find the same
three-phase pattern in the tempo of events observed in many sports. Tempo and
balance are highly predictable from a competition's structural features alone
and teams exploit environmental heterogeneities for sustained competitive
advantage. The most balanced competitions are associated with specific
environmental heterogeneities, not from equally skilled teams. These results
shed new light on the principles of balanced competition, and illustrate the
potential of online game data for investigating social dynamics and
competition.


Predicting sports scoring dynamics with restoration and anti-persistence

  Professional team sports provide an excellent domain for studying the
dynamics of social competitions. These games are constructed with simple,
well-defined rules and payoffs that admit a high-dimensional set of possible
actions and nontrivial scoring dynamics. The resulting gameplay and efforts to
predict its evolution are the object of great interest to both sports
professionals and enthusiasts. In this paper, we consider two online prediction
problems for team sports:~given a partially observed game Who will score next?
and ultimately Who will win? We present novel interpretable generative models
of within-game scoring that allow for dependence on lead size (restoration) and
on the last team to score (anti-persistence). We then apply these models to
comprehensive within-game scoring data for four sports leagues over a ten year
period. By assessing these models' relative goodness-of-fit we shed new light
on the underlying mechanisms driving the observed scoring dynamics of each
sport. Furthermore, in both predictive tasks, the performance of our models
consistently outperforms baselines models, and our models make quantitative
assessments of the latent team skill, over time.


Detecting change points in the large-scale structure of evolving
  networks

  Interactions among people or objects are often dynamic in nature and can be
represented as a sequence of networks, each providing a snapshot of the
interactions over a brief period of time. An important task in analyzing such
evolving networks is change-point detection, in which we both identify the
times at which the large-scale pattern of interactions changes fundamentally
and quantify how large and what kind of change occurred. Here, we formalize for
the first time the network change-point detection problem within an online
probabilistic learning framework and introduce a method that can reliably solve
it. This method combines a generalized hierarchical random graph model with a
Bayesian hypothesis test to quantitatively determine if, when, and precisely
how a change point has occurred. We analyze the detectability of our method
using synthetic data with known change points of different types and
magnitudes, and show that this method is more accurate than several previously
used alternatives. Applied to two high-resolution evolving social networks,
this method identifies a sequence of change points that align with known
external "shocks" to these networks.


Efficiently inferring community structure in bipartite networks

  Bipartite networks are a common type of network data in which there are two
types of vertices, and only vertices of different types can be connected. While
bipartite networks exhibit community structure like their unipartite
counterparts, existing approaches to bipartite community detection have
drawbacks, including implicit parameter choices, loss of information through
one-mode projections, and lack of interpretability. Here we solve the community
detection problem for bipartite networks by formulating a bipartite stochastic
block model, which explicitly includes vertex type information and may be
trivially extended to $k$-partite networks. This bipartite stochastic block
model yields a projection-free and statistically principled method for
community detection that makes clear assumptions and parameter choices and
yields interpretable results. We demonstrate this model's ability to
efficiently and accurately find community structure in synthetic bipartite
networks with known structure and in real-world bipartite networks with unknown
structure, and we characterize its performance in practical contexts.


Adapting the Stochastic Block Model to Edge-Weighted Networks

  We generalize the stochastic block model to the important case in which edges
are annotated with weights drawn from an exponential family distribution. This
generalization introduces several technical difficulties for model estimation,
which we solve using a Bayesian approach. We introduce a variational algorithm
that efficiently approximates the model's posterior distribution for dense
graphs. In specific numerical experiments on edge-weighted networks, this
weighted stochastic block model outperforms the common approach of first
applying a single threshold to all weights and then applying the classic
stochastic block model, which can obscure latent block structure in networks.
This model will enable the recovery of latent structure in a broader range of
network data than was previously possible.


A unified view of generative models for networks: models, methods,
  opportunities, and challenges

  Research on probabilistic models of networks now spans a wide variety of
fields, including physics, sociology, biology, statistics, and machine
learning. These efforts have produced a diverse ecology of models and methods.
Despite this diversity, many of these models share a common underlying
structure: pairwise interactions (edges) are generated with probability
conditional on latent vertex attributes. Differences between models generally
stem from different philosophical choices about how to learn from data or
different empirically-motivated goals. The highly interdisciplinary nature of
work on these generative models, however, has inhibited the development of a
unified view of their similarities and differences. For instance, novel
theoretical models and optimization techniques developed in machine learning
are largely unknown within the social and biological sciences, which have
instead emphasized model interpretability. Here, we describe a unified view of
generative models for networks that draws together many of these disparate
threads and highlights the fundamental similarities and differences that span
these fields. We then describe a number of opportunities and challenges for
future work that are revealed by this view.


Environmental Changes and the Dynamics of Musical Identity

  Musical tastes reflect our unique values and experiences, our relationships
with others, and the places where we live. But as each of these things changes,
do our tastes also change to reflect the present, or remain fixed, reflecting
our past? Here, we investigate how where a person lives shapes their musical
preferences, using geographic relocation to construct quasi-natural experiments
that measure short- and long-term effects. Analyzing comprehensive data on over
16 million users on Spotify, we show that relocation within the United States
has only a small impact on individuals' tastes, which remain more similar to
those of their past environments. We then show that the age gap between a
person and the music they consume indicates that adolescence, and likely their
environment during these years, shapes their lifelong musical tastes. Our
results demonstrate the robustness of individuals' musical identity, and shed
new light on the development of preferences.


On the Bias of Traceroute Sampling; or, Power-law Degree Distributions
  in Regular Graphs

  Understanding the structure of the Internet graph is a crucial step for
building accurate network models and designing efficient algorithms for
Internet applications. Yet, obtaining its graph structure is a surprisingly
difficult task, as edges cannot be explicitly queried. Instead, empirical
studies rely on traceroutes to build what are essentially single-source,
all-destinations, shortest-path trees. These trees only sample a fraction of
the network's edges, and a recent paper by Lakhina et al. found empirically
that the resuting sample is intrinsically biased. For instance, the observed
degree distribution under traceroute sampling exhibits a power law even when
the underlying degree distribution is Poisson.
  In this paper, we study the bias of traceroute sampling systematically, and,
for a very general class of underlying degree distributions, calculate the
likely observed distributions explicitly. To do this, we use a continuous-time
realization of the process of exposing the BFS tree of a random graph with a
given degree distribution, calculate the expected degree distribution of the
tree, and show that it is sharply concentrated. As example applications of our
machinery, we show how traceroute sampling finds power-law degree distributions
in both delta-regular and Poisson-distributed random graphs. Thus, our work
puts the observations of Lakhina et al. on a rigorous footing, and extends them
to nearly arbitrary degree distributions.


Detecting Friendship Within Dynamic Online Interaction Networks

  In many complex social systems, the timing and frequency of interactions
between individuals are observable but friendship ties are hidden. Recovering
these hidden ties, particularly for casual users who are relatively less
active, would enable a wide variety of friendship-aware applications in domains
where labeled data are often unavailable, including online advertising and
national security. Here, we investigate the accuracy of multiple statistical
features, based either purely on temporal interaction patterns or on the
cooperative nature of the interactions, for automatically extracting latent
social ties. Using self-reported friendship and non-friendship labels derived
from an anonymous online survey, we learn highly accurate predictors for
recovering hidden friendships within a massive online data set encompassing 18
billion interactions among 17 million individuals of the popular online game
Halo: Reach. We find that the accuracy of many features improves as more data
accumulates, and cooperative features are generally reliable. However,
periodicities in interaction time series are sufficient to correctly classify
95% of ties, even for casual users. These results clarify the nature of
friendship in online social environments and suggest new opportunities and new
privacy concerns for friendship-aware applications that do not require the
disclosure of private friendship information.


Social Network Dynamics in a Massive Online Game: Network Turnover,
  Non-densification, and Team Engagement in Halo Reach

  Online multiplayer games are a popular form of social interaction, used by
hundreds of millions of individuals. However, little is known about the social
networks within these online games, or how they evolve over time. Understanding
human social dynamics within massive online games can shed new light on social
interactions in general and inform the development of more engaging systems.
Here, we study a novel, large friendship network, inferred from nearly 18
billion social interactions over 44 weeks between 17 million individuals in the
popular online game Halo: Reach. This network is one of the largest, most
detailed temporal interaction networks studied to date, and provides a novel
perspective on the dynamics of online friendship networks, as opposed to mere
interaction graphs. Initially, this network exhibits strong structural turnover
and decays rapidly from a peak size. In the following period, however, both
network size and turnover stabilize, producing a dynamic structural
equilibrium. In contrast to other studies, we find that the Halo friendship
network is non-densifying: both the mean degree and the average pairwise
distance are stable, suggesting that densification cannot occur when
maintaining friendships is costly. Finally, players with greater long-term
engagement exhibit stronger local clustering, suggesting a group-level social
engagement process. These results demonstrate the utility of online games for
studying social networks, shed new light on empirical temporal graph patterns,
and clarify the claims of universality of network densification.


Learning Latent Block Structure in Weighted Networks

  Community detection is an important task in network analysis, in which we aim
to learn a network partition that groups together vertices with similar
community-level connectivity patterns. By finding such groups of vertices with
similar structural roles, we extract a compact representation of the network's
large-scale structure, which can facilitate its scientific interpretation and
the prediction of unknown or future interactions. Popular approaches, including
the stochastic block model, assume edges are unweighted, which limits their
utility by throwing away potentially useful information. We introduce the
`weighted stochastic block model' (WSBM), which generalizes the stochastic
block model to networks with edge weights drawn from any exponential family
distribution. This model learns from both the presence and weight of edges,
allowing it to discover structure that would otherwise be hidden when weights
are discarded or thresholded. We describe a Bayesian variational algorithm for
efficiently approximating this model's posterior distribution over latent block
structures. We then evaluate the WSBM's performance on both edge-existence and
edge-weight prediction tasks for a set of real-world weighted networks. In all
cases, the WSBM performs as well or better than the best alternatives on these
tasks.


Untangling the roles of parasites in food webs with generative network
  models

  Food webs represent the set of consumer-resource interactions among a set of
species that co-occur in a habitat, but most food web studies have omitted
parasites and their interactions. Recent studies have provided conflicting
evidence on whether including parasites changes food web structure, with some
suggesting that parasitic interactions are structurally distinct from those
among free-living species while others claim the opposite. Here, we describe a
principled method for understanding food web structure that combines an
efficient optimization algorithm from statistical physics called parallel
tempering with a probabilistic generalization of the empirically well-supported
food web niche model. This generative model approach allows us to rigorously
estimate the degree to which interactions that involve parasites are
statistically distinguishable from interactions among free-living species,
whether parasite niches behave similarly to free-living niches, and the degree
to which existing hypotheses about food web structure are naturally recovered.
We apply this method to the well-studied Flensburg Fjord food web and show that
while predation on parasites, concomitant predation of parasites, and parasitic
intraguild trophic interactions are largely indistinguishable from free-living
predation interactions, parasite-host interactions are different. These results
provide a powerful new tool for evaluating the impact of classes of species and
interactions on food web structure to shed new light on the roles of parasites
in food webs


Gender, Productivity, and Prestige in Computer Science Faculty Hiring
  Networks

  Women are dramatically underrepresented in computer science at all levels in
academia and account for just 15% of tenure-track faculty. Understanding the
causes of this gender imbalance would inform both policies intended to rectify
it and employment decisions by departments and individuals. Progress in this
direction, however, is complicated by the complexity and decentralized nature
of faculty hiring and the non-independence of hires. Using comprehensive data
on both hiring outcomes and scholarly productivity for 2659 tenure-track
faculty across 205 Ph.D.-granting departments in North America, we investigate
the multi-dimensional nature of gender inequality in computer science faculty
hiring through a network model of the hiring process. Overall, we find that
hiring outcomes are most directly affected by (i) the relative prestige between
hiring and placing institutions and (ii) the scholarly productivity of the
candidates. After including these, and other features, the addition of gender
did not significantly reduce modeling error. However, gender differences do
exist, e.g., in scholarly productivity, postdoctoral training rates, and in
career movements up the rankings of universities, suggesting that the effects
of gender are indirectly incorporated into hiring decisions through gender's
covariates. Furthermore, we find evidence that more highly ranked departments
recruit female faculty at higher than expected rates, which appears to inhibit
similar efforts by lower ranked departments. These findings illustrate the
subtle nature of gender inequality in faculty hiring networks and provide new
insights to the underrepresentation of women in computer science.


