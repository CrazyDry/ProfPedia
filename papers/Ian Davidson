Generalized Davidson and multidirectional-type methods for the  generalized singular value decomposition

  We propose new iterative methods for computing nontrivial extremalgeneralized singular values and vectors. The first method is a generalizedDavidson-type algorithm and the second method employs a multidirectionalsubspace expansion technique. Essential to the latter is a fast truncation stepdesigned to remove a low quality search direction and to ensure moderate growthof the search space. Both methods rely on thick restarts and may be combinedwith two different deflation approaches. We argue that the methods havemonotonic and (asymptotic) linear convergence, derive and discuss locallyoptimal expansion vectors, and explain why the fast truncation step ideallyremoves search directions orthogonal to the desired generalized singularvector. Furthermore, we identify the relation between our generalizedDavidson-type algorithm and the Jacobi--Davidson algorithm for the generalizedsingular value decomposition. Finally, we generalize several known convergenceresults for the Hermitian eigenvalue problem to the Hermitian positive definitegeneralized eigenvalue problem. Numerical experiments indicate that bothmethods are competitive.

Rank Restricted Semidefinite Matrices and Image Closedness

  We study the closure of the projection of the (nonconvex) cone of rankrestricted positive semidefinite matrices onto subsets of the matrix entries.This defines the feasible sets for semidefinite completion problems withrestrictions on the ranks. Applications include conditions for low-rankcompletions using the nuclear norm heuristic.

Minimum Message Length Clustering Using Gibbs Sampling

  The K-Mean and EM algorithms are popular in clustering and mixture modeling,due to their simplicity and ease of implementation. However, they have severalsignificant limitations. Both coverage to a local optimum of their respectiveobjective functions (ignoring the uncertainty in the model space), require theapriori specification of the number of classes/clsuters, and are inconsistent.In this work we overcome these limitations by using the Minimum Message Length(MML) principle and a variation to the K-Means/EM observation assignment andparameter calculation scheme. We maintain the simplicity of these approacheswhile constructing a Bayesian mixture modeling tool that samples/searches themodel space using a Markov Chain Monte Carlo (MCMC) sampler known as a Gibbssampler. Gibbs sampling allows us to visit each model according to itsposterior probability. Therefore, if the model space is multi-modal we willvisit all models and not get stuck in local optima. We call our approachmultiple chains at equilibrium (MCE) MML sampling.

Deep Constrained Clustering - Algorithms and Advances

  The area of constrained clustering has been extensively explored byresearchers and used by practitioners. Constrained clustering formulationsexist for popular algorithms such as k-means, mixture models, and spectralclustering but have several limitations. We explore a deep learning formulationof constrained clustering and in particular explore how it can extend the fieldof constrained clustering. We show that our formulation can not only handlestandard together/apart constraints without the well documented negativeeffects reported but can also model instance level constraints(level-of-difficulty), cluster level constraints (balancing cluster size) andtriplet constraints. The first two are new ways for domain experts to enforceguidance whilst the later importantly allows generating ordering constraintsfrom continuous side-information.

Some Advances in Role Discovery in Graphs

  Role discovery in graphs is an emerging area that allows analysis of complexgraphs in an intuitive way. In contrast to other graph prob- lems such ascommunity discovery, which finds groups of highly connected nodes, the rolediscovery problem finds groups of nodes that share similar graph topologicalstructure. However, existing work so far has two severe limitations thatprevent its use in some domains. Firstly, it is completely unsupervised whichis undesirable for a number of reasons. Secondly, most work is limited to asingle relational graph. We address both these lim- itations in an intuitiveand easy to implement alternating least squares framework. Our framework allowsconvex constraints to be placed on the role discovery problem which can provideuseful supervision. In par- ticular we explore supervision to enforce i)sparsity, ii) diversity and iii) alternativeness. We then show how to lift thiswork for multi-relational graphs. A natural representation of amulti-relational graph is an order 3 tensor (rather than a matrix) and that aTucker decomposition allows us to find complex interactions between collectionsof entities (E-groups) and the roles they play for a combination of relations(R-groups). Existing Tucker decomposition methods in tensor toolboxes are notsuited for our purpose, so we create our own algorithm that we demonstrate ispragmatically useful.

On The Equivalence of Tries and Dendrograms - Efficient Hierarchical  Clustering of Traffic Data

  The widespread use of GPS-enabled devices generates voluminous and continuousamounts of traffic data but analyzing such data for interpretable andactionable insights poses challenges. A hierarchical clustering of the tripshas many uses such as discovering shortest paths, common routes and oftentraversed areas. However, hierarchical clustering typically has time complexityof $O(n^2 \log n)$ where $n$ is the number of instances, and is difficult toscale to large data sets associated with GPS data. Furthermore, incrementalhierarchical clustering is still a developing area. Prefix trees (also calledtries) can be efficiently constructed and updated in linear time (in $n$). Weshow how a specially constructed trie can compactly store the trips and furthershow this trie is equivalent to a dendrogram that would have been built byclassic agglomerative hierarchical algorithms using a specific distance metric.This allows creating hierarchical clusterings of GPS trip data and updatingthis hierarchy in linear time. %we can extract a meaningful kernel and can alsointerpret the structure as clusterings of differing granularity as oneprogresses down the tree. We demonstrate the usefulness of our proposedapproach on a real world data set of half a million taxis' GPS traces, wellbeyond the capabilities of agglomerative clustering methods. Our work is notlimited to trip data and can be used with other data with a stringrepresentation.

The Magnetic Field Morphology of the Class 0 Protostar L1157-mm

  We present the first detection of polarization around the Class 0 low-massprotostar L1157-mm at two different wavelengths. We show polarimetric maps atlarge scales (10" resolution at 350 um) from the SHARC-II Polarimeter and atsmaller scales (1.2"-4.5" at 1.3 mm) from the Combined Array for Research inMillimeter-wave Astronomy (CARMA). The observations are consistent with eachother and show inferred magnetic field lines aligned with the outflow. TheCARMA observations suggest a full hourglass magnetic field morphology centeredabout the core; this is only the second well-defined hourglass detected arounda low-mass protostar to date. We apply two different methods to CARMApolarimetric observations to estimate the plane-of-sky magnetic fieldmagnitude, finding values of 1.4 and 3.4 mG.

Towards a spectroscopically accurate set of potentials for heavy hydride  laser cooling candidates: effective core potential calculations of BaH

  BaH (and its isotopomers) is an attractive molecular candidate for lasercooling to ultracold temperatures and a potential precursor for the productionof ultracold gases of hydrogen and deuterium. The theoretical challenge is tosimulate the laser cooling cycle as reliably as possible and this paperaddresses the generation of a highly accurate ab initio $^{2}\Sigma^+$potential for such studies. The performance of various basis sets within themulti-reference configuration-interaction (MRCI) approximation with theDavidson correction (MRCI+Q) is tested and taken to the complete basis setlimit. It is shown that the calculated molecular constants using a 46 electronEffective Core-Potential (ECP), the augmented polarized core-valence quintupletbasis set (aug-pCV5Z-PP) but only including three active electrons in the MRCIcalculation are in close agreement with the available experimental values. Thepredicted dissociation energy D$_e$ for the X$^2\Sigma^+$ state (extrapolatedto the complete basis set (CBS) limit) is 16895.12 cm$^{-1}$ (2.094 eV), whichagrees within 0.1$\%$ of a revised experimental value of $<$16910.6 cm$^{-1}$,while the calculated r$_e$ is within 0.03 pm of the experimental result.

Dense Transformer Networks

  The key idea of current deep learning methods for dense prediction is toapply a model on a regular patch centered on each pixel to make pixel-wisepredictions. These methods are limited in the sense that the patches aredetermined by network architecture instead of learned from data. In this work,we propose the dense transformer networks, which can learn the shapes and sizesof patches from data. The dense transformer networks employ an encoder-decoderarchitecture, and a pair of dense transformer modules are inserted into each ofthe encoder and decoder paths. The novelty of this work is that we providetechnical solutions for learning the shapes and sizes of patches from data andefficiently restoring the spatial correspondence required for dense prediction.The proposed dense transformer modules are differentiable, thus the entirenetwork can be trained. We apply the proposed networks on natural andbiological image segmentation tasks and show superior performance is achievedin comparison to baseline methods.

Transfer Regression via Pairwise Similarity Regularization

  Transfer learning methods address the situation where little labeled trainingdata from the "target" problem exists, but much training data from a related"source" domain is available. However, the overwhelming majority of transferlearning methods are designed for simple settings where the source and targetpredictive functions are almost identical, limiting the applicability oftransfer learning methods to real world data. We propose a novel, weaker,property of the source domain that can be transferred even when the source andtarget predictive functions diverge. Our method assumes the source and targetfunctions share a Pairwise Similarity property, where if the source functionmakes similar predictions on a pair of instances, then so will the targetfunction. We propose Pairwise Similarity Regularization Transfer, a flexiblegraph-based regularization framework which can incorporate this modelingassumption into standard supervised learning algorithms. We show how users canencode domain knowledge into our regularizer in the form of spatial continuity,pairwise "similarity constraints" and how our method can be scaled to largedata sets using the Nystrom approximation. Finally, we present positive andnegative results on real and synthetic data sets and discuss when our PairwiseSimilarity transfer assumption seems to hold in practice.

Probabilistic Formulations of Regression with Mixed Guidance

  Regression problems assume every instance is annotated (labeled) with a realvalue, a form of annotation we call \emph{strong guidance}. In order for theseannotations to be accurate, they must be the result of a precise experiment ormeasurement. However, in some cases additional \emph{weak guidance} might begiven by imprecise measurements, a domain expert or even crowd sourcing.Current formulations of regression are unable to use both types of guidance. Wepropose a regression framework that can also incorporate weak guidance based onrelative orderings, bounds, neighboring and similarity relations. Considerlearning to predict ages from portrait images, these new types of guidanceallow weaker forms of guidance such as stating a person is in their 20s or twopeople are similar in age. These types of annotations can be easier to generatethan strong guidance. We introduce a probabilistic formulation for these formsof weak guidance and show that the resulting optimization problems are convex.Our experimental results show the benefits of these formulations on severaldata sets.

Towards Fair Deep Clustering With Multi-State Protected Variables

  Fair clustering under the disparate impact doctrine requires that populationof each protected group should be approximately equal in every cluster.Previous work investigated a difficult-to-scale pre-processing step for$k$-center and $k$-median style algorithms for the special case of this problemwhen the number of protected groups is two. In this work, we consider a moregeneral and practical setting where there can be many protected groups. To thisend, we propose Deep Fair Clustering, which learns a discriminative but faircluster assignment function. The experimental results on three public datasetswith different types of protected attribute show that our approach can steadilyimprove the degree of fairness while only having minor loss in terms ofclustering quality.

On Constrained Spectral Clustering and Its Applications

  Constrained clustering has been well-studied for algorithms such as $K$-meansand hierarchical clustering. However, how to satisfy many constraints in thesealgorithmic settings has been shown to be intractable. One alternative toencode many constraints is to use spectral clustering, which remains adeveloping area. In this paper, we propose a flexible framework for constrainedspectral clustering. In contrast to some previous efforts that implicitlyencode Must-Link and Cannot-Link constraints by modifying the graph Laplacianor constraining the underlying eigenspace, we present a more natural andprincipled formulation, which explicitly encodes the constraints as part of aconstrained optimization problem. Our method offers several practicaladvantages: it can encode the degree of belief in Must-Link and Cannot-Linkconstraints; it guarantees to lower-bound how well the given constraints aresatisfied using a user-specified threshold; it can be solved deterministicallyin polynomial time through generalized eigendecomposition. Furthermore, byinheriting the objective function from spectral clustering and encoding theconstraints explicitly, much of the existing analysis of unconstrained spectralclustering techniques remains valid for our formulation. We validate theeffectiveness of our approach by empirical results on both artificial and realdatasets. We also demonstrate an innovative use of encoding large number ofconstraints: transfer learning via constraints.

A Reconstruction Error Formulation for Semi-Supervised Multi-task and  Multi-view Learning

  A significant challenge to make learning techniques more suitable for generalpurpose use is to move beyond i) complete supervision, ii) low dimensionaldata, iii) a single task and single view per instance. Solving these challengesallows working with "Big Data" problems that are typically high dimensionalwith multiple (but possibly incomplete) labelings and views. While other workhas addressed each of these problems separately, in this paper we show how toaddress them together, namely semi-supervised dimension reduction formulti-task and multi-view learning (SSDR-MML), which performs optimization fordimension reduction and label inference in semi-supervised setting. Theproposed framework is designed to handle both multi-task and multi-viewlearning settings, and can be easily adapted to many useful applications.Information obtained from all tasks and views is combined via reconstructionerrors in a linear fashion that can be efficiently solved using an alternatingoptimization scheme. Our formulation has a number of advantages. We explicitlymodel the information combining mechanism as a data structure (aweight/nearest-neighbor matrix) which allows investigating fundamentalquestions in multi-task and multi-view learning. We address one such questionby presenting a general measure to quantify the success of simultaneouslearning of multiple tasks or from multiple views. We show that our SSDR-MMLapproach can outperform many state-of-the-art baseline methods and demonstratethe effectiveness of connecting dimension reduction and learning.

Stochastic Coordinate Coding and Its Application for Drosophila Gene  Expression Pattern Annotation

  \textit{Drosophila melanogaster} has been established as a model organism forinvestigating the fundamental principles of developmental gene interactions.The gene expression patterns of \textit{Drosophila melanogaster} can bedocumented as digital images, which are annotated with anatomical ontologyterms to facilitate pattern discovery and comparison. The automated annotationof gene expression pattern images has received increasing attention due to therecent expansion of the image database. The effectiveness of gene expressionpattern annotation relies on the quality of feature representation. Previousstudies have demonstrated that sparse coding is effective for extractingfeatures from gene expression images. However, solving sparse coding remains acomputationally challenging problem, especially when dealing with large-scaledata sets and learning large size dictionaries. In this paper, we propose anovel algorithm to solve the sparse coding problem, called StochasticCoordinate Coding (SCC). The proposed algorithm alternatively updates thesparse codes via just a few steps of coordinate descent and updates thedictionary via second order stochastic gradient descent. The computational costis further reduced by focusing on the non-zero components of the sparse codesand the corresponding columns of the dictionary only in the updating procedure.Thus, the proposed algorithm significantly improves the efficiency and thescalability, making sparse coding applicable for large-scale data sets andlarge dictionary sizes. Our experiments on Drosophila gene expression data setsdemonstrate the efficiency and the effectiveness of the proposed algorithm.

Learning Latent Dynamics for Planning from Pixels

  Planning has been very successful for control tasks with known environmentdynamics. To leverage planning in unknown environments, the agent needs tolearn the dynamics from interactions with the world. However, learning dynamicsmodels that are accurate enough for planning has been a long-standingchallenge, especially in image-based domains. We propose the Deep PlanningNetwork (PlaNet), a purely model-based agent that learns the environmentdynamics from images and chooses actions through fast online planning in latentspace. To achieve high performance, the dynamics model must accurately predictthe rewards ahead for multiple time steps. We approach this problem using alatent dynamics model with both deterministic and stochastic transitioncomponents and a multi-step variational inference objective that we call latentovershooting. Using only pixel observations, our agent solves continuouscontrol tasks with contact dynamics, partial observability, and sparse rewards,which exceed the difficulty of tasks that were previously solved by planningwith learned models. PlaNet uses substantially fewer episodes and reaches finalperformance close to and sometimes higher than strong model-free algorithms.

The Thirteenth Data Release of the Sloan Digital Sky Survey: First  Spectroscopic Data from the SDSS-IV Survey MApping Nearby Galaxies at Apache  Point Observatory

  The fourth generation of the Sloan Digital Sky Survey (SDSS-IV) beganobservations in July 2014. It pursues three core programs: APOGEE-2, MaNGA, andeBOSS. In addition, eBOSS contains two major subprograms: TDSS and SPIDERS.This paper describes the first data release from SDSS-IV, Data Release 13(DR13), which contains new data, reanalysis of existing data sets and, like allSDSS data releases, is inclusive of previously released data. DR13 makespublicly available 1390 spatially resolved integral field unit observations ofnearby galaxies from MaNGA, the first data released from this survey. Itincludes new observations from eBOSS, completing SEQUELS. In addition totargeting galaxies and quasars, SEQUELS also targeted variability-selectedobjects from TDSS and X-ray selected objects from SPIDERS. DR13 includes newreductions of the SDSS-III BOSS data, improving the spectrophotometriccalibration and redshift classification. DR13 releases new reductions of theAPOGEE-1 data from SDSS-III, with abundances of elements not previouslyincluded and improved stellar parameters for dwarf stars and cooler stars. Forthe SDSS imaging data, DR13 provides new, more robust and precise photometriccalibrations. Several value-added catalogs are being released in tandem withDR13, in particular target catalogs relevant for eBOSS, TDSS, and SPIDERS, andan updated red-clump catalog for APOGEE. This paper describes the location andformat of the data now publicly available, as well as providing references tothe important technical papers that describe the targeting, observing, and datareduction. The SDSS website, http://www.sdss.org, provides links to the data,tutorials and examples of data access, and extensive documentation of thereduction and analysis procedures. DR13 is the first of a scheduled set thatwill contain new data and analyses from the planned ~6-year operations ofSDSS-IV.

The Fourteenth Data Release of the Sloan Digital Sky Survey: First  Spectroscopic Data from the extended Baryon Oscillation Spectroscopic Survey  and from the second phase of the Apache Point Observatory Galactic Evolution  Experiment

  The fourth generation of the Sloan Digital Sky Survey (SDSS-IV) has been inoperation since July 2014. This paper describes the second data release fromthis phase, and the fourteenth from SDSS overall (making this, Data ReleaseFourteen or DR14). This release makes public data taken by SDSS-IV in its firsttwo years of operation (July 2014-2016). Like all previous SDSS releases, DR14is cumulative, including the most recent reductions and calibrations of alldata taken by SDSS since the first phase began operations in 2000. New in DR14is the first public release of data from the extended Baryon OscillationSpectroscopic Survey (eBOSS); the first data from the second phase of theApache Point Observatory (APO) Galactic Evolution Experiment (APOGEE-2),including stellar parameter estimates from an innovative data driven machinelearning algorithm known as "The Cannon"; and almost twice as many data cubesfrom the Mapping Nearby Galaxies at APO (MaNGA) survey as were in the previousrelease (N = 2812 in total). This paper describes the location and format ofthe publicly available data from SDSS-IV surveys. We provide references to theimportant technical papers describing how these data have been taken (bothtargeting and observation details) and processed for scientific use. The SDSSwebsite (www.sdss.org) has been updated for this release, and provides links todata downloads, as well as tutorials and examples of data use. SDSS-IV isplanning to continue to collect astronomical data until 2020, and will befollowed by SDSS-V.

