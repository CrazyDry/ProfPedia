Learning Selectively Conditioned Forest Structures with Applications to  DBNs and Classification

  Dealing with uncertainty in Bayesian Network structures using maximum aposteriori (MAP) estimation or Bayesian Model Averaging (BMA) is oftenintractable due to the superexponential number of possible directed, acyclicgraphs. When the prior is decomposable, two classes of graphs where efficientlearning can take place are tree structures, and fixed-orderings with limitedin-degree. We show how MAP estimates and BMA for selectively conditionedforests (SCF), a combination of these two classes, can be computed efficientlyfor ordered sets of variables. We apply SCFs to temporal data to learn DynamicBayesian Networks having an intra-timestep forest and inter-timestep limitedin-degree structure, improving model accuracy over DBNs without the combinationof structures. We also apply SCFs to Bayes Net classification to learnselective forest augmented Naive Bayes classifiers. We argue that the built-infeature selection of selective augmented Bayes classifiers makes thempreferable to similar non-selective classifiers based on empirical evidence.

Computational Rationalization: The Inverse Equilibrium Problem

  Modeling the purposeful behavior of imperfect agents from a small number ofobservations is a challenging task. When restricted to the single-agentdecision-theoretic setting, inverse optimal control techniques assume thatobserved behavior is an approximately optimal solution to an unknown decisionproblem. These techniques learn a utility function that explains the examplebehavior and can then be used to accurately predict or imitate future behaviorin similar observed or unobserved situations.  In this work, we consider similar tasks in competitive and cooperativemulti-agent domains. Here, unlike single-agent settings, a player cannotmyopically maximize its reward --- it must speculate on how the other agentsmay act to influence the game's outcome. Employing the game-theoretic notion ofregret and the principle of maximum entropy, we introduce a technique forpredicting and generalizing behavior, as well as recovering a reward functionin these domains.

Computational Rationalization: The Inverse Equilibrium Problem

  Modeling the purposeful behavior of imperfect agents from a small number ofobservations is a challenging task. When restricted to the single-agentdecision-theoretic setting, inverse optimal control techniques assume thatobserved behavior is an approximately optimal solution to an unknown decisionproblem. These techniques learn a utility function that explains the examplebehavior and can then be used to accurately predict or imitate future behaviorin similar observed or unobserved situations.  In this work, we consider similar tasks in competitive and cooperativemulti-agent domains. Here, unlike single-agent settings, a player cannotmyopically maximize its reward; it must speculate on how the other agents mayact to influence the game's outcome. Employing the game-theoretic notion ofregret and the principle of maximum entropy, we introduce a technique forpredicting and generalizing behavior.

ADA: A Game-Theoretic Perspective on Data Augmentation for Object  Detection

  The use of random perturbations of ground truth data, such as randomtranslation or scaling of bounding boxes, is a common heuristic used for dataaugmentation that has been shown to prevent overfitting and improvegeneralization. Since the design of data augmentation is largely guided byreported best practices, it is difficult to understand if those design choicesare optimal. To provide a more principled perspective, we develop agame-theoretic interpretation of data augmentation in the context of objectdetection. We aim to find an optimal adversarial perturbations of the groundtruth data (i.e., the worst case perturbations) that forces the object boundingbox predictor to learn from the hardest distribution of perturbed examples forbetter test-time performance. We establish that the game theoretic solution,the Nash equilibrium, provides both an optimal predictor and optimal dataaugmentation distribution. We show that our adversarial method of training apredictor can significantly improve test time performance for the task ofobject detection. On the ImageNet object detection task, our adversarialapproach improves performance by over 16\% compared to the best performing dataaugmentation method

Adversarial Structured Prediction for Multivariate Measures

  Many predicted structured objects (e.g., sequences, matchings, trees) areevaluated using the F-score, alignment error rate (AER), or other multivariateperformance measures. Since inductively optimizing these measures usingtraining data is typically computationally difficult, empirical riskminimization of surrogate losses is employed, using, e.g., the hinge loss for(structured) support vector machines. These approximations often introduce amismatch between the learner's objective and the desired applicationperformance, leading to inconsistency. We take a different approach:adversarially approximate training data while optimizing the exact F-score orAER. Structured predictions under this formulation result from solving zero-sumgames between a predictor seeking the best performance and an adversary seekingthe worst while required to (approximately) match certain structured propertiesof the training data. We explore this approach for word alignment (AERevaluation) and named entity recognition (F-score evaluation) with linear-chainconstraints.

Robust Covariate Shift Prediction with General Losses and Feature Views

  Covariate shift relaxes the widely-employed independent and identicallydistributed (IID) assumption by allowing different training and testing inputdistributions. Unfortunately, common methods for addressing covariate shift bytrying to remove the bias between training and testing distributions usingimportance weighting often provide poor performance guarantees in theory andunreliable predictions with high variance in practice. Recently developedmethods that construct a predictor that is inherently robust to thedifficulties of learning under covariate shift are restricted to minimizinglogloss and can be too conservative when faced with high-dimensional learningtasks. We address these limitations in two ways: by robustly minimizing variousloss functions, including non-convex ones, under the testing distribution; andby separately shaping the influence of covariate shift according to differentfeature-based views of the relationship between input variables and examplelabels. These generalizations make robust covariate shift prediction applicableto more task scenarios. We demonstrate the benefits on classification undercovariate shift tasks.

Kernel Robust Bias-Aware Prediction under Covariate Shift

  Under covariate shift, training (source) data and testing (target) datadiffer in input space distribution, but share the same conditional labeldistribution. This poses a challenging machine learning task. Robust Bias-Aware(RBA) prediction provides the conditional label distribution that is robust tothe worstcase logarithmic loss for the target distribution while matchingfeature expectation constraints from the source distribution. However,employing RBA with insufficient feature constraints may result in highcertainty predictions for much of the source data, while leaving too muchuncertainty for target data predictions. To overcome this issue, we extend therepresenter theorem to the RBA setting, enabling minimization of regularizedexpected target risk by a reweighted kernel expectation under the sourcedistribution. By applying kernel methods, we establish consistency guaranteesand demonstrate better performance of the RBA classifier than competing methodson synthetically biased UCI datasets as well as datasets that have naturalcovariate shift.

Distributionally Robust Graphical Models

  In many structured prediction problems, complex relationships betweenvariables are compactly defined using graphical structures. The most prevalentgraphical prediction methods---probabilistic graphical models and large marginmethods---have their own distinct strengths but also possess significantdrawbacks. Conditional random fields (CRFs) are Fisher consistent, but they donot permit integration of customized loss metrics into their learning process.Large-margin models, such as structured support vector machines (SSVMs), havethe flexibility to incorporate customized loss metrics, but lack Fisherconsistency guarantees. We present adversarial graphical models (AGM), adistributionally robust approach for constructing a predictor that performsrobustly for a class of data distributions defined using a graphical structure.Our approach enjoys both the flexibility of incorporating customized lossmetrics into its design as well as the statistical guarantee of Fisherconsistency. We present exact learning and prediction algorithms for AGM withtime complexity similar to existing graphical models and show the practicalbenefits of our approach with experiments.

Consistent Robust Adversarial Prediction for General Multiclass  Classification

  We propose a robust adversarial prediction framework for general multiclassclassification. Our method seeks predictive distributions that robustlyoptimize non-convex and non-continuous multiclass loss metrics against theworst-case conditional label distributions (the adversarial distributions) that(approximately) match the statistics of the training data. Although theoptimized loss metrics are non-convex and non-continuous, the dual formulationof the framework is a convex optimization problem that can be recast as a riskminimization model with a prescribed convex surrogate loss we call theadversarial surrogate loss. We show that the adversarial surrogate losses fillan existing gap in surrogate loss construction for general multiclassclassification problems, by simultaneously aligning better with the originalmulticlass loss, guaranteeing Fisher consistency, enabling a way to incorporaterich feature spaces via the kernel trick, and providing competitive performancein practice.

