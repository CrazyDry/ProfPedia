Identifiability of two-component skew normal mixtures with one known  component

  We give sufficient identifiability conditions for estimating mixingproportions in two-component mixtures of skew normal distributions with oneknown component. We consider the univariate case as well as two multivariateextensions: a multivariate skew normal distribution (MSN) by Azzalini and DallaValle (1996) and the canonical fundamental skew normal distribution (CFUSN) byArellano-Valle and Genton (2005). The characteristic function of the CFUSNdistribution is additionally derived.

Community-Wide Evaluation of Computational Function Prediction

  A biological experiment is the most reliable way of assigning function to aprotein. However, in the era of high-throughput sequencing, scientists areunable to carry out experiments to determine the function of every single geneproduct. Therefore, to gain insights into the activity of these molecules andguide experiments, we must rely on computational means to functionally annotatethe majority of sequence data. To understand how well these algorithms perform,we have established a challenge involving a broad scientific community in whichwe evaluate different annotation methods according to their ability to predictthe associations between previously unannotated protein sequences and GeneOntology terms. Here we discuss the rationale, benefits and issues associatedwith evaluating computational methods in an ongoing community-wide challenge.

Nonparametric semi-supervised learning of class proportions

  The problem of developing binary classifiers from positive and unlabeled datais often encountered in machine learning. A common requirement in this settingis to approximate posterior probabilities of positive and negative classes fora previously unseen data point. This problem can be decomposed into two steps:(i) the development of accurate predictors that discriminate between positiveand unlabeled data, and (ii) the accurate estimation of the prior probabilitiesof positive and negative examples. In this work we primarily focus on thelatter subproblem. We study nonparametric class prior estimation and formulatethis problem as an estimation of mixing proportions in two-component mixturemodels, given a sample from one of the components and another sample from themixture itself. We show that estimation of mixing proportions is generallyill-defined and propose a canonical form to obtain identifiability whilemaintaining the flexibility to model any distribution. We use insights fromthis theory to elucidate the optimization surface of the class priors andpropose an algorithm for estimating them. To address the problems ofhigh-dimensional density estimation, we provide practical transformations tolow-dimensional spaces that preserve class priors. Finally, we demonstrate theefficacy of our method on univariate and multivariate data.

Estimating the class prior and posterior from noisy positives and  unlabeled data

  We develop a classification algorithm for estimating posterior distributionsfrom positive-unlabeled data, that is robust to noise in the positive labelsand effective for high-dimensional data. In recent years, several algorithmshave been proposed to learn from positive-unlabeled data; however, many ofthese contributions remain theoretical, performing poorly on realhigh-dimensional data that is typically contaminated with noise. We build onthis previous work to develop two practical classification algorithms thatexplicitly model the noise in the positive labels and utilize univariatetransforms built on discriminative classifiers. We prove that these univariatetransforms preserve the class prior, enabling estimation in the univariatespace and avoiding kernel density estimation for high-dimensional data. Thetheoretical development and both parametric and nonparametric algorithmsproposed here constitutes an important step towards wide-spread use of robustclassification algorithms for positive-unlabeled data.

Recovering True Classifier Performance in Positive-Unlabeled Learning

  A common approach in positive-unlabeled learning is to train a classificationmodel between labeled and unlabeled data. This strategy is in fact known togive an optimal classifier under mild conditions; however, it results in biasedempirical estimates of the classifier performance. In this work, we show thatthe typically used performance measures such as the receiver operatingcharacteristic curve, or the precision-recall curve obtained on such data canbe corrected with the knowledge of class priors; i.e., the proportions of thepositive and negative examples in the unlabeled data. We extend the results toa noisy setting where some of the examples labeled positive are in factnegative and show that the correction also requires the knowledge of theproportion of noisy examples in the labeled positives. Using state-of-the-artalgorithms to estimate the positive class prior and the proportion of noise, weexperimentally evaluate two correction approaches and demonstrate theirefficacy on real-life data.

Classification in biological networks with hypergraphlet kernels

  Biological and cellular systems are often modeled as graphs in which verticesrepresent objects of interest (genes, proteins, drugs) and edges representrelational ties among these objects (binds-to, interacts-with, regulates). Thisapproach has been highly successful owing to the theory, methodology andsoftware that support analysis and learning on graphs. Graphs, however, oftensuffer from information loss when modeling physical systems due to theirinability to accurately represent multiobject relationships. Hypergraphs, ageneralization of graphs, provide a framework to mitigate information loss andunify disparate graph-based methodologies. In this paper, we present ahypergraph-based approach for modeling physical systems and formulate vertexclassification, edge classification and link prediction problems on(hyper)graphs as instances of vertex classification on (extended, dual)hypergraphs in a semi-supervised setting. We introduce a novel kernel method onvertex- and edge-labeled (colored) hypergraphs for analysis and learning. Themethod is based on exact and inexact (via hypergraph edit distances)enumeration of small simple hypergraphs, referred to as hypergraphlets, rootedat a vertex of interest. We extensively evaluate this method and show itspotential use in a positive-unlabeled setting to estimate the number of missingand false positive links in protein-protein interaction networks.

A new class of metrics for learning on real-valued and structured data

  We propose a new class of metrics on sets, vectors, and functions that can beused in various stages of data mining, including exploratory data analysis,learning, and result interpretation. These new distance functions unify andgeneralize some of the popular metrics, such as the Jaccard and bag distanceson sets, Manhattan distance on vector spaces, and Marczewski-Steinhaus distanceon integrable functions. We prove that the new metrics are complete and showuseful relationships with $f$-divergences for probability distributions. Tofurther extend our approach to structured objects such as concept hierarchiesand ontologies, we introduce information-theoretic metrics on directed acyclicgraphs drawn according to a fixed probability distribution. We conductempirical investigation to demonstrate intuitive interpretation of the newmetrics and their effectiveness on real-valued, high-dimensional, andstructured data. Extensive comparative evaluation demonstrates that the newmetrics outperformed multiple similarity and dissimilarity functionstraditionally used in data mining, including the Minkowski family, thefractional $L^p$ family, two $f$-divergences, cosine distance, and twocorrelation coefficients. Finally, we argue that the new class of metrics isparticularly appropriate for rapid processing of high-dimensional andstructured data in distance-based learning.

Ultra High-Dimensional Nonlinear Feature Selection for Big Biological  Data

  Machine learning methods are used to discover complex nonlinear relationshipsin biological and medical data. However, sophisticated learning models arecomputationally unfeasible for data with millions of features. Here weintroduce the first feature selection method for nonlinear learning problemsthat can scale up to large, ultra-high dimensional biological data. Morespecifically, we scale up the novel Hilbert-Schmidt Independence CriterionLasso (HSIC Lasso) to handle millions of features with tens of thousandsamples. The proposed method is guaranteed to find an optimal subset ofmaximally predictive features with minimal redundancy, yielding higherpredictive power and improved interpretability. Its effectiveness isdemonstrated through applications to classify phenotypes based on moduleexpression in human prostate cancer patients and to detect enzymes amongprotein structures. We achieve high accuracy with as few as 20 out of onemillion features --- a dimensionality reduction of 99.998%. Our algorithm canbe implemented on commodity cloud computing platforms. The dramatic reductionof features may lead to the ubiquitous deployment of sophisticated predictionmodels in mobile health care applications.

Enumerating consistent subgraphs of directed acyclic graphs: an insight  into biomedical ontologies

  Modern problems of concept annotation associate an object of interest (gene,individual, text document) with a set of interrelated textual descriptors(functions, diseases, topics), often organized in concept hierarchies orontologies. Most ontologies can be seen as directed acyclic graphs, where nodesrepresent concepts and edges represent relational ties between these concepts.Given an ontology graph, each object can only be annotated by a consistentsubgraph; that is, a subgraph such that if an object is annotated by aparticular concept, it must also be annotated by all other concepts thatgeneralize it. Ontologies therefore provide a compact representation of a largespace of possible consistent subgraphs; however, until now we have not beenaware of a practical algorithm that can enumerate such annotation spaces for agiven ontology. In this work we propose an algorithm for enumerating consistentsubgraphs of directed acyclic graphs. The algorithm recursively partitions thegraph into strictly smaller graphs until the resulting graph becomes a rootedtree (forest), for which a linear-time solution is computed. It then combinesthe tallies from graphs created in the recursion to obtain the final count. Weprove the correctness of this algorithm and then apply it to characterize fourmajor biomedical ontologies. We believe this work provides valuable insightsinto concept annotation spaces and predictability of ontological annotation.

Uncovering protein interaction in abstracts and text using a novel  linear model and word proximity networks

  We participated in three of the protein-protein interaction subtasks of theSecond BioCreative Challenge: classification of abstracts relevant forprotein-protein interaction (IAS), discovery of protein pairs (IPS) and textpassages characterizing protein interaction (ISS) in full text documents. Weapproached the abstract classification task with a novel, lightweight linearmodel inspired by spam-detection techniques, as well as an uncertainty-basedintegration scheme. We also used a Support Vector Machine and the SingularValue Decomposition on the same features for comparison purposes. Our approachto the full text subtasks (protein pair and passage identification) includes afeature expansion method based on word-proximity networks. Our approach to theabstract classification task (IAS) was among the top submissions for this taskin terms of the measures of performance used in the challenge evaluation(accuracy, F-score and AUC). We also report on a web-tool we produced using ourapproach: the Protein Interaction Abstract Relevance Evaluator (PIARE). Ourapproach to the full text tasks resulted in one of the highest recall rates aswell as mean reciprocal rank of correct passages. Our approach to abstractclassification shows that a simple linear model, using relatively few features,is capable of generalizing and uncovering the conceptual nature ofprotein-protein interaction from the bibliome. Since the novel approach isbased on a very lightweight linear model, it can be easily ported and appliedto similar problems. In full text problems, the expansion of word features withword-proximity networks is shown to be useful, though the need for someimprovements is discussed.

The sequencing and interpretation of the genome obtained from a Serbian  individual

  Recent genetic studies and whole-genome sequencing projects have greatlyimproved our understanding of human variation and clinically actionable geneticinformation. Smaller ethnic populations, however, remain underrepresented inboth individual and large-scale sequencing efforts and hence present anopportunity to discover new variants of biomedical and demographicsignificance. This report describes the sequencing and analysis of a genomeobtained from an individual of Serbian origin, introducing tens of thousands ofpreviously unknown variants to the currently available pool. Ancestry analysisplaces this individual in close proximity of the Central and Eastern Europeanpopulations; i.e., closest to Croatian, Bulgarian and Hungarian individualsand, in terms of other Europeans, furthest from Ashkenazi Jewish, Spanish,Sicilian, and Baltic individuals. Our analysis confirmed gene flow betweenNeanderthal and ancestral pan-European populations, with similar contributionsto the Serbian genome as those observed in other European groups. Finally, toassess the burden of potentially disease-causing/clinically relevant variationin the sequenced genome, we utilized manually curated genotype-phenotypeassociation databases and variant-effect predictors. We identified severalvariants that have previously been associated with severe early-onset diseasethat is not evident in the proband, as well as variants that could yet prove tobe clinically relevant to the proband over the next decades. The presence ofnumerous private and low-frequency variants along with the observed andpredicted disease-causing mutations in this genome exemplify some of the globalchallenges of genome interpretation, especially in the context of understudiedethnic groups.

An expanded evaluation of protein function prediction methods shows an  improvement in accuracy

  Background: The increasing volume and variety of genotypic and phenotypicdata is a major defining characteristic of modern biomedical sciences. At thesame time, the limitations in technology for generating data and the inherentlystochastic nature of biomolecular events have led to the discrepancy betweenthe volume of data and the amount of knowledge gleaned from it. A majorbottleneck in our ability to understand the molecular underpinnings of life isthe assignment of function to biological macromolecules, especially proteins.While molecular experiments provide the most reliable annotation of proteins,their relatively low throughput and restricted purview have led to anincreasing role for computational function prediction. However, accuratelyassessing methods for protein function prediction and tracking progress in thefield remain challenging. Methodology: We have conducted the second CriticalAssessment of Functional Annotation (CAFA), a timed challenge to assesscomputational methods that automatically assign protein function. One hundredtwenty-six methods from 56 research groups were evaluated for their ability topredict biological functions using the Gene Ontology and gene-diseaseassociations using the Human Phenotype Ontology on a set of 3,681 proteins from18 species. CAFA2 featured significantly expanded analysis compared with CAFA1,with regards to data set size, variety, and assessment metrics. To reviewprogress in the field, the analysis also compared the best methodsparticipating in CAFA1 to those of CAFA2. Conclusions: The top performingmethods in CAFA2 outperformed the best methods from CAFA1, demonstrating thatcomputational function prediction is improving. This increased accuracy can beattributed to the combined effect of the growing number of experimentalannotations and improved methods for function prediction.

