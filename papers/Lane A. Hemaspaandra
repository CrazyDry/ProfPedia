Take-home Complexity

  We discuss the use of projects in first-year graduate complexity theorycourses.

P-Immune Sets with Holes Lack Self-Reducibility Properties

  No P-immune set having exponential gaps is positive-Turing self-reducible.

All Superlinear Inverse Schemes are coNP-Hard

  How hard is it to invert NP-problems? We show that all superlinearlycertified inverses of NP problems are coNP-hard. To do so, we develop a novelproof technique that builds diagonalizations against certificates directly intoa circuit.

A Richer Understanding of the Complexity of Election Systems

  We provide an overview of some recent progress on the complexity of electionsystems. The issues studied include the complexity of the winner, manipulation,bribery, and control problems.

Downward Collapse from a Weaker Hypothesis

  Hemaspaandra et al. proved that, for $m > 0$ and $0 < i < k - 1$: if$\Sigma_i^p \BoldfaceDelta DIFF_m(\Sigma_k^p)$ is closed under complementation,then $DIFF_m(\Sigma_k^p) = coDIFF_m(\Sigma_k^p)$. This sharply asymmetricresult fails to apply to the case in which the hypothesis is weakened byallowing the $\Sigma_i^p$ to be replaced by any class in its differencehierarchy. We so extend the result by proving that, for $s,m > 0$ and $0 < i <k - 1$: if $DIFF_s(\Sigma_i^p) \BoldfaceDelta DIFF_m(\Sigma_k^p)$ is closedunder complementation, then $DIFF_m(\Sigma_k^p) = coDIFF_m(\Sigma_k^p)$.

On Bounded-Weight Error-Correcting Codes

  This paper computationally obtains optimal bounded-weight, binary,error-correcting codes for a variety of distance bounds and dimensions. Wecompare the sizes of our codes to the sizes of optimal constant-weight, binary,error-correcting codes, and evaluate the differences.

A Moment of Perfect Clarity II: Consequences of Sparse Sets Hard for NP  with Respect to Weak Reductions

  This paper discusses advances, due to the work of Cai, Naik, and Sivakumarand Glasser, in the complexity class collapses that follow if NP has sparsehard sets under reductions weaker than (full) truth-table reductions.

A Note on Nonuniform versus Uniform ACC^k Circuits for NE

  We note that for each k \in {0,1,2, ...} the following holds: NE has(nonuniform) ACC^k circuits if and only if NE has P^{NE}-uniform ACC^kcircuits. And we mention how to get analogous results for other circuit andcomplexity classes.

Weighted Electoral Control

  Although manipulation and bribery have been extensively studied underweighted voting, there has been almost no work done on election control underweighted voting. This is unfortunate, since weighted voting appears in manyimportant natural settings. In this paper, we study the complexity ofcontrolling the outcome of weighted elections through adding and deletingvoters. We obtain polynomial-time algorithms, NP-completeness results, and formany NP-complete cases, approximation algorithms. In particular, for scoringrules we completely characterize the complexity of weighted voter control. Ourwork shows that for quite a few important cases, either polynomial-time exactalgorithms or polynomial-time approximation algorithms exist.

Almost-Everywhere Superiority for Quantum Computing

  Simon as extended by Brassard and H{\o}yer shows that there are tasks onwhich polynomial-time quantum machines are exponentially faster than eachclassical machine infinitely often. The present paper shows that there aretasks on which polynomial-time quantum machines are exponentially faster thaneach classical machine almost everywhere.

Writing and Editing Complexity Theory: Tales and Tools

  Each researcher should have a full shelf---physical or virtual---of books onwriting and editing prose. Though we make no claim to any special degree ofexpertise, we recently edited a book of complexity theory surveys (ComplexityTheory Retrospective II, Springer-Verlag, 1997), and in doing so we werebrought into particularly close contact with the subject of this article, andwith a number of the excellent resources available to writers and editors. Inthis article, we list some of these resources, and we also relate some of theadventures we had as our book moved from concept to reality.

A Moment of Perfect Clarity I: The Parallel Census Technique

  We discuss the history and uses of the parallel census technique---an eleganttool in the study of certain computational objects having polynomially boundedcensus functions. A sequel will discuss advances (including Cai, Naik, andSivakumar [CNS95] and Glasser [Gla00]), some related to the parallel censustechnique and some due to other approaches, in the complexity-class collapsesthat follow if NP has sparse hard sets under reductions weaker than (full)truth-table reductions.

Computational Social Choice and Computational Complexity: BFFs?

  We discuss the connection between computational social choice (comsoc) andcomputational complexity. We stress the work so far on, and urge continuedfocus on, two less-recognized aspects of this connection. Firstly, this is verymuch a two-way street: Everyone knows complexity classification is used incomsoc, but we also highlight benefits to complexity that have arisen from itsuse in comsoc. Secondly, more subtle, less-known complexity tools often can bevery productively used in comsoc.

P-Selectivity, Immunity, and the Power of One Bit

  We prove that P-sel, the class of all P-selective sets, is EXP-immune, but isnot EXP/1-immune. That is, we prove that some infinite P-selective set has noinfinite EXP-time subset, but we also prove that every infinite P-selective sethas some infinite subset in EXP/1. Informally put, the immunity of P-sel is sofragile that it is pierced by a single bit of information.  The above claims follow from broader results that we obtain about theimmunity of the P-selective sets. In particular, we prove that for everyrecursive function f, P-sel is DTIME(f)-immune. Yet we also prove that P-sel isnot \Pi_2^p/1-immune.

Frequency of Correctness versus Average-Case Polynomial Time and  Generalized Juntas

  We prove that every distributional problem solvable in polynomial time on theaverage with respect to the uniform distribution has a frequentlyself-knowingly correct polynomial-time algorithm. We also study some featuresof probability weight of correctness with respect to generalizations ofProcaccia and Rosenschein's junta distributions [PR07b].

Beautiful Structures: An Appreciation of the Contributions of Alan  Selman

  Professor Alan Selman has been a giant in the field of computationalcomplexity for the past forty years. This article is an appreciation, on theoccasion of his retirement, of some of the most lovely concepts and resultsthat Alan has contributed to the field.

Overhead-Free Computation, DCFLs, and CFLs

  We study Turing machines that are allowed absolutely no space overhead. Theonly work space the machines have, beyond the fixed amount of memory implicitin their finite-state control, is that which they can create by cannibalizingthe input bits' own space. This model more closely reflects the fixed-sizedmemory of real computers than does the standard complexity-theoretic model oflinear space.  Though some context-sensitive languages cannot be accepted by such machines,we show that all context-free languages can be accepted nondeterministically inpolynomial time with absolutely no space overhead, and that all deterministiccontext-free languages can be accepted deterministically in polynomial timewith absolutely no space overhead.

The Complexity of Kings

  A king in a directed graph is a node from which each node in the graph can bereached via paths of length at most two. There is a broad literature ontournaments (completely oriented digraphs), and it has been known for more thanhalf a century that all tournaments have at least one king [Lan53]. Recently,kings have proven useful in theoretical computer science, in particular in thestudy of the complexity of the semifeasible sets [HNP98,HT05] and in the studyof the complexity of reachability problems [Tan01,NT02].  In this paper, we study the complexity of recognizing kings. For eachsuccinctly specified family of tournaments, the king problem is known to belongto $\Pi_2^p$ [HOZZ]. We prove that this bound is optimal: We construct asuccinctly specified tournament family whose king problem is$\Pi_2^p$-complete. It follows easily from our proof approach that the problemof testing kingship in succinctly specified graphs (which need not betournaments) is $\Pi_2^p$-complete. We also obtain $\Pi_2^p$-completenessresults for k-kings in succinctly specified j-partite tournaments, $k,j \geq2$, and we generalize our main construction to show that $\Pi_2^p$-completenessholds for testing k-kingship in succinctly specified families of tournamentsfor all $k \geq 2$.

On Approximating Optimal Weighted Lobbying, and Frequency of Correctness  versus Average-Case Polynomial Time

  We investigate issues related to two hard problems related to voting, theoptimal weighted lobbying problem and the winner problem for Dodgson elections.Regarding the former, Christian et al. [CFRS06] showed that optimal lobbying isintractable in the sense of parameterized complexity. We provide an efficientgreedy algorithm that achieves a logarithmic approximation ratio for thisproblem and even for a more general variant--optimal weighted lobbying. Weprove that essentially no better approximation ratio than ours can be provenfor this greedy algorithm.  The problem of determining Dodgson winners is known to be complete forparallel access to NP [HHR97]. Homan and Hemaspaandra [HH06] proposed anefficient greedy heuristic for finding Dodgson winners with a guaranteedfrequency of success, and their heuristic is a ``frequently self-knowinglycorrect algorithm.'' We prove that every distributional problem solvable inpolynomial time on the average with respect to the uniform distribution has afrequently self-knowingly correct polynomial-time algorithm. Furthermore, westudy some features of probability weight of correctness with respect toProcaccia and Rosenschein's junta distributions [PR07].

Dichotomy for Voting Systems

  Scoring protocols are a broad class of voting systems. Each is defined by avector $(\alpha_1,\alpha_2,...,\alpha_m)$, $\alpha_1 \geq \alpha_2 \geq >...\geq \alpha_m$, of integers such that each voter contributes $\alpha_1$ pointsto his/her first choice, $\alpha_2$ points to his/her second choice, and so on,and any candidate receiving the most points is a winner.  What is it about scoring-protocol election systems that makes some have thedesirable property of being NP-complete to manipulate, while others can bemanipulated in polynomial time? We find the complete, dichotomizing answer:Diversity of dislike. Every scoring-protocol election system having two or morepoint values assigned to candidates other than the favorite--i.e., having$||\{\alpha_i \condition 2 \leq i \leq m\}||\geq 2$--is NP-complete tomanipulate. Every other scoring-protocol election system can be manipulated inpolynomial time. In effect, we show that--other than trivial systems (where allcandidates alway tie), plurality voting, and plurality voting's transparentlydisguised translations--\emph{every} scoring-protocol election system isNP-complete to manipulate.

Hybrid Elections Broaden Complexity-Theoretic Resistance to Control

  Electoral control refers to attempts by an election's organizer ("the chair")to influence the outcome by adding/deleting/partitioning voters or candidates.The groundbreaking work of Bartholdi, Tovey, and Trick [BTT92] on(constructive) control proposes computational complexity as a means ofresisting control attempts: Look for election systems where the chair's task inseeking control is itself computationally infeasible.  We introduce and study a method of combining two or more candidate-anonymouselection schemes in such a way that the combined scheme possesses all theresistances to control (i.e., all the NP-hardnesses of control) possessed byany of its constituents: It combines their strengths. From this and newresistance constructions, we prove for the first time that there exists anelection scheme that is resistant to all twenty standard types of electoralcontrol.

Control in the Presence of Manipulators: Cooperative and Competitive  Cases

  Control and manipulation are two of the most studied types of attacks onelections. In this paper, we study the complexity of control attacks onelections in which there are manipulators. We study both the case where the"chair" who is seeking to control the election is allied with the manipulators,and the case where the manipulators seek to thwart the chair. In the lattercase, we see that the order of play substantially influences the complexity. Weprove upper bounds, holding over every election system with a polynomial-timewinner problem, for all standard control cases, and some of these bounds are atthe second or third level of the polynomial hierarchy, and we provide matchinglower bounds to prove these tight. Nonetheless, for important natural systemsthe complexity can be much lower. We prove that for approval and pluralityelections, the complexity of even competitive clashes between a controller andmanipulators falls far below those high bounds, even as low as polynomial time.Yet for a Borda-voting case we show that such clashes raise the complexityunless NP = coNP.

Algebraic Properties for Selector Functions

  The nondeterministic advice complexity of the P-selective sets is known to beexactly linear. Regarding the deterministic advice complexity of theP-selective sets--i.e., the amount of Karp--Lipton advice needed forpolynomial-time machines to recognize them in general--the best current upperbound is quadratic [Ko, 1983] and the best current lower bound is linear[Hemaspaandra and Torenvliet, 1996].  We prove that every associatively P-selective set is commutatively,associatively P-selective. Using this, we establish an algebraic sufficientcondition for the P-selective sets to have a linear upper bound (which thuswould match the existing lower bound) on their deterministic advice complexity:If all P-selective sets are associatively P-selective then the deterministicadvice complexity of the P-selective sets is linear. The weakest previouslyknown sufficient condition was P=NP.  We also establish related results for algebraic properties of, and advicecomplexity of, the nondeterministically selective sets.

Search versus Decision for Election Manipulation Problems

  Most theoretical definitions about the complexity of manipulating electionsfocus on the decision problem of recognizing which instances can besuccessfully manipulated, rather than the search problem of finding thesuccessful manipulative actions. Since the latter is a far more natural goalfor manipulators, that definitional focus may be misguided if these twocomplexities can differ. Our main result is that they probably do differ: Ifinteger factoring is hard, then for election manipulation, election bribery,and some types of election control, there are election systems for whichrecognizing which instances can be successfully manipulated is in polynomialtime but producing the successful manipulations cannot be done in polynomialtime.

X THEN X: Manipulation of Same-System Runoff Elections

  Do runoff elections, using the same voting rule as the initial election butjust on the winning candidates, increase or decrease the complexity ofmanipulation? Does allowing revoting in the runoff increase or decrease thecomplexity relative to just having a runoff without revoting? For both weightedand unweighted voting, we show that even for election systems with simplewinner problems the complexity of manipulation, manipulation with runoffs, andmanipulation with revoting runoffs are independent, in the abstract. On theother hand, for some important, well-known election systems we determine whatholds for each of these cases. For no such systems do we find runoffs loweringcomplexity, and for some we find that runoffs raise complexity. Ours is thefirst paper to show that for natural, unweighted election systems, runoffs canincrease the manipulation complexity.

Credimus

  We believe that economic design and computational complexity---while alreadyimportant to each other---should become even more important to each other witheach passing year. But for that to happen, experts in on the one hand suchareas as social choice, economics, and political science and on the other handcomputational complexity will have to better understand each other'sworldviews.  This article, written by two complexity theorists who also work incomputational social choice theory, focuses on one direction of that process bypresenting a brief overview of how most computational complexity theorists viewthe world. Although our immediate motivation is to make the lens through whichcomplexity theorists see the world be better understood by those in the socialsciences, we also feel that even within computer science it is very importantfor nontheoreticians to understand how theoreticians think, just as it isequally important within computer science for theoreticians to understand hownontheoreticians think.

A Downward Collapse within the Polynomial Hierarchy

  Downward collapse (a.k.a. upward separation) refers to cases where theequality of two larger classes implies the equality of two smaller classes. Weprovide an unqualified downward collapse result completely within thepolynomial hierarchy. In particular, we prove that, for k > 2, if $\psigkone =\psigktwo$ then $\sigmak = \pik = \ph$. We extend this to obtain a more generaldownward collapse result.

What's Up with Downward Collapse: Using the Easy-Hard Technique to Link  Boolean and Polynomial Hierarchy Collapses

  During the past decade, nine papers have obtained increasingly strongconsequences from the assumption that boolean or bounded-query hierarchiescollapse. The final four papers of this nine-paper progression actually achievedownward collapse---that is, they show that high-level collapses inducecollapses at (what beforehand were thought to be) lower complexity levels. Forexample, for each $k\geq 2$ it is now known that if $\psigkone=\psigktwo$ then$\ph=\sigmak$. This article surveys the history, the results, and thetechnique---the so-called easy-hard method---of these nine papers.

An Introduction to Query Order

  Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] raised the followingquestions: If one is allowed one question to each of two different informationsources, does the order in which one asks the questions affect the class ofproblems that one can solve with the given access? If so, which order yieldsthe greater computational power?  The answers to these questions have been learned-inasfar as they can belearned without resolving whether or not the polynomial hierarchy collapses-forboth the polynomial hierarchy and the boolean hierarchy. In the polynomialhierarchy, query order never matters. In the boolean hierarchy, query ordersometimes does not matter and, unless the polynomial hierarchy collapses,sometimes does matter. Furthermore, the study of query order has yieldeddividends in seemingly unrelated areas, such as bottleneck computations anddownward translation of equality.  In this article, we present some of the central results on query order. Thearticle is written in such a way as to encourage the reader to try his or herown hand at proving some of these results. We also give literature pointers tothe quickly growing set of related results and applications.

Query Order and the Polynomial Hierarchy

  Hemaspaandra, Hempel, and Wechsung [cs.CC/9909020] initiated the field ofquery order, which studies the ways in which computational power is affected bythe order in which information sources are accessed. The present paper studies,for the first time, query order as it applies to the levels of the polynomialhierarchy. We prove that the levels of the polynomial hierarchy areorder-oblivious. Yet, we also show that these ordered query classes form newlevels in the polynomial hierarchy unless the polynomial hierarchy collapses.We prove that all leaf language classes - and thus essentially all standardcomplexity classes - inherit all order-obliviousness results that hold for P.

Using the No-Search Easy-Hard Technique for Downward Collapse

  The top part of the preceding figure [figure appears in actual paper] showssome classes from the (truth-table) bounded-query and boolean hierarchies. Itis well-known that if either of these hierarchies collapses at a given level,then all higher levels of that hierarchy collapse to that same level. This is astandard ``upward translation of equality'' that has been known for over adecade. The issue of whether these hierarchies can translate equality {\emdownwards\/} has proven vastly more challenging. In particular, with regard tothe figure above, consider the following claim:  $$P_{m-tt}^{\Sigma_k^p} = P_{m+1-tt}^{\Sigma_k^p} \implies  DIFF_m(\Sigma_k^p) coDIFF_m(\Sigma_k^p) = BH(\Sigma_k^p). (*) $$  This claim, if true, says that equality translates downwards between levelsof the bounded-query hierarchy and the boolean hierarchy levels that (beforethe fact) are immediately below them.  Until recently, it was not known whether (*) {\em ever\/} held, except forthe degenerate cases $m=0$ and $k=0$. Then Hemaspaandra, Hemaspaandra, andHempel \cite{hem-hem-hem:j:downward-translation} proved that (*) holds for all$m$, for $k > 2$. Buhrman and Fortnow~\cite{buh-for:j:two-queries} then showedthat, when $k=2$, (*) holds for the case $m = 1$. In this paper, we prove thatfor the case $k=2$, (*) holds for all values of $m$. Since there is an oraclerelative to which ``for $k=1$, (*) holds for all $m$'' fails\cite{buh-for:j:two-queries}, our achievement of the $k=2$ case cannot to bestrengthened to $k=1$ by any relativizable proof technique. The new downwardtranslation we obtain also tightens the collapse in the polynomial hierarchyimplied by a collapse in the bounded-query hierarchy of the second level of thepolynomial hierarchy.

A Control Dichotomy for Pure Scoring Rules

  Scoring systems are an extremely important class of election systems. Alength-$m$ (so-called) scoring vector applies only to $m$-candidate elections.To handle general elections, one must use a family of vectors, one per length.The most elegant approach to making sure such families are "family-like" is therecently introduced notion of (polynomial-time uniform) pure scoring rules[Betzler and Dorn 2010], where each scoring vector is obtained from itsprecursor by adding one new coefficient. We obtain the first dichotomy theoremfor pure scoring rules for a control problem. In particular, for constructivecontrol by adding voters (CCAV), we show that CCAV is solvable in polynomialtime for $k$-approval with $k \leq 3$, $k$-veto with $k \leq 2$, every purescoring rule in which only the two top-rated candidates gain nonzero scores,and a particular rule that is a "hybrid" of 1-approval and 1-veto. For allother pure scoring rules, CCAV is NP-complete. We also investigate thedescriptive richness of different models for defining pure scoring rules,proving how more rule-generation time gives more rules, proving that rationalsgive more rules than do the natural numbers, and proving that some restrictionspreviously thought to be "w.l.o.g." in fact do lose generality.

Anyone but Him: The Complexity of Precluding an Alternative

  Preference aggregation in a multiagent setting is a central issue in bothhuman and computer contexts. In this paper, we study in terms of complexity thevulnerability of preference aggregation to destructive control. That is, westudy the ability of an election's chair to, through such mechanisms asvoter/candidate addition/suppression/partition, ensure that a particularcandidate (equivalently, alternative) does not win. And we study the extent towhich election systems can make it impossible, or computationally costly(NP-complete), for the chair to execute such control. Among the systems westudy--plurality, Condorcet, and approval voting--we find cases where systemsimmune or computationally resistant to a chair choosing the winner nonethelessare vulnerable to the chair blocking a victory. Beyond that, we see that amongour studied systems no one system offers the best protection againstdestructive control. Rather, the choice of a preference aggregation system willdepend closely on which types of control one wishes to be protected against. Wealso find concrete cases where the complexity of or susceptibility to controlvaries dramatically based on the choice among natural tie-handling rules.

How Hard Is Bribery in Elections?

  We study the complexity of influencing elections through bribery: Howcomputationally complex is it for an external actor to determine whether by acertain amount of bribing voters a specified candidate can be made theelection's winner? We study this problem for election systems as varied asscoring protocols and Dodgson voting, and in a variety of settings regardinghomogeneous-vs.-nonhomogeneous electorate bribability,bounded-size-vs.-arbitrary-sized candidate sets, weighted-vs.-unweightedvoters, and succinct-vs.-nonsuccinct input specification. We obtain bothpolynomial-time bribery algorithms and proofs of the intractability of bribery,and indeed our results show that the complexity of bribery is extremelysensitive to the setting. For example, we find settings in which bribery isNP-complete but manipulation (by voters) is in P, and we find settings in whichbribing weighted voters is NP-complete but bribing voters with individual bribethresholds is in P. For the broad class of elections (including plurality,Borda, k-approval, and veto) known as scoring protocols, we prove a dichotomyresult for bribery of weighted voters: We find a simple-to-evaluate conditionthat classifies every case as either NP-complete or in P.

The Robustness of LWPP and WPP, with an Application to Graph  Reconstruction

  We show that the counting class LWPP [FFK94] remains unchanged even if oneallows a polynomial number of gap values rather than one. On the other hand, weshow that it is impossible to improve this from polynomially many gap values toa superpolynomial number of gap values by relativizable proof techniques.  The first of these results implies that the Legitimate Deck Problem (from thestudy of graph reconstruction) is in LWPP (and thus low for PP, i.e., $\rmPP^{\mbox{Legitimate Deck}} = PP$) if the weakened version of theReconstruction Conjecture holds in which the number of nonisomorphic preimagesis assumed merely to be polynomially bounded. This strengthens the 1992 resultof K\"{o}bler, Sch\"{o}ning, and Tor\'{a}n [KST92] that the Legitimate DeckProblem is in LWPP if the Reconstruction Conjecture holds, and providesstrengthened evidence that the Legitimate Deck Problem is not NP-hard.  We additionally show on the one hand that our main LWPP robustness resultalso holds for WPP, and also holds even when one allows both the rejection- andacceptance- gap-value targets to simultaneously be polynomial-sized lists; yeton the other hand, we show that for the #P-based analog of LWPP the behaviormuch differs in that, in some relativized worlds, even two target valuesalready yield a richer class than one value does. Despite that nonrobustnessresult for a #P-based class, we show that the #P-based "exact counting" class$\rm C_{=}P$ remains unchanged even if one allows a polynomial number of targetvalues for the number of accepting paths of the machine.

Recursion-Theoretic Ranking and Compression

  For which sets A does there exist a mapping, computed by a total or partialrecursive function, such that the mapping, when its domain is restricted to A,is a 1-to-1, onto mapping to $\Sigma^*$? And for which sets A does there existsuch a mapping that respects the lexicographical ordering within A? Both casesare types of perfect, minimal hash functions. The complexity-theoretic versionsof these notions are known as compression functions and ranking functions. Thepresent paper defines and studies the recursion-theoretic versions ofcompression and ranking functions, and in particular studies the question ofwhich sets have, or lack, such functions. Thus, this is a case where, incontrast to the usual direction of notion transferal, notions from complexitytheory are inspiring notions, and an investigation, in computability theory.  We show that the rankable and compressible sets broadly populate the1-truth-table degrees, and we prove that every nonempty coRE cylinder isrecursively compressible.

Complexity Results in Graph Reconstruction

  We investigate the relative complexity of the graph isomorphism problem (GI)and problems related to the reconstruction of a graph from its vertex-deletedor edge-deleted subgraphs (in particular, deck checking (DC) and legitimatedeck (LD) problems). We show that these problems are closely related for allamounts $c \geq 1$ of deletion:  1) $GI \equiv^{l}_{iso} VDC_{c}$, $GI \equiv^{l}_{iso} EDC_{c}$, $GI\leq^{l}_{m} LVD_c$, and $GI \equiv^{p}_{iso} LED_c$.  2) For all $k \geq 2$, $GI \equiv^{p}_{iso} k-VDC_c$ and $GI \equiv^{p}_{iso}k-EDC_c$.  3) For all $k \geq 2$, $GI \leq^{l}_{m} k-LVD_c$.  4)$GI \equiv^{p}_{iso} 2-LVC_c$.  5) For all $k \geq 2$, $GI \equiv^{p}_{iso} k-LED_c$.  For many of these results, even the $c = 1$ case was not previously known.  Similar to the definition of reconstruction numbers $vrn_{\exists}(G)$ [HP85]and $ern_{\exists}(G)$ (see page 120 of [LS03]), we introduce two new graphparameters, $vrn_{\forall}(G)$ and $ern_{\forall}(G)$, and give an example of afamily $\{G_n\}_{n \geq 4}$ of graphs on $n$ vertices for which$vrn_{\exists}(G_n) < vrn_{\forall}(G_n)$. For every $k \geq 2$ and $n \geq 1$,we show that there exists a collection of $k$ graphs on $(2^{k-1}+1)n+k$vertices with $2^{n}$ 1-vertex-preimages, i.e., one has families of graphcollections whose number of 1-vertex-preimages is huge relative to the size ofthe graphs involved.

Llull and Copeland Voting Computationally Resist Bribery and Control

  The only systems previously known to be resistant to all the standard controltypes were highly artificial election systems created by hybridization. Westudy a parameterized version of Copeland voting, denoted by Copeland^\alpha,where the parameter \alpha is a rational number between 0 and 1 that specifieshow ties are valued in the pairwise comparisons of candidates. We prove thatCopeland^{0.5}, the system commonly referred to as "Copeland voting," providesfull resistance to constructive control, and we prove the same forCopeland^\alpha, for all rational \alpha, 0 < \alpha < 1. Copeland voting isthe first natural election system proven to have full resistance toconstructive control. We also prove that both Copeland^1 (Llull elections) andCopeland^0 are resistant to all standard types of constructive control otherthan one variant of addition of candidates. Moreover, we show that for eachrational \alpha, 0 \leq \alpha \leq 1, Copeland^\alpha voting is fullyresistant to bribery attacks, and we establish fixed-parameter tractability ofbounded-case control for Copeland^\alpha. We also study Copeland^\alphaelections under more flexible models such as microbribery and extended controland we integrate the potential irrationality of voter preferences into many ofour results.

Guarantees for the Success Frequency of an Algorithm for Finding  Dodgson-Election Winners

  In the year 1876 the mathematician Charles Dodgson, who wrote fiction underthe now more famous name of Lewis Carroll, devised a beautiful voting systemthat has long fascinated political scientists. However, determining the winnerof a Dodgson election is known to be complete for the \Theta_2^p level of thepolynomial hierarchy. This implies that unless P=NP no polynomial-time solutionto this problem exists, and unless the polynomial hierarchy collapses to NP theproblem is not even in NP. Nonetheless, we prove that when the number of votersis much greater than the number of candidates--although the number of votersmay still be polynomial in the number of candidates--a simple greedy algorithmvery frequently finds the Dodgson winners in such a way that it ``knows'' thatit has found them, and furthermore the algorithm never incorrectly declares anonwinner to be a winner.

More Natural Models of Electoral Control by Partition

  "Control" studies attempts to set the outcome of elections through theaddition, deletion, or partition of voters or candidates. The set of benchmarkcontrol types was largely set in the seminal 1992 paper by Bartholdi, Tovey,and Trick that introduced control, and there now is a large literature studyinghow many of the benchmark types various election systems are vulnerable to,i.e., have polynomial-time attack algorithms for.  However, although the longstanding benchmark models of addition and deletionmodel relatively well the real-world settings that inspire them, thelongstanding benchmark models of partition model settings that are arguablyquite distant from those they seek to capture.  In this paper, we introduce--and for some important cases analyze thecomplexity of--new partition models that seek to better capture many real-worldpartition settings. In particular, in many partition settings one wants the twoparts of the partition to be of (almost) equal size, or is partitioning intomore than two parts, or has groups of actors who must be placed in the samepart of the partition. Our hope is that having these new partition types willallow studies of control attacks to include such models that more realisticallycapture many settings.

Open Questions in the Theory of Semifeasible Computation

  The study of semifeasible algorithms was initiated by Selman's work a quarterof century ago [Sel79,Sel81,Sel82]. Informally put, this research streamstudies the power of those sets L for which there is a deterministic (or insome cases, the function may belong to one of various nondeterministic functionclasses) polynomial-time function f such that when at least one of x and ybelongs to L, then f(x,y) \in L \cap \{x,y\}. The intuition here is that it issaying: ``Regarding membership in L, if you put a gun to my head and forced meto bet on one of x or y as belonging to L, my money would be on f(x,y).''  In this article, we present a number of open problems from the theory ofsemifeasible algorithms. For each we present its background and review whatpartial results, if any, are known.

Barbosa, Uniform Polynomial Time Bounds, and Promises

  This note is a commentary on, and critique of, Andre Luiz Barbosa's paperentitled "P != NP Proof." Despite its provocative title, what the paper isseeking to do is not to prove P \neq NP in the standard sense in which thatnotation is used in the literature. Rather, Barbosa is (and is aware that heis) arguing that a different meaning should be associated with the notation P\neq NP, and he claims to prove the truth of the statement P \neq NP in hisquite different sense of that statement. However, we note that (1) the paperfails even on its own terms, as due to a uniformity problem, the paper's proofdoes not establish, even in its unusual sense of the notation, that P \neq NP;and (2) what the paper means by the claim P \neq NP in fact implies that P \neqNP holds even under the standard meaning that that notation has in theliterature (and so it is exceedingly unlikely that Barbosa's proof can be fixedany time soon).

Robust Reductions

  We continue the study of robust reductions initiated by Gavalda and Balcazar.In particular, a 1991 paper of Gavalda and Balcazar claimed an optimalseparation between the power of robust and nondeterministic strong reductions.Unfortunately, their proof is invalid. We re-establish their theorem.  Generalizing robust reductions, we note that robustly strong reductions arebuilt from two restrictions, robust underproductivity and robustoverproductivity, both of which have been separately studied before in othercontexts. By systematically analyzing the power of these reductions, we explorethe extent to which each restriction weakens the power of reductions. We showthat one of these reductions yields a new, strong form of the Karp-LiptonTheorem.

The Consequences of Eliminating NP Solutions

  Given a function based on the computation of an NP machine, can one ingeneral eliminate some solutions? That is, can one in general decrease theambiguity? This simple question remains, even after extensive study by manyresearchers over many years, mostly unanswered. However, complexity-theoreticconsequences and enabling conditions are known. In this tutorial-style articlewe look at some of those, focusing on the most natural framings: reducing thenumber of solutions of NP functions, refining the solutions of NP functions,and subtracting from or otherwise shrinking #P functions. We will see how smalladvice strings are important here, but we also will see how increasing advicesize to achieve robustness is central to the proof of a key ambiguity-reductionresult for NP functions.

An Atypical Survey of Typical-Case Heuristic Algorithms

  Heuristic approaches often do so well that they seem to pretty much alwaysgive the right answer. How close can heuristic algorithms get to always givingthe right answer, without inducing seismic complexity-theoretic consequences?This article first discusses how a series of results by Berman, Buhrman,Hartmanis, Homer, Longpr\'{e}, Ogiwara, Sch\"{o}ening, and Watanabe, from theearly 1970s through the early 1990s, explicitly or implicitly limited how wellheuristic algorithms can do on NP-hard problems. In particular, many desirablelevels of heuristic success cannot be obtained unless severe, highly unlikelycomplexity class collapses occur. Second, we survey work initiated by Goldreichand Wigderson, who showed how under plausible assumptions deterministicheuristics for randomized computation can achieve a very high frequency ofcorrectness. Finally, we consider formal ways in which theory can help explainthe effectiveness of heuristics that solve NP-hard problems in practice.

Schulze and Ranked-Pairs Voting are Fixed-Parameter Tractable to Bribe,  Manipulate, and Control

  Schulze and ranked-pairs elections have received much attention recently, andthe former has quickly become a quite widely used election system. For manycases these systems have been proven resistant to bribery, control, ormanipulation, with ranked pairs being particularly praised for being NP-hardfor all three of those. Nonetheless, the present paper shows that with respectto the number of candidates, Schulze and ranked-pairs elections arefixed-parameter tractable to bribe, control, and manipulate: we obtain uniform,polynomial-time algorithms whose degree does not depend on the number ofcandidates. We also provide such algorithms for some weighted variants of theseproblems.

Creating Strong Total Commutative Associative Complexity-Theoretic  One-Way Functions from Any Complexity-Theoretic One-Way Function

  Rabi and Sherman [RS97] presented novel digital signature and unauthenticatedsecret-key agreement protocols, developed by themselves and by Rivest andSherman. These protocols use ``strong,'' total, commutative (in the case ofmulti-party secret-key agreement), associative one-way functions as their keybuilding blocks. Though Rabi and Sherman did prove that associative one-wayfunctions exist if $\p \neq \np$, they left as an open question whether anynatural complexity-theoretic assumption is sufficient to ensure the existenceof ``strong,'' total, commutative, associative one-way functions. In thispaper, we prove that if $\p \neq \np$ then ``strong,'' total, commutative,associative one-way functions exist.

Exact Analysis of Dodgson Elections: Lewis Carroll's 1876 Voting System  is Complete for Parallel Access to NP

  In 1876, Lewis Carroll proposed a voting system in which the winner is thecandidate who with the fewest changes in voters' preferences becomes aCondorcet winner---a candidate who beats all other candidates in pairwisemajority-rule elections. Bartholdi, Tovey, and Trick provided a lowerbound---NP-hardness---on the computational complexity of determining theelection winner in Carroll's system. We provide a stronger lower bound and anupper bound that matches our lower bound. In particular, determining the winnerin Carroll's system is complete for parallel access to NP, i.e., it is completefor $\thetatwo$, for which it becomes the most natural complete problem known.It follows that determining the winner in Carroll's elections is notNP-complete unless the polynomial hierarchy collapses.

Translating Equality Downwards

  Downward translation of equality refers to cases where a collapse of somepair of complexity classes would induce a collapse of some other pair ofcomplexity classes that (a priori) one expects are smaller. Recently, the firstdownward translation of equality was obtained that applied to the polynomialhierarchy-in particular, to bounded access to its levels [cs.CC/9910007]. Inthis paper, we provide a much broader downward translation that extends notonly that downward translation but also that translation's elegant enhancementby Buhrman and Fortnow. Our work also sheds light on previous research on thestructure of refined polynomial hierarchies, and strengthens the connectionbetween the collapse of bounded query hierarchies and the collapse of thepolynomial hierarchy.

Multimode Control Attacks on Elections

  In 1992, Bartholdi, Tovey, and Trick opened the study of control attacks onelections---attempts to improve the election outcome by such actions asadding/deleting candidates or voters. That work has led to many results on howalgorithms can be used to find attacks on elections and howcomplexity-theoretic hardness results can be used as shields against attacks.However, all the work in this line has assumed that the attacker employs just asingle type of attack. In this paper, we model and study the case in which theattacker launches a multipronged (i.e., multimode) attack. We do so to morerealistically capture the richness of real-life settings. For example, anattacker might simultaneously try to suppress some voters, attract new votersinto the election, and introduce a spoiler candidate. Our model provides aunified framework for such varied attacks, and by constructing polynomial-timemultiprong attack algorithms we prove that for various election systems evensuch concerted, flexible attacks can be perfectly planned in deterministicpolynomial time.

