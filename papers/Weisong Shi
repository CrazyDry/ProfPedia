In Cloud, Can Scientific Communities Benefit from the Economies of  Scale?

  The basic idea behind Cloud computing is that resource providers offerelastic resources to end users. In this paper, we intend to answer one keyquestion to the success of Cloud computing: in Cloud, can small or medium-scalescientific computing communities benefit from the economies of scale? Ourresearch contributions are three-fold: first, we propose an enhanced scientificpublic cloud model (ESP) that encourages small- or medium-scale organizationsto rent elastic resources from a public cloud provider; second, on a basis ofthe ESP model, we design and implement the DawningCloud system that canconsolidate heterogeneous scientific workloads on a Cloud site; third, wepropose an innovative emulation methodology and perform a comprehensiveevaluation. We found that for two typical workloads: high throughput computing(HTC) and many task computing (MTC), DawningCloud saves the resourceconsumption maximally by 44.5% (HTC) and 72.6% (MTC) for service providers, andsaves the total resource consumption maximally by 47.3% for a resource providerwith respect to the previous two public Cloud solutions. To this end, weconclude that for typical workloads: HTC and MTC, DawningCloud can enablescientific communities to benefit from the economies of scale of public Clouds.

Secure and Reliable Transmission with Cooperative Relays in Two-Hop  Wireless Networks

  This work considers the secure and reliable information transmission intwo-hop relay wireless networks without the information of both eavesdropperchannels and locations. While the previous work on this problem mainly studiedinfinite networks and their asymptotic behavior and scaling law results, thispapers focuses on a more practical network with finite number of system nodesand explores the corresponding exact results on the number of eavesdroppers thenetwork can tolerant to ensure a desired secrecy and reliability. For achievingsecure and reliable information transmission in a finite network, twotransmission protocols are considered in this paper, one adopts an optimal butcomplex relay selection process with less load balance capacity while the otheradopts a random but simple relay selection process with good load balancecapacity. Theoretical analysis is further provided to determine the exact andmaximum number of independent and also uniformly distributed eavesdroppers onenetwork can tolerate to satisfy a specified requirement in terms of the maximumsecrecy outage probability and maximum transmission outage probability allowed.

PI-Edge: A Low-Power Edge Computing System for Real-Time Autonomous  Driving Services

  To simultaneously enable multiple autonomous driving services on affordableembedded systems, we designed and implemented {\pi}-Edge, a complete edgecomputing framework for autonomous robots and vehicles. The contributions ofthis paper are three-folds: first, we developed a runtime layer to fullyutilize the heterogeneous computing resources of low-power edge computingsystems; second, we developed an extremely lightweight operating system tomanage multiple autonomous driving services and their communications; third, wedeveloped an edge-cloud coordinator to dynamically offload tasks to the cloudto optimize client system energy consumption. To the best of our knowledge,this is the first complete edge computing system of a production autonomousvehicle. In addition, we successfully implemented {\pi}-Edge on a Nvidia Jetsonand demonstrated that we could successfully support multiple autonomous drivingservices with only 11 W of power consumption, and hence proving theeffectiveness of the proposed {\pi}-Edge system.

PhoenixCloud: Provisioning Resources for Heterogeneous Cloud Workloads

  As more and more service providers choose Cloud platforms, a resourceprovider needs to provision resources and supporting runtime environments (REs)for heterogeneous workloads in different scenarios. Previous work fails toresolve this issue in several ways: (1) it fails to pay attention to diverse RErequirements, and does not enable creating coordinated REs on demand; (2) fewwork investigates coordinated resource provisioning for heterogeneousworkloads. In this paper, our contributions are three-fold: (1) we present anRE agreement that expresses diverse RE requirements, and build an innovativesystem PhoenixCloud that enables a resource provider to create REs on demandaccording to RE agreements; (2) we propose two coordinated resourceprovisioning solutions for heterogeneous workloads in two typical Cloudscenarios: first, a large organization operates a private Cloud for twoheterogeneous workloads; second, a large organization or two service providersrunning heterogeneous workloads revert to a public Cloud; and (3) Acomprehensive evaluation has been performed in experiments. For typicalworkload traces of parallel batch jobs and Web services, our experiments showthat: a) In the first Cloud scenario, when the throughput is almost same likethat of a dedicated cluster system, our solution decreases the configurationsize of cluster by about 40%; b) in the second scenario, our solution decreasesnot only the total resource consumption, but also the peak resource consumptionmaximally to 31% with respect to that of EC2 + RightScale solution.

In Cloud, Do MTC or HTC Service Providers Benefit from the Economies of  Scale?

  In this paper, we intend to answer one key question to the success of cloudcomputing: in cloud, do many task computing (MTC) or high throughput computing(HTC) service providers, which offer the corresponding computing service to endusers, benefit from the economies of scale? Our research contributions arethree-fold: first, we propose an innovative usage model, called dynamic serviceprovision (DSP) model, for MTC or HTC service providers. In the DSP model, theresource provider provides the service of creating and managing runtimeenvironments for MTC or HTC service providers, and consolidates heterogeneousMTC or HTC workloads on the cloud platform; second, according to the DSP model,we design and implement DawningCloud, which provides automatic management forheterogeneous workloads; third, a comprehensive evaluation of DawningCloud hasbeen performed in an emulatation experiment. We found that for typicalworkloads, in comparison with the previous two cloud solutions, DawningCloudsaves the resource consumption maximally by 46.4% (HTC) and 74.9% (MTC) for theservice providers, and saves the total resource consumption maximally by 29.7%for the resource provider. At the same time, comparing with the traditionalsolution that provides MTC or HTC services with dedicated systems, DawningCloudis more cost-effective. To this end, we conclude that for typical MTC and HTCworkloads, on the cloud platform, MTC and HTC service providers and theresource provider can benefit from the economies of scale.

Automatic Performance Debugging of SPMD-style Parallel Programs

  The simple program and multiple data (SPMD) programming model is widely usedfor both high performance computing and Cloud computing. In this paper, wedesign and implement an innovative system, AutoAnalyzer, that automates theprocess of debugging performance problems of SPMD-style parallel programs,including data collection, performance behavior analysis, locating bottlenecks,and uncovering their root causes. AutoAnalyzer is unique in terms of twofeatures: first, without any apriori knowledge, it automatically locatesbottlenecks and uncovers their root causes for performance optimization;second, it is lightweight in terms of the size of performance data to becollected and analyzed. Our contributions are three-fold: first, we propose twoeffective clustering algorithms to investigate the existence of performancebottlenecks that cause process behavior dissimilarity or code region behaviordisparity, respectively; meanwhile, we present two searching algorithms tolocate bottlenecks; second, on a basis of the rough set theory, we propose aninnovative approach to automatically uncovering root causes of bottlenecks;third, on the cluster systems with two different configurations, we use twoproduction applications, written in Fortran 77, and one open sourcecode-MPIBZIP2 (http://compression.ca/mpibzip2/), written in C++, to verify theeffectiveness and correctness of our methods. For three applications, we alsopropose an experimental approach to investigating the effects of differentmetrics on locating bottlenecks.

Exploring Relay Cooperation for Secure and Reliable Transmission in  Two-Hop Wireless Networks

  This work considers the problem of secure and reliable informationtransmission via relay cooperation in two-hop relay wireless networks withoutthe information of both eavesdropper channels and locations. While previouswork on this problem mainly studied infinite networks and their asymptoticbehavior and scaling law results, this papers focuses on a more practicalnetwork with finite number of system nodes and explores the corresponding exactresult on the number of eavesdroppers one network can tolerant to ensuredesired secrecy and reliability. We first study the scenario where path-loss isequal between all pairs of nodes and consider two transmission protocols there,one adopts an optimal but complex relay selection process with less loadbalance capacity while the other adopts a random but simple relay selectionprocess with good load balance capacity. Theoretical analysis is then providedto determine the maximum number of eavesdroppers one network can tolerate toensure a desired performance in terms of the secrecy outage probability andtransmission outage probability. We further extend our study to the moregeneral scenario where path-loss between each pair of nodes also depends thedistance between them, for which a new transmission protocol with bothpreferable relay selection and good load balance as well as the correspondingtheoretical analysis are presented.

Teaching Autonomous Driving Using a Modular and Integrated Approach

  Autonomous driving is not one single technology but rather a complex systemintegrating many technologies, which means that teaching autonomous driving isa challenging task. Indeed, most existing autonomous driving classes focus onone of the technologies involved. This not only fails to provide acomprehensive coverage, but also sets a high entry barrier for students withdifferent technology backgrounds. In this paper, we present a modular,integrated approach to teaching autonomous driving. Specifically, we organizethe technologies used in autonomous driving into modules. This is described inthe textbook we have developed as well as a series of multimedia onlinelectures designed to provide technical overview for each module. Then, once thestudents have understood these modules, the experimental platforms forintegration we have developed allow the students to fully understand how themodules interact with each other. To verify this teaching approach, we presentthree case studies: an introductory class on autonomous driving for studentswith only a basic technology background; a new session in an existing embeddedsystems class to demonstrate how embedded system technologies can be applied toautonomous driving; and an industry professional training session to quicklybring up experienced engineers to work in autonomous driving. The results showthat students can maintain a high interest level and make great progress bystarting with familiar concepts before moving onto other modules.

Co-KV: A Collaborative Key-Value Store Using Near-Data Processing to  Improve Compaction for the LSM-tree

  Log-structured merge tree (LSM-tree) based key-value stores are widelyemployed in large-scale storage systems. In the compaction of the key-valuestore, SSTables are merged with overlapping key ranges and sorted for dataqueries. This, however, incurs write amplification and thus degrades systemperformance, especially under update-intensive workloads. Current optimizationfocuses mostly on the reduction of the overload of compaction in the host, butrarely makes full use of computation in the device. To address these issues, wepropose Co-KV, a Collaborative Key-Value store between the host and a near-dataprocessing ( i.e., NDP) model based SSD to improve compaction. Co-KV offersthree benefits: (1) reducing write amplification by a compaction offloadingscheme between host and device; (2) relieving the overload of compaction in thehost and leveraging computation in the SSD based on the NDP model; and (3)improving the performance of LSM-tree based key-value stores underupdate-intensive workloads.  Extensive db_bench experiment show that Co-KV largely achieves a 2.0x overallthroughput improvement, and a write amplification reduction by up to 36.0% overthe state-of-the-art LevelDB. Under YCSB workloads, Co-KV increases thethroughput by 1.7x - 2.4x while decreases the write amplification and averagelatency by up to 30.0% and 43.0%, respectively.

CAVBench: A Benchmark Suite for Connected and Autonomous Vehicles

  Connected and autonomous vehicles (CAVs) have recently attracted asignificant amount of attention both from researchers and industry. Numerousstudies targeting algorithms, software frameworks, and applications on the CAVsscenario have emerged. Meanwhile, several pioneer efforts have focused on theedge computing system and architecture design for the CAVs scenario andprovided various heterogeneous platform prototypes for CAVs. However, astandard and comprehensive application benchmark for CAVs is missing, hinderingthe study of these emerging computing systems. To address this challengingproblem, we present CAVBench, the first benchmark suite for the edge computingsystem in the CAVs scenario. CAVBench is comprised of six typical applicationscovering four dominate CAVs scenarios and takes four datasets as standardinput. CAVBench provides quantitative evaluation results via application andsystem perspective output metrics. We perform a series of experiments andacquire three systemic characteristics of the applications in CAVBench. First,the operation intensity of the applications is polarized, which explains whyheterogeneous hardware is important for a CAVs computing system. Second, allapplications in CAVBench consume high memory bandwidth, so the system should beequipped with high bandwidth memory or leverage good memory bandwidthmanagement to avoid the performance degradation caused by memory bandwidthcompetition. Third, some applications have worse data/instruction localitybased on the cache miss observation, so the computing system targeting theseapplications should optimize the cache architecture. Last, we use the CAVBenchto evaluate a typical edge computing platform and present the quantitative andqualitative analysis of the benchmarking results.

A Mobility-Aware Vehicular Caching Scheme in Content Centric Networks:  Model and Optimization

  Edge caching is being explored as a promising technology to alleviate thenetwork burden of cellular networks by separating the computing functionalitiesaway from cellular base stations. However, the service capability of existingcaching scheme is limited by fixed edge infrastructure when facing theuncertainties of users' requests and locations. The vehicular caching, whichuses the moving vehicles as cache carriers, is regard as an efficient method tosolve the problem above. This paper studies the effectiveness of vehicularcaching scheme in content centric networks by developing optimization modeltowards the minimization of network energy consumption. Particularly, we modelthe interactions between caching vehicles and mobile users as a 2-D Markovprocess, in order to characterize the network availability of mobile users.Based on the developed model, we propose an online vehicular caching design byoptimizing network energy efficiency. Specifically, the problem of cachingdecision making is firstly formulated as a fractional optimization model,towards the optimal energy efficiency. Using nonlinear fractional programmingtechnology and Lyapunov optimization theory, we derive the theoretical solutionfor the optimization model. An online caching algorithm to enable the optimalvehicular caching is developed based on the solution. Finally, extensivesimulations are conducted to examine the performance of our proposal. Bycomparison, our online caching scheme outperforms the existing scheme in termsof energy efficiency, hit ratio, cache utilization, and system gain.

PhoenixCloud: Provisioning Resources for Heterogeneous Workloads in  Cloud Computing

  As more and more service providers choose Cloud platforms, which is providedby third party resource providers, resource providers needs to provisionresources for heterogeneous workloads in different Cloud scenarios. Taking intoaccount the dramatic differences of heterogeneous workloads, can wecoordinately provision resources for heterogeneous workloads in Cloudcomputing? In this paper we focus on this important issue, which isinvestigated by few previous work. Our contributions are threefold: (1) werespectively propose a coordinated resource provisioning solution forheterogeneous workloads in two typical Cloud scenarios: first, a largeorganization operates a private Cloud for two heterogeneous workloads; second,a large organization or two service providers running heterogeneous workloadsrevert to a public Cloud; (2) we build an agile system PhoenixCloud thatenables a resource provider to create coordinated runtime environments ondemand for heterogeneous workloads when they are consolidated on a Cloud site;and (3) A comprehensive evaluation has been performed in experiments. For twotypical heterogeneous workload traces: parallel batch jobs and Web services,our experiments show that: a) in a private Cloud scenario, when the throughputis almost same like that of a dedicated cluster system, our solution decreasesthe configuration size of a cluster by about 40%; b) in a public Cloudscenario, our solution decreases not only the total resource consumption, butalso the peak resource consumption maximally to 31% with respect to that of EC2+RightScale solution.

