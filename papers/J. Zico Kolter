Probabilistic Segmentation via Total Variation Regularization

  We present a convex approach to probabilistic segmentation and modeling of
time series data. Our approach builds upon recent advances in multivariate
total variation regularization, and seeks to learn a separate set of parameters
for the distribution over the observations at each time point, but with an
additional penalty that encourages the parameters to remain constant over time.
We propose efficient optimization methods for solving the resulting (large)
optimization problems, and a two-stage procedure for estimating recurring
clusters under such models, based upon kernel density estimation. Finally, we
show on a number of real-world segmentation tasks, the resulting methods often
perform as well or better than existing latent variable models, while being
substantially easier to train.


Task-based End-to-end Model Learning in Stochastic Optimization

  With the increasing popularity of machine learning techniques, it has become
common to see prediction algorithms operating within some larger process.
However, the criteria by which we train these algorithms often differ from the
ultimate criteria on which we evaluate them. This paper proposes an end-to-end
approach for learning probabilistic machine learning models in a manner that
directly captures the ultimate task-based objective for which they will be
used, within the context of stochastic programming. We present three
experimental evaluations of the proposed approach: a classical inventory stock
problem, a real-world electrical grid scheduling task, and a real-world energy
storage arbitrage task. We show that the proposed approach can outperform both
traditional modeling and purely black-box policy optimization approaches in
these applications.


The Multiple Quantile Graphical Model

  We introduce the Multiple Quantile Graphical Model (MQGM), which extends the
neighborhood selection approach of Meinshausen and Buhlmann for learning sparse
graphical models. The latter is defined by the basic subproblem of modeling the
conditional mean of one variable as a sparse function of all others. Our
approach models a set of conditional quantiles of one variable as a sparse
function of all others, and hence offers a much richer, more expressive class
of conditional distribution estimates. We establish that, under suitable
regularity conditions, the MQGM identifies the exact conditional independencies
with probability tending to one as the problem size grows, even outside of the
usual homoskedastic Gaussian data model. We develop an efficient algorithm for
fitting the MQGM using the alternating direction method of multipliers. We also
describe a strategy for sampling from the joint distribution that underlies the
MQGM estimate. Lastly, we present detailed experiments that demonstrate the
flexibility and effectiveness of the MQGM in modeling hetereoskedastic
non-Gaussian data.


A Continuous-Time View of Early Stopping for Least Squares

  We study the statistical properties of the iterates generated by gradient
descent, applied to the fundamental problem of least squares regression. We
take a continuous-time view, i.e., consider infinitesimal step sizes in
gradient descent, in which case the iterates form a trajectory called gradient
flow. Our primary focus is to compare the risk of gradient flow to that of
ridge regression. Under the calibration $t=1/\lambda$---where $t$ is the time
parameter in gradient flow, and $\lambda$ the tuning parameter in ridge
regression---we prove that the risk of gradient flow is no less than 1.69 times
that of ridge, along the entire path (for all $t \geq 0$). This holds in finite
samples with very weak assumptions on the data model (in particular, with no
assumptions on the features $X$). We prove that the same relative risk bound
holds for prediction risk, in an average sense over the underlying signal
$\beta_0$. Finally, we examine limiting risk expressions (under standard
Marchenko-Pastur asymptotics), and give supporting numerical experiments.


Convex programming with fast proximal and linear operators

  We present Epsilon, a system for general convex programming using fast linear
and proximal operators. As with existing convex programming frameworks, users
specify convex optimization problems using a natural grammar for mathematical
expressions, composing functions in a way that is guaranteed to be convex by
the rules of disciplined convex programming. Given such an input, the Epsilon
compiler transforms the optimization problem into a mathematically equivalent
form consisting only of functions with efficient proximal operators---an
intermediate representation we refer to as prox-affine form. By reducing
problems to this form, Epsilon enables solving general convex problems using a
large library of fast proximal and linear operators; numerical examples on many
popular problems from statistics and machine learning show that this often
improves running times by an order of magnitude or more vs. existing approaches
based on conic solvers.


A Fast Algorithm for Sparse Controller Design

  We consider the task of designing sparse control laws for large-scale systems
by directly minimizing an infinite horizon quadratic cost with an $\ell_1$
penalty on the feedback controller gains. Our focus is on an improved algorithm
that allows us to scale to large systems (i.e. those where sparsity is most
useful) with convergence times that are several orders of magnitude faster than
existing algorithms. In particular, we develop an efficient proximal Newton
method which minimizes per-iteration cost with a coordinate descent active set
approach and fast numerical solutions to the Lyapunov equations. Experimentally
we demonstrate the appeal of this approach on synthetic examples and real power
networks significantly larger than those previously considered in the
literature.


Contextually Supervised Source Separation with Application to Energy
  Disaggregation

  We propose a new framework for single-channel source separation that lies
between the fully supervised and unsupervised setting. Instead of supervision,
we provide input features for each source signal and use convex methods to
estimate the correlations between these features and the unobserved signal
decomposition. We analyze the case of $\ell_2$ loss theoretically and show that
recovery of the signal components depends only on cross-correlation between
features for different signals, not on correlations between features for the
same signal. Contextually supervised source separation is a natural fit for
domains with large amounts of data but no explicit supervision; our motivating
application is energy disaggregation of hourly smart meter data (the separation
of whole-home power signals into different energy uses). Here we apply
contextual supervision to disaggregate the energy usage of thousands homes over
four years, a significantly larger scale than previously published efforts, and
demonstrate on synthetic data that our method outperforms the unsupervised
approach.


Input Convex Neural Networks

  This paper presents the input convex neural network architecture. These are
scalar-valued (potentially deep) neural networks with constraints on the
network parameters such that the output of the network is a convex function of
(some of) the inputs. The networks allow for efficient inference via
optimization over some inputs to the network given others, and can be applied
to settings including structured prediction, data imputation, reinforcement
learning, and others. In this paper we lay the basic groundwork for these
models, proposing methods for inference, optimization and learning, and analyze
their representational power. We show that many existing neural network
architectures can be made input-convex with a minor modification, and develop
specialized optimization algorithms tailored to this setting. Finally, we
highlight the performance of the methods on multi-label prediction, image
completion, and reinforcement learning problems, where we show improvement over
the existing state of the art in many cases.


A Semismooth Newton Method for Fast, Generic Convex Programming

  We introduce Newton-ADMM, a method for fast conic optimization. The basic
idea is to view the residuals of consecutive iterates generated by the
alternating direction method of multipliers (ADMM) as a set of fixed point
equations, and then use a nonsmooth Newton method to find a solution; we apply
the basic idea to the Splitting Cone Solver (SCS), a state-of-the-art method
for solving generic conic optimization problems. We demonstrate theoretically,
by extending the theory of semismooth operators, that Newton-ADMM converges
rapidly (i.e., quadratically) to a solution; empirically, Newton-ADMM is
significantly faster than SCS on a number of problems. The method also has
essentially no tuning parameters, generates certificates of primal or dual
infeasibility, when appropriate, and can be specialized to solve specific
convex problems.


Gradient descent GAN optimization is locally stable

  Despite the growing prominence of generative adversarial networks (GANs),
optimization in GANs is still a poorly understood topic. In this paper, we
analyze the "gradient descent" form of GAN optimization i.e., the natural
setting where we simultaneously take small gradient steps in both generator and
discriminator parameters. We show that even though GAN optimization does not
correspond to a convex-concave game (even for simple parameterizations), under
proper conditions, equilibrium points of this optimization procedure are still
\emph{locally asymptotically stable} for the traditional GAN formulation. On
the other hand, we show that the recently proposed Wasserstein GAN can have
non-convergent limit cycles near equilibrium. Motivated by this stability
analysis, we propose an additional regularization term for gradient descent GAN
updates, which \emph{is} able to guarantee local stability for both the WGAN
and the traditional GAN, and also shows practical promise in speeding up
convergence and addressing mode collapse.


An Empirical Evaluation of Generic Convolutional and Recurrent Networks
  for Sequence Modeling

  For most deep learning practitioners, sequence modeling is synonymous with
recurrent networks. Yet recent results indicate that convolutional
architectures can outperform recurrent networks on tasks such as audio
synthesis and machine translation. Given a new sequence modeling task or
dataset, which architecture should one use? We conduct a systematic evaluation
of generic convolutional and recurrent architectures for sequence modeling. The
models are evaluated across a broad range of standard tasks that are commonly
used to benchmark recurrent networks. Our results indicate that a simple
convolutional architecture outperforms canonical recurrent networks such as
LSTMs across a diverse range of tasks and datasets, while demonstrating longer
effective memory. We conclude that the common association between sequence
modeling and recurrent networks should be reconsidered, and convolutional
networks should be regarded as a natural starting point for sequence modeling
tasks. To assist related work, we have made code available at
http://github.com/locuslab/TCN .


Trellis Networks for Sequence Modeling

  We present trellis networks, a new architecture for sequence modeling. On the
one hand, a trellis network is a temporal convolutional network with special
structure, characterized by weight tying across depth and direct injection of
the input into deep layers. On the other hand, we show that truncated recurrent
networks are equivalent to trellis networks with special sparsity structure in
their weight matrices. Thus trellis networks with general weight matrices
generalize truncated recurrent networks. We leverage these connections to
design high-performing trellis networks that absorb structural and algorithmic
elements from both recurrent and convolutional models. Experiments demonstrate
that trellis networks outperform the current state of the art methods on a
variety of challenging benchmarks, including word-level language modeling and
character-level language modeling tasks, and stress tests designed to evaluate
long-term memory retention. The code is available at
https://github.com/locuslab/trellisnet .


Differentiable MPC for End-to-end Planning and Control

  We present foundations for using Model Predictive Control (MPC) as a
differentiable policy class for reinforcement learning in continuous state and
action spaces. This provides one way of leveraging and combining the advantages
of model-free and model-based approaches. Specifically, we differentiate
through MPC by using the KKT conditions of the convex approximation at a fixed
point of the controller. Using this strategy, we are able to learn the cost and
dynamics of a controller via end-to-end learning. Our experiments focus on
imitation learning in the pendulum and cartpole domains, where we learn the
cost and dynamics terms of an MPC policy class. We show that our MPC policies
are significantly more data-efficient than a generic neural network and that
our method is superior to traditional system identification in a setting where
the expert is unrealizable.


Low-rank semidefinite programming for the MAX2SAT problem

  This paper proposes a new algorithm for solving MAX2SAT problems based on
combining search methods with semidefinite programming approaches. Semidefinite
programming techniques are well-known as a theoretical tool for approximating
maximum satisfiability problems, but their application has traditionally been
very limited by their speed and randomized nature. Our approach overcomes this
difficult by using a recent approach to low-rank semidefinite programming,
specialized to work in an incremental fashion suitable for use in an exact
search algorithm. The method can be used both within complete or incomplete
solver, and we demonstrate on a variety of problems from recent competitions.
Our experiments show that the approach is faster (sometimes by orders of
magnitude) than existing state-of-the-art complete and incomplete solvers,
representing a substantial advance in search methods specialized for MAX2SAT
problems.


Generalization in Deep Networks: The Role of Distance from
  Initialization

  Why does training deep neural networks using stochastic gradient descent
(SGD) result in a generalization error that does not worsen with the number of
parameters in the network? To answer this question, we advocate a notion of
effective model capacity that is dependent on {\em a given random
initialization of the network} and not just the training algorithm and the data
distribution. We provide empirical evidences that demonstrate that the model
capacity of SGD-trained deep networks is in fact restricted through implicit
regularization of {\em the $\ell_2$ distance from the initialization}. We also
provide theoretical arguments that further highlight the need for
initialization-dependent notions of model capacity. We leave as open questions
how and why distance from initialization is regularized, and whether it is
sufficient to explain generalization.


Certified Adversarial Robustness via Randomized Smoothing

  Recent work has shown that any classifier which classifies well under
Gaussian noise can be leveraged to create a new classifier that is provably
robust to adversarial perturbations in L2 norm. However, existing guarantees
for such classifiers are suboptimal. In this work we provide the first tight
analysis of this "randomized smoothing" technique. We then demonstrate that
this extremely simple method outperforms by a wide margin all other provably
L2-robust classifiers proposed in the literature. Furthermore, we train an
ImageNet classifier with e.g. a provable top-1 accuracy of 49% under
adversarial perturbations with L2 norm less than 0.5 (=127/255). No other
provable adversarial defense has been shown to be feasible on ImageNet. While
randomized smoothing with Gaussian noise only confers robustness in L2 norm,
the empirical success of the approach suggests that provable methods based on
randomization at test time are a promising direction for future research into
adversarially robust classification. Code and trained models are available at
https://github.com/locuslab/smoothing .


Uniform convergence may be unable to explain generalization in deep
  learning

  We cast doubt on the power of uniform convergence-based generalization bounds
to provide a complete picture of why overparameterized deep networks generalize
well. While it is well-known that many existing bounds are numerically large,
through a variety of experiments, we first bring to light another crucial and
more concerning aspect of these bounds: in practice, these bounds can {\em
increase} with the dataset size. Guided by our observations, we then present
examples of overparameterized linear classifiers and neural networks trained by
stochastic gradient descent (SGD) where uniform convergence provably cannot
`explain generalization,' even if we take into account implicit regularization
{\em to the fullest extent possible}. More precisely, even if we consider only
the set of classifiers output by SGD that have test errors less than some small
$\epsilon$, applying (two-sided) uniform convergence on this set of classifiers
yields a generalization guarantee that is larger than $1-\epsilon$ and is
therefore nearly vacuous.


OptNet: Differentiable Optimization as a Layer in Neural Networks

  This paper presents OptNet, a network architecture that integrates
optimization problems (here, specifically in the form of quadratic programs) as
individual layers in larger end-to-end trainable deep networks. These layers
encode constraints and complex dependencies between the hidden states that
traditional convolutional and fully-connected layers often cannot capture. In
this paper, we explore the foundations for such an architecture: we show how
techniques from sensitivity analysis, bilevel optimization, and implicit
differentiation can be used to exactly differentiate through these layers and
with respect to layer parameters; we develop a highly efficient solver for
these layers that exploits fast GPU-based batch solves within a primal-dual
interior point method, and which provides backpropagation gradients with
virtually no additional cost on top of the solve; and we highlight the
application of these approaches in several problems. In one notable example, we
show that the method is capable of learning to play mini-Sudoku (4x4) given
just input and output games, with no a priori information about the rules of
the game; this highlights the ability of our architecture to learn hard
constraints better than other neural architectures.


The Mixing method: low-rank coordinate descent for semidefinite
  programming with diagonal constraints

  In this paper, we propose a low-rank coordinate descent approach to
structured semidefinite programming with diagonal constraints. The approach,
which we call the Mixing method, is extremely simple to implement, has no free
parameters, and typically attains an order of magnitude or better improvement
in optimization performance over the current state of the art. We show that the
method is strictly decreasing, converges to a critical point, and further that
for sufficient rank all non-optimal critical points are unstable. Moreover, we
prove that with a step size, the Mixing method converges to the global optimum
of the semidefinite program almost surely in a locally linear rate under random
initialization. This is the first low-rank semidefinite programming method that
has been shown to achieve a global optimum on the spherical manifold without
assumption. We apply our algorithm to two related domains: solving the maximum
cut semidefinite relaxation, and solving a maximum satisfiability relaxation
(we also briefly consider additional applications such as learning word
embeddings). In all settings, we demonstrate substantial improvement over the
existing state of the art along various dimensions, and in total, this work
expands the scope and scale of problems that can be solved using semidefinite
programming methods.


Intelligent Pothole Detection and Road Condition Assessment

  Poor road conditions are a public nuisance, causing passenger discomfort,
damage to vehicles, and accidents. In the U.S., road-related conditions are a
factor in 22,000 of the 42,000 traffic fatalities each year. Although we often
complain about bad roads, we have no way to detect or report them at scale. To
address this issue, we developed a system to detect potholes and assess road
conditions in real-time. Our solution is a mobile application that captures
data on a car's movement from gyroscope and accelerometer sensors in the phone.
To assess roads using this sensor data, we trained SVM models to classify road
conditions with 93% accuracy and potholes with 92% accuracy, beating the base
rate for both problems. As the user drives, the models use the sensor data to
classify whether the road is good or bad, and whether it contains potholes.
Then, the classification results are used to create data-rich maps that
illustrate road conditions across the city. Our system will empower civic
officials to identify and repair damaged roads which inconvenience passengers
and cause accidents. This paper details our data science process for collecting
training data on real roads, transforming noisy sensor data into useful
signals, training and evaluating machine learning models, and deploying those
models to production through a real-time classification app. It also highlights
how cities can use our system to crowdsource data and deliver road repair
resources to areas in need.


Provable defenses against adversarial examples via the convex outer
  adversarial polytope

  We propose a method to learn deep ReLU-based classifiers that are provably
robust against norm-bounded adversarial perturbations on the training data. For
previously unseen examples, the approach is guaranteed to detect all
adversarial examples, though it may flag some non-adversarial examples as well.
The basic idea is to consider a convex outer approximation of the set of
activations reachable through a norm-bounded perturbation, and we develop a
robust optimization procedure that minimizes the worst case loss over this
outer region (via a linear program). Crucially, we show that the dual problem
to this linear program can be represented itself as a deep network similar to
the backpropagation network, leading to very efficient optimization approaches
that produce guaranteed bounds on the robust loss. The end result is that by
executing a few more forward and backward passes through a slightly modified
version of the original network (though possibly with much larger batch sizes),
we can learn a classifier that is provably robust to any norm-bounded
adversarial attack. We illustrate the approach on a number of tasks to train
classifiers with robust adversarial guarantees (e.g. for MNIST, we produce a
convolutional classifier that provably has less than 5.8% test error for any
adversarial attack with bounded $\ell_\infty$ norm less than $\epsilon = 0.1$),
and code for all experiments in the paper is available at
https://github.com/locuslab/convex_adversarial.


What game are we playing? End-to-end learning in normal and extensive
  form games

  Although recent work in AI has made great progress in solving large,
zero-sum, extensive-form games, the underlying assumption in most past work is
that the parameters of the game itself are known to the agents. This paper
deals with the relatively under-explored but equally important "inverse"
setting, where the parameters of the underlying game are not known to all
agents, but must be learned through observations. We propose a differentiable,
end-to-end learning framework for addressing this task. In particular, we
consider a regularized version of the game, equivalent to a particular form of
quantal response equilibrium, and develop 1) a primal-dual Newton method for
finding such equilibrium points in both normal and extensive form games; and 2)
a backpropagation method that lets us analytically compute gradients of all
relevant game parameters through the solution itself. This ultimately lets us
learn the game by training in an end-to-end fashion, effectively by integrating
a "differentiable game solver" into the loop of larger deep network
architectures. We demonstrate the effectiveness of the learning method in
several settings including poker and security game tasks.


Scaling provable adversarial defenses

  Recent work has developed methods for learning deep network classifiers that
are provably robust to norm-bounded adversarial perturbation; however, these
methods are currently only possible for relatively small feedforward networks.
In this paper, in an effort to scale these approaches to substantially larger
models, we extend previous work in three main directions. First, we present a
technique for extending these training procedures to much more general
networks, with skip connections (such as ResNets) and general nonlinearities;
the approach is fully modular, and can be implemented automatically (analogous
to automatic differentiation). Second, in the specific case of $\ell_\infty$
adversarial perturbations and networks with ReLU nonlinearities, we adopt a
nonlinear random projection for training, which scales linearly in the number
of hidden units (previous approaches scaled quadratically). Third, we show how
to further improve robust error through cascade models. On both MNIST and CIFAR
data sets, we train classifiers that improve substantially on the state of the
art in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST
(with $\ell_\infty$ perturbations of $\epsilon=0.1$), and from 80% to 36.4% on
CIFAR (with $\ell_\infty$ perturbations of $\epsilon=2/255$). Code for all
experiments in the paper is available at
https://github.com/locuslab/convex_adversarial/.


Wasserstein Adversarial Examples via Projected Sinkhorn Iterations

  A rapidly growing area of work has studied the existence of adversarial
examples, datapoints which have been perturbed to fool a classifier, but the
vast majority of these works have focused primarily on threat models defined by
$\ell_p$ norm-bounded perturbations. In this paper, we propose a new threat
model for adversarial attacks based on the Wasserstein distance. In the image
classification setting, such distances measure the cost of moving pixel mass,
which naturally cover "standard" image manipulations such as scaling, rotation,
translation, and distortion (and can potentially be applied to other settings
as well). To generate Wasserstein adversarial examples, we develop a procedure
for projecting onto the Wasserstein ball, based upon a modified version of the
Sinkhorn iteration. The resulting algorithm can successfully attack image
classification models, bringing traditional CIFAR10 models down to 3% accuracy
within a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1
pixel), and we demonstrate that PGD-based adversarial training can improve this
adversarial accuracy to 76%. In total, this work opens up a new direction of
study in adversarial robustness, more formally considering convex metrics that
accurately capture the invariances that we typically believe should exist in
classifiers. Code for all experiments in the paper is available at
https://github.com/locuslab/projected_sinkhorn.


Large Scale Learning of Agent Rationality in Two-Player Zero-Sum Games

  With the recent advances in solving large, zero-sum extensive form games,
there is a growing interest in the inverse problem of inferring underlying game
parameters given only access to agent actions. Although a recent work provides
a powerful differentiable end-to-end learning frameworks which embed a game
solver within a deep-learning framework, allowing unknown game parameters to be
learned via backpropagation, this framework faces significant limitations when
applied to boundedly rational human agents and large scale problems, leading to
poor practicality. In this paper, we address these limitations and propose a
framework that is applicable for more practical settings. First, seeking to
learn the rationality of human agents in complex two-player zero-sum games, we
draw upon well-known ideas in decision theory to obtain a concise and
interpretable agent behavior model, and derive solvers and gradients for
end-to-end learning. Second, to scale up to large, real-world scenarios, we
propose an efficient first-order primal-dual method which exploits the
structure of extensive-form games, yielding significantly faster computation
for both game solving and gradient computation. When tested on randomly
generated games, we report speedups of orders of magnitude over previous
approaches. We also demonstrate the effectiveness of our model on both
real-world one-player settings and synthetic data.


Adversarial camera stickers: A physical camera-based attack on deep
  learning systems

  Recent work has thoroughly documented the susceptibility of deep learning
systems to adversarial examples, but most such instances directly manipulate
the digital input to a classifier. Although a smaller line of work considers
physical adversarial attacks, in all cases these involve manipulating the
object of interest, e.g., putting a physical sticker on a object to misclassify
it, or manufacturing an object specifically intended to be misclassified. In
this work, we consider an alternative question: is it possible to fool deep
classifiers, over all perceived objects of a certain type, by physically
manipulating the camera itself? We show that this is indeed possible, that by
placing a carefully crafted and mainly-translucent sticker over the lens of a
camera, one can create universal perturbations of the observed images that are
inconspicuous, yet reliably misclassify target objects as a different
(targeted) class. To accomplish this, we propose an iterative procedure for
both updating the attack perturbation (to make it adversarial for a given
classifier), and the threat model itself (to ensure it is physically
realizable). For example, we show that we can achieve physically-realizable
attacks that fool ImageNet classifiers in a targeted fashion 49.6% of the time.
This presents a new class of physically-realizable threat models to consider in
the context of adversarially robust machine learning. Our demo video can be
viewed at: https://youtu.be/wUVmL33Fx54


