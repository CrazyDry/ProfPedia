Probabilistic Segmentation via Total Variation Regularization

  We present a convex approach to probabilistic segmentation and modeling oftime series data. Our approach builds upon recent advances in multivariatetotal variation regularization, and seeks to learn a separate set of parametersfor the distribution over the observations at each time point, but with anadditional penalty that encourages the parameters to remain constant over time.We propose efficient optimization methods for solving the resulting (large)optimization problems, and a two-stage procedure for estimating recurringclusters under such models, based upon kernel density estimation. Finally, weshow on a number of real-world segmentation tasks, the resulting methods oftenperform as well or better than existing latent variable models, while beingsubstantially easier to train.

Task-based End-to-end Model Learning in Stochastic Optimization

  With the increasing popularity of machine learning techniques, it has becomecommon to see prediction algorithms operating within some larger process.However, the criteria by which we train these algorithms often differ from theultimate criteria on which we evaluate them. This paper proposes an end-to-endapproach for learning probabilistic machine learning models in a manner thatdirectly captures the ultimate task-based objective for which they will beused, within the context of stochastic programming. We present threeexperimental evaluations of the proposed approach: a classical inventory stockproblem, a real-world electrical grid scheduling task, and a real-world energystorage arbitrage task. We show that the proposed approach can outperform bothtraditional modeling and purely black-box policy optimization approaches inthese applications.

The Multiple Quantile Graphical Model

  We introduce the Multiple Quantile Graphical Model (MQGM), which extends theneighborhood selection approach of Meinshausen and Buhlmann for learning sparsegraphical models. The latter is defined by the basic subproblem of modeling theconditional mean of one variable as a sparse function of all others. Ourapproach models a set of conditional quantiles of one variable as a sparsefunction of all others, and hence offers a much richer, more expressive classof conditional distribution estimates. We establish that, under suitableregularity conditions, the MQGM identifies the exact conditional independencieswith probability tending to one as the problem size grows, even outside of theusual homoskedastic Gaussian data model. We develop an efficient algorithm forfitting the MQGM using the alternating direction method of multipliers. We alsodescribe a strategy for sampling from the joint distribution that underlies theMQGM estimate. Lastly, we present detailed experiments that demonstrate theflexibility and effectiveness of the MQGM in modeling hetereoskedasticnon-Gaussian data.

A Continuous-Time View of Early Stopping for Least Squares

  We study the statistical properties of the iterates generated by gradientdescent, applied to the fundamental problem of least squares regression. Wetake a continuous-time view, i.e., consider infinitesimal step sizes ingradient descent, in which case the iterates form a trajectory called gradientflow. Our primary focus is to compare the risk of gradient flow to that ofridge regression. Under the calibration $t=1/\lambda$---where $t$ is the timeparameter in gradient flow, and $\lambda$ the tuning parameter in ridgeregression---we prove that the risk of gradient flow is no less than 1.69 timesthat of ridge, along the entire path (for all $t \geq 0$). This holds in finitesamples with very weak assumptions on the data model (in particular, with noassumptions on the features $X$). We prove that the same relative risk boundholds for prediction risk, in an average sense over the underlying signal$\beta_0$. Finally, we examine limiting risk expressions (under standardMarchenko-Pastur asymptotics), and give supporting numerical experiments.

A Fast Algorithm for Sparse Controller Design

  We consider the task of designing sparse control laws for large-scale systemsby directly minimizing an infinite horizon quadratic cost with an $\ell_1$penalty on the feedback controller gains. Our focus is on an improved algorithmthat allows us to scale to large systems (i.e. those where sparsity is mostuseful) with convergence times that are several orders of magnitude faster thanexisting algorithms. In particular, we develop an efficient proximal Newtonmethod which minimizes per-iteration cost with a coordinate descent active setapproach and fast numerical solutions to the Lyapunov equations. Experimentallywe demonstrate the appeal of this approach on synthetic examples and real powernetworks significantly larger than those previously considered in theliterature.

Contextually Supervised Source Separation with Application to Energy  Disaggregation

  We propose a new framework for single-channel source separation that liesbetween the fully supervised and unsupervised setting. Instead of supervision,we provide input features for each source signal and use convex methods toestimate the correlations between these features and the unobserved signaldecomposition. We analyze the case of $\ell_2$ loss theoretically and show thatrecovery of the signal components depends only on cross-correlation betweenfeatures for different signals, not on correlations between features for thesame signal. Contextually supervised source separation is a natural fit fordomains with large amounts of data but no explicit supervision; our motivatingapplication is energy disaggregation of hourly smart meter data (the separationof whole-home power signals into different energy uses). Here we applycontextual supervision to disaggregate the energy usage of thousands homes overfour years, a significantly larger scale than previously published efforts, anddemonstrate on synthetic data that our method outperforms the unsupervisedapproach.

Convex programming with fast proximal and linear operators

  We present Epsilon, a system for general convex programming using fast linearand proximal operators. As with existing convex programming frameworks, usersspecify convex optimization problems using a natural grammar for mathematicalexpressions, composing functions in a way that is guaranteed to be convex bythe rules of disciplined convex programming. Given such an input, the Epsiloncompiler transforms the optimization problem into a mathematically equivalentform consisting only of functions with efficient proximal operators---anintermediate representation we refer to as prox-affine form. By reducingproblems to this form, Epsilon enables solving general convex problems using alarge library of fast proximal and linear operators; numerical examples on manypopular problems from statistics and machine learning show that this oftenimproves running times by an order of magnitude or more vs. existing approachesbased on conic solvers.

Input Convex Neural Networks

  This paper presents the input convex neural network architecture. These arescalar-valued (potentially deep) neural networks with constraints on thenetwork parameters such that the output of the network is a convex function of(some of) the inputs. The networks allow for efficient inference viaoptimization over some inputs to the network given others, and can be appliedto settings including structured prediction, data imputation, reinforcementlearning, and others. In this paper we lay the basic groundwork for thesemodels, proposing methods for inference, optimization and learning, and analyzetheir representational power. We show that many existing neural networkarchitectures can be made input-convex with a minor modification, and developspecialized optimization algorithms tailored to this setting. Finally, wehighlight the performance of the methods on multi-label prediction, imagecompletion, and reinforcement learning problems, where we show improvement overthe existing state of the art in many cases.

A Semismooth Newton Method for Fast, Generic Convex Programming

  We introduce Newton-ADMM, a method for fast conic optimization. The basicidea is to view the residuals of consecutive iterates generated by thealternating direction method of multipliers (ADMM) as a set of fixed pointequations, and then use a nonsmooth Newton method to find a solution; we applythe basic idea to the Splitting Cone Solver (SCS), a state-of-the-art methodfor solving generic conic optimization problems. We demonstrate theoretically,by extending the theory of semismooth operators, that Newton-ADMM convergesrapidly (i.e., quadratically) to a solution; empirically, Newton-ADMM issignificantly faster than SCS on a number of problems. The method also hasessentially no tuning parameters, generates certificates of primal or dualinfeasibility, when appropriate, and can be specialized to solve specificconvex problems.

Gradient descent GAN optimization is locally stable

  Despite the growing prominence of generative adversarial networks (GANs),optimization in GANs is still a poorly understood topic. In this paper, weanalyze the "gradient descent" form of GAN optimization i.e., the naturalsetting where we simultaneously take small gradient steps in both generator anddiscriminator parameters. We show that even though GAN optimization does notcorrespond to a convex-concave game (even for simple parameterizations), underproper conditions, equilibrium points of this optimization procedure are still\emph{locally asymptotically stable} for the traditional GAN formulation. Onthe other hand, we show that the recently proposed Wasserstein GAN can havenon-convergent limit cycles near equilibrium. Motivated by this stabilityanalysis, we propose an additional regularization term for gradient descent GANupdates, which \emph{is} able to guarantee local stability for both the WGANand the traditional GAN, and also shows practical promise in speeding upconvergence and addressing mode collapse.

An Empirical Evaluation of Generic Convolutional and Recurrent Networks  for Sequence Modeling

  For most deep learning practitioners, sequence modeling is synonymous withrecurrent networks. Yet recent results indicate that convolutionalarchitectures can outperform recurrent networks on tasks such as audiosynthesis and machine translation. Given a new sequence modeling task ordataset, which architecture should one use? We conduct a systematic evaluationof generic convolutional and recurrent architectures for sequence modeling. Themodels are evaluated across a broad range of standard tasks that are commonlyused to benchmark recurrent networks. Our results indicate that a simpleconvolutional architecture outperforms canonical recurrent networks such asLSTMs across a diverse range of tasks and datasets, while demonstrating longereffective memory. We conclude that the common association between sequencemodeling and recurrent networks should be reconsidered, and convolutionalnetworks should be regarded as a natural starting point for sequence modelingtasks. To assist related work, we have made code available athttp://github.com/locuslab/TCN .

Trellis Networks for Sequence Modeling

  We present trellis networks, a new architecture for sequence modeling. On theone hand, a trellis network is a temporal convolutional network with specialstructure, characterized by weight tying across depth and direct injection ofthe input into deep layers. On the other hand, we show that truncated recurrentnetworks are equivalent to trellis networks with special sparsity structure intheir weight matrices. Thus trellis networks with general weight matricesgeneralize truncated recurrent networks. We leverage these connections todesign high-performing trellis networks that absorb structural and algorithmicelements from both recurrent and convolutional models. Experiments demonstratethat trellis networks outperform the current state of the art methods on avariety of challenging benchmarks, including word-level language modeling andcharacter-level language modeling tasks, and stress tests designed to evaluatelong-term memory retention. The code is available athttps://github.com/locuslab/trellisnet .

Differentiable MPC for End-to-end Planning and Control

  We present foundations for using Model Predictive Control (MPC) as adifferentiable policy class for reinforcement learning in continuous state andaction spaces. This provides one way of leveraging and combining the advantagesof model-free and model-based approaches. Specifically, we differentiatethrough MPC by using the KKT conditions of the convex approximation at a fixedpoint of the controller. Using this strategy, we are able to learn the cost anddynamics of a controller via end-to-end learning. Our experiments focus onimitation learning in the pendulum and cartpole domains, where we learn thecost and dynamics terms of an MPC policy class. We show that our MPC policiesare significantly more data-efficient than a generic neural network and thatour method is superior to traditional system identification in a setting wherethe expert is unrealizable.

Low-rank semidefinite programming for the MAX2SAT problem

  This paper proposes a new algorithm for solving MAX2SAT problems based oncombining search methods with semidefinite programming approaches. Semidefiniteprogramming techniques are well-known as a theoretical tool for approximatingmaximum satisfiability problems, but their application has traditionally beenvery limited by their speed and randomized nature. Our approach overcomes thisdifficult by using a recent approach to low-rank semidefinite programming,specialized to work in an incremental fashion suitable for use in an exactsearch algorithm. The method can be used both within complete or incompletesolver, and we demonstrate on a variety of problems from recent competitions.Our experiments show that the approach is faster (sometimes by orders ofmagnitude) than existing state-of-the-art complete and incomplete solvers,representing a substantial advance in search methods specialized for MAX2SATproblems.

Generalization in Deep Networks: The Role of Distance from  Initialization

  Why does training deep neural networks using stochastic gradient descent(SGD) result in a generalization error that does not worsen with the number ofparameters in the network? To answer this question, we advocate a notion ofeffective model capacity that is dependent on {\em a given randominitialization of the network} and not just the training algorithm and the datadistribution. We provide empirical evidences that demonstrate that the modelcapacity of SGD-trained deep networks is in fact restricted through implicitregularization of {\em the $\ell_2$ distance from the initialization}. We alsoprovide theoretical arguments that further highlight the need forinitialization-dependent notions of model capacity. We leave as open questionshow and why distance from initialization is regularized, and whether it issufficient to explain generalization.

Certified Adversarial Robustness via Randomized Smoothing

  Recent work has shown that any classifier which classifies well underGaussian noise can be leveraged to create a new classifier that is provablyrobust to adversarial perturbations in L2 norm. However, existing guaranteesfor such classifiers are suboptimal. In this work we provide the first tightanalysis of this "randomized smoothing" technique. We then demonstrate thatthis extremely simple method outperforms by a wide margin all other provablyL2-robust classifiers proposed in the literature. Furthermore, we train anImageNet classifier with e.g. a provable top-1 accuracy of 49% underadversarial perturbations with L2 norm less than 0.5 (=127/255). No otherprovable adversarial defense has been shown to be feasible on ImageNet. Whilerandomized smoothing with Gaussian noise only confers robustness in L2 norm,the empirical success of the approach suggests that provable methods based onrandomization at test time are a promising direction for future research intoadversarially robust classification. Code and trained models are available athttps://github.com/locuslab/smoothing .

Uniform convergence may be unable to explain generalization in deep  learning

  We cast doubt on the power of uniform convergence-based generalization boundsto provide a complete picture of why overparameterized deep networks generalizewell. While it is well-known that many existing bounds are numerically large,through a variety of experiments, we first bring to light another crucial andmore concerning aspect of these bounds: in practice, these bounds can {\emincrease} with the dataset size. Guided by our observations, we then presentexamples of overparameterized linear classifiers and neural networks trained bystochastic gradient descent (SGD) where uniform convergence provably cannot`explain generalization,' even if we take into account implicit regularization{\em to the fullest extent possible}. More precisely, even if we consider onlythe set of classifiers output by SGD that have test errors less than some small$\epsilon$, applying (two-sided) uniform convergence on this set of classifiersyields a generalization guarantee that is larger than $1-\epsilon$ and istherefore nearly vacuous.

OptNet: Differentiable Optimization as a Layer in Neural Networks

  This paper presents OptNet, a network architecture that integratesoptimization problems (here, specifically in the form of quadratic programs) asindividual layers in larger end-to-end trainable deep networks. These layersencode constraints and complex dependencies between the hidden states thattraditional convolutional and fully-connected layers often cannot capture. Inthis paper, we explore the foundations for such an architecture: we show howtechniques from sensitivity analysis, bilevel optimization, and implicitdifferentiation can be used to exactly differentiate through these layers andwith respect to layer parameters; we develop a highly efficient solver forthese layers that exploits fast GPU-based batch solves within a primal-dualinterior point method, and which provides backpropagation gradients withvirtually no additional cost on top of the solve; and we highlight theapplication of these approaches in several problems. In one notable example, weshow that the method is capable of learning to play mini-Sudoku (4x4) givenjust input and output games, with no a priori information about the rules ofthe game; this highlights the ability of our architecture to learn hardconstraints better than other neural architectures.

The Mixing method: low-rank coordinate descent for semidefinite  programming with diagonal constraints

  In this paper, we propose a low-rank coordinate descent approach tostructured semidefinite programming with diagonal constraints. The approach,which we call the Mixing method, is extremely simple to implement, has no freeparameters, and typically attains an order of magnitude or better improvementin optimization performance over the current state of the art. We show that themethod is strictly decreasing, converges to a critical point, and further thatfor sufficient rank all non-optimal critical points are unstable. Moreover, weprove that with a step size, the Mixing method converges to the global optimumof the semidefinite program almost surely in a locally linear rate under randominitialization. This is the first low-rank semidefinite programming method thathas been shown to achieve a global optimum on the spherical manifold withoutassumption. We apply our algorithm to two related domains: solving the maximumcut semidefinite relaxation, and solving a maximum satisfiability relaxation(we also briefly consider additional applications such as learning wordembeddings). In all settings, we demonstrate substantial improvement over theexisting state of the art along various dimensions, and in total, this workexpands the scope and scale of problems that can be solved using semidefiniteprogramming methods.

Intelligent Pothole Detection and Road Condition Assessment

  Poor road conditions are a public nuisance, causing passenger discomfort,damage to vehicles, and accidents. In the U.S., road-related conditions are afactor in 22,000 of the 42,000 traffic fatalities each year. Although we oftencomplain about bad roads, we have no way to detect or report them at scale. Toaddress this issue, we developed a system to detect potholes and assess roadconditions in real-time. Our solution is a mobile application that capturesdata on a car's movement from gyroscope and accelerometer sensors in the phone.To assess roads using this sensor data, we trained SVM models to classify roadconditions with 93% accuracy and potholes with 92% accuracy, beating the baserate for both problems. As the user drives, the models use the sensor data toclassify whether the road is good or bad, and whether it contains potholes.Then, the classification results are used to create data-rich maps thatillustrate road conditions across the city. Our system will empower civicofficials to identify and repair damaged roads which inconvenience passengersand cause accidents. This paper details our data science process for collectingtraining data on real roads, transforming noisy sensor data into usefulsignals, training and evaluating machine learning models, and deploying thosemodels to production through a real-time classification app. It also highlightshow cities can use our system to crowdsource data and deliver road repairresources to areas in need.

Provable defenses against adversarial examples via the convex outer  adversarial polytope

  We propose a method to learn deep ReLU-based classifiers that are provablyrobust against norm-bounded adversarial perturbations on the training data. Forpreviously unseen examples, the approach is guaranteed to detect alladversarial examples, though it may flag some non-adversarial examples as well.The basic idea is to consider a convex outer approximation of the set ofactivations reachable through a norm-bounded perturbation, and we develop arobust optimization procedure that minimizes the worst case loss over thisouter region (via a linear program). Crucially, we show that the dual problemto this linear program can be represented itself as a deep network similar tothe backpropagation network, leading to very efficient optimization approachesthat produce guaranteed bounds on the robust loss. The end result is that byexecuting a few more forward and backward passes through a slightly modifiedversion of the original network (though possibly with much larger batch sizes),we can learn a classifier that is provably robust to any norm-boundedadversarial attack. We illustrate the approach on a number of tasks to trainclassifiers with robust adversarial guarantees (e.g. for MNIST, we produce aconvolutional classifier that provably has less than 5.8% test error for anyadversarial attack with bounded $\ell_\infty$ norm less than $\epsilon = 0.1$),and code for all experiments in the paper is available athttps://github.com/locuslab/convex_adversarial.

What game are we playing? End-to-end learning in normal and extensive  form games

  Although recent work in AI has made great progress in solving large,zero-sum, extensive-form games, the underlying assumption in most past work isthat the parameters of the game itself are known to the agents. This paperdeals with the relatively under-explored but equally important "inverse"setting, where the parameters of the underlying game are not known to allagents, but must be learned through observations. We propose a differentiable,end-to-end learning framework for addressing this task. In particular, weconsider a regularized version of the game, equivalent to a particular form ofquantal response equilibrium, and develop 1) a primal-dual Newton method forfinding such equilibrium points in both normal and extensive form games; and 2)a backpropagation method that lets us analytically compute gradients of allrelevant game parameters through the solution itself. This ultimately lets uslearn the game by training in an end-to-end fashion, effectively by integratinga "differentiable game solver" into the loop of larger deep networkarchitectures. We demonstrate the effectiveness of the learning method inseveral settings including poker and security game tasks.

Scaling provable adversarial defenses

  Recent work has developed methods for learning deep network classifiers thatare provably robust to norm-bounded adversarial perturbation; however, thesemethods are currently only possible for relatively small feedforward networks.In this paper, in an effort to scale these approaches to substantially largermodels, we extend previous work in three main directions. First, we present atechnique for extending these training procedures to much more generalnetworks, with skip connections (such as ResNets) and general nonlinearities;the approach is fully modular, and can be implemented automatically (analogousto automatic differentiation). Second, in the specific case of $\ell_\infty$adversarial perturbations and networks with ReLU nonlinearities, we adopt anonlinear random projection for training, which scales linearly in the numberof hidden units (previous approaches scaled quadratically). Third, we show howto further improve robust error through cascade models. On both MNIST and CIFARdata sets, we train classifiers that improve substantially on the state of theart in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST(with $\ell_\infty$ perturbations of $\epsilon=0.1$), and from 80% to 36.4% onCIFAR (with $\ell_\infty$ perturbations of $\epsilon=2/255$). Code for allexperiments in the paper is available athttps://github.com/locuslab/convex_adversarial/.

Wasserstein Adversarial Examples via Projected Sinkhorn Iterations

  A rapidly growing area of work has studied the existence of adversarialexamples, datapoints which have been perturbed to fool a classifier, but thevast majority of these works have focused primarily on threat models defined by$\ell_p$ norm-bounded perturbations. In this paper, we propose a new threatmodel for adversarial attacks based on the Wasserstein distance. In the imageclassification setting, such distances measure the cost of moving pixel mass,which naturally cover "standard" image manipulations such as scaling, rotation,translation, and distortion (and can potentially be applied to other settingsas well). To generate Wasserstein adversarial examples, we develop a procedurefor projecting onto the Wasserstein ball, based upon a modified version of theSinkhorn iteration. The resulting algorithm can successfully attack imageclassification models, bringing traditional CIFAR10 models down to 3% accuracywithin a Wasserstein ball with radius 0.1 (i.e., moving 10% of the image mass 1pixel), and we demonstrate that PGD-based adversarial training can improve thisadversarial accuracy to 76%. In total, this work opens up a new direction ofstudy in adversarial robustness, more formally considering convex metrics thataccurately capture the invariances that we typically believe should exist inclassifiers. Code for all experiments in the paper is available athttps://github.com/locuslab/projected_sinkhorn.

Large Scale Learning of Agent Rationality in Two-Player Zero-Sum Games

  With the recent advances in solving large, zero-sum extensive form games,there is a growing interest in the inverse problem of inferring underlying gameparameters given only access to agent actions. Although a recent work providesa powerful differentiable end-to-end learning frameworks which embed a gamesolver within a deep-learning framework, allowing unknown game parameters to belearned via backpropagation, this framework faces significant limitations whenapplied to boundedly rational human agents and large scale problems, leading topoor practicality. In this paper, we address these limitations and propose aframework that is applicable for more practical settings. First, seeking tolearn the rationality of human agents in complex two-player zero-sum games, wedraw upon well-known ideas in decision theory to obtain a concise andinterpretable agent behavior model, and derive solvers and gradients forend-to-end learning. Second, to scale up to large, real-world scenarios, wepropose an efficient first-order primal-dual method which exploits thestructure of extensive-form games, yielding significantly faster computationfor both game solving and gradient computation. When tested on randomlygenerated games, we report speedups of orders of magnitude over previousapproaches. We also demonstrate the effectiveness of our model on bothreal-world one-player settings and synthetic data.

Adversarial camera stickers: A physical camera-based attack on deep  learning systems

  Recent work has thoroughly documented the susceptibility of deep learningsystems to adversarial examples, but most such instances directly manipulatethe digital input to a classifier. Although a smaller line of work considersphysical adversarial attacks, in all cases these involve manipulating theobject of interest, e.g., putting a physical sticker on a object to misclassifyit, or manufacturing an object specifically intended to be misclassified. Inthis work, we consider an alternative question: is it possible to fool deepclassifiers, over all perceived objects of a certain type, by physicallymanipulating the camera itself? We show that this is indeed possible, that byplacing a carefully crafted and mainly-translucent sticker over the lens of acamera, one can create universal perturbations of the observed images that areinconspicuous, yet reliably misclassify target objects as a different(targeted) class. To accomplish this, we propose an iterative procedure forboth updating the attack perturbation (to make it adversarial for a givenclassifier), and the threat model itself (to ensure it is physicallyrealizable). For example, we show that we can achieve physically-realizableattacks that fool ImageNet classifiers in a targeted fashion 49.6% of the time.This presents a new class of physically-realizable threat models to consider inthe context of adversarially robust machine learning. Our demo video can beviewed at: https://youtu.be/wUVmL33Fx54

