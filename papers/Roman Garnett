Active Learning of Linear Embeddings for Gaussian Processes

  We propose an active learning method for discovering low-dimensionalstructure in high-dimensional Gaussian process (GP) tasks. Such problems areincreasingly frequent and important, but have hitherto presented severepractical difficulties. We further introduce a novel technique forapproximately marginalizing GP hyperparameters, yielding marginal predictionsrobust to hyperparameter mis-specification. Our method offers an efficientmeans of performing GP regression, quadrature, or Bayesian optimization inhigh-dimensional spaces.

Propagation Kernels

  We introduce propagation kernels, a general graph-kernel framework forefficiently measuring the similarity of structured data. Propagation kernelsare based on monitoring how information spreads through a set of given graphs.They leverage early-stage distributions from propagation schemes such as randomwalks to capture structural information encoded in node labels, attributes, andedge information. This has two benefits. First, off-the-shelf propagationschemes can be used to naturally construct kernels for many graph types,including labeled, partially labeled, unlabeled, directed, and attributedgraphs. Second, by leveraging existing efficient and informative propagationschemes, propagation kernels can be considerably faster than state-of-the-artapproaches without sacrificing predictive performance. We will also show thatif the graphs at hand have a regular structure, for instance when modelingimage or video data, one can exploit this regularity to scale the kernelcomputation to large databases of graphs with thousands of nodes. We supportour contributions by exhaustive experiments on a number of real-world graphsfrom a variety of application domains.

Detecting Damped Lyman-$Î±$ Absorbers with Gaussian Processes

  We develop an automated technique for detecting damped Lyman-$\alpha$absorbers (DLAs) along spectroscopic lines of sight to quasi-stellar objects(QSOs or quasars). The detection of DLAs in large-scale spectroscopic surveyssuch as SDSS-III sheds light on galaxy formation at high redshift, showing thenucleation of galaxies from diffuse gas. We use nearly 50 000 QSO spectra tolearn a novel tailored Gaussian process model for quasar emission spectra,which we apply to the DLA detection problem via Bayesian model selection. Wepropose models for identifying an arbitrary number of DLAs along a given lineof sight. We demonstrate our method's effectiveness using a large-scalevalidation experiment, with excellent performance. We also provide a catalog ofour results applied to 162 858 spectra from SDSS-III data release 12.

Statistical properties of damped Lyman-alpha systems from Sloan Digital  Sky Survey DR12

  We present new estimates for the statistical properties of dampedLyman-$\alpha$ absorbers (DLAs). We compute the column density distributionfunction at $z>2$, the line density, $\mathrm{d}N/\mathrm{d}X$, and the neutralhydrogen density, $\Omega_\mathrm{DLA}$. Our estimates are derived from the DLAcatalogue of Garnett 2016, which uses the SDSS-III DR12 quasar spectroscopicsurvey. This catalogue provides a probability that a given spectrum contains aDLA, allowing us to use even the noisiest data without biasing our results andthus substantially increase our sample size. We measure a non-zero columndensity distribution function at $95\%$ confidence for all column densities$N_\mathrm{HI} < 5\times 10^{22}$ cm$^{-2}$. We make the first measurementsfrom SDSS of $\mathrm{d}N/\mathrm{d}X$ and $\Omega_\mathrm{DLA}$ at $z>4$. Weshow that our results are insensitive to the signal-to-noise ratio of thespectra, but that there is a residual dependence on quasar redshift for$z<2.5$, which may be due to remaining systematics in our analysis.

Bayesian Optimal Active Search and Surveying

  We consider two active binary-classification problems with atypicalobjectives. In the first, active search, our goal is to actively uncover asmany members of a given class as possible. In the second, active surveying, ourgoal is to actively query points to ultimately predict the proportion of agiven class. Numerous real-world problems can be framed in these terms, and ineither case typical model-based concerns such as generalization error are onlyof secondary importance.  We approach these problems via Bayesian decision theory; after choosingnatural utility functions, we derive the optimal policies. We provide threecontributions. In addition to introducing the active surveying problem, weextend previous work on active search in two ways. First, we prove a noveltheoretical result, that less-myopic approximations to the optimal policy canoutperform more-myopic approximations by any arbitrary degree. We then derivebounds that for certain models allow us to reduce (in practice dramatically)the exponential search space required by a naive implementation of the optimalpolicy, enabling further lookahead while still ensuring that optimal decisionsare always made.

Newly Identified Star Clusters in M33. II. Radial HST/ACS Fields

  We present integrated photometry and color-magnitude diagrams for 161 starclusters in M33, of which 115 were previously uncataloged, using the AdvancedCamera For Surveys Wide Field Channel onboard the Hubble Space Telescope. Theintegrated V-band magnitudes of these clusters range from Mv~-9 to as faint asMv~-4, extending the depth of the existing M33 cluster catalogs by ~1 mag.Comparisons of theoretical isochrones to the color-magnitude diagrams using thePadova models yield ages for 148 of these star clusters. The ages range fromLog (t)~7.0 to Log (t)~9.0. Our color-magnitude diagrams are not sensitive toclusters older than ~1 Gyr. We find that the variation of the clusters'integrated colors and absolute magnitudes with age is consistent with thepredictions of simple stellar population models. These same models suggest thatthe masses of the clusters in our sample range from 5x10^3 to 5x10^4 *Msun.

Submodularity in Batch Active Learning and Survey Problems on Gaussian  Random Fields

  Many real-world datasets can be represented in the form of a graph whose edgeweights designate similarities between instances. A discrete Gaussian randomfield (GRF) model is a finite-dimensional Gaussian process (GP) whose priorcovariance is the inverse of a graph Laplacian. Minimizing the trace of thepredictive covariance Sigma (V-optimality) on GRFs has proven successful inbatch active learning classification problems with budget constraints. However,its worst-case bound has been missing. We show that the V-optimality on GRFs asa function of the batch query set is submodular and hence its greedy selectionalgorithm guarantees an (1-1/e) approximation ratio. Moreover, GRF models havethe absence-of-suppressor (AofS) condition. For active survey problems, wepropose a similar survey criterion which minimizes 1'(Sigma)1. In practice,V-optimality criterion performs better than GPs with mutual information gaincriteria and allows nonuniform costs for different nodes.

Sampling for Inference in Probabilistic Models with Fast Bayesian  Quadrature

  We propose a novel sampling framework for inference in probabilistic models:an active learning approach that converges more quickly (in wall-clock time)than Markov chain Monte Carlo (MCMC) benchmarks. The central challenge inprobabilistic inference is numerical integration, to average over ensembles ofmodels or unknown (hyper-)parameters (for example to compute the marginallikelihood or a partition function). MCMC has provided approaches to numericalintegration that deliver state-of-the-art inference, but can suffer from sampleinefficiency and poor convergence diagnostics. Bayesian quadrature techniquesoffer a model-based solution to such problems, but their uptake has beenhindered by prohibitive computation costs. We introduce a warped model forprobabilistic integrands (likelihoods) that are known to be non-negative,permitting a cheap active learning scheme to optimally select sample locations.Our algorithm is demonstrated to offer faster convergence (in seconds) relativeto simple Monte Carlo and annealed importance sampling on both synthetic andreal-world examples.

Differentially Private Bayesian Optimization

  Bayesian optimization is a powerful tool for fine-tuning the hyper-parametersof a wide variety of machine learning models. The success of machine learninghas led practitioners in diverse real-world settings to learn classifiers forpractical problems. As machine learning becomes commonplace, Bayesianoptimization becomes an attractive method for practitioners to automate theprocess of classifier hyper-parameter tuning. A key observation is that thedata used for tuning models in these settings is often sensitive. Certain datasuch as genetic predisposition, personal email statistics, and car accidenthistory, if not properly private, may be at risk of being inferred fromBayesian optimization outputs. To address this, we introduce methods forreleasing the best hyper-parameters and classifier accuracy privately.Leveraging the strong theoretical guarantees of differential privacy and knownBayesian optimization convergence bounds, we prove that under a GP assumptionthese private quantities are also near-optimal. Finally, even if thisassumption is not satisfied, we can use different smoothness guarantees toprotect privacy.

Anomaly Detection and Removal Using Non-Stationary Gaussian Processes

  This paper proposes a novel Gaussian process approach to fault removal intime-series data. Fault removal does not delete the faulty signal data but,instead, massages the fault from the data. We assume that only one fault occursat any one time and model the signal by two separate non-parametric Gaussianprocess models for both the physical phenomenon and the fault. In order tofacilitate fault removal we introduce the Markov Region Link kernel forhandling non-stationary Gaussian processes. This kernel is piece-wisestationary but guarantees that functions generated by it and their derivatives(when required) are everywhere continuous. We apply this kernel to the removalof drift and bias errors in faulty sensor data and also to the recovery of EOGartifact corrupted EEG signals.

Exact Sampling from Determinantal Point Processes

  Determinantal point processes (DPPs) are an important concept in randommatrix theory and combinatorics. They have also recently attracted interest inthe study of numerical methods for machine learning, as they offer an elegant"missing link" between independent Monte Carlo sampling and deterministicevaluation on regular grids, applicable to a general set of spaces. This ishelpful whenever an algorithm explores to reduce uncertainty, such as in activelearning, Bayesian optimization, reinforcement learning, and marginalization ingraphical models. To draw samples from a DPP in practice, existing literaturefocuses on approximate schemes of low cost, or comparably inefficient exactalgorithms like rejection sampling. We point out that, for many settings ofrelevance to machine learning, it is also possible to draw exact samples fromDPPs on continuous domains. We start from an intuitive example on the realline, which is then generalized to multivariate real vector spaces. We alsocompare to previously studied approximations, showing that exact sampling,despite higher cost, can be preferable where precision is needed.

Improving Quadrature for Constrained Integrands

  We present an improved Bayesian framework for performing inference of affinetransformations of constrained functions. We focus on quadrature withnonnegative functions, a common task in Bayesian inference. We considerconstraints on the range of the function of interest, such as nonnegativity orboundedness. Although our framework is general, we derive explicitapproximation schemes for these constraints, and argue for the use of a logtransformation for functions with high dynamic range such as likelihoodsurfaces. We propose a novel method for optimizing hyperparameters in thisframework: we optimize the marginal likelihood in the original space, asopposed to in the transformed space. The result is a model that better explainsthe actual data. Experiments on synthetic and real-world data demonstrate ourframework achieves superior estimates using less wall-clock time than existingBayesian quadrature procedures.

Learning and Anticipating Future Actions During Exploratory Data  Analysis

  The goal of visual analytics is to create a symbiosis between human andcomputer by leveraging their unique strengths. While this model hasdemonstrated immense success, we are yet to realize the full potential of sucha human-computer partnership. In a perfect collaborative mixed-initiativesystem, the computer must possess skills for learning and anticipating theusers' needs. Addressing this gap, we propose a framework for inferring focusareas from passive observations of the user's actions, thereby allowingaccurate predictions of future events. We evaluate this technique with a crimemap and demonstrate that users' clicks appear in our prediction set 95% - 97%of the time. Further analysis shows that we can achieve high predictionaccuracy typically after three clicks. Altogether, we show that passiveobservations of interaction data can reveal valuable information that willallow the system to learn and anticipate future events, laying the foundationfor next-generation tools.

Automated Model Selection with Bayesian Quadrature

  We present a novel technique for tailoring Bayesian quadrature (BQ) to modelselection. The state-of-the-art for comparing the evidence of multiple modelsrelies on Monte Carlo methods, which converge slowly and are unreliable forcomputationally expensive models. Previous research has shown that BQ offerssample efficiency superior to Monte Carlo in computing the evidence of anindividual model. However, applying BQ directly to model comparison may wastecomputation producing an overly-accurate estimate for the evidence of a clearlypoor model. We propose an automated and efficient algorithm for computing themost-relevant quantity for model selection: the posterior probability of amodel. Our technique maximizes the mutual information between this quantity andobservations of the models' likelihoods, yielding efficient acquisition ofsamples across disparate model spaces when likelihood observations are limited.Our method produces more-accurate model posterior estimates using fewer modellikelihood evaluations than standard Bayesian quadrature and Monte Carloestimators, as we demonstrate on synthetic and real-world examples.

The entropic basis of collective behaviour

  In this paper, we identify a radically new viewpoint on the collectivebehaviour of groups of intelligent agents. We first develop a highly generalabstract model for the possible future lives that these agents may encounter asa result of their decisions. In the context of these possible futures, we showthat the causal entropic principle, whereby agents follow behavioural rulesthat maximise their entropy over all paths through the future, predicts many ofthe observed features of social interactions between individuals in both humanand animal groups. Our results indicate that agents are often able to maximisetheir future path entropy by remaining cohesive as a group, and that thiscohesion leads to collectively intelligent outcomes that depend strongly on thedistribution of the number of future paths that are possible. We derive socialinteraction rules that are consistent with maximum-entropy group behaviour forboth discrete and continuous decision spaces. Our analysis further predictsthat social interactions are likely to be fundamentally based on Weber's law ofresponse to proportional stimuli, supporting many studies that find aneurological basis for this stimulus-response mechanism, and providing a novelbasis for the common assumption of linearly additive 'social forces' insimulation studies of collective behaviour.

Active Search for Sparse Signals with Region Sensing

  Autonomous systems can be used to search for sparse signals in a large space;e.g., aerial robots can be deployed to localize threats, detect gas leaks, orrespond to distress calls. Intuitively, search algorithms may increaseefficiency by collecting aggregate measurements summarizing large contiguousregions. However, most existing search methods either ignore the possibility ofsuch region observations (e.g., Bayesian optimization and multi-armed bandits)or make strong assumptions about the sensing mechanism that allow eachmeasurement to arbitrarily encode all signals in the entire environment (e.g.,compressive sensing). We propose an algorithm that actively collects data tosearch for sparse signals using only noisy measurements of the average valueson rectangular regions (including single points), based on the greedymaximization of information gain. We analyze our algorithm in 1d and show thatit requires $\tilde{O}(\frac{n}{\mu^2}+k^2)$ measurements to recover all of $k$signal locations with small Bayes error, where $\mu$ and $n$ are the signalstrength and the size of the search space, respectively. We also show thatactive designs can be fundamentally more efficient than passive designs withregion sensing, contrasting with the results of Arias-Castro, Candes, andDavenport (2013). We demonstrate the empirical performance of our algorithm ona search problem using satellite image data and in high dimensions.

Efficient nonmyopic active search with applications in drug and  materials discovery

  Active search is a learning paradigm for actively identifying as many membersof a given class as possible. A critical target scenario is high-throughputscreening for scientific discovery, such as drug or materials discovery. Inthis paper, we approach this problem in Bayesian decision framework. We firstderive the Bayesian optimal policy under a natural utility, and establish atheoretical hardness of active search, proving that the optimal policy can notbe approximated for any constant ratio. We also study the batch setting for thefirst time, where a batch of $b>1$ points can be queried at each iteration. Wegive an asymptotic lower bound, linear in batch size, on the adaptivity gap:how much we could lose if we query $b$ points at a time for $t$ iterations,instead of one point at a time for $bt$ iterations. We then introduce a novelapproach to nonmyopic approximations of the optimal policy that admitsefficient computation. Our proposed policy can automatically trade offexploration and exploitation, without relying on any tuning parameters. We alsogeneralize our policy to batch setting, and propose two approaches to tacklethe combinatorial search challenge. We evaluate our proposed policies on alarge database of drug discovery and materials science. Results demonstrate thesuperior performance of our proposed policy in both sequential and batchsetting; the nonmyopic behavior is also illustrated in various aspects.

Newly Identified Star Clusters in M33. III. Structural Parameters

  We present the morphological properties of 161 star clusters in M33 using theAdvanced Camera For Surveys Wide Field Channel onboard the Hubble SpaceTelescope using observations with the F606W and F814W filters. We obtain, forthe first time, ellipticities, position angles, and surface brightness profilesfor a significant number of clusters. On average, M33 clusters are moreflattened than those of the Milky Way and M31, and more similar to clusters inthe Small Magellanic Cloud. The ellipticities do not show any correlation withage or mass, suggesting that rotation is not the main cause of elongation inthe M33 clusters. The position angles of the clusters show a bimodality with astrong peak perpendicular to the position angle of the galaxy major axis. Theseresults support the notion that tidal forces are the reason for the clusterflattening. We fit King and EFF models to the surface brightness profiles andderive structural parameters including core radii, concentration, half-lightradii and central surface brightness for both filters. The surface brightnessprofiles of a significant number of clusters show irregularities such as bumpsand dips. Young clusters (Log age < 8) are notably better fitted by models withno radial truncation (EFF models), while older clusters show no significantdifferences between King or EFF fits. M33 star clusters seem to have smallersizes, smaller concentrations, and smaller central surface brightness ascompared to clusters in the MW, M31, LMC and SMC. Analysis of the structuralparameters presents a age-radius relation also detected in other star clustersystems. The overall analysis shows differences in the structural evolutionbetween the M33 cluster system and cluster systems in nearby galaxies. Thesedifferences could have been caused by the strong differences in these variousenvironments.

