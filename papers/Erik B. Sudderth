Bayesian Nonparametric Inference of Switching Linear Dynamical Systems

  Many complex dynamical phenomena can be effectively modeled by a system that
switches among a set of conditionally linear dynamical modes. We consider two
such models: the switching linear dynamical system (SLDS) and the switching
vector autoregressive (VAR) process. Our Bayesian nonparametric approach
utilizes a hierarchical Dirichlet process prior to learn an unknown number of
persistent, smooth dynamical modes. We additionally employ automatic relevance
determination to infer a sparse set of dynamic dependencies allowing us to
learn SLDS with varying state dimension or switching VAR processes with varying
autoregressive order. We develop a sampling algorithm that combines a truncated
approximation to the Dirichlet process with efficient joint sampling of the
mode and state sequences. The utility and flexibility of our model are
demonstrated on synthetic data, sequences of dancing honey bees, the IBOVESPA
stock index, and a maneuvering target tracking application.


Joint Modeling of Multiple Related Time Series via the Beta Process

  We propose a Bayesian nonparametric approach to the problem of jointly
modeling multiple related time series. Our approach is based on the discovery
of a set of latent, shared dynamical behaviors. Using a beta process prior, the
size of the set and the sharing pattern are both inferred from data. We develop
efficient Markov chain Monte Carlo methods based on the Indian buffet process
representation of the predictive distribution of the beta process, without
relying on a truncated model. In particular, our approach uses the sum-product
algorithm to efficiently compute Metropolis-Hastings acceptance probabilities,
and explores new dynamical behaviors via birth and death proposals. We examine
the benefits of our proposed feature-based model on several synthetic datasets,
and also demonstrate promising results on unsupervised segmentation of visual
motion capture data.


Gibbs Sampling in Open-Universe Stochastic Languages

  Languages for open-universe probabilistic models (OUPMs) can represent
situations with an unknown number of objects and iden- tity uncertainty. While
such cases arise in a wide range of important real-world appli- cations,
existing general purpose inference methods for OUPMs are far less efficient
than those available for more restricted lan- guages and model classes. This
paper goes some way to remedying this deficit by in- troducing, and proving
correct, a generaliza- tion of Gibbs sampling to partial worlds with possibly
varying model structure. Our ap- proach draws on and extends previous generic
OUPM inference methods, as well as aux- iliary variable samplers for
nonparametric mixture models. It has been implemented for BLOG, a well-known
OUPM language. Combined with compile-time optimizations, the resulting
algorithm yields very substan- tial speedups over existing methods on sev- eral
test cases, and substantially improves the practicality of OUPM languages
generally.


Fast Learning of Clusters and Topics via Sparse Posteriors

  Mixture models and topic models generate each observation from a single
cluster, but standard variational posteriors for each observation assign
positive probability to all possible clusters. This requires dense storage and
runtime costs that scale with the total number of clusters, even though
typically only a few clusters have significant posterior mass for any data
point. We propose a constrained family of sparse variational distributions that
allow at most $L$ non-zero entries, where the tunable threshold $L$ trades off
speed for accuracy. Previous sparse approximations have used hard assignments
($L=1$), but we find that moderate values of $L>1$ provide superior
performance. Our approach easily integrates with stochastic or incremental
optimization algorithms to scale to millions of examples. Experiments training
mixture models of image patches and topic models for news articles show that
our approach produces better-quality models in far less time than baseline
methods.


Prediction-Constrained Training for Semi-Supervised Mixture and Topic
  Models

  Supervisory signals have the potential to make low-dimensional data
representations, like those learned by mixture and topic models, more
interpretable and useful. We propose a framework for training latent variable
models that explicitly balances two goals: recovery of faithful generative
explanations of high-dimensional data, and accurate prediction of associated
semantic labels. Existing approaches fail to achieve these goals due to an
incomplete treatment of a fundamental asymmetry: the intended application is
always predicting labels from data, not data from labels. Our
prediction-constrained objective for training generative models coherently
integrates loss-based supervisory signals while enabling effective
semi-supervised learning from partially labeled data. We derive learning
algorithms for semi-supervised mixture and topic models using stochastic
gradient descent with automatic differentiation. We demonstrate improved
prediction quality compared to several previous supervised topic models,
achieving predictions competitive with high-dimensional logistic regression on
text sentiment analysis and electronic health records tasks while
simultaneously learning interpretable topics.


Cascaded Scene Flow Prediction using Semantic Segmentation

  Given two consecutive frames from a pair of stereo cameras, 3D scene flow
methods simultaneously estimate the 3D geometry and motion of the observed
scene. Many existing approaches use superpixels for regularization, but may
predict inconsistent shapes and motions inside rigidly moving objects. We
instead assume that scenes consist of foreground objects rigidly moving in
front of a static background, and use semantic cues to produce pixel-accurate
scene flow estimates. Our cascaded classification framework accurately models
3D scenes by iteratively refining semantic segmentation masks, stereo
correspondences, 3D rigid motion estimates, and optical flow fields. We
evaluate our method on the challenging KITTI autonomous driving benchmark, and
show that accounting for the motion of segmented vehicles leads to
state-of-the-art performance.


Bayesian Paragraph Vectors

  Word2vec (Mikolov et al., 2013) has proven to be successful in natural
language processing by capturing the semantic relationships between different
words. Built on top of single-word embeddings, paragraph vectors (Le and
Mikolov, 2014) find fixed-length representations for pieces of text with
arbitrary lengths, such as documents, paragraphs, and sentences. In this work,
we propose a novel interpretation for neural-network-based paragraph vectors by
developing an unsupervised generative model whose maximum likelihood solution
corresponds to traditional paragraph vectors. This probabilistic formulation
allows us to go beyond point estimates of parameters and to perform Bayesian
posterior inference. We find that the entropy of paragraph vectors decreases
with the length of documents, and that information about posterior uncertainty
improves performance in supervised learning tasks such as sentiment analysis
and paraphrase detection.


Prediction-Constrained Topic Models for Antidepressant Recommendation

  Supervisory signals can help topic models discover low-dimensional data
representations that are more interpretable for clinical tasks. We propose a
framework for training supervised latent Dirichlet allocation that balances two
goals: faithful generative explanations of high-dimensional data and accurate
prediction of associated class labels. Existing approaches fail to balance
these goals by not properly handling a fundamental asymmetry: the intended task
is always predicting labels from data, not data from labels. Our new
prediction-constrained objective trains models that predict labels from heldout
data well while also producing good generative likelihoods and interpretable
topic-word parameters. In a case study on predicting depression medications
from electronic health records, we demonstrate improved recommendations
compared to previous supervised topic models and high- dimensional logistic
regression from words alone.


A Fusion Approach for Multi-Frame Optical Flow Estimation

  To date, top-performing optical flow estimation methods only take pairs of
consecutive frames into account. While elegant and appealing, the idea of using
more than two frames has not yet produced state-of-the-art results. We present
a simple, yet effective fusion approach for multi-frame optical flow that
benefits from longer-term temporal cues. Our method first warps the optical
flow from previous frames to the current, thereby yielding multiple plausible
estimates. It then fuses the complementary information carried by these
estimates into a new optical flow field. At the time of writing, our method
ranks first among published results in the MPI Sintel and KITTI 2015
benchmarks. Our models will be available on https://github.com/NVlabs/PWC-Net.


Multi-layer Depth and Epipolar Feature Transformers for 3D Scene
  Reconstruction

  We tackle the problem of automatically reconstructing a complete 3D model of
a scene from a single RGB image. This challenging task requires inferring the
shape of both visible and occluded surfaces. Our approach utilizes
viewer-centered, multi-layer representation of scene geometry adapted from
recent methods for single object shape completion. To improve the accuracy of
view-centered representations for complex scenes, we introduce a novel
"Epipolar Feature Transformer" that transfers convolutional network features
from an input view to other virtual camera viewpoints, and thus better covers
the 3D scene geometry. Unlike existing approaches that first detect and
localize objects in 3D, and then infer object shape using category-specific
models, our approach is fully convolutional, end-to-end differentiable, and
avoids the resolution and memory limitations of voxel representations. We
demonstrate the advantages of multi-layer depth representations and epipolar
feature transformers on the reconstruction of a large database of indoor
scenes.


A sticky HDP-HMM with application to speaker diarization

  We consider the problem of speaker diarization, the problem of segmenting an
audio recording of a meeting into temporal segments corresponding to individual
speakers. The problem is rendered particularly difficult by the fact that we
are not allowed to assume knowledge of the number of people participating in
the meeting. To address this problem, we take a Bayesian nonparametric approach
to speaker diarization that builds on the hierarchical Dirichlet process hidden
Markov model (HDP-HMM) of Teh et al. [J. Amer. Statist. Assoc. 101 (2006)
1566--1581]. Although the basic HDP-HMM tends to over-segment the audio
data---creating redundant states and rapidly switching among them---we describe
an augmented HDP-HMM that provides effective control over the switching rate.
We also show that this augmentation makes it possible to treat emission
distributions nonparametrically. To scale the resulting architecture to
realistic diarization problems, we develop a sampling algorithm that employs a
truncated approximation of the Dirichlet process to jointly resample the full
state sequence, greatly improving mixing rates. Working with a benchmark NIST
data set, we show that our Bayesian nonparametric architecture yields
state-of-the-art speaker diarization results.


Joint modeling of multiple time series via the beta process with
  application to motion capture segmentation

  We propose a Bayesian nonparametric approach to the problem of jointly
modeling multiple related time series. Our model discovers a latent set of
dynamical behaviors shared among the sequences, and segments each time series
into regions defined by a subset of these behaviors. Using a beta process
prior, the size of the behavior set and the sharing pattern are both inferred
from data. We develop Markov chain Monte Carlo (MCMC) methods based on the
Indian buffet process representation of the predictive distribution of the beta
process. Our MCMC inference algorithm efficiently adds and removes behaviors
via novel split-merge moves as well as data-driven birth and death proposals,
avoiding the need to consider a truncated model. We demonstrate promising
results on unsupervised segmentation of human motion capture data.


