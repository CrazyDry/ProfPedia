Gaussian Process Random Fields

  Gaussian processes have been successful in both supervised and unsupervised
machine learning tasks, but their computational complexity has constrained
practical applications. We introduce a new approximation for large-scale
Gaussian processes, the Gaussian Process Random Field (GPRF), in which local
GPs are coupled via pairwise potentials. The GPRF likelihood is a simple,
tractable, and parallelizeable approximation to the full GP marginal
likelihood, enabling latent variable modeling and hyperparameter selection on
large datasets. We demonstrate its effectiveness on synthetic spatial data as
well as a real-world application to seismic event location.


Multi-element Germanium Detectors for Synchrotron Applications

  We have developed a series of monolithic multi-element germanium detectors,
based on sensor arrays produced by the Forschungzentrum Julich, and on
Application-specific integrated circuits (ASICs) developed at Brookhaven.
Devices have been made with element counts ranging from 64 to 384. These
detectors are being used at NSLS-II and APS for a range of diffraction
experiments, both monochromatic and energy-dispersive. Compact and powerful
readout systems have been developed, based on the new generation of FPGA
system-on-chip devices, which provide closely coupled multi-core processors
embedded in large gate arrays. We will discuss the technical details of the
systems, and present some of the results from them.


The Extended Parameter Filter

  The parameters of temporal models, such as dynamic Bayesian networks, may be
modelled in a Bayesian context as static or atemporal variables that influence
transition probabilities at every time step. Particle filters fail for models
that include such variables, while methods that use Gibbs sampling of parameter
variables may incur a per-sample cost that grows linearly with the length of
the observation sequence. Storvik devised a method for incremental computation
of exact sufficient statistics that, for some cases, reduces the per-sample
cost to a constant. In this paper, we demonstrate a connection between
Storvik's filter and a Kalman filter in parameter space and establish more
general conditions under which Storvik's filter works. Drawing on an analogy to
the extended Kalman filter, we develop and analyze, both theoretically and
experimentally, a Taylor approximation to the parameter posterior that allows
Storvik's method to be applied to a broader class of models. Our experiments on
both synthetic examples and real applications show improvement over existing
methods.


Signal-based Bayesian Seismic Monitoring

  Detecting weak seismic events from noisy sensors is a difficult perceptual
task. We formulate this task as Bayesian inference and propose a generative
model of seismic events and signals across a network of spatially distributed
stations. Our system, SIGVISA, is the first to directly model seismic
waveforms, allowing it to incorporate a rich representation of the physics
underlying the signal generation process. We use Gaussian processes over
wavelet parameters to predict detailed waveform fluctuations based on
historical events, while degrading smoothly to simple parametric envelopes in
regions with no historical seismicity. Evaluating on data from the western US,
we recover three times as many events as previous work, and reduce mean
location errors by a factor of four while greatly increasing sensitivity to
low-magnitude events.


Meta-Learning MCMC Proposals

  Effective implementations of sampling-based probabilistic inference often
require manually constructed, model-specific proposals. Inspired by recent
progresses in meta-learning for training learning agents that can generalize to
unseen environments, we propose a meta-learning approach to building effective
and generalizable MCMC proposals. We parametrize the proposal as a neural
network to provide fast approximations to block Gibbs conditionals. The learned
neural proposals generalize to occurrences of common structural motifs across
different models, allowing for the construction of a library of learned
inference primitives that can accelerate inference on unseen models with no
model-specific training required. We explore several applications including
open-universe Gaussian mixture models, in which our learned proposals
outperform a hand-tuned sampler, and a real-world named entity recognition
task, in which our sampler yields higher final F1 scores than classical
single-site Gibbs sampling.


SunPy - Python for Solar Physics

  This paper presents SunPy (version 0.5), a community-developed Python package
for solar physics. Python, a free, cross-platform, general-purpose, high-level
programming language, has seen widespread adoption among the scientific
community, resulting in the availability of a large number of software
packages, from numerical computation (NumPy, SciPy) and machine learning
(scikit-learn) to visualisation and plotting (matplotlib). SunPy is a
data-analysis environment specialising in providing the software necessary to
analyse solar and heliospheric data in Python. SunPy is open-source software
(BSD licence) and has an open and transparent development workflow that anyone
can contribute to. SunPy provides access to solar data through integration with
the Virtual Solar Observatory (VSO), the Heliophysics Event Knowledgebase
(HEK), and the HELiophysics Integrated Observatory (HELIO) webservices. It
currently supports image data from major solar missions (e.g., SDO, SOHO,
STEREO, and IRIS), time-series data from missions such as GOES, SDO/EVE, and
PROBA2/LYRA, and radio spectra from e-Callisto and STEREO/SWAVES. We describe
SunPy's functionality, provide examples of solar data analysis in SunPy, and
show how Python-based solar data-analysis can leverage the many existing tools
already available in Python. We discuss the future goals of the project and
encourage interested users to become involved in the planning and development
of SunPy.


Ion heating and magnetic flux pile-up in a magnetic reconnection
  experiment with super-Alfvenic plasma inflows

  This work presents a magnetic reconnection experiment in which the kinetic,
magnetic and thermal properties of the plasma each play an important role in
the overall energy balance and structure of the generated reconnection layer.
Magnetic reconnection occurs during the interaction of continuous and steady
flows of super-Alfvenic, magnetized, aluminum plasma, which collide in a
geometry with two-dimensional symmetry, producing a stable and long-lasting
reconnection layer. Optical Thomson scattering measurements show that when the
layer forms, ions inside the layer are more strongly heated than electrons,
reaching temperatures of Ti~ZTe>300 eV - much greater than can be expected from
strong shock and viscous heating alone. Later in time, as the plasma density in
the layer increases, the electron and ion temperatures are found to
equilibrate, and a constant plasma temperature is achieved through a balance of
the heating mechanisms and radiative losses of the plasma. Measurements from
Faraday rotation polarimetry also indicate the presence of significant magnetic
field pile-up occurring at the boundary of the reconnection region, which is
consistent with the super-Alfvenic velocity of the inflows.


The 2dF Galaxy Redshift Survey: Near Infrared Galaxy Luminosity
  Functions

  We combine the 2MASS extended source catalogue and the 2dFGRS to produce an
IR selected galaxy catalogue with 17,173 measured redshifts. We use this
extensive dataset to estimate the J and K-band galaxy luminosity functions. The
LFs are fairly well fit by Schechter functions with J: M*-5log h=
-22.36+/-0.02, alpha= -0.93+/-0.04, Phi=0.0104+/-0.0016 h^3/Mpc^3 and K:
M*-5log h= -23.44+/-0.03, alpha=-0.96+/-0.05, Phi=0.0108+/-0.0016 h^3/Mpc^3
(2MASS Kron magnitudes). These parameters assume a cosmological model with
Omega=0.3 and Lambda=0.7. With datasets of this size, systematic rather than
random errors are the dominant source of uncertainty in the determination of
the LF. We carry out a careful investigation of possible systematic effects in
our data. The surface brightness distribution of the sample shows no evidence
that significant numbers of low surface brightness or compact galaxies are
missed by the survey. We estimate the present-day distributions of B-K and J-K
colours as a function of absolute magnitude and use models of the galaxy
stellar populations, constrained by the observed optical and infrared colours,
to infer the galaxy stellar mass function. Integrated over all galaxy masses,
this yields a total mass fraction in stars (in units of the critical mass
density) of Omega_*.h= (1.6+/-0.24)/10^3 for a Kennicutt IMF and Omega_*.h=
(2.9+/-0.43)/10^3 for a Salpeter IMF. These values agree with those inferred
from observational estimates of the star formation history of the universe
provided that dust extinction corrections are modest.


The 2dF Galaxy Redshift Survey: correlation with the ROSAT-ESO Flux
  Limited X-ray (REFLEX) galaxy cluster survey

  The ROSAT-ESO Flux Limited X-ray (REFLEX) galaxy cluster survey and the 2dF
Galaxy Redshift Survey (2dFGRS) respectively comprise the largest, homogeneous
X-ray selected cluster catalogue and completed galaxy redshift survey. In this
work we combine these two outstanding datasets in order to study the effect of
the large-scale cluster environment, as traced by X-ray luminosity, on the
properties of the cluster member galaxies. We measure the LX-sigma relation
from the correlated dataset and find it to be consistent with recent results
found in the literature. Using a sample of 19 clusters with LX>=0.36*10^44 erg
s^-1 in the (0.1-2.4 keV) band, and 49 clusters with lower X-ray luminosity, we
find that the fraction of early spectral type (eta<=-1.4), passively-evolving
galaxies is significantly higher in the high-LX sample within R200. We extend
the investigation to include composite bJ cluster luminosity functions, and
find that the characteristic magnitude of the Schechter-function fit to the
early-type luminosity function is fainter for the high-LX sample compared to
the low-LX sample (Delta M*=0.58+/-0.14). This seems to be driven by a deficit
of such galaxies with M_bJ ~ -21. In contrast, we find no significant
differences between the luminosity functions of star-forming, late-type
galaxies. We believe these results are consistent with a scenario in which the
high-LX clusters are more dynamically evolved systems than the low-LX clusters.


The 2dF Galaxy Redshift Survey: The power spectrum and the matter
  content of the universe

  The 2dF Galaxy Redshift Survey has now measured in excess of 160000 galaxy
redshifts. This paper presents the power spectrum of the galaxy distribution,
calculated using a direct FFT-based technique. We argue that, within the
k-space region 0.02<k<0.15 h Mpc^-1, the shape of this spectrum should be close
to that of the linear density perturbations convolved with the window function
of the survey. This window function and its convolving effect on the power
spectrum estimate are analyzed in detail. By convolving model spectra, we are
able to fit the power-spectrum data and provide a measure of the matter content
of the universe. Our results show that models containing baryon oscillations
are mildly preferred over featureless power spectra. Analysis of the data
yields 68% confidence limits on the total matter density times the Hubble
parameter \Omega_m h = 0.20 +/- 0.03, and the baryon fraction \Omega_b/\Omega_m
= 0.15 +/- 0.07, assuming scale-invariant primordial fluctuations.


Evidence for a non-zero Lambda and a low matter density from a combined
  analysis of the 2dF Galaxy Redshift Survey and Cosmic Microwave Background
  Anisotropies

  We perform a joint likelihood analysis of the power spectra of the 2dF Galaxy
Redshift Survey (2dFGRS) and the cosmic microwave background (CMB) anisotropies
under the assumptions that the initial fluctuations were adiabatic, Gaussian
and well described by power laws with scalar and tensor indices of n_s and n_t.
On its own, the 2dFGRS sets tight limits on the parameter combination Omega_m
h, but relatively weak limits on the fraction of the cosmic matter density in
baryons Omega_b/Omega_m. The CMB anisotropy data alone set poor constraints on
the cosmological constant and Hubble constant because of a `geometrical
degeneracy' among parameters. Furthermore, if tensor modes are allowed, the CMB
data allow a wide range of values for the physical densities in baryons and
cold dark matter. Combining the CMB and 2dFGRS data sets helps to break both
the geometrical and tensor mode degeneracies. The values of the parameters
derived here are consistent with the predictions of the simplest models of
inflation, with the baryon density derived from primordial nucleosynthesis and
with direct measurements of the Hubble parameter. In particular, we find strong
evidence for a positive cosmological constant with a pm 2sigma range of 0.65 <
Omega_Lambda < 0.85, completely independently of constraints on Omega_\Lambda
derived from Type Ia supernovae.


Parameter constraints for flat cosmologies from CMB and 2dFGRS power
  spectra

  We constrain flat cosmological models with a joint likelihood analysis of a
new compilation of data from the cosmic microwave background (CMB) and from the
2dF Galaxy Redshift Survey (2dFGRS). Fitting the CMB alone yields a known
degeneracy between the Hubble constant h and the matter density Omega_m, which
arises mainly from preserving the location of the peaks in the angular power
spectrum. This `horizon-angle degeneracy' is considered in some detail and
shown to follow a simple relation Omega_m h^{3.4} = constant. Adding the 2dFGRS
power spectrum constrains Omega_m h and breaks the degeneracy. If tensor
anisotropies are assumed to be negligible, we obtain values for the Hubble
constant h=0.665 +/- 0.047, the matter density Omega_m=0.313 +/- 0.055, and the
physical CDM and baryon densities Omega_c h^2 = 0.115 +/- 0.009, Omega_b h^2 =
0.022 +/- 0.002 (standard rms errors). Including a possible tensor component
causes very little change to these figures; we set a upper limit to the
tensor-to-scalar ratio of r<0.7 at 95% confidence. We then show how these data
can be used to constrain the equation of state of the vacuum, and find w<-0.52
at 95% confidence. The preferred cosmological model is thus very well
specified, and we discuss the precision with which future CMB data can be
predicted, given the model assumptions. The 2dFGRS power-spectrum data and
covariance matrix, and the CMB data compilation used here, are available from
http://www.roe.ac.uk/~wjp/


The 2dF Galaxy Redshift Survey: Spherical Harmonics analysis of
  fluctuations in the final catalogue

  We present the result of a decomposition of the 2dFGRS galaxy overdensity
field into an orthonormal basis of spherical harmonics and spherical Bessel
functions. Galaxies are expected to directly follow the bulk motion of the
density field on large scales, so the absolute amplitude of the observed
large-scale redshift-space distortions caused by this motion is expected to be
independent of galaxy properties. By splitting the overdensity field into
radial and angular components, we linearly model the observed distortion and
obtain the cosmological constraint Omega_m^{0.6} sigma_8=0.46+/-0.06. The
amplitude of the linear redshift-space distortions relative to the galaxy
overdensity field is dependent on galaxy properties and, for L_* galaxies at
redshift z=0, we measure beta(L_*,0)=0.58+/-0.08, and the amplitude of the
overdensity fluctuations b(L_*,0) sigma_8=0.79+/-0.03, marginalising over the
power spectrum shape parameters. Assuming a fixed power spectrum shape
consistent with the full Fourier analysis produces very similar parameter
constraints.


An elevation of 0.1 light-seconds for the optical jet base in an
  accreting Galactic black hole system

  Relativistic plasma jets are observed in many accreting black holes.
According to theory, coiled magnetic fields close to the black hole accelerate
and collimate the plasma, leading to a jet being launched. Isolating emission
from this acceleration and collimation zone is key to measuring its size and
understanding jet formation physics. But this is challenging because emission
from the jet base cannot be easily disentangled from other accreting
components. Here, we show that rapid optical flux variations from a Galactic
black-hole binary are delayed with respect to X-rays radiated from close to the
black hole by ~0.1 seconds, and that this delayed signal appears together with
a brightening radio jet. The origin of these sub-second optical variations has
hitherto been controversial. Not only does our work strongly support a jet
origin for the optical variations, it also sets a characteristic elevation of
<~10$^3$ Schwarzschild radii for the main inner optical emission zone above the
black hole, constraining both internal shock and magnetohydrodynamic models.
Similarities with blazars suggest that jet structure and launching physics
could potentially be unified under mass-invariant models. Two of the
best-studied jetted black hole binaries show very similar optical lags, so this
size scale may be a defining feature of such systems.


Science with the Murchison Widefield Array

  Significant new opportunities for astrophysics and cosmology have been
identified at low radio frequencies. The Murchison Widefield Array is the first
telescope in the Southern Hemisphere designed specifically to explore the
low-frequency astronomical sky between 80 and 300 MHz with arcminute angular
resolution and high survey efficiency. The telescope will enable new advances
along four key science themes, including searching for redshifted 21 cm
emission from the epoch of reionisation in the early Universe; Galactic and
extragalactic all-sky southern hemisphere surveys; time-domain astrophysics;
and solar, heliospheric, and ionospheric science and space weather. The
Murchison Widefield Array is located in Western Australia at the site of the
planned Square Kilometre Array (SKA) low-band telescope and is the only
low-frequency SKA precursor facility. In this paper, we review the performance
properties of the Murchison Widefield Array and describe its primary scientific
objectives.


A study of fundamental limitations to statistical detection of
  redshifted HI from the epoch of reionization

  In this paper we explore for the first time the relative magnitudes of three
fundamental sources of uncertainty, namely, foreground contamination, thermal
noise and sample variance in detecting the HI power spectrum from the Epoch of
Reionization (EoR). We derive limits on the sensitivity of a Fourier synthesis
telescope to detect EoR based on its array configuration and a statistical
representation of images made by the instrument. We use the Murchison Widefield
Array (MWA) configuration for our studies. Using a unified framework for
estimating signal and noise components in the HI power spectrum, we derive an
expression for and estimate the contamination from extragalactic point-like
sources in three-dimensional k-space. Sensitivity for EoR HI power spectrum
detection is estimated for different observing modes with MWA. With 1000 hours
of observing on a single field using the 128-tile MWA, EoR detection is
feasible (S/N > 1 for $k\lesssim 0.8$ Mpc$^{-1}$). Bandpass shaping and
refinements to the EoR window are found to be effective in containing
foreground contamination, which makes the instrument tolerant to imaging
errors. We find that for a given observing time, observing many independent
fields of view does not offer an advantage over a single field observation when
thermal noise dominates over other uncertainties in the derived power spectrum.


Low Frequency Imaging of Fields at High Galactic Latitude with the
  Murchison Widefield Array 32-Element Prototype

  The Murchison Widefield Array (MWA) is a new low-frequency, wide
field-of-view radio interferometer under development at the Murchison
Radio-astronomy Observatory (MRO) in Western Australia. We have used a
32-element MWA prototype interferometer (MWA-32T) to observe two 50-degree
diameter fields in the southern sky in the 110 MHz to 200 MHz band in order to
evaluate the performance of the MWA-32T, to develop techniques for epoch of
reionization experiments, and to make measurements of astronomical foregrounds.
We developed a calibration and imaging pipeline for the MWA-32T, and used it to
produce ~15' angular resolution maps of the two fields. We perform a blind
source extraction using these confusion-limited images, and detect 655 sources
at high significance with an additional 871 lower significance source
candidates. We compare these sources with existing low-frequency radio surveys
in order to assess the MWA-32T system performance, wide field analysis
algorithms, and catalog quality. Our source catalog is found to agree well with
existing low-frequency surveys in these regions of the sky and with statistical
distributions of point sources derived from Northern Hemisphere surveys; it
represents one of the deepest surveys to date of this sky field in the 110 MHz
to 200 MHz band.


A Digital-Receiver for the Murchison Widefield Array

  An FPGA-based digital-receiver has been developed for a low-frequency imaging
radio interferometer, the Murchison Widefield Array (MWA). The MWA, located at
the Murchison Radio-astronomy Observatory (MRO) in Western Australia, consists
of 128 dual-polarized aperture-array elements (tiles) operating between 80 and
300\,MHz, with a total processed bandwidth of 30.72 MHz for each polarization.
Radio-frequency signals from the tiles are amplified and band limited using
analog signal conditioning units; sampled and channelized by digital-receivers.
The signals from eight tiles are processed by a single digital-receiver, thus
requiring 16 digital-receivers for the MWA. The main function of the
digital-receivers is to digitize the broad-band signals from each tile,
channelize them to form the sky-band, and transport it through optical fibers
to a centrally located correlator for further processing. The digital-receiver
firmware also implements functions to measure the signal power, perform power
equalization across the band, detect interference-like events, and invoke
diagnostic modes. The digital-receiver is controlled by high-level programs
running on a single-board-computer. This paper presents the digital-receiver
design, implementation, current status, and plans for future enhancements.


The 2dF Galaxy Redshift Survey: The amplitudes of fluctuations in the
  2dFGRS and the CMB, and implications for galaxy biasing

  We compare the amplitudes of fluctuations probed by the 2dF Galaxy Redshift
Survey and by the latest measurements of the Cosmic Microwave Background
anisotropies. By combining the 2dFGRS and CMB data we find the linear-theory
rms mass fluctuations in 8 Mpc/h spheres to be sigma_8 = 0.73 +-0.05 (after
marginalization over the matter density parameter Omega_m and three other free
parameters). This normalization is lower than the COBE normalization and
previous estimates from cluster abundance, but it is in agreement with some
revised cluster abundance determinations. We also estimate the
scale-independent bias parameter of present-epoch L_s = 1.9L_* APM-selected
galaxies to be b(L_s,z=0) = 1.10 +- 0.08 on comoving scales of 0.02 < k < 0.15
h/Mpc. If luminosity segregation operates on these scales, L_* galaxies would
be almost un-biased, b(L_*,z=0) = 0.96. These results are derived by assuming a
flat Lambda-CDM Universe, and by marginalizing over other free parameters and
fixing the spectral index n=1 and the optical depth due to reionization tau=0.
We also study the best fit pair (Omega_m,b), and the robustness of the results
to varying n and tau. Various modelling corrections can each change the
resulting b by 5-15 per cent. The results are compared with other independent
measurements from the 2dFGRS itself, and from the SDSS, cluster abundance and
cosmic shear.


The 2dF Galaxy Redshift Survey: Clustering properties of radio galaxies

  The clustering properties of local, S_{1.4 GHz} > 1 mJy, radio sources are
investigated for a sample of 820 objects drawn from the joint use of the FIRST
and 2dF Galaxy Redshift surveys. To this aim, we present 271 new bj < 19.45
spectroscopic counterparts of FIRST radio sources to be added to those already
introduced in Magliocchetti et al. (2002). The two-point correlation function
for the local radio population is found to be entirely consistent with
estimates obtained for the whole sample of 2dFGRS galaxies. We estimate the
parameters of the real-space correlation function xi(r)=(r/r_0)^{-\gamma},
r_0=6.7^{+0.9}_{-1.1} Mpc and \gamma=1.6\pm 0.1, where h=0.7 is assumed.
Different results are instead obtained if we only consider sources that present
signatures of AGN activity in their spectra. These objects are shown to be very
strongly correlated, with r_0=10.9^{+1.0}_{-1.2} Mpc and \gamma=2\pm 0.1, a
steeper slope than has been claimed in other recent works. No difference is
found in the clustering properties of radio-AGNs of different radio luminosity.
These results show that AGN-fuelled sources reside in dark matter halos more
massive than \sim 10^{13.4} M_{\sun}},higher the corresponding figure for
radio-quiet QSOs. This value can be converted into a minimum black hole mass
associated with radio-loud, AGN-fuelled objects of M_{BH}^{min}\sim 10^9
M_{\sun}. The above results then suggest -at least for relatively faint radio
objects -the existence of a threshold black hole mass associated with the onset
of significant radio activity such as that of radio-loud AGNs; however, once
the activity is triggered, there appears to be no evidence for a connection
between black hole mass and level of radio output. (abridged)


The DUNE Far Detector Interim Design Report, Volume 2: Single-Phase
  Module

  The DUNE IDR describes the proposed physics program and technical designs of
the DUNE far detector modules in preparation for the full TDR to be published
in 2019. It is intended as an intermediate milestone on the path to a full TDR,
justifying the technical choices that flow down from the high-level physics
goals through requirements at all levels of the Project. These design choices
will enable the DUNE experiment to make the ground-breaking discoveries that
will help to answer fundamental physics questions. Volume 2 describes the
single-phase module's subsystems, the technical coordination required for its
design, construction, installation, and integration, and its organizational
structure.


The DUNE Far Detector Interim Design Report Volume 1: Physics,
  Technology and Strategies

  The DUNE IDR describes the proposed physics program and technical designs of
the DUNE Far Detector modules in preparation for the full TDR to be published
in 2019. It is intended as an intermediate milestone on the path to a full TDR,
justifying the technical choices that flow down from the high-level physics
goals through requirements at all levels of the Project. These design choices
will enable the DUNE experiment to make the ground-breaking discoveries that
will help to answer fundamental physics questions. Volume 1 contains an
executive summary that describes the general aims of this document. The
remainder of this first volume provides a more detailed description of the DUNE
physics program that drives the choice of detector technologies. It also
includes concise outlines of two overarching systems that have not yet evolved
to consortium structures: computing and calibration. Volumes 2 and 3 of this
IDR describe, for the single-phase and dual-phase technologies, respectively,
each detector module's subsystems, the technical coordination required for its
design, construction, installation, and integration, and its organizational
structure.


The DUNE Far Detector Interim Design Report, Volume 3: Dual-Phase Module

  The DUNE IDR describes the proposed physics program and technical designs of
the DUNE far detector modules in preparation for the full TDR to be published
in 2019. It is intended as an intermediate milestone on the path to a full TDR,
justifying the technical choices that flow down from the high-level physics
goals through requirements at all levels of the Project. These design choices
will enable the DUNE experiment to make the ground-breaking discoveries that
will help to answer fundamental physics questions. Volume 3 describes the
dual-phase module's subsystems, the technical coordination required for its
design, construction, installation, and integration, and its organizational
structure.


LSST: from Science Drivers to Reference Design and Anticipated Data
  Products

  (Abridged) We describe here the most ambitious survey currently planned in
the optical, the Large Synoptic Survey Telescope (LSST). A vast array of
science will be enabled by a single wide-deep-fast sky survey, and LSST will
have unique survey capability in the faint time domain. The LSST design is
driven by four main science themes: probing dark energy and dark matter, taking
an inventory of the Solar System, exploring the transient optical sky, and
mapping the Milky Way. LSST will be a wide-field ground-based system sited at
Cerro Pach\'{o}n in northern Chile. The telescope will have an 8.4 m (6.5 m
effective) primary mirror, a 9.6 deg$^2$ field of view, and a 3.2 Gigapixel
camera. The standard observing sequence will consist of pairs of 15-second
exposures in a given field, with two such visits in each pointing in a given
night. With these repeats, the LSST system is capable of imaging about 10,000
square degrees of sky in a single filter in three nights. The typical 5$\sigma$
point-source depth in a single visit in $r$ will be $\sim 24.5$ (AB). The
project is in the construction phase and will begin regular survey operations
by 2022. The survey area will be contained within 30,000 deg$^2$ with
$\delta<+34.5^\circ$, and will be imaged multiple times in six bands, $ugrizy$,
covering the wavelength range 320--1050 nm. About 90\% of the observing time
will be devoted to a deep-wide-fast survey mode which will uniformly observe a
18,000 deg$^2$ region about 800 times (summed over all six bands) during the
anticipated 10 years of operations, and yield a coadded map to $r\sim27.5$. The
remaining 10\% of the observing time will be allocated to projects such as a
Very Deep and Fast time domain survey. The goal is to make LSST data products,
including a relational database of about 32 trillion observations of 40 billion
objects, available to the public and scientists around the world.


Searching for long-lived particles beyond the Standard Model at the
  Large Hadron Collider

  Particles beyond the Standard Model (SM) can generically have lifetimes that
are long compared to SM particles at the weak scale. When produced at
experiments such as the Large Hadron Collider (LHC) at CERN, these long-lived
particles (LLPs) can decay far from the interaction vertex of the primary
proton-proton collision. Such LLP signatures are distinct from those of
promptly decaying particles that are targeted by the majority of searches for
new physics at the LHC, often requiring customized techniques to identify, for
example, significantly displaced decay vertices, tracks with atypical
properties, and short track segments. Given their non-standard nature, a
comprehensive overview of LLP signatures at the LHC is beneficial to ensure
that possible avenues of the discovery of new physics are not overlooked. Here
we report on the joint work of a community of theorists and experimentalists
with the ATLAS, CMS, and LHCb experiments --- as well as those working on
dedicated experiments such as MoEDAL, milliQan, MATHUSLA, CODEX-b, and FASER
--- to survey the current state of LLP searches at the LHC, and to chart a path
for the development of LLP searches into the future, both in the upcoming Run 3
and at the High-Luminosity LHC. The work is organized around the current and
future potential capabilities of LHC experiments to generally discover new
LLPs, and takes a signature-based approach to surveying classes of models that
give rise to LLPs rather than emphasizing any particular theory motivation. We
develop a set of simplified models; assess the coverage of current searches;
document known, often unexpected backgrounds; explore the capabilities of
proposed detector upgrades; provide recommendations for the presentation of
search results; and look towards the newest frontiers, namely high-multiplicity
"dark showers", highlighting opportunities for expanding the LHC reach for
these signals.


