Gaussian Process Random Fields

  Gaussian processes have been successful in both supervised and unsupervisedmachine learning tasks, but their computational complexity has constrainedpractical applications. We introduce a new approximation for large-scaleGaussian processes, the Gaussian Process Random Field (GPRF), in which localGPs are coupled via pairwise potentials. The GPRF likelihood is a simple,tractable, and parallelizeable approximation to the full GP marginallikelihood, enabling latent variable modeling and hyperparameter selection onlarge datasets. We demonstrate its effectiveness on synthetic spatial data aswell as a real-world application to seismic event location.

Multi-element Germanium Detectors for Synchrotron Applications

  We have developed a series of monolithic multi-element germanium detectors,based on sensor arrays produced by the Forschungzentrum Julich, and onApplication-specific integrated circuits (ASICs) developed at Brookhaven.Devices have been made with element counts ranging from 64 to 384. Thesedetectors are being used at NSLS-II and APS for a range of diffractionexperiments, both monochromatic and energy-dispersive. Compact and powerfulreadout systems have been developed, based on the new generation of FPGAsystem-on-chip devices, which provide closely coupled multi-core processorsembedded in large gate arrays. We will discuss the technical details of thesystems, and present some of the results from them.

The Extended Parameter Filter

  The parameters of temporal models, such as dynamic Bayesian networks, may bemodelled in a Bayesian context as static or atemporal variables that influencetransition probabilities at every time step. Particle filters fail for modelsthat include such variables, while methods that use Gibbs sampling of parametervariables may incur a per-sample cost that grows linearly with the length ofthe observation sequence. Storvik devised a method for incremental computationof exact sufficient statistics that, for some cases, reduces the per-samplecost to a constant. In this paper, we demonstrate a connection betweenStorvik's filter and a Kalman filter in parameter space and establish moregeneral conditions under which Storvik's filter works. Drawing on an analogy tothe extended Kalman filter, we develop and analyze, both theoretically andexperimentally, a Taylor approximation to the parameter posterior that allowsStorvik's method to be applied to a broader class of models. Our experiments onboth synthetic examples and real applications show improvement over existingmethods.

Signal-based Bayesian Seismic Monitoring

  Detecting weak seismic events from noisy sensors is a difficult perceptualtask. We formulate this task as Bayesian inference and propose a generativemodel of seismic events and signals across a network of spatially distributedstations. Our system, SIGVISA, is the first to directly model seismicwaveforms, allowing it to incorporate a rich representation of the physicsunderlying the signal generation process. We use Gaussian processes overwavelet parameters to predict detailed waveform fluctuations based onhistorical events, while degrading smoothly to simple parametric envelopes inregions with no historical seismicity. Evaluating on data from the western US,we recover three times as many events as previous work, and reduce meanlocation errors by a factor of four while greatly increasing sensitivity tolow-magnitude events.

Meta-Learning MCMC Proposals

  Effective implementations of sampling-based probabilistic inference oftenrequire manually constructed, model-specific proposals. Inspired by recentprogresses in meta-learning for training learning agents that can generalize tounseen environments, we propose a meta-learning approach to building effectiveand generalizable MCMC proposals. We parametrize the proposal as a neuralnetwork to provide fast approximations to block Gibbs conditionals. The learnedneural proposals generalize to occurrences of common structural motifs acrossdifferent models, allowing for the construction of a library of learnedinference primitives that can accelerate inference on unseen models with nomodel-specific training required. We explore several applications includingopen-universe Gaussian mixture models, in which our learned proposalsoutperform a hand-tuned sampler, and a real-world named entity recognitiontask, in which our sampler yields higher final F1 scores than classicalsingle-site Gibbs sampling.

SunPy - Python for Solar Physics

  This paper presents SunPy (version 0.5), a community-developed Python packagefor solar physics. Python, a free, cross-platform, general-purpose, high-levelprogramming language, has seen widespread adoption among the scientificcommunity, resulting in the availability of a large number of softwarepackages, from numerical computation (NumPy, SciPy) and machine learning(scikit-learn) to visualisation and plotting (matplotlib). SunPy is adata-analysis environment specialising in providing the software necessary toanalyse solar and heliospheric data in Python. SunPy is open-source software(BSD licence) and has an open and transparent development workflow that anyonecan contribute to. SunPy provides access to solar data through integration withthe Virtual Solar Observatory (VSO), the Heliophysics Event Knowledgebase(HEK), and the HELiophysics Integrated Observatory (HELIO) webservices. Itcurrently supports image data from major solar missions (e.g., SDO, SOHO,STEREO, and IRIS), time-series data from missions such as GOES, SDO/EVE, andPROBA2/LYRA, and radio spectra from e-Callisto and STEREO/SWAVES. We describeSunPy's functionality, provide examples of solar data analysis in SunPy, andshow how Python-based solar data-analysis can leverage the many existing toolsalready available in Python. We discuss the future goals of the project andencourage interested users to become involved in the planning and developmentof SunPy.

Ion heating and magnetic flux pile-up in a magnetic reconnection  experiment with super-Alfvenic plasma inflows

  This work presents a magnetic reconnection experiment in which the kinetic,magnetic and thermal properties of the plasma each play an important role inthe overall energy balance and structure of the generated reconnection layer.Magnetic reconnection occurs during the interaction of continuous and steadyflows of super-Alfvenic, magnetized, aluminum plasma, which collide in ageometry with two-dimensional symmetry, producing a stable and long-lastingreconnection layer. Optical Thomson scattering measurements show that when thelayer forms, ions inside the layer are more strongly heated than electrons,reaching temperatures of Ti~ZTe>300 eV - much greater than can be expected fromstrong shock and viscous heating alone. Later in time, as the plasma density inthe layer increases, the electron and ion temperatures are found toequilibrate, and a constant plasma temperature is achieved through a balance ofthe heating mechanisms and radiative losses of the plasma. Measurements fromFaraday rotation polarimetry also indicate the presence of significant magneticfield pile-up occurring at the boundary of the reconnection region, which isconsistent with the super-Alfvenic velocity of the inflows.

The 2dF Galaxy Redshift Survey: Near Infrared Galaxy Luminosity  Functions

  We combine the 2MASS extended source catalogue and the 2dFGRS to produce anIR selected galaxy catalogue with 17,173 measured redshifts. We use thisextensive dataset to estimate the J and K-band galaxy luminosity functions. TheLFs are fairly well fit by Schechter functions with J: M*-5log h=-22.36+/-0.02, alpha= -0.93+/-0.04, Phi=0.0104+/-0.0016 h^3/Mpc^3 and K:M*-5log h= -23.44+/-0.03, alpha=-0.96+/-0.05, Phi=0.0108+/-0.0016 h^3/Mpc^3(2MASS Kron magnitudes). These parameters assume a cosmological model withOmega=0.3 and Lambda=0.7. With datasets of this size, systematic rather thanrandom errors are the dominant source of uncertainty in the determination ofthe LF. We carry out a careful investigation of possible systematic effects inour data. The surface brightness distribution of the sample shows no evidencethat significant numbers of low surface brightness or compact galaxies aremissed by the survey. We estimate the present-day distributions of B-K and J-Kcolours as a function of absolute magnitude and use models of the galaxystellar populations, constrained by the observed optical and infrared colours,to infer the galaxy stellar mass function. Integrated over all galaxy masses,this yields a total mass fraction in stars (in units of the critical massdensity) of Omega_*.h= (1.6+/-0.24)/10^3 for a Kennicutt IMF and Omega_*.h=(2.9+/-0.43)/10^3 for a Salpeter IMF. These values agree with those inferredfrom observational estimates of the star formation history of the universeprovided that dust extinction corrections are modest.

The 2dF Galaxy Redshift Survey: correlation with the ROSAT-ESO Flux  Limited X-ray (REFLEX) galaxy cluster survey

  The ROSAT-ESO Flux Limited X-ray (REFLEX) galaxy cluster survey and the 2dFGalaxy Redshift Survey (2dFGRS) respectively comprise the largest, homogeneousX-ray selected cluster catalogue and completed galaxy redshift survey. In thiswork we combine these two outstanding datasets in order to study the effect ofthe large-scale cluster environment, as traced by X-ray luminosity, on theproperties of the cluster member galaxies. We measure the LX-sigma relationfrom the correlated dataset and find it to be consistent with recent resultsfound in the literature. Using a sample of 19 clusters with LX>=0.36*10^44 ergs^-1 in the (0.1-2.4 keV) band, and 49 clusters with lower X-ray luminosity, wefind that the fraction of early spectral type (eta<=-1.4), passively-evolvinggalaxies is significantly higher in the high-LX sample within R200. We extendthe investigation to include composite bJ cluster luminosity functions, andfind that the characteristic magnitude of the Schechter-function fit to theearly-type luminosity function is fainter for the high-LX sample compared tothe low-LX sample (Delta M*=0.58+/-0.14). This seems to be driven by a deficitof such galaxies with M_bJ ~ -21. In contrast, we find no significantdifferences between the luminosity functions of star-forming, late-typegalaxies. We believe these results are consistent with a scenario in which thehigh-LX clusters are more dynamically evolved systems than the low-LX clusters.

The 2dF Galaxy Redshift Survey: The power spectrum and the matter  content of the universe

  The 2dF Galaxy Redshift Survey has now measured in excess of 160000 galaxyredshifts. This paper presents the power spectrum of the galaxy distribution,calculated using a direct FFT-based technique. We argue that, within thek-space region 0.02<k<0.15 h Mpc^-1, the shape of this spectrum should be closeto that of the linear density perturbations convolved with the window functionof the survey. This window function and its convolving effect on the powerspectrum estimate are analyzed in detail. By convolving model spectra, we areable to fit the power-spectrum data and provide a measure of the matter contentof the universe. Our results show that models containing baryon oscillationsare mildly preferred over featureless power spectra. Analysis of the datayields 68% confidence limits on the total matter density times the Hubbleparameter \Omega_m h = 0.20 +/- 0.03, and the baryon fraction \Omega_b/\Omega_m= 0.15 +/- 0.07, assuming scale-invariant primordial fluctuations.

Evidence for a non-zero Lambda and a low matter density from a combined  analysis of the 2dF Galaxy Redshift Survey and Cosmic Microwave Background  Anisotropies

  We perform a joint likelihood analysis of the power spectra of the 2dF GalaxyRedshift Survey (2dFGRS) and the cosmic microwave background (CMB) anisotropiesunder the assumptions that the initial fluctuations were adiabatic, Gaussianand well described by power laws with scalar and tensor indices of n_s and n_t.On its own, the 2dFGRS sets tight limits on the parameter combination Omega_mh, but relatively weak limits on the fraction of the cosmic matter density inbaryons Omega_b/Omega_m. The CMB anisotropy data alone set poor constraints onthe cosmological constant and Hubble constant because of a `geometricaldegeneracy' among parameters. Furthermore, if tensor modes are allowed, the CMBdata allow a wide range of values for the physical densities in baryons andcold dark matter. Combining the CMB and 2dFGRS data sets helps to break boththe geometrical and tensor mode degeneracies. The values of the parametersderived here are consistent with the predictions of the simplest models ofinflation, with the baryon density derived from primordial nucleosynthesis andwith direct measurements of the Hubble parameter. In particular, we find strongevidence for a positive cosmological constant with a pm 2sigma range of 0.65 <Omega_Lambda < 0.85, completely independently of constraints on Omega_\Lambdaderived from Type Ia supernovae.

Parameter constraints for flat cosmologies from CMB and 2dFGRS power  spectra

  We constrain flat cosmological models with a joint likelihood analysis of anew compilation of data from the cosmic microwave background (CMB) and from the2dF Galaxy Redshift Survey (2dFGRS). Fitting the CMB alone yields a knowndegeneracy between the Hubble constant h and the matter density Omega_m, whicharises mainly from preserving the location of the peaks in the angular powerspectrum. This `horizon-angle degeneracy' is considered in some detail andshown to follow a simple relation Omega_m h^{3.4} = constant. Adding the 2dFGRSpower spectrum constrains Omega_m h and breaks the degeneracy. If tensoranisotropies are assumed to be negligible, we obtain values for the Hubbleconstant h=0.665 +/- 0.047, the matter density Omega_m=0.313 +/- 0.055, and thephysical CDM and baryon densities Omega_c h^2 = 0.115 +/- 0.009, Omega_b h^2 =0.022 +/- 0.002 (standard rms errors). Including a possible tensor componentcauses very little change to these figures; we set a upper limit to thetensor-to-scalar ratio of r<0.7 at 95% confidence. We then show how these datacan be used to constrain the equation of state of the vacuum, and find w<-0.52at 95% confidence. The preferred cosmological model is thus very wellspecified, and we discuss the precision with which future CMB data can bepredicted, given the model assumptions. The 2dFGRS power-spectrum data andcovariance matrix, and the CMB data compilation used here, are available fromhttp://www.roe.ac.uk/~wjp/

The 2dF Galaxy Redshift Survey: Spherical Harmonics analysis of  fluctuations in the final catalogue

  We present the result of a decomposition of the 2dFGRS galaxy overdensityfield into an orthonormal basis of spherical harmonics and spherical Besselfunctions. Galaxies are expected to directly follow the bulk motion of thedensity field on large scales, so the absolute amplitude of the observedlarge-scale redshift-space distortions caused by this motion is expected to beindependent of galaxy properties. By splitting the overdensity field intoradial and angular components, we linearly model the observed distortion andobtain the cosmological constraint Omega_m^{0.6} sigma_8=0.46+/-0.06. Theamplitude of the linear redshift-space distortions relative to the galaxyoverdensity field is dependent on galaxy properties and, for L_* galaxies atredshift z=0, we measure beta(L_*,0)=0.58+/-0.08, and the amplitude of theoverdensity fluctuations b(L_*,0) sigma_8=0.79+/-0.03, marginalising over thepower spectrum shape parameters. Assuming a fixed power spectrum shapeconsistent with the full Fourier analysis produces very similar parameterconstraints.

An elevation of 0.1 light-seconds for the optical jet base in an  accreting Galactic black hole system

  Relativistic plasma jets are observed in many accreting black holes.According to theory, coiled magnetic fields close to the black hole accelerateand collimate the plasma, leading to a jet being launched. Isolating emissionfrom this acceleration and collimation zone is key to measuring its size andunderstanding jet formation physics. But this is challenging because emissionfrom the jet base cannot be easily disentangled from other accretingcomponents. Here, we show that rapid optical flux variations from a Galacticblack-hole binary are delayed with respect to X-rays radiated from close to theblack hole by ~0.1 seconds, and that this delayed signal appears together witha brightening radio jet. The origin of these sub-second optical variations hashitherto been controversial. Not only does our work strongly support a jetorigin for the optical variations, it also sets a characteristic elevation of<~10$^3$ Schwarzschild radii for the main inner optical emission zone above theblack hole, constraining both internal shock and magnetohydrodynamic models.Similarities with blazars suggest that jet structure and launching physicscould potentially be unified under mass-invariant models. Two of thebest-studied jetted black hole binaries show very similar optical lags, so thissize scale may be a defining feature of such systems.

Science with the Murchison Widefield Array

  Significant new opportunities for astrophysics and cosmology have beenidentified at low radio frequencies. The Murchison Widefield Array is the firsttelescope in the Southern Hemisphere designed specifically to explore thelow-frequency astronomical sky between 80 and 300 MHz with arcminute angularresolution and high survey efficiency. The telescope will enable new advancesalong four key science themes, including searching for redshifted 21 cmemission from the epoch of reionisation in the early Universe; Galactic andextragalactic all-sky southern hemisphere surveys; time-domain astrophysics;and solar, heliospheric, and ionospheric science and space weather. TheMurchison Widefield Array is located in Western Australia at the site of theplanned Square Kilometre Array (SKA) low-band telescope and is the onlylow-frequency SKA precursor facility. In this paper, we review the performanceproperties of the Murchison Widefield Array and describe its primary scientificobjectives.

A study of fundamental limitations to statistical detection of  redshifted HI from the epoch of reionization

  In this paper we explore for the first time the relative magnitudes of threefundamental sources of uncertainty, namely, foreground contamination, thermalnoise and sample variance in detecting the HI power spectrum from the Epoch ofReionization (EoR). We derive limits on the sensitivity of a Fourier synthesistelescope to detect EoR based on its array configuration and a statisticalrepresentation of images made by the instrument. We use the Murchison WidefieldArray (MWA) configuration for our studies. Using a unified framework forestimating signal and noise components in the HI power spectrum, we derive anexpression for and estimate the contamination from extragalactic point-likesources in three-dimensional k-space. Sensitivity for EoR HI power spectrumdetection is estimated for different observing modes with MWA. With 1000 hoursof observing on a single field using the 128-tile MWA, EoR detection isfeasible (S/N > 1 for $k\lesssim 0.8$ Mpc$^{-1}$). Bandpass shaping andrefinements to the EoR window are found to be effective in containingforeground contamination, which makes the instrument tolerant to imagingerrors. We find that for a given observing time, observing many independentfields of view does not offer an advantage over a single field observation whenthermal noise dominates over other uncertainties in the derived power spectrum.

Low Frequency Imaging of Fields at High Galactic Latitude with the  Murchison Widefield Array 32-Element Prototype

  The Murchison Widefield Array (MWA) is a new low-frequency, widefield-of-view radio interferometer under development at the MurchisonRadio-astronomy Observatory (MRO) in Western Australia. We have used a32-element MWA prototype interferometer (MWA-32T) to observe two 50-degreediameter fields in the southern sky in the 110 MHz to 200 MHz band in order toevaluate the performance of the MWA-32T, to develop techniques for epoch ofreionization experiments, and to make measurements of astronomical foregrounds.We developed a calibration and imaging pipeline for the MWA-32T, and used it toproduce ~15' angular resolution maps of the two fields. We perform a blindsource extraction using these confusion-limited images, and detect 655 sourcesat high significance with an additional 871 lower significance sourcecandidates. We compare these sources with existing low-frequency radio surveysin order to assess the MWA-32T system performance, wide field analysisalgorithms, and catalog quality. Our source catalog is found to agree well withexisting low-frequency surveys in these regions of the sky and with statisticaldistributions of point sources derived from Northern Hemisphere surveys; itrepresents one of the deepest surveys to date of this sky field in the 110 MHzto 200 MHz band.

A Digital-Receiver for the Murchison Widefield Array

  An FPGA-based digital-receiver has been developed for a low-frequency imagingradio interferometer, the Murchison Widefield Array (MWA). The MWA, located atthe Murchison Radio-astronomy Observatory (MRO) in Western Australia, consistsof 128 dual-polarized aperture-array elements (tiles) operating between 80 and300\,MHz, with a total processed bandwidth of 30.72 MHz for each polarization.Radio-frequency signals from the tiles are amplified and band limited usinganalog signal conditioning units; sampled and channelized by digital-receivers.The signals from eight tiles are processed by a single digital-receiver, thusrequiring 16 digital-receivers for the MWA. The main function of thedigital-receivers is to digitize the broad-band signals from each tile,channelize them to form the sky-band, and transport it through optical fibersto a centrally located correlator for further processing. The digital-receiverfirmware also implements functions to measure the signal power, perform powerequalization across the band, detect interference-like events, and invokediagnostic modes. The digital-receiver is controlled by high-level programsrunning on a single-board-computer. This paper presents the digital-receiverdesign, implementation, current status, and plans for future enhancements.

The 2dF Galaxy Redshift Survey: The amplitudes of fluctuations in the  2dFGRS and the CMB, and implications for galaxy biasing

  We compare the amplitudes of fluctuations probed by the 2dF Galaxy RedshiftSurvey and by the latest measurements of the Cosmic Microwave Backgroundanisotropies. By combining the 2dFGRS and CMB data we find the linear-theoryrms mass fluctuations in 8 Mpc/h spheres to be sigma_8 = 0.73 +-0.05 (aftermarginalization over the matter density parameter Omega_m and three other freeparameters). This normalization is lower than the COBE normalization andprevious estimates from cluster abundance, but it is in agreement with somerevised cluster abundance determinations. We also estimate thescale-independent bias parameter of present-epoch L_s = 1.9L_* APM-selectedgalaxies to be b(L_s,z=0) = 1.10 +- 0.08 on comoving scales of 0.02 < k < 0.15h/Mpc. If luminosity segregation operates on these scales, L_* galaxies wouldbe almost un-biased, b(L_*,z=0) = 0.96. These results are derived by assuming aflat Lambda-CDM Universe, and by marginalizing over other free parameters andfixing the spectral index n=1 and the optical depth due to reionization tau=0.We also study the best fit pair (Omega_m,b), and the robustness of the resultsto varying n and tau. Various modelling corrections can each change theresulting b by 5-15 per cent. The results are compared with other independentmeasurements from the 2dFGRS itself, and from the SDSS, cluster abundance andcosmic shear.

The 2dF Galaxy Redshift Survey: Clustering properties of radio galaxies

  The clustering properties of local, S_{1.4 GHz} > 1 mJy, radio sources areinvestigated for a sample of 820 objects drawn from the joint use of the FIRSTand 2dF Galaxy Redshift surveys. To this aim, we present 271 new bj < 19.45spectroscopic counterparts of FIRST radio sources to be added to those alreadyintroduced in Magliocchetti et al. (2002). The two-point correlation functionfor the local radio population is found to be entirely consistent withestimates obtained for the whole sample of 2dFGRS galaxies. We estimate theparameters of the real-space correlation function xi(r)=(r/r_0)^{-\gamma},r_0=6.7^{+0.9}_{-1.1} Mpc and \gamma=1.6\pm 0.1, where h=0.7 is assumed.Different results are instead obtained if we only consider sources that presentsignatures of AGN activity in their spectra. These objects are shown to be verystrongly correlated, with r_0=10.9^{+1.0}_{-1.2} Mpc and \gamma=2\pm 0.1, asteeper slope than has been claimed in other recent works. No difference isfound in the clustering properties of radio-AGNs of different radio luminosity.These results show that AGN-fuelled sources reside in dark matter halos moremassive than \sim 10^{13.4} M_{\sun}},higher the corresponding figure forradio-quiet QSOs. This value can be converted into a minimum black hole massassociated with radio-loud, AGN-fuelled objects of M_{BH}^{min}\sim 10^9M_{\sun}. The above results then suggest -at least for relatively faint radioobjects -the existence of a threshold black hole mass associated with the onsetof significant radio activity such as that of radio-loud AGNs; however, oncethe activity is triggered, there appears to be no evidence for a connectionbetween black hole mass and level of radio output. (abridged)

The DUNE Far Detector Interim Design Report, Volume 2: Single-Phase  Module

  The DUNE IDR describes the proposed physics program and technical designs ofthe DUNE far detector modules in preparation for the full TDR to be publishedin 2019. It is intended as an intermediate milestone on the path to a full TDR,justifying the technical choices that flow down from the high-level physicsgoals through requirements at all levels of the Project. These design choiceswill enable the DUNE experiment to make the ground-breaking discoveries thatwill help to answer fundamental physics questions. Volume 2 describes thesingle-phase module's subsystems, the technical coordination required for itsdesign, construction, installation, and integration, and its organizationalstructure.

The DUNE Far Detector Interim Design Report Volume 1: Physics,  Technology and Strategies

  The DUNE IDR describes the proposed physics program and technical designs ofthe DUNE Far Detector modules in preparation for the full TDR to be publishedin 2019. It is intended as an intermediate milestone on the path to a full TDR,justifying the technical choices that flow down from the high-level physicsgoals through requirements at all levels of the Project. These design choiceswill enable the DUNE experiment to make the ground-breaking discoveries thatwill help to answer fundamental physics questions. Volume 1 contains anexecutive summary that describes the general aims of this document. Theremainder of this first volume provides a more detailed description of the DUNEphysics program that drives the choice of detector technologies. It alsoincludes concise outlines of two overarching systems that have not yet evolvedto consortium structures: computing and calibration. Volumes 2 and 3 of thisIDR describe, for the single-phase and dual-phase technologies, respectively,each detector module's subsystems, the technical coordination required for itsdesign, construction, installation, and integration, and its organizationalstructure.

The DUNE Far Detector Interim Design Report, Volume 3: Dual-Phase Module

  The DUNE IDR describes the proposed physics program and technical designs ofthe DUNE far detector modules in preparation for the full TDR to be publishedin 2019. It is intended as an intermediate milestone on the path to a full TDR,justifying the technical choices that flow down from the high-level physicsgoals through requirements at all levels of the Project. These design choiceswill enable the DUNE experiment to make the ground-breaking discoveries thatwill help to answer fundamental physics questions. Volume 3 describes thedual-phase module's subsystems, the technical coordination required for itsdesign, construction, installation, and integration, and its organizationalstructure.

LSST: from Science Drivers to Reference Design and Anticipated Data  Products

  (Abridged) We describe here the most ambitious survey currently planned inthe optical, the Large Synoptic Survey Telescope (LSST). A vast array ofscience will be enabled by a single wide-deep-fast sky survey, and LSST willhave unique survey capability in the faint time domain. The LSST design isdriven by four main science themes: probing dark energy and dark matter, takingan inventory of the Solar System, exploring the transient optical sky, andmapping the Milky Way. LSST will be a wide-field ground-based system sited atCerro Pach\'{o}n in northern Chile. The telescope will have an 8.4 m (6.5 meffective) primary mirror, a 9.6 deg$^2$ field of view, and a 3.2 Gigapixelcamera. The standard observing sequence will consist of pairs of 15-secondexposures in a given field, with two such visits in each pointing in a givennight. With these repeats, the LSST system is capable of imaging about 10,000square degrees of sky in a single filter in three nights. The typical 5$\sigma$point-source depth in a single visit in $r$ will be $\sim 24.5$ (AB). Theproject is in the construction phase and will begin regular survey operationsby 2022. The survey area will be contained within 30,000 deg$^2$ with$\delta<+34.5^\circ$, and will be imaged multiple times in six bands, $ugrizy$,covering the wavelength range 320--1050 nm. About 90\% of the observing timewill be devoted to a deep-wide-fast survey mode which will uniformly observe a18,000 deg$^2$ region about 800 times (summed over all six bands) during theanticipated 10 years of operations, and yield a coadded map to $r\sim27.5$. Theremaining 10\% of the observing time will be allocated to projects such as aVery Deep and Fast time domain survey. The goal is to make LSST data products,including a relational database of about 32 trillion observations of 40 billionobjects, available to the public and scientists around the world.

Searching for long-lived particles beyond the Standard Model at the  Large Hadron Collider

  Particles beyond the Standard Model (SM) can generically have lifetimes thatare long compared to SM particles at the weak scale. When produced atexperiments such as the Large Hadron Collider (LHC) at CERN, these long-livedparticles (LLPs) can decay far from the interaction vertex of the primaryproton-proton collision. Such LLP signatures are distinct from those ofpromptly decaying particles that are targeted by the majority of searches fornew physics at the LHC, often requiring customized techniques to identify, forexample, significantly displaced decay vertices, tracks with atypicalproperties, and short track segments. Given their non-standard nature, acomprehensive overview of LLP signatures at the LHC is beneficial to ensurethat possible avenues of the discovery of new physics are not overlooked. Herewe report on the joint work of a community of theorists and experimentalistswith the ATLAS, CMS, and LHCb experiments --- as well as those working ondedicated experiments such as MoEDAL, milliQan, MATHUSLA, CODEX-b, and FASER--- to survey the current state of LLP searches at the LHC, and to chart a pathfor the development of LLP searches into the future, both in the upcoming Run 3and at the High-Luminosity LHC. The work is organized around the current andfuture potential capabilities of LHC experiments to generally discover newLLPs, and takes a signature-based approach to surveying classes of models thatgive rise to LLPs rather than emphasizing any particular theory motivation. Wedevelop a set of simplified models; assess the coverage of current searches;document known, often unexpected backgrounds; explore the capabilities ofproposed detector upgrades; provide recommendations for the presentation ofsearch results; and look towards the newest frontiers, namely high-multiplicity"dark showers", highlighting opportunities for expanding the LHC reach forthese signals.

