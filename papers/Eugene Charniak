Review of Charniak's "Statistical Language Learning"

  This article is an in-depth review of Eugene Charniak's book, "StatisticalLanguage Learning". The review evaluates the appropriateness of the book as anintroductory text for statistical language learning for a variety of audiences.It also includes an extensive bibliography of articles and papers which mightbe used as a supplement to this book for learning or teaching statisticallanguage modeling.

Plan Recognition in Stories and in Life

  Plan recognition does not work the same way in stories and in "real life"(people tend to jump to conclusions more in stories). We present a theory ofthis, for the particular case of how objects in stories (or in life) influenceplan recognition decisions. We provide a Bayesian network formalization of asimple first-order theory of plans, and show how a particular network parameterseems to govern the difference between "life-like" and "story-like" response.We then show why this parameter would be influenced (in the desired way) by amodel of speaker (or author) topic selection which assumes that facts instories are typically "relevant".

A Probabilistic Analysis of Marker-Passing Techniques for  Plan-Recognition

  Useless paths are a chronic problem for marker-passing techniques. We use aprobabilistic analysis to justify a method for quickly identifying andrejecting useless paths. Using the same analysis, we identify key conditionsand assumptions necessary for marker-passing to perform well.

Dynamic Construction of Belief Networks

  We describe a method for incrementally constructing belief networks. We havedeveloped a network-construction language similar to a forward-chaininglanguage using data dependencies, but with additional features for specifyingdistributions. Using this language, we can define parameterized classes ofprobabilistic models. These parameterized models make it possible to applyprobabilistic reasoning to problems for which it is impractical to have asingle large static model.

A New Algorithm for Finding MAP Assignments to Belief Networks

  We present a new algorithm for finding maximum a-posterior) (MAP) assignmentsof values to belief networks. The belief network is compiled into a networkconsisting only of nodes with boolean (i.e. only 0 or 1) conditionalprobabilities. The MAP assignment is then found using a best-first search onthe resulting network. We argue that, as one would anticipate, the algorithm isexponential for the general case, but only linear in the size of the networkfor poly trees.

Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon  construction

  Generating semantic lexicons semi-automatically could be a great time saver,relative to creating them by hand. In this paper, we present an algorithm forextracting potential entries for a category from an on-line corpus, based upona small set of exemplars. Our algorithm finds more correct terms and fewerincorrect ones than previous work in this area. Additionally, the entries thatare generated potentially provide broader coverage of the category than wouldoccur to an individual coding them by hand. Our algorithm finds many terms notincluded within Wordnet (many more than previous algorithms), and could beviewed as an ``enhancer'' of existing broad-coverage resources.

Measuring efficiency in high-accuracy, broad-coverage statistical  parsing

  Very little attention has been paid to the comparison of efficiency betweenhigh accuracy statistical parsers. This paper proposes one machine-independentmetric that is general enough to allow comparisons across very differentparsing architectures. This metric, which we call ``events considered'',measures the number of ``events'', however they are defined for a particularparser, for which a probability must be calculated, in order to find the parse.It is applicable to single-pass or multi-stage parsers. We discuss theadvantages of the metric, and demonstrate its usefulness by using it to comparetwo parsers which differ in several fundamental ways.

Cost-Sharing in Bayesian Knowledge Bases

  Bayesian knowledge bases (BKBs) are a generalization of Bayes networks andweighted proof graphs (WAODAGs), that allow cycles in the causal graph.Reasoning in BKBs requires finding the most probable inferences consistent withthe evidence. The cost-sharing heuristic for finding least-cost explanations inWAODAGs was presented and shown to be effective by Charniak and Husain.However, the cycles in BKBs would make the definition of cost-sharing cyclic aswell, if applied directly to BKBs. By treating the defining equations ofcost-sharing as a system of equations, one can properly define an admissiblecost-sharing heuristic for BKBs. Empirical evaluation shows that cost-sharingimproves performance significantly when applied to BKBs.

