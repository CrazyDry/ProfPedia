Review of Charniak's "Statistical Language Learning"

  This article is an in-depth review of Eugene Charniak's book, "Statistical
Language Learning". The review evaluates the appropriateness of the book as an
introductory text for statistical language learning for a variety of audiences.
It also includes an extensive bibliography of articles and papers which might
be used as a supplement to this book for learning or teaching statistical
language modeling.


Plan Recognition in Stories and in Life

  Plan recognition does not work the same way in stories and in "real life"
(people tend to jump to conclusions more in stories). We present a theory of
this, for the particular case of how objects in stories (or in life) influence
plan recognition decisions. We provide a Bayesian network formalization of a
simple first-order theory of plans, and show how a particular network parameter
seems to govern the difference between "life-like" and "story-like" response.
We then show why this parameter would be influenced (in the desired way) by a
model of speaker (or author) topic selection which assumes that facts in
stories are typically "relevant".


A Probabilistic Analysis of Marker-Passing Techniques for
  Plan-Recognition

  Useless paths are a chronic problem for marker-passing techniques. We use a
probabilistic analysis to justify a method for quickly identifying and
rejecting useless paths. Using the same analysis, we identify key conditions
and assumptions necessary for marker-passing to perform well.


Dynamic Construction of Belief Networks

  We describe a method for incrementally constructing belief networks. We have
developed a network-construction language similar to a forward-chaining
language using data dependencies, but with additional features for specifying
distributions. Using this language, we can define parameterized classes of
probabilistic models. These parameterized models make it possible to apply
probabilistic reasoning to problems for which it is impractical to have a
single large static model.


A New Algorithm for Finding MAP Assignments to Belief Networks

  We present a new algorithm for finding maximum a-posterior) (MAP) assignments
of values to belief networks. The belief network is compiled into a network
consisting only of nodes with boolean (i.e. only 0 or 1) conditional
probabilities. The MAP assignment is then found using a best-first search on
the resulting network. We argue that, as one would anticipate, the algorithm is
exponential for the general case, but only linear in the size of the network
for poly trees.


Noun-phrase co-occurrence statistics for semi-automatic semantic lexicon
  construction

  Generating semantic lexicons semi-automatically could be a great time saver,
relative to creating them by hand. In this paper, we present an algorithm for
extracting potential entries for a category from an on-line corpus, based upon
a small set of exemplars. Our algorithm finds more correct terms and fewer
incorrect ones than previous work in this area. Additionally, the entries that
are generated potentially provide broader coverage of the category than would
occur to an individual coding them by hand. Our algorithm finds many terms not
included within Wordnet (many more than previous algorithms), and could be
viewed as an ``enhancer'' of existing broad-coverage resources.


Measuring efficiency in high-accuracy, broad-coverage statistical
  parsing

  Very little attention has been paid to the comparison of efficiency between
high accuracy statistical parsers. This paper proposes one machine-independent
metric that is general enough to allow comparisons across very different
parsing architectures. This metric, which we call ``events considered'',
measures the number of ``events'', however they are defined for a particular
parser, for which a probability must be calculated, in order to find the parse.
It is applicable to single-pass or multi-stage parsers. We discuss the
advantages of the metric, and demonstrate its usefulness by using it to compare
two parsers which differ in several fundamental ways.


Cost-Sharing in Bayesian Knowledge Bases

  Bayesian knowledge bases (BKBs) are a generalization of Bayes networks and
weighted proof graphs (WAODAGs), that allow cycles in the causal graph.
Reasoning in BKBs requires finding the most probable inferences consistent with
the evidence. The cost-sharing heuristic for finding least-cost explanations in
WAODAGs was presented and shown to be effective by Charniak and Husain.
However, the cycles in BKBs would make the definition of cost-sharing cyclic as
well, if applied directly to BKBs. By treating the defining equations of
cost-sharing as a system of equations, one can properly define an admissible
cost-sharing heuristic for BKBs. Empirical evaluation shows that cost-sharing
improves performance significantly when applied to BKBs.


