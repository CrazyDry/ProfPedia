Identifying Independencies in Causal Graphs with Feedback

  We show that the d -separation criterion constitutes a valid test for
conditional independence relationships that are induced by feedback systems
involving discrete variables.


Introduction to Judea Pearl's Do-Calculus

  This is a purely pedagogical paper with no new results. The goal of the paper
is to give a fairly self-contained introduction to Judea Pearl's do-calculus,
including proofs of his 3 rules.


Do We Need Higher-Order Probabilities and, If So, What Do They Mean?

  The apparent failure of individual probabilistic expressions to distinguish
uncertainty about truths from uncertainty about probabilistic assessments have
prompted researchers to seek formalisms where the two types of uncertainties
are given notational distinction. This paper demonstrates that the desired
distinction is already a built-in feature of classical probabilistic models,
thus, specialized notations are unnecessary.


A Constraint Propagation Approach to Probabilistic Reasoning

  The paper demonstrates that strict adherence to probability theory does not
preclude the use of concurrent, self-activated constraint-propagation
mechanisms for managing uncertainty. Maintaining local records of
sources-of-belief allows both predictive and diagnostic inferences to be
activated simultaneously and propagate harmoniously towards a stable
equilibrium.


On Measurement Bias in Causal Inference

  This paper addresses the problem of measurement errors in causal inference
and highlights several algebraic and graphical methods for eliminating
systematic bias induced by such errors. In particulars, the paper discusses the
control of partially observable confounders in parametric and non parametric
models and the computational problem of obtaining bias-free effect estimates in
such models.


On the Testability of Causal Models with Latent and Instrumental
  Variables

  Certain causal models involving unmeasured variables induce no independence
constraints among the observed variables but imply, nevertheless, inequality
contraints on the observed distribution. This paper derives a general formula
for such instrumental variables, that is, exogenous variables that directly
affect some variables but not all. With the help of this formula, it is
possible to test whether a model involving instrumental variables may account
for the data, or, conversely, whether a given variables can be deemed
instrumental.


Probabilistic Evaluation of Sequential Plans from Causal Models with
  Hidden Variables

  The paper concerns the probabilistic evaluation of plans in the presence of
unmeasured variables, each plan consisting of several concurrent or sequential
actions. We establish a graphical criterion for recognizing when the effects of
a given plan can be predicted from passive observations on measured variables
only. When the criterion is satisfied, a closed-form expression is provided for
the probability that the plan will achieve a specified goal.


From Conditional Oughts to Qualitative Decision Theory

  The primary theme of this investigation is a decision theoretic account of
conditional ought statements (e.g., "You ought to do A, if C") that rectifies
glaring deficiencies in classical deontic logic. The resulting account forms a
sound basis for qualitative decision theory, thus providing a framework for
qualitative planning under uncertainty. In particular, we show that adding
causal relationships (in the form of a single graph) as part of an epistemic
state is sufficient to facilitate the analysis of action sequences, their
consequences, their interaction with observations, their expected utilities
and, hence, the synthesis of plans and strategies under uncertainty.


Confounding Equivalence in Causal Inference

  The paper provides a simple test for deciding, from a given causal diagram,
whether two sets of variables have the same bias-reducing potential under
adjustment. The test requires that one of the following two conditions holds:
either (1) both sets are admissible (i.e., satisfy the back-door criterion) or
(2) the Markov boundaries surrounding the manipulated variable(s) are identical
in both sets. Applications to covariate selection and model testing are
discussed.


Robustness of Causal Claims

  A causal claim is any assertion that invokes causal relationships between
variables, for example that a drug has a certain effect on preventing a
disease. Causal claims are established through a combination of data and a set
of causal assumptions called a causal model. A claim is robust when it is
insensitive to violations of some of the causal assumptions embodied in the
model. This paper gives a formal definition of this notion of robustness and
establishes a graphical condition for quantifying the degree of robustness of a
given causal claim. Algorithms for computing the degree of robustness are also
presented.


Direct and Indirect Effects

  The direct effect of one eventon another can be defined and measured
byholding constant all intermediate variables between the two.Indirect effects
present conceptual andpractical difficulties (in nonlinear models), because
they cannot be isolated by holding certain variablesconstant. This paper shows
a way of defining any path-specific effectthat does not invoke blocking the
remainingpaths.This permits the assessment of a more naturaltype of direct and
indirect effects, one thatis applicable in both linear and nonlinear models.
The paper establishesconditions under which such assessments can be estimated
consistentlyfrom experimental and nonexperimental data,and thus extends
path-analytic techniques tononlinear and nonparametric models.


Graphical Models for Processing Missing Data

  This paper reviews recent advances in missing data research using graphical
models to represent multivariate dependencies. We first examine the limitations
of traditional frameworks from three different perspectives:
\textit{transparency, estimability and testability}. We then show how
procedures based on graphical models can overcome these limitations and provide
meaningful performance guarantees even when data are Missing Not At Random
(MNAR). In particular, we identify conditions that guarantee consistent
estimation in broad categories of missing data problems, and derive procedures
for implementing this estimation. Finally we derive testable implications for
missing data models in both MAR (Missing At Random) and MNAR categories.


Theoretical Impediments to Machine Learning With Seven Sparks from the
  Causal Revolution

  Current machine learning systems operate, almost exclusively, in a
statistical, or model-free mode, which entails severe theoretical limits on
their power and performance. Such systems cannot reason about interventions and
retrospection and, therefore, cannot serve as the basis for strong AI. To
achieve human level intelligence, learning machines need the guidance of a
model of reality, similar to the ones used in causal inference tasks. To
demonstrate the essential role of such models, I will present a summary of
seven tasks which are beyond reach of current machine learning systems and
which have been accomplished using the tools of causal modeling.


Human-Level Intelligence or Animal-Like Abilities?

  The vision systems of the eagle and the snake outperform everything that we
can make in the laboratory, but snakes and eagles cannot build an eyeglass or a
telescope or a microscope. (Judea Pearl)


The Do-Calculus Revisited

  The do-calculus was developed in 1995 to facilitate the identification of
causal effects in non-parametric models. The completeness proofs of [Huang and
Valtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of
[Tian and Shpitser, 2010] have laid this identification problem to rest. Recent
explorations unveil the usefulness of the do-calculus in three additional
areas: mediation analysis [Pearl, 2012], transportability [Pearl and
Bareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is the
task of fusing empirical results from several diverse studies, conducted on
heterogeneous populations and under different conditions, so as to synthesize
an estimate of a causal relation in some target environment, potentially
different from those under study. The talk surveys these results with emphasis
on the challenges posed by meta-synthesis. For background material, see
http://bayes.cs.ucla.edu/csl_papers.html


An Information Theoretic Measure of Judea Pearl's Identifiability and
  Causal Influence

  In this paper, we define a new information theoretic measure that we call the
"uprooted information". We show that a necessary and sufficient condition for a
probability $P(s|do(t))$ to be "identifiable" (in the sense of Pearl) in a
graph $G$ is that its uprooted information be non-negative for all models of
the graph $G$. In this paper, we also give a new algorithm for deciding, for a
Bayesian net that is semi-Markovian, whether a probability $P(s|do(t))$ is
identifiable, and, if it is identifiable, for expressing it without allusions
to confounding variables. Our algorithm is closely based on a previous
algorithm by Tian and Pearl, but seems to correct a small flaw in theirs. In
this paper, we also find a {\it necessary and sufficient graphical condition}
for a probability $P(s|do(t))$ to be identifiable when $t$ is a singleton set.
So far, in the prior literature, it appears that only a {\it sufficient
graphical condition} has been given for this. By "graphical" we mean that it is
directly based on Judea Pearl's 3 rules of do-calculus.


Deciding Morality of Graphs is NP-complete

  In order to find a causal explanation for data presented in the form of
covariance and concentration matrices it is necessary to decide if the graph
formed by such associations is a projection of a directed acyclic graph (dag).
We show that the general problem of deciding whether such a dag exists is
NP-complete.


d-Separation: From Theorems to Algorithms

  An efficient algorithm is developed that identifies all independencies
implied by the topology of a Bayesian network. Its correctness and maximality
stems from the soundness and completeness of d-separation with respect to
probability theory. The algorithm runs in time O (l E l) where E is the number
of edges in the network.


Learning Link-Probabilities in Causal Trees

  A learning algorithm is presented which given the structure of a causal tree,
will estimate its link probabilities by sequential measurements on the leaves
only. Internal nodes of the tree represent conceptual (hidden) variables
inaccessible to observation. The method described is incremental, local,
efficient, and remains robust to measurement imprecisions.


Probabilities of Causation: Bounds and Identification

  This paper deals with the problem of estimating the probability that one
event was a cause of another in a given scenario. Using structural-semantical
definitions of the probabilities of necessary or sufficient causation (or
both), we show how to optimally bound these quantities from data obtained in
experimental and observational studies, making minimal assumptions concerning
the data-generating process. In particular, we strengthen the results of Pearl
(1999) by weakening the data-generation assumptions and deriving theoretically
sharp bounds on the probabilities of causation. These results delineate
precisely how empirical data can be used both in settling questions of
attribution and in solving attribution-related problems of decision making.


Identification of Conditional Interventional Distributions

  The subject of this paper is the elucidation of effects of actions from
causal assumptions represented as a directed graph, and statistical knowledge
given as a probability distribution. In particular, we are interested in
predicting conditional distributions resulting from performing an action on a
set of variables and, subsequently, taking measurements of another set. We
provide a necessary and sufficient graphical condition for the cases where such
distributions can be uniquely computed from the available information, as well
as an algorithm which performs this computation whenever the condition holds.
Furthermore, we use our results to prove completeness of do-calculus [Pearl,
1995] for the same identification problem.


A Probabilistic Calculus of Actions

  We present a symbolic machinery that admits both probabilistic and causal
information about a given domain and produces probabilistic statements about
the effect of actions and the impact of observations. The calculus admits two
types of conditioning operators: ordinary Bayes conditioning, P(y|X = x), which
represents the observation X = x, and causal conditioning, P(y|do(X = x)), read
the probability of Y = y conditioned on holding X constant (at x) by deliberate
action. Given a mixture of such observational and causal sentences, together
with the topology of the causal graph, the calculus derives new conditional
probabilities of both types, thus enabling one to quantify the effects of
actions (and policies) from partially specified knowledge bases, such as
Bayesian networks in which some conditional probabilities may not be available.


Distributed Revision of Belief Commitment in Multi-Hypothesis
  Interpretations

  This paper extends the applications of belief-networks to include the
revision of belief commitments, i.e., the categorical acceptance of a subset of
hypotheses which, together, constitute the most satisfactory explanation of the
evidence at hand. A coherent model of non-monotonic reasoning is established
and distributed algorithms for belief revision are presented. We show that, in
singly connected networks, the most satisfactory explanation can be found in
linear time by a message-passing algorithm similar to the one used in belief
updating. In multiply-connected networks, the problem may be exponentially hard
but, if the network is sparse, topological considerations can be used to render
the interpretation task tractable. In general, finding the most probable
combination of hypotheses is no more complex than computing the degree of
belief for any individual hypothesis. Applications to medical diagnosis are
illustrated.


On a Class of Bias-Amplifying Variables that Endanger Effect Estimates

  This note deals with a class of variables that, if conditioned on, tends to
amplify confounding bias in the analysis of causal effects. This class,
independently discovered by Bhattacharya and Vogt (2007) and Wooldridge (2009),
includes instrumental variables and variables that have greater influence on
treatment selection than on the outcome. We offer a simple derivation and an
intuitive explanation of this phenomenon and then extend the analysis to non
linear models. We show that: 1. the bias-amplifying potential of instrumental
variables extends over to non-linear models, though not as sweepingly as in
linear models; 2. in non-linear models, conditioning on instrumental variables
may introduce new bias where none existed before; 3. in both linear and
non-linear models, instrumental variables have no effect on selection-induced
bias.


External Validity: From Do-Calculus to Transportability Across
  Populations

  The generalizability of empirical findings to new environments, settings or
populations, often called "external validity," is essential in most scientific
explorations. This paper treats a particular problem of generalizability,
called "transportability," defined as a license to transfer causal effects
learned in experimental studies to a new population, in which only
observational studies can be conducted. We introduce a formal representation
called "selection diagrams" for expressing knowledge about differences and
commonalities between populations of interest and, using this representation,
we reduce questions of transportability to symbolic derivations in the
do-calculus. This reduction yields graph-based procedures for deciding, prior
to observing any data, whether causal effects in the target population can be
inferred from experimental findings in the study population. When the answer is
affirmative, the procedures identify what experimental and observational
findings need be obtained from the two populations, and how they can be
combined to ensure bias-free transport.


Directed information and Pearl's causal calculus

  Probabilistic graphical models are a fundamental tool in statistics, machine
learning, signal processing, and control. When such a model is defined on a
directed acyclic graph (DAG), one can assign a partial ordering to the events
occurring in the corresponding stochastic system. Based on the work of Judea
Pearl and others, these DAG-based "causal factorizations" of joint probability
measures have been used for characterization and inference of functional
dependencies (causal links). This mostly expository paper focuses on several
connections between Pearl's formalism (and in particular his notion of
"intervention") and information-theoretic notions of causality and feedback
(such as causal conditioning, directed stochastic kernels, and directed
information). As an application, we show how conditional directed information
can be used to develop an information-theoretic version of Pearl's "back-door"
criterion for identifiability of causal effects from passive observations. This
suggests that the back-door criterion can be thought of as a causal analog of
statistical sufficiency.


Causes and Explanations: A Structural-Model Approach, Part I: Causes

  We propose a new definition of actual cause, using structural equations to
model counterfactuals. We show that the definition yields a plausible and
elegant account of causation that handles well examples which have caused
problems for other definitions and resolves major difficulties in the
traditional account.


On the Tweety Penguin Triangle Problem

  In this paper, one studies the famous well-known and challenging Tweety
Penguin Triangle Problem (TPTP or TP2) pointed out by Judea Pearl in one of his
books. We first present the solution of the TP2 based on the fallacious
Bayesian reasoning and prove that reasoning cannot be used to conclude on the
ability of the penguin-bird Tweety to fly or not to fly. Then we present in
details the counter-intuitive solution obtained from the Dempster-Shafer Theory
(DST). Finally, we show how the solution can be obtained with our new theory of
plausible and paradoxical reasoning (DSmT).


Counterfactuals and Policy Analysis in Structural Models

  Evaluation of counterfactual queries (e.g., "If A were true, would C have
been true?") is important to fault diagnosis, planning, determination of
liability, and policy analysis. We present a method of revaluating
counterfactuals when the underlying causal model is represented by structural
models - a nonlinear generalization of the simultaneous equations models
commonly used in econometrics and social sciences. This new method provides a
coherent means for evaluating policies involving the control of variables
which, prior to enacting the policy were influenced by other variables in the
system.


Testing Identifiability of Causal Effects

  This paper concerns the probabilistic evaluation of the effects of actions in
the presence of unmeasured variables. We show that the identification of causal
effect between a singleton variable X and a set of variables Y can be
accomplished systematically, in time polynomial in the number of variables in
the graph. When the causal effect is identifiable, a closed-form expression can
be obtained for the probability that the action will achieve a specified goal,
or a set of goals.


Deciding Consistency of Databases Containing Defeasible and Strict
  Information

  We propose a norm of consistency for a mixed set of defeasible and strict
sentences, based on a probabilistic semantics. This norm establishes a clear
distinction between knowledge bases depicting exceptions and those containing
outright contradictions. We then define a notion of entailment based also on
probabilistic considerations and provide a characterization of the relation
between consistency and entailment. We derive necessary and sufficient
conditions for consistency, and provide a simple decision procedure for testing
consistency and deciding whether a sentence is entailed by a database. Finally,
it is shown that if al1 sentences are Horn clauses, consistency and entailment
can be tested in polynomial time.


On the Logic of Causal Models

  This paper explores the role of Directed Acyclic Graphs (DAGs) as a
representation of conditional independence relationships. We show that DAGs
offer polynomially sound and complete inference mechanisms for inferring
conditional independence relationships from a given causal set of such
relationships. As a consequence, d-separation, a graphical criterion for
identifying independencies in a DAG, is shown to uncover more valid
independencies then any other criterion. In addition, we employ the Armstrong
property of conditional independence to show that the dependence relationships
displayed by a DAG are inherently consistent, i.e. for every DAG D there exists
some probability distribution P that embodies all the conditional
independencies displayed in D and none other.


Causal Networks: Semantics and Expressiveness

  Dependency knowledge of the form "x is independent of y once z is known"
invariably obeys the four graphoid axioms, examples include probabilistic and
database dependencies. Often, such knowledge can be represented efficiently
with graphical structures such as undirected graphs and directed acyclic graphs
(DAGs). In this paper we show that the graphical criterion called d-separation
is a sound rule for reading independencies from any DAG based on a causal input
list drawn from a graphoid. The rule may be extended to cover DAGs that
represent functional dependencies as well as conditional dependencies.


The Recovery of Causal Poly-Trees from Statistical Data

  Poly-trees are singly connected causal networks in which variables may arise
from multiple causes. This paper develops a method of recovering ply-trees from
empirically measured probability distributions of pairs of variables. The
method guarantees that, if the measured distributions are generated by a causal
process structured as a ply-tree then the topological structure of such tree
can be recovered precisely and, in addition, the causal directionality of the
branches can be determined up to the maximum extent possible. The method also
pinpoints the minimum (if any) external semantics required to determine the
causal relationships among the variables considered.


Qualitative MDPs and POMDPs: An Order-Of-Magnitude Approximation

  We develop a qualitative theory of Markov Decision Processes (MDPs) and
Partially Observable MDPs that can be used to model sequential decision making
tasks when only qualitative information is available. Our approach is based
upon an order-of-magnitude approximation of both probabilities and utilities,
similar to epsilon-semantics. The result is a qualitative theory that has close
ties with the standard maximum-expected-utility theory and is amenable to
general planning techniques.


Generalized Instrumental Variables

  This paper concerns the assessment of direct causal effects from a
combination of: (i) non-experimental data, and (ii) qualitative domain
knowledge. Domain knowledge is encoded in the form of a directed acyclic graph
(DAG), in which all interactions are assumed linear, and some variables are
presumed to be unobserved. We provide a generalization of the well-known method
of Instrumental Variables, which allows its application to models with few
conditional independeces.


On the Testable Implications of Causal Models with Hidden Variables

  The validity OF a causal model can be tested ONLY IF the model imposes
constraints ON the probability distribution that governs the generated data. IN
the presence OF unmeasured variables, causal models may impose two types OF
constraints : conditional independencies, AS READ through the d - separation
criterion, AND functional constraints, FOR which no general criterion IS
available.This paper offers a systematic way OF identifying functional
constraints AND, thus, facilitates the task OF testing causal models AS well AS
inferring such models FROM data.


Causes and Explanations: A Structural-Model Approach --- Part 1: Causes

  We propose a new definition of actual causes, using structural equations to
model counterfactuals.We show that the definitions yield a plausible and
elegant account ofcausation that handles well examples which have caused
problems forother definitions and resolves major difficulties in the
traditionalaccount. In a companion paper, we show how the definition of
causality can beused to give an elegant definition of (causal) explanation.


Causal Discovery from Changes

  We propose a new method of discovering causal structures, based on the
detection of local, spontaneous changes in the underlying data-generating
model. We analyze the classes of structures that are equivalent relative to a
stream of distributions produced by local changes, and devise algorithms that
output graphical representations of these equivalence classes. We present
experimental results, using simulated data, and examine the errors associated
with detection of changes and recovery of structures.


Actual causation and the art of modeling

  We look more carefully at the modeling of causality using structural
equations. It is clear that the structural equations can have a major impact on
the conclusions we draw about causality. In particular, the choice of variables
and their values can also have a significant impact on causality. These choices
are, to some extent, subjective. We consider what counts as an appropriate
choice. More generally, we consider what makes a model an appropriate model,
especially if we want to take defaults into account, as was argued is necessary
in recent work.


What Counterfactuals Can Be Tested

  Counterfactual statements, e.g., "my headache would be gone had I taken an
aspirin" are central to scientific discourse, and are formally interpreted as
statements derived from "alternative worlds". However, since they invoke
hypothetical states of affairs, often incompatible with what is actually known
or observed, testing counterfactuals is fraught with conceptual and practical
difficulties. In this paper, we provide a complete characterization of
"testable counterfactuals," namely, counterfactual statements whose
probabilities can be inferred from physical experiments. We provide complete
procedures for discerning whether a given counterfactual is testable and, if
so, expressing its probability in terms of experimental data.


Compact Representations of Extended Causal Models

  Judea Pearl was the first to propose a definition of actual causation using
causal models. A number of authors have suggested that an adequate account of
actual causation must appeal not only to causal structure, but also to
considerations of normality. In earlier work, we provided a definition of
actual causation using extended causal models, which include information about
both causal structure and normality. Extended causal models are potentially
very complex. In this paper, we show how it is possible to achieve a compact
representation of extended causal models.


Efficient Algorithms for Bayesian Network Parameter Learning from
  Incomplete Data

  We propose an efficient family of algorithms to learn the parameters of a
Bayesian network from incomplete data. In contrast to textbook approaches such
as EM and the gradient method, our approach is non-iterative, yields closed
form parameter estimates, and eliminates the need for inference in a Bayesian
network. Our approach provides consistent parameter estimates for missing data
problems that are MCAR, MAR, and in some cases, MNAR. Empirically, our approach
is orders of magnitude faster than EM (as our approach requires no inference).
Given sufficient data, we learn parameters that can be orders of magnitude more
accurate.


Propagation of Belief Functions: A Distributed Approach

  In this paper, we describe a scheme for propagating belief functions in
certain kinds of trees using only local computations. This scheme generalizes
the computational scheme proposed by Shafer and Logan1 for diagnostic trees of
the type studied by Gordon and Shortliffe, and the slightly more general scheme
given by Shafer for hierarchical evidence. It also generalizes the scheme
proposed by Pearl for Bayesian causal trees (see Shenoy and Shafer). Pearl's
causal trees and Gordon and Shortliffe's diagnostic trees are both ways of
breaking the evidence that bears on a large problem down into smaller items of
evidence that bear on smaller parts of the problem so that these smaller
problems can be dealt with one at a time. This localization of effort is often
essential in order to make the process of probability judgment feasible, both
for the person who is making probability judgments and for the machine that is
combining them. The basic structure for our scheme is a type of tree that
generalizes both Pearl's and Gordon and Shortliffe's trees. Trees of this
general type permit localized computation in Pearl's sense. They are based on
qualitative judgments of conditional independence. We believe that the scheme
we describe here will prove useful in expert systems. It is now clear that the
successful propagation of probabilities or certainty factors in expert systems
requires much more structure than can be provided in a pure production-system
framework. Bayesian schemes, on the other hand, often make unrealistic demands
for structure. The propagation of belief functions in trees and more general
networks stands on a middle ground where some sensible and useful things can be
done. We would like to emphasize that the basic idea of local computation for
propagating probabilities is due to Judea Pearl. It is a very innovative idea;
we do not believe that it can be found in the Bayesian literature prior to
Pearl's work. We see our contribution as extending the usefulness of Pearl's
idea by generalizing it from Bayesian probabilities to belief functions. In the
next section, we give a brief introduction to belief functions. The notions of
qualitative independence for partitions and a qualitative Markov tree are
introduced in Section III. Finally, in Section IV, we describe a scheme for
propagating belief functions in qualitative Markov trees.


Causal Inference by Surrogate Experiments: z-Identifiability

  We address the problem of estimating the effect of intervening on a set of
variables X from experiments on a different set, Z, that is more accessible to
manipulation. This problem, which we call z-identifiability, reduces to
ordinary identifiability when Z = empty and, like the latter, can be given
syntactic characterization using the do-calculus [Pearl, 1995; 2000]. We
provide a graphical necessary and sufficient condition for z-identifiability
for arbitrary sets X,Z, and Y (the outcomes). We further develop a complete
algorithm for computing the causal effect of X on Y using information provided
by experiments on Z. Finally, we use our results to prove completeness of
do-calculus relative to z-identifiability, a result that does not follow from
completeness relative to ordinary identifiability.


Counterfactual Probabilities: Computational Methods, Bounds and
  Applications

  Evaluation of counterfactual queries (e.g., "If A were true, would C have
been true?") is important to fault diagnosis, planning, and determination of
liability. In this paper we present methods for computing the probabilities of
such queries using the formulation proposed in [Balke and Pearl, 1994], where
the antecedent of the query is interpreted as an external action that forces
the proposition A to be true. When a prior probability is available on the
causal mechanisms governing the domain, counterfactual probabilities can be
evaluated precisely. However, when causal knowledge is specified as conditional
probabilities on the observables, only bounds can computed. This paper develops
techniques for evaluating these bounds, and demonstrates their use in two
applications: (1) the determination of treatment efficacy from studies in which
subjects may choose their own treatment, and (2) the determination of liability
in product-safety litigation.


An Algorithm for Deciding if a Set of Observed Independencies Has a
  Causal Explanation

  In a previous paper [Pearl and Verma, 1991] we presented an algorithm for
extracting causal influences from independence information, where a causal
influence was defined as the existence of a directed arc in all minimal causal
models consistent with the data. In this paper we address the question of
deciding whether there exists a causal model that explains ALL the observed
dependencies and independencies. Formally, given a list M of conditional
independence statements, it is required to decide whether there exists a
directed acyclic graph (dag) D that is perfectly consistent with M, namely,
every statement in M, and no other, is reflected via dseparation in D. We
present and analyze an effective algorithm that tests for the existence of such
a day, and produces one, if it exists.


Structuring Causal Tree Models with Continuous Variables

  This paper considers the problem of invoking auxiliary, unobservable
variables to facilitate the structuring of causal tree models for a given set
of continuous variables. Paralleling the treatment of bi-valued variables in
[Pearl 1986], we show that if a collection of coupled variables are governed by
a joint normal distribution and a tree-structured representation exists, then
both the topology and all internal relationships of the tree can be uncovered
by observing pairwise dependencies among the observed variables (i.e., the
leaves of the tree). Furthermore, the conditions for normally distributed
variables are less restrictive than those governing bi-valued variables. The
result extends the applications of causal tree models which were found useful
in evidential reasoning tasks.


A General Algorithm for Deciding Transportability of Experimental
  Results

  Generalizing empirical findings to new environments, settings, or populations
is essential in most scientific explorations. This article treats a particular
problem of generalizability, called "transportability", defined as a license to
transfer information learned in experimental studies to a different population,
on which only observational studies can be conducted. Given a set of
assumptions concerning commonalities and differences between the two
populations, Pearl and Bareinboim (2011) derived sufficient conditions that
permit such transfer to take place. This article summarizes their findings and
supplements them with an effective procedure for deciding when and how
transportability is feasible. It establishes a necessary and sufficient
condition for deciding when causal effects in the target population are
estimable from both the statistical information available and the causal
information transferred from the experiments. The article further provides a
complete algorithm for computing the transport formula, that is, a way of
combining observational and experimental information to synthesize bias-free
estimate of the desired causal relation. Finally, the article examines the
differences between transportability and other variants of generalizability.


Counterfactual Graphical Models for Longitudinal Mediation Analysis with
  Unobserved Confounding

  Questions concerning mediated causal effects are of great interest in
psychology, cognitive science, medicine, social science, public health, and
many other disciplines. For instance, about 60% of recent papers published in
leading journals in social psychology contain at least one mediation test
(Rucker, Preacher, Tormala, & Petty, 2011). Standard parametric approaches to
mediation analysis employ regression models, and either the "difference method"
(Judd & Kenny, 1981), more common in epidemiology, or the "product method"
(Baron & Kenny, 1986), more common in the social sciences. In this paper we
first discuss a known, but perhaps often unappreciated fact: that these
parametric approaches are a special case of a general counterfactual framework
for reasoning about causality first described by Neyman (1923), and Rubin
(1974), and linked to causal graphical models by J. Robins (1986), and Pearl
(2000). We then show a number of advantages of this framework. First, it makes
the strong assumptions underlying mediation analysis explicit. Second, it
avoids a number of problems present in the product and difference methods, such
as biased estimates of effects in certain cases. Finally, we show the
generality of this framework by proving a novel result which allows mediation
analysis to be applied to longitudinal settings with unobserved confounders.


