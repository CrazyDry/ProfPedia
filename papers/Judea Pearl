Identifying Independencies in Causal Graphs with Feedback

  We show that the d -separation criterion constitutes a valid test forconditional independence relationships that are induced by feedback systemsinvolving discrete variables.

Introduction to Judea Pearl's Do-Calculus

  This is a purely pedagogical paper with no new results. The goal of the paperis to give a fairly self-contained introduction to Judea Pearl's do-calculus,including proofs of his 3 rules.

On Measurement Bias in Causal Inference

  This paper addresses the problem of measurement errors in causal inferenceand highlights several algebraic and graphical methods for eliminatingsystematic bias induced by such errors. In particulars, the paper discusses thecontrol of partially observable confounders in parametric and non parametricmodels and the computational problem of obtaining bias-free effect estimates insuch models.

Do We Need Higher-Order Probabilities and, If So, What Do They Mean?

  The apparent failure of individual probabilistic expressions to distinguishuncertainty about truths from uncertainty about probabilistic assessments haveprompted researchers to seek formalisms where the two types of uncertaintiesare given notational distinction. This paper demonstrates that the desireddistinction is already a built-in feature of classical probabilistic models,thus, specialized notations are unnecessary.

A Constraint Propagation Approach to Probabilistic Reasoning

  The paper demonstrates that strict adherence to probability theory does notpreclude the use of concurrent, self-activated constraint-propagationmechanisms for managing uncertainty. Maintaining local records ofsources-of-belief allows both predictive and diagnostic inferences to beactivated simultaneously and propagate harmoniously towards a stableequilibrium.

Confounding Equivalence in Causal Inference

  The paper provides a simple test for deciding, from a given causal diagram,whether two sets of variables have the same bias-reducing potential underadjustment. The test requires that one of the following two conditions holds:either (1) both sets are admissible (i.e., satisfy the back-door criterion) or(2) the Markov boundaries surrounding the manipulated variable(s) are identicalin both sets. Applications to covariate selection and model testing arediscussed.

Robustness of Causal Claims

  A causal claim is any assertion that invokes causal relationships betweenvariables, for example that a drug has a certain effect on preventing adisease. Causal claims are established through a combination of data and a setof causal assumptions called a causal model. A claim is robust when it isinsensitive to violations of some of the causal assumptions embodied in themodel. This paper gives a formal definition of this notion of robustness andestablishes a graphical condition for quantifying the degree of robustness of agiven causal claim. Algorithms for computing the degree of robustness are alsopresented.

Direct and Indirect Effects

  The direct effect of one eventon another can be defined and measuredbyholding constant all intermediate variables between the two.Indirect effectspresent conceptual andpractical difficulties (in nonlinear models), becausethey cannot be isolated by holding certain variablesconstant. This paper showsa way of defining any path-specific effectthat does not invoke blocking theremainingpaths.This permits the assessment of a more naturaltype of direct andindirect effects, one thatis applicable in both linear and nonlinear models.The paper establishesconditions under which such assessments can be estimatedconsistentlyfrom experimental and nonexperimental data,and thus extendspath-analytic techniques tononlinear and nonparametric models.

On the Testability of Causal Models with Latent and Instrumental  Variables

  Certain causal models involving unmeasured variables induce no independenceconstraints among the observed variables but imply, nevertheless, inequalitycontraints on the observed distribution. This paper derives a general formulafor such instrumental variables, that is, exogenous variables that directlyaffect some variables but not all. With the help of this formula, it ispossible to test whether a model involving instrumental variables may accountfor the data, or, conversely, whether a given variables can be deemedinstrumental.

Probabilistic Evaluation of Sequential Plans from Causal Models with  Hidden Variables

  The paper concerns the probabilistic evaluation of plans in the presence ofunmeasured variables, each plan consisting of several concurrent or sequentialactions. We establish a graphical criterion for recognizing when the effects ofa given plan can be predicted from passive observations on measured variablesonly. When the criterion is satisfied, a closed-form expression is provided forthe probability that the plan will achieve a specified goal.

From Conditional Oughts to Qualitative Decision Theory

  The primary theme of this investigation is a decision theoretic account ofconditional ought statements (e.g., "You ought to do A, if C") that rectifiesglaring deficiencies in classical deontic logic. The resulting account forms asound basis for qualitative decision theory, thus providing a framework forqualitative planning under uncertainty. In particular, we show that addingcausal relationships (in the form of a single graph) as part of an epistemicstate is sufficient to facilitate the analysis of action sequences, theirconsequences, their interaction with observations, their expected utilitiesand, hence, the synthesis of plans and strategies under uncertainty.

Graphical Models for Processing Missing Data

  This paper reviews recent advances in missing data research using graphicalmodels to represent multivariate dependencies. We first examine the limitationsof traditional frameworks from three different perspectives:\textit{transparency, estimability and testability}. We then show howprocedures based on graphical models can overcome these limitations and providemeaningful performance guarantees even when data are Missing Not At Random(MNAR). In particular, we identify conditions that guarantee consistentestimation in broad categories of missing data problems, and derive proceduresfor implementing this estimation. Finally we derive testable implications formissing data models in both MAR (Missing At Random) and MNAR categories.

Theoretical Impediments to Machine Learning With Seven Sparks from the  Causal Revolution

  Current machine learning systems operate, almost exclusively, in astatistical, or model-free mode, which entails severe theoretical limits ontheir power and performance. Such systems cannot reason about interventions andretrospection and, therefore, cannot serve as the basis for strong AI. Toachieve human level intelligence, learning machines need the guidance of amodel of reality, similar to the ones used in causal inference tasks. Todemonstrate the essential role of such models, I will present a summary ofseven tasks which are beyond reach of current machine learning systems andwhich have been accomplished using the tools of causal modeling.

Human-Level Intelligence or Animal-Like Abilities?

  The vision systems of the eagle and the snake outperform everything that wecan make in the laboratory, but snakes and eagles cannot build an eyeglass or atelescope or a microscope. (Judea Pearl)

The Do-Calculus Revisited

  The do-calculus was developed in 1995 to facilitate the identification ofcausal effects in non-parametric models. The completeness proofs of [Huang andValtorta, 2006] and [Shpitser and Pearl, 2006] and the graphical criteria of[Tian and Shpitser, 2010] have laid this identification problem to rest. Recentexplorations unveil the usefulness of the do-calculus in three additionalareas: mediation analysis [Pearl, 2012], transportability [Pearl andBareinboim, 2011] and metasynthesis. Meta-synthesis (freshly coined) is thetask of fusing empirical results from several diverse studies, conducted onheterogeneous populations and under different conditions, so as to synthesizean estimate of a causal relation in some target environment, potentiallydifferent from those under study. The talk surveys these results with emphasison the challenges posed by meta-synthesis. For background material, seehttp://bayes.cs.ucla.edu/csl_papers.html

An Information Theoretic Measure of Judea Pearl's Identifiability and  Causal Influence

  In this paper, we define a new information theoretic measure that we call the"uprooted information". We show that a necessary and sufficient condition for aprobability $P(s|do(t))$ to be "identifiable" (in the sense of Pearl) in agraph $G$ is that its uprooted information be non-negative for all models ofthe graph $G$. In this paper, we also give a new algorithm for deciding, for aBayesian net that is semi-Markovian, whether a probability $P(s|do(t))$ isidentifiable, and, if it is identifiable, for expressing it without allusionsto confounding variables. Our algorithm is closely based on a previousalgorithm by Tian and Pearl, but seems to correct a small flaw in theirs. Inthis paper, we also find a {\it necessary and sufficient graphical condition}for a probability $P(s|do(t))$ to be identifiable when $t$ is a singleton set.So far, in the prior literature, it appears that only a {\it sufficientgraphical condition} has been given for this. By "graphical" we mean that it isdirectly based on Judea Pearl's 3 rules of do-calculus.

Deciding Morality of Graphs is NP-complete

  In order to find a causal explanation for data presented in the form ofcovariance and concentration matrices it is necessary to decide if the graphformed by such associations is a projection of a directed acyclic graph (dag).We show that the general problem of deciding whether such a dag exists isNP-complete.

d-Separation: From Theorems to Algorithms

  An efficient algorithm is developed that identifies all independenciesimplied by the topology of a Bayesian network. Its correctness and maximalitystems from the soundness and completeness of d-separation with respect toprobability theory. The algorithm runs in time O (l E l) where E is the numberof edges in the network.

Learning Link-Probabilities in Causal Trees

  A learning algorithm is presented which given the structure of a causal tree,will estimate its link probabilities by sequential measurements on the leavesonly. Internal nodes of the tree represent conceptual (hidden) variablesinaccessible to observation. The method described is incremental, local,efficient, and remains robust to measurement imprecisions.

Identification of Conditional Interventional Distributions

  The subject of this paper is the elucidation of effects of actions fromcausal assumptions represented as a directed graph, and statistical knowledgegiven as a probability distribution. In particular, we are interested inpredicting conditional distributions resulting from performing an action on aset of variables and, subsequently, taking measurements of another set. Weprovide a necessary and sufficient graphical condition for the cases where suchdistributions can be uniquely computed from the available information, as wellas an algorithm which performs this computation whenever the condition holds.Furthermore, we use our results to prove completeness of do-calculus [Pearl,1995] for the same identification problem.

Probabilities of Causation: Bounds and Identification

  This paper deals with the problem of estimating the probability that oneevent was a cause of another in a given scenario. Using structural-semanticaldefinitions of the probabilities of necessary or sufficient causation (orboth), we show how to optimally bound these quantities from data obtained inexperimental and observational studies, making minimal assumptions concerningthe data-generating process. In particular, we strengthen the results of Pearl(1999) by weakening the data-generation assumptions and deriving theoreticallysharp bounds on the probabilities of causation. These results delineateprecisely how empirical data can be used both in settling questions ofattribution and in solving attribution-related problems of decision making.

On a Class of Bias-Amplifying Variables that Endanger Effect Estimates

  This note deals with a class of variables that, if conditioned on, tends toamplify confounding bias in the analysis of causal effects. This class,independently discovered by Bhattacharya and Vogt (2007) and Wooldridge (2009),includes instrumental variables and variables that have greater influence ontreatment selection than on the outcome. We offer a simple derivation and anintuitive explanation of this phenomenon and then extend the analysis to nonlinear models. We show that: 1. the bias-amplifying potential of instrumentalvariables extends over to non-linear models, though not as sweepingly as inlinear models; 2. in non-linear models, conditioning on instrumental variablesmay introduce new bias where none existed before; 3. in both linear andnon-linear models, instrumental variables have no effect on selection-inducedbias.

A Probabilistic Calculus of Actions

  We present a symbolic machinery that admits both probabilistic and causalinformation about a given domain and produces probabilistic statements aboutthe effect of actions and the impact of observations. The calculus admits twotypes of conditioning operators: ordinary Bayes conditioning, P(y|X = x), whichrepresents the observation X = x, and causal conditioning, P(y|do(X = x)), readthe probability of Y = y conditioned on holding X constant (at x) by deliberateaction. Given a mixture of such observational and causal sentences, togetherwith the topology of the causal graph, the calculus derives new conditionalprobabilities of both types, thus enabling one to quantify the effects ofactions (and policies) from partially specified knowledge bases, such asBayesian networks in which some conditional probabilities may not be available.

Distributed Revision of Belief Commitment in Multi-Hypothesis  Interpretations

  This paper extends the applications of belief-networks to include therevision of belief commitments, i.e., the categorical acceptance of a subset ofhypotheses which, together, constitute the most satisfactory explanation of theevidence at hand. A coherent model of non-monotonic reasoning is establishedand distributed algorithms for belief revision are presented. We show that, insingly connected networks, the most satisfactory explanation can be found inlinear time by a message-passing algorithm similar to the one used in beliefupdating. In multiply-connected networks, the problem may be exponentially hardbut, if the network is sparse, topological considerations can be used to renderthe interpretation task tractable. In general, finding the most probablecombination of hypotheses is no more complex than computing the degree ofbelief for any individual hypothesis. Applications to medical diagnosis areillustrated.

External Validity: From Do-Calculus to Transportability Across  Populations

  The generalizability of empirical findings to new environments, settings orpopulations, often called "external validity," is essential in most scientificexplorations. This paper treats a particular problem of generalizability,called "transportability," defined as a license to transfer causal effectslearned in experimental studies to a new population, in which onlyobservational studies can be conducted. We introduce a formal representationcalled "selection diagrams" for expressing knowledge about differences andcommonalities between populations of interest and, using this representation,we reduce questions of transportability to symbolic derivations in thedo-calculus. This reduction yields graph-based procedures for deciding, priorto observing any data, whether causal effects in the target population can beinferred from experimental findings in the study population. When the answer isaffirmative, the procedures identify what experimental and observationalfindings need be obtained from the two populations, and how they can becombined to ensure bias-free transport.

Directed information and Pearl's causal calculus

  Probabilistic graphical models are a fundamental tool in statistics, machinelearning, signal processing, and control. When such a model is defined on adirected acyclic graph (DAG), one can assign a partial ordering to the eventsoccurring in the corresponding stochastic system. Based on the work of JudeaPearl and others, these DAG-based "causal factorizations" of joint probabilitymeasures have been used for characterization and inference of functionaldependencies (causal links). This mostly expository paper focuses on severalconnections between Pearl's formalism (and in particular his notion of"intervention") and information-theoretic notions of causality and feedback(such as causal conditioning, directed stochastic kernels, and directedinformation). As an application, we show how conditional directed informationcan be used to develop an information-theoretic version of Pearl's "back-door"criterion for identifiability of causal effects from passive observations. Thissuggests that the back-door criterion can be thought of as a causal analog ofstatistical sufficiency.

Causes and Explanations: A Structural-Model Approach, Part I: Causes

  We propose a new definition of actual cause, using structural equations tomodel counterfactuals. We show that the definition yields a plausible andelegant account of causation that handles well examples which have causedproblems for other definitions and resolves major difficulties in thetraditional account.

On the Tweety Penguin Triangle Problem

  In this paper, one studies the famous well-known and challenging TweetyPenguin Triangle Problem (TPTP or TP2) pointed out by Judea Pearl in one of hisbooks. We first present the solution of the TP2 based on the fallaciousBayesian reasoning and prove that reasoning cannot be used to conclude on theability of the penguin-bird Tweety to fly or not to fly. Then we present indetails the counter-intuitive solution obtained from the Dempster-Shafer Theory(DST). Finally, we show how the solution can be obtained with our new theory ofplausible and paradoxical reasoning (DSmT).

Actual causation and the art of modeling

  We look more carefully at the modeling of causality using structuralequations. It is clear that the structural equations can have a major impact onthe conclusions we draw about causality. In particular, the choice of variablesand their values can also have a significant impact on causality. These choicesare, to some extent, subjective. We consider what counts as an appropriatechoice. More generally, we consider what makes a model an appropriate model,especially if we want to take defaults into account, as was argued is necessaryin recent work.

What Counterfactuals Can Be Tested

  Counterfactual statements, e.g., "my headache would be gone had I taken anaspirin" are central to scientific discourse, and are formally interpreted asstatements derived from "alternative worlds". However, since they invokehypothetical states of affairs, often incompatible with what is actually knownor observed, testing counterfactuals is fraught with conceptual and practicaldifficulties. In this paper, we provide a complete characterization of"testable counterfactuals," namely, counterfactual statements whoseprobabilities can be inferred from physical experiments. We provide completeprocedures for discerning whether a given counterfactual is testable and, ifso, expressing its probability in terms of experimental data.

Qualitative MDPs and POMDPs: An Order-Of-Magnitude Approximation

  We develop a qualitative theory of Markov Decision Processes (MDPs) andPartially Observable MDPs that can be used to model sequential decision makingtasks when only qualitative information is available. Our approach is basedupon an order-of-magnitude approximation of both probabilities and utilities,similar to epsilon-semantics. The result is a qualitative theory that has closeties with the standard maximum-expected-utility theory and is amenable togeneral planning techniques.

Generalized Instrumental Variables

  This paper concerns the assessment of direct causal effects from acombination of: (i) non-experimental data, and (ii) qualitative domainknowledge. Domain knowledge is encoded in the form of a directed acyclic graph(DAG), in which all interactions are assumed linear, and some variables arepresumed to be unobserved. We provide a generalization of the well-known methodof Instrumental Variables, which allows its application to models with fewconditional independeces.

On the Testable Implications of Causal Models with Hidden Variables

  The validity OF a causal model can be tested ONLY IF the model imposesconstraints ON the probability distribution that governs the generated data. INthe presence OF unmeasured variables, causal models may impose two types OFconstraints : conditional independencies, AS READ through the d - separationcriterion, AND functional constraints, FOR which no general criterion ISavailable.This paper offers a systematic way OF identifying functionalconstraints AND, thus, facilitates the task OF testing causal models AS well ASinferring such models FROM data.

Causes and Explanations: A Structural-Model Approach --- Part 1: Causes

  We propose a new definition of actual causes, using structural equations tomodel counterfactuals.We show that the definitions yield a plausible andelegant account ofcausation that handles well examples which have causedproblems forother definitions and resolves major difficulties in thetraditionalaccount. In a companion paper, we show how the definition ofcausality can beused to give an elegant definition of (causal) explanation.

Causal Discovery from Changes

  We propose a new method of discovering causal structures, based on thedetection of local, spontaneous changes in the underlying data-generatingmodel. We analyze the classes of structures that are equivalent relative to astream of distributions produced by local changes, and devise algorithms thatoutput graphical representations of these equivalence classes. We presentexperimental results, using simulated data, and examine the errors associatedwith detection of changes and recovery of structures.

Counterfactuals and Policy Analysis in Structural Models

  Evaluation of counterfactual queries (e.g., "If A were true, would C havebeen true?") is important to fault diagnosis, planning, determination ofliability, and policy analysis. We present a method of revaluatingcounterfactuals when the underlying causal model is represented by structuralmodels - a nonlinear generalization of the simultaneous equations modelscommonly used in econometrics and social sciences. This new method provides acoherent means for evaluating policies involving the control of variableswhich, prior to enacting the policy were influenced by other variables in thesystem.

Testing Identifiability of Causal Effects

  This paper concerns the probabilistic evaluation of the effects of actions inthe presence of unmeasured variables. We show that the identification of causaleffect between a singleton variable X and a set of variables Y can beaccomplished systematically, in time polynomial in the number of variables inthe graph. When the causal effect is identifiable, a closed-form expression canbe obtained for the probability that the action will achieve a specified goal,or a set of goals.

Deciding Consistency of Databases Containing Defeasible and Strict  Information

  We propose a norm of consistency for a mixed set of defeasible and strictsentences, based on a probabilistic semantics. This norm establishes a cleardistinction between knowledge bases depicting exceptions and those containingoutright contradictions. We then define a notion of entailment based also onprobabilistic considerations and provide a characterization of the relationbetween consistency and entailment. We derive necessary and sufficientconditions for consistency, and provide a simple decision procedure for testingconsistency and deciding whether a sentence is entailed by a database. Finally,it is shown that if al1 sentences are Horn clauses, consistency and entailmentcan be tested in polynomial time.

On the Logic of Causal Models

  This paper explores the role of Directed Acyclic Graphs (DAGs) as arepresentation of conditional independence relationships. We show that DAGsoffer polynomially sound and complete inference mechanisms for inferringconditional independence relationships from a given causal set of suchrelationships. As a consequence, d-separation, a graphical criterion foridentifying independencies in a DAG, is shown to uncover more validindependencies then any other criterion. In addition, we employ the Armstrongproperty of conditional independence to show that the dependence relationshipsdisplayed by a DAG are inherently consistent, i.e. for every DAG D there existssome probability distribution P that embodies all the conditionalindependencies displayed in D and none other.

Causal Networks: Semantics and Expressiveness

  Dependency knowledge of the form "x is independent of y once z is known"invariably obeys the four graphoid axioms, examples include probabilistic anddatabase dependencies. Often, such knowledge can be represented efficientlywith graphical structures such as undirected graphs and directed acyclic graphs(DAGs). In this paper we show that the graphical criterion called d-separationis a sound rule for reading independencies from any DAG based on a causal inputlist drawn from a graphoid. The rule may be extended to cover DAGs thatrepresent functional dependencies as well as conditional dependencies.

The Recovery of Causal Poly-Trees from Statistical Data

  Poly-trees are singly connected causal networks in which variables may arisefrom multiple causes. This paper develops a method of recovering ply-trees fromempirically measured probability distributions of pairs of variables. Themethod guarantees that, if the measured distributions are generated by a causalprocess structured as a ply-tree then the topological structure of such treecan be recovered precisely and, in addition, the causal directionality of thebranches can be determined up to the maximum extent possible. The method alsopinpoints the minimum (if any) external semantics required to determine thecausal relationships among the variables considered.

Compact Representations of Extended Causal Models

  Judea Pearl was the first to propose a definition of actual causation usingcausal models. A number of authors have suggested that an adequate account ofactual causation must appeal not only to causal structure, but also toconsiderations of normality. In earlier work, we provided a definition ofactual causation using extended causal models, which include information aboutboth causal structure and normality. Extended causal models are potentiallyvery complex. In this paper, we show how it is possible to achieve a compactrepresentation of extended causal models.

Efficient Algorithms for Bayesian Network Parameter Learning from  Incomplete Data

  We propose an efficient family of algorithms to learn the parameters of aBayesian network from incomplete data. In contrast to textbook approaches suchas EM and the gradient method, our approach is non-iterative, yields closedform parameter estimates, and eliminates the need for inference in a Bayesiannetwork. Our approach provides consistent parameter estimates for missing dataproblems that are MCAR, MAR, and in some cases, MNAR. Empirically, our approachis orders of magnitude faster than EM (as our approach requires no inference).Given sufficient data, we learn parameters that can be orders of magnitude moreaccurate.

Propagation of Belief Functions: A Distributed Approach

  In this paper, we describe a scheme for propagating belief functions incertain kinds of trees using only local computations. This scheme generalizesthe computational scheme proposed by Shafer and Logan1 for diagnostic trees ofthe type studied by Gordon and Shortliffe, and the slightly more general schemegiven by Shafer for hierarchical evidence. It also generalizes the schemeproposed by Pearl for Bayesian causal trees (see Shenoy and Shafer). Pearl'scausal trees and Gordon and Shortliffe's diagnostic trees are both ways ofbreaking the evidence that bears on a large problem down into smaller items ofevidence that bear on smaller parts of the problem so that these smallerproblems can be dealt with one at a time. This localization of effort is oftenessential in order to make the process of probability judgment feasible, bothfor the person who is making probability judgments and for the machine that iscombining them. The basic structure for our scheme is a type of tree thatgeneralizes both Pearl's and Gordon and Shortliffe's trees. Trees of thisgeneral type permit localized computation in Pearl's sense. They are based onqualitative judgments of conditional independence. We believe that the schemewe describe here will prove useful in expert systems. It is now clear that thesuccessful propagation of probabilities or certainty factors in expert systemsrequires much more structure than can be provided in a pure production-systemframework. Bayesian schemes, on the other hand, often make unrealistic demandsfor structure. The propagation of belief functions in trees and more generalnetworks stands on a middle ground where some sensible and useful things can bedone. We would like to emphasize that the basic idea of local computation forpropagating probabilities is due to Judea Pearl. It is a very innovative idea;we do not believe that it can be found in the Bayesian literature prior toPearl's work. We see our contribution as extending the usefulness of Pearl'sidea by generalizing it from Bayesian probabilities to belief functions. In thenext section, we give a brief introduction to belief functions. The notions ofqualitative independence for partitions and a qualitative Markov tree areintroduced in Section III. Finally, in Section IV, we describe a scheme forpropagating belief functions in qualitative Markov trees.

Causal Inference by Surrogate Experiments: z-Identifiability

  We address the problem of estimating the effect of intervening on a set ofvariables X from experiments on a different set, Z, that is more accessible tomanipulation. This problem, which we call z-identifiability, reduces toordinary identifiability when Z = empty and, like the latter, can be givensyntactic characterization using the do-calculus [Pearl, 1995; 2000]. Weprovide a graphical necessary and sufficient condition for z-identifiabilityfor arbitrary sets X,Z, and Y (the outcomes). We further develop a completealgorithm for computing the causal effect of X on Y using information providedby experiments on Z. Finally, we use our results to prove completeness ofdo-calculus relative to z-identifiability, a result that does not follow fromcompleteness relative to ordinary identifiability.

Counterfactual Probabilities: Computational Methods, Bounds and  Applications

  Evaluation of counterfactual queries (e.g., "If A were true, would C havebeen true?") is important to fault diagnosis, planning, and determination ofliability. In this paper we present methods for computing the probabilities ofsuch queries using the formulation proposed in [Balke and Pearl, 1994], wherethe antecedent of the query is interpreted as an external action that forcesthe proposition A to be true. When a prior probability is available on thecausal mechanisms governing the domain, counterfactual probabilities can beevaluated precisely. However, when causal knowledge is specified as conditionalprobabilities on the observables, only bounds can computed. This paper developstechniques for evaluating these bounds, and demonstrates their use in twoapplications: (1) the determination of treatment efficacy from studies in whichsubjects may choose their own treatment, and (2) the determination of liabilityin product-safety litigation.

An Algorithm for Deciding if a Set of Observed Independencies Has a  Causal Explanation

  In a previous paper [Pearl and Verma, 1991] we presented an algorithm forextracting causal influences from independence information, where a causalinfluence was defined as the existence of a directed arc in all minimal causalmodels consistent with the data. In this paper we address the question ofdeciding whether there exists a causal model that explains ALL the observeddependencies and independencies. Formally, given a list M of conditionalindependence statements, it is required to decide whether there exists adirected acyclic graph (dag) D that is perfectly consistent with M, namely,every statement in M, and no other, is reflected via dseparation in D. Wepresent and analyze an effective algorithm that tests for the existence of sucha day, and produces one, if it exists.

Structuring Causal Tree Models with Continuous Variables

  This paper considers the problem of invoking auxiliary, unobservablevariables to facilitate the structuring of causal tree models for a given setof continuous variables. Paralleling the treatment of bi-valued variables in[Pearl 1986], we show that if a collection of coupled variables are governed bya joint normal distribution and a tree-structured representation exists, thenboth the topology and all internal relationships of the tree can be uncoveredby observing pairwise dependencies among the observed variables (i.e., theleaves of the tree). Furthermore, the conditions for normally distributedvariables are less restrictive than those governing bi-valued variables. Theresult extends the applications of causal tree models which were found usefulin evidential reasoning tasks.

A General Algorithm for Deciding Transportability of Experimental  Results

  Generalizing empirical findings to new environments, settings, or populationsis essential in most scientific explorations. This article treats a particularproblem of generalizability, called "transportability", defined as a license totransfer information learned in experimental studies to a different population,on which only observational studies can be conducted. Given a set ofassumptions concerning commonalities and differences between the twopopulations, Pearl and Bareinboim (2011) derived sufficient conditions thatpermit such transfer to take place. This article summarizes their findings andsupplements them with an effective procedure for deciding when and howtransportability is feasible. It establishes a necessary and sufficientcondition for deciding when causal effects in the target population areestimable from both the statistical information available and the causalinformation transferred from the experiments. The article further provides acomplete algorithm for computing the transport formula, that is, a way ofcombining observational and experimental information to synthesize bias-freeestimate of the desired causal relation. Finally, the article examines thedifferences between transportability and other variants of generalizability.

Counterfactual Graphical Models for Longitudinal Mediation Analysis with  Unobserved Confounding

  Questions concerning mediated causal effects are of great interest inpsychology, cognitive science, medicine, social science, public health, andmany other disciplines. For instance, about 60% of recent papers published inleading journals in social psychology contain at least one mediation test(Rucker, Preacher, Tormala, & Petty, 2011). Standard parametric approaches tomediation analysis employ regression models, and either the "difference method"(Judd & Kenny, 1981), more common in epidemiology, or the "product method"(Baron & Kenny, 1986), more common in the social sciences. In this paper wefirst discuss a known, but perhaps often unappreciated fact: that theseparametric approaches are a special case of a general counterfactual frameworkfor reasoning about causality first described by Neyman (1923), and Rubin(1974), and linked to causal graphical models by J. Robins (1986), and Pearl(2000). We then show a number of advantages of this framework. First, it makesthe strong assumptions underlying mediation analysis explicit. Second, itavoids a number of problems present in the product and difference methods, suchas biased estimates of effects in certain cases. Finally, we show thegenerality of this framework by proving a novel result which allows mediationanalysis to be applied to longitudinal settings with unobserved confounders.

