A Notation for Markov Decision Processes

  This paper specifies a notation for Markov decision processes.


Policy Gradient Methods for Reinforcement Learning with Function
  Approximation and Action-Dependent Baselines

  We show how an action-dependent baseline can be used by the policy gradient
theorem using function approximation, originally presented with
action-independent baselines by (Sutton et al. 2000).


Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning

  In this paper we present a new way of predicting the performance of a
reinforcement learning policy given historical data that may have been
generated by a different policy. The ability to evaluate a policy from
historical data is important for applications where the deployment of a bad
policy can be dangerous or costly. We show empirically that our algorithm
produces estimates that often have orders of magnitude lower mean squared error
than existing methods---it makes more efficient use of the available data. Our
new estimator is based on two advances: an extension of the doubly robust
estimator (Jiang and Li, 2015), and a new way to mix between model based
estimates and importance sampling based estimates.


Increasing the Action Gap: New Operators for Reinforcement Learning

  This paper introduces new optimality-preserving operators on Q-functions. We
first describe an operator for tabular representations, the consistent Bellman
operator, which incorporates a notion of local policy consistency. We show that
this local consistency leads to an increase in the action gap at each state;
increasing this gap, we argue, mitigates the undesirable effects of
approximation and estimation errors on the induced greedy policies. This
operator can also be applied to discretized continuous space and time problems,
and we provide empirical results evidencing superior performance in this
context. Extending the idea of a locally consistent operator, we then derive
sufficient conditions for an operator to preserve optimality, leading to a
family of operators which includes our consistent Bellman operator. As
corollaries we provide a proof of optimality for Baird's advantage learning
algorithm and derive other gap-increasing operators with interesting
properties. We conclude with an empirical study on 60 Atari 2600 games
illustrating the strong potential of these new operators.


Importance Sampling with Unequal Support

  Importance sampling is often used in machine learning when training and
testing data come from different distributions. In this paper we propose a new
variant of importance sampling that can reduce the variance of importance
sampling-based estimates by orders of magnitude when the supports of the
training and testing distributions differ. After motivating and presenting our
new importance sampling estimator, we provide a detailed theoretical analysis
that characterizes both its bias and variance relative to the ordinary
importance sampling estimator (in various settings, which include cases where
ordinary importance sampling is biased, while our new estimator is not, and
vice versa). We conclude with an example of how our new importance sampling
estimator can be used to improve estimates of how well a new treatment policy
for diabetes will work for an individual, using only data from when the
individual used a previous treatment policy.


Decoupling Learning Rules from Representations

  In the artificial intelligence field, learning often corresponds to changing
the parameters of a parameterized function. A learning rule is an algorithm or
mathematical expression that specifies precisely how the parameters should be
changed. When creating an artificial intelligence system, we must make two
decisions: what representation should be used (i.e., what parameterized
function should be used) and what learning rule should be used to search
through the resulting set of representable functions. Using most learning
rules, these two decisions are coupled in a subtle (and often unintentional)
way. That is, using the same learning rule with two different representations
that can represent the same sets of functions can result in two different
outcomes. After arguing that this coupling is undesirable, particularly when
using artificial neural networks, we present a method for partially decoupling
these two decisions for a broad class of learning rules that span unsupervised
learning, reinforcement learning, and supervised learning.


On Ensuring that Intelligent Machines Are Well-Behaved

  Machine learning algorithms are everywhere, ranging from simple data analysis
and pattern recognition tools used across the sciences to complex systems that
achieve super-human performance on various tasks. Ensuring that they are
well-behaved---that they do not, for example, cause harm to humans or act in a
racist or sexist way---is therefore not a hypothetical problem to be dealt with
in the future, but a pressing one that we address here. We propose a new
framework for designing machine learning algorithms that simplifies the problem
of specifying and regulating undesirable behaviors. To show the viability of
this new framework, we use it to create new machine learning algorithms that
preclude the sexist and harmful behaviors exhibited by standard machine
learning algorithms in our experiments. Our framework for designing machine
learning algorithms simplifies the safe and responsible application of machine
learning.


Hole Concentration Effect on the Microwave Nonlinearity of
  Tl2Ba2CaCu2O8-d Superconducting Thin Films

  The carrier concentration of Tl2Ba2CaCu2O8 films was modified by annealing in
N2 gas. X-ray analysis of the structure and the oxygen content revealed a
correspondence between carrier concentration and oxygen depletion. The TC and
nonlinear surface impedance was measured using a dielectric resonator and the
nonlinearity slope parameter r=dXS/dRS was found to converge to unity at the
critical temperature, indicating a dominance of Josephson fluxon hysteresis on
the nonlinearity. Highly inductive nonlinearity was observed in a small range
of doping levels between 0.180<p<0.195 holes/Cu, which does not include the
optimal doping level of 0.16 holes/Cu.


Saturation Spectroscopy of Iodine in Hollow-core Optical Fibre

  We present high-resolution spectroscopy of Iodine vapour that is loaded and
trapped within the core of a hollow-core photonic crystal fibre (HC-PCF). We
compare the observed spectroscopic features to those seen in a conventional
iodine cell and show that the saturation characteristics differ significantly.
Despite the confined geometry it was still possible to obtain sub-Doppler
features with a spectral width of ~6 MHz with very high contrast. We provide a
simple theory which closely reproduces all the key observations of the
experiment.


Privacy Preserving Off-Policy Evaluation

  Many reinforcement learning applications involve the use of data that is
sensitive, such as medical records of patients or financial information.
However, most current reinforcement learning methods can leak information
contained within the (possibly sensitive) data on which they are trained. To
address this problem, we present the first differentially private approach for
off-policy evaluation. We provide a theoretical analysis of the
privacy-preserving properties of our algorithm and analyze its utility (speed
of convergence). After describing some results of this theoretical analysis, we
show empirically that our method outperforms previous methods (which are
restricted to the on-policy setting).


Coupling between QPOs and broadband noise components in GRS 1915+105

  We explore the use of the bispectrum for understanding quasiperiodic
oscillations. The bispectrum is a statistic which probes the relations between
the relative phases of the Fourier spectrum at different frequencies. The use
of the bispectrum allows us to break the degeneracies between different models
for time series which produce identical power spectra. We look at data from
several observations of GRS 1915+105 when the source shows strong
quasi-periodic oscillations and strong broadband noise components in its power
spectrum. We show that, despite strong similarities in the power spectrum, the
bispectra can differ strongly. In all cases, there are frequency ranges where
the bicoherence, a measure of nonlinearity, is strong for frequencies involving
the frequency of the quasi-periodic oscillations, indicating that the
quasi-periodic oscillations are coupled to the noise components, rather than
being generated independently. We compare the bicoherences from the data to
simple models, finding some qualitative similarities.


Spitzer, Near-Infrared, and Submillimeter Imaging of the Relatively
  Sparse Young Cluster, Lynds 988e

  We present {\it Spitzer} images of the relatively sparse, low luminosity
young cluster L988e, as well as complementary near-infrared (NIR) and
submillimeter images of the region. The cluster is asymmetric, with the western
region of the cluster embedded within the molecular cloud, and the slightly
less dense eastern region to the east of, and on the edge of, the molecular
cloud. With these data, as well as with extant H$\alpha$ data of stars
primarily found in the eastern region of the cluster, and a molecular $^{13}$CO
gas emission map of the entire region, we investigate the distribution of
forming young stars with respect to the cloud material, concentrating
particularly on the differences and similarities between the exposed and
embedded regions of the cluster. We also compare star formation in this region
to that in denser, more luminous and more massive clusters already investigated
in our comprehensive multi-wavelength study of young clusters within 1 kpc of
the Sun.


Dissipation and the Fundamental Plane: Observational Tests

  We develop observational tests of the idea that dissipation in gas-rich
mergers produces the fundamental plane (FP) and related correlations obeyed by
ellipticals. The FP 'tilt' implies lower-mass ellipticals have a higher ratio
of stellar to dark matter within their stellar effective radii. Models argue
that mergers between more gas-rich (typically lower-mass) disks yield larger
mass fractions formed in compact starbursts, giving a smaller stellar R_e and
higher M_stellar/M_tot within that R_e. Such starbursts leave a characteristic
imprint in the surface brightness profile: a central excess above an outer
profile established by the dissipationless violent relaxation of disk stars. In
previous work, we developed empirical methods to decompose the observed
profiles of ellipticals and robustly estimate the amount of dissipation in the
original spheroid-forming merger(s). Applying this to a large sample of
observed ellipticals, we test whether or not their location on the FP and its
tilt are driven by dissipation. At fixed mass, ellipticals formed in more
dissipational events are smaller and have higher M_stellar/M_tot. At fixed
degree of dissipation, there is no tilt in the FP. We show that the dynamical
mass estimator R_e*sigma^2/G is a good estimator of the true mass: the observed
FP tilt cannot primarily owe to other forms of non-homology. Removing the
effects of dissipation, observed ellipticals obey the same FP correlations as
disks: unusual progenitors are not required to make typical ellipticals.
Dissipation appears to be both necessary and sufficient to explain the FP tilt.


IRAC Colors of Young Stellar Objects

  We compare the infrared colors predicted by theoretical models of
protostellar envelopes and protoplanetary disks with initial observations of
young stellar objects made with the Infrared Array Camera (IRAC) on the Spitzer
Space Telescope (Werner et al. 2004, Fazio et al. 2004). Disk and envelope
models characterized by infall and/or accretion rates found in previous studies
can quantitatively account for the range of IRAC colors found in four young
embedded clusters: S 140, S 171, NGC 7129, and Cep C. The IRAC color-color
diagram ([3.6]-[4.5] vs. [5.8]-[8.0]) can be used to help to distinguish
between young stars with only disk emission and protostars with circumstellar
envelopes.


Mesoscale Modeling of Impact Compaction of Primitive Solar System Solids

  We have developed a method for simulating the mesoscale compaction of early
solar system solids in low velocity impact events, using the iSALE shock
physics code. Chondrules are represented by nonporous disks, placed within a
porous matrix. By simulating impacts into bimodal mixtures over a wide range of
parameter space (including the chondrule-to-matrix ratio, the matrix porosity
and composition and the impact velocity), we have shown how each of these
parameters influences the shock processing of heterogeneous materials. The
temperature after shock processing shows a strong dichotomy: matrix
temperatures are elevated much higher than the chondrules, which remain largely
cold. Chondrules can protect some matrix from shock compaction, with shadow
regions in the lee side of chondrules exhibiting higher porosity that elsewhere
in the matrix. Using the results from this mesoscale modelling, we show how the
$\varepsilon-\alpha$ porous compaction model parameters depend on initial bulk
porosity. We also show that the timescale for the temperature dichotomy to
equilibrate is highly dependent on the porosity of the matrix after the shock,
and will be on the order of seconds for matrix porosities of less than 0.1, and
on the order of 10's to 100's seconds for matrix porosities of $\sim$ 0.3--0.5.
Finally, we have shown that the composition of the post-shock material is able
to match the bulk porosity and chondrule-to-matrix ratios of meteorite groups
such as carbonaceous chondrites and unequilibrated ordinary chondrites.


The First Passage Probability of Intracellular Particle Trafficking

  The first passage probability (FPP), of trafficked intracellular particles
reaching a displacement L, in a given time t or inverse velocity S = t/L, can
be calculated robustly from measured particle tracks, and gives a measure of
particle movement in which different types of motion, e.g. diffusion, ballistic
motion, and transient run-rest motion, can readily be distinguished in a single
graph, and compared with mathematical models. The FPP is attractive in that it
offers a means of reducing the data in the measured tracks, without making
assumptions about the mechanism of motion: for example, it does not employ
smoothing, segementation or arbitrary thresholds to discriminate between
different types of motion in a particle track. Taking experimental data from
tracked endocytic vesicles, and calculating the FPP, we see how three molecular
treatments affect the trafficking. We show the FPP can quantify complicated
movement which is neither completely random nor completely deterministic,
making it highly applicable to trafficked particles in cell biology.


Relativistic Scott correction in self-generated magnetic fields

  We consider a large neutral molecule with total nuclear charge $Z$ in a model
with self-generated classical magnetic field and where the kinetic energy of
the electrons is treated relativistically. To ensure stability, we assume that
$Z \alpha < 2/\pi$, where $\alpha$ denotes the fine structure constant. We are
interested in the ground state energy in the simultaneous limit $Z \rightarrow
\infty$, $\alpha \rightarrow 0$ such that $\kappa=Z \alpha$ is fixed. The
leading term in the energy asymptotics is independent of $\kappa$, it is given
by the Thomas-Fermi energy of order $Z^{7/3}$ and it is unchanged by including
the self-generated magnetic field. We prove the first correction term to this
energy, the so-called Scott correction of the form $S(\alpha Z) Z^2$. The
current paper extends the result of \cite{SSS} on the Scott correction for
relativistic molecules to include a self-generated magnetic field. Furthermore,
we show that the corresponding Scott correction function $S$, first identified
in \cite{SSS}, is unchanged by including a magnetic field. We also prove new
Lieb-Thirring inequalities for the relativistic kinetic energy with magnetic
fields.


Measuring velocity of sound with nuclear resonant inelastic x-ray
  scattering

  Nuclear resonant inelastic x-ray scattering is used to measure the projected
partial phonon density of states of materials. A relationship is derived
between the low-energy part of this frequency distribution function and the
sound velocity of materials. Our derivation is valid for harmonic solids with
Debye-like low-frequency dynamics. This method of sound velocity determination
is applied to elemental, composite, and impurity samples which are
representative of a wide variety of both crystalline and noncrystalline
materials. Advantages and limitations of this method are elucidated.


Feature Selection Strategies for Classifying High Dimensional
  Astronomical Data Sets

  The amount of collected data in many scientific fields is increasing, all of
them requiring a common task: extract knowledge from massive, multi parametric
data sets, as rapidly and efficiently possible. This is especially true in
astronomy where synoptic sky surveys are enabling new research frontiers in the
time domain astronomy and posing several new object classification challenges
in multi dimensional spaces; given the high number of parameters available for
each object, feature selection is quickly becoming a crucial task in analyzing
astronomical data sets. Using data sets extracted from the ongoing Catalina
Real-Time Transient Surveys (CRTS) and the Kepler Mission we illustrate a
variety of feature selection strategies used to identify the subsets that give
the most information and the results achieved applying these techniques to
three major astronomical problems.


Using Options and Covariance Testing for Long Horizon Off-Policy Policy
  Evaluation

  Evaluating a policy by deploying it in the real world can be risky and
costly. Off-policy policy evaluation (OPE) algorithms use historical data
collected from running a previous policy to evaluate a new policy, which
provides a means for evaluating a policy without requiring it to ever be
deployed. Importance sampling is a popular OPE method because it is robust to
partial observability and works with continuous states and actions. However,
the amount of historical data required by importance sampling can scale
exponentially with the horizon of the problem: the number of sequential
decisions that are made. We propose using policies over temporally extended
actions, called options, and show that combining these policies with importance
sampling can significantly improve performance for long-horizon problems. In
addition, we can take advantage of special cases that arise due to
options-based policies to further improve the performance of importance
sampling. We further generalize these special cases to a general covariance
testing rule that can be used to decide which weights to drop in an IS
estimate, and derive a new IS algorithm called Incremental Importance Sampling
that can provide significantly more accurate estimates for a broad class of
domains.


Data-Efficient Policy Evaluation Through Behavior Policy Search

  We consider the task of evaluating a policy for a Markov decision process
(MDP). The standard unbiased technique for evaluating a policy is to deploy the
policy and observe its performance. We show that the data collected from
deploying a different policy, commonly called the behavior policy, can be used
to produce unbiased estimates with lower mean squared error than this standard
technique. We derive an analytic expression for the optimal behavior policy ---
the behavior policy that minimizes the mean squared error of the resulting
estimates. Because this expression depends on terms that are unknown in
practice, we propose a novel policy evaluation sub-problem, behavior policy
search: searching for a behavior policy that reduces mean squared error. We
present a behavior policy search algorithm and empirically demonstrate its
effectiveness in lowering the mean squared error of policy performance
estimates.


A Compression-Inspired Framework for Macro Discovery

  In this paper we consider the problem of how a reinforcement learning agent
tasked with solving a set of related Markov decision processes can use
knowledge acquired early in its lifetime to improve its ability to more rapidly
solve novel, but related, tasks. One way of exploiting this experience is by
identifying recurrent patterns in trajectories obtained from well-performing
policies. We propose a three-step framework in which an agent 1) generates a
set of candidate open-loop macros by compressing trajectories drawn from
near-optimal policies; 2) evaluates the value of each macro; and 3) selects a
maximally diverse subset of macros that spans the space of policies typically
required for solving the set of related tasks. Our experiments show that
extending the original primitive action-set of the agent with the identified
macros allows it to more rapidly learn an optimal policy in unseen, but similar
MDPs.


Natural Option Critic

  The recently proposed option-critic architecture Bacon et al. provide a
stochastic policy gradient approach to hierarchical reinforcement learning.
Specifically, they provide a way to estimate the gradient of the expected
discounted return with respect to parameters that define a finite number of
temporally extended actions, called \textit{options}. In this paper we show how
the option-critic architecture can be extended to estimate the natural gradient
of the expected discounted return. To this end, the central questions that we
consider in this paper are: 1) what is the definition of the natural gradient
in this context, 2) what is the Fisher information matrix associated with an
option's parameterized policy, 3) what is the Fisher information matrix
associated with an option's parameterized termination function, and 4) how can
a compatible function approximation approach be leveraged to obtain natural
gradient estimates for both the parameterized policy and parameterized
termination functions of an option with per-time-step time and space complexity
linear in the total number of parameters. Based on answers to these questions
we introduce the natural option critic algorithm. Experimental results showcase
improvement over the vanilla gradient approach.


Learning Action Representations for Reinforcement Learning

  Most model-free reinforcement learning methods leverage state representations
(embeddings) for generalization, but either ignore structure in the space of
actions or assume the structure is provided a priori. We show how a policy can
be decomposed into a component that acts in a low-dimensional space of action
representations and a component that transforms these representations into
actual actions. These representations improve generalization over large, finite
action sets by allowing the agent to infer the outcomes of actions similar to
actions already taken. We provide an algorithm to both learn and use action
representations and provide conditions for its convergence. The efficacy of the
proposed method is demonstrated on large-scale real-world problems.


A Meta-MDP Approach to Exploration for Lifelong Reinforcement Learning

  In this paper we consider the problem of how a reinforcement learning agent
that is tasked with solving a sequence of reinforcement learning problems (a
sequence of Markov decision processes) can use knowledge acquired early in its
lifetime to improve its ability to solve new problems. We argue that previous
experience with similar problems can provide an agent with information about
how it should explore when facing a new but related problem. We show that the
search for an optimal exploration strategy can be formulated as a reinforcement
learning problem itself and demonstrate that such strategy can leverage
patterns found in the structure of related problems. We conclude with
experiments that show the benefits of optimizing an exploration strategy using
our proposed approach.


Asynchronous Coagent Networks: Stochastic Networks for Reinforcement
  Learning without Backpropagation or a Clock

  In this paper we introduce a reinforcement learning (RL) approach for
training policies, including artificial neural network policies, that is both
backpropagation-free and clock-free. It is backpropagation-free in that it does
not propagate any information backwards through the network. It is clock-free
in that no signal is given to each node in the network to specify when it
should compute its output and when it should update its weights. We contend
that these two properties increase the biological plausibility of our
algorithms and facilitate distributed implementations. Additionally, our
approach eliminates the need for customized learning rules for hierarchical RL
algorithms like the option-critic.


Learning to Adapt for Stereo

  Real world applications of stereo depth estimation require models that are
robust to dynamic variations in the environment. Even though deep learning
based stereo methods are successful, they often fail to generalize to unseen
variations in the environment, making them less suitable for practical
applications such as autonomous driving. In this work, we introduce a
"learning-to-adapt" framework that enables deep stereo methods to continuously
adapt to new target domains in an unsupervised manner. Specifically, our
approach incorporates the adaptation procedure into the learning objective to
obtain a base set of parameters that are better suited for unsupervised online
adaptation. To further improve the quality of the adaptation, we learn a
confidence measure that effectively masks the errors introduced during the
unsupervised adaptation. We evaluate our method on synthetic and real-world
stereo datasets and our experiments evidence that learning-to-adapt is, indeed
beneficial for online adaptation on vastly different domains.


EmpiriciSN: Re-sampling Observed Supernova/Host Galaxy Populations using
  an XD Gaussian Mixture Model

  We describe two new open source tools written in Python for performing
extreme deconvolution Gaussian mixture modeling (XDGMM) and using a conditioned
model to re-sample observed supernova and host galaxy populations. XDGMM is new
program for using Gaussian mixtures to do density estimation of noisy data
using extreme deconvolution (XD) algorithms that has functionality not
available in other XD tools. It allows the user to select between the AstroML
(Vanderplas et al. 2012; Ivezic et al. 2015) and Bovy et al. (2011) fitting
methods and is compatible with scikit-learn machine learning algorithms
(Pedregosa et al. 2011). Most crucially, it allows the user to condition a
model based on the known values of a subset of parameters. This gives the user
the ability to produce a tool that can predict unknown parameters based on a
model conditioned on known values of other parameters. EmpiriciSN is an example
application of this functionality that can be used for fitting an XDGMM model
to observed supernova/host datasets and predicting likely supernova parameters
using on a model conditioned on observed host properties. It is primarily
intended for simulating realistic supernovae for LSST data simulations based on
empirical galaxy properties.


The Galaxy Stellar Mass Function and Low Surface Brightness Galaxies
  from Core-Collapse Supernovae

  We introduce a method for producing a galaxy sample unbiased by surface
brightness and stellar mass, by selecting star-forming galaxies via the
positions of core-collapse supernovae (CCSNe). Whilst matching $\sim$2400
supernovae from the SDSS-II Supernova Survey to their host galaxies using IAC
Stripe 82 legacy coadded imaging, we find $\sim$150 previously unidentified low
surface brightness galaxies (LSBGs). Using a sub-sample of $\sim$900 CCSNe, we
infer CCSN-rate and star-formation rate densities as a function of galaxy
stellar mass, and the star-forming galaxy stellar mass function. Resultant
star-forming galaxy number densities are found to increase following a
power-law down to our low mass limit of $\sim10^{6.4}$ M$_{\odot}$ by a single
Schechter function with a faint-end slope of $\alpha = -1.41$. Number densities
are consistent with those found by the EAGLE simulations invoking a
$\Lambda$-CDM cosmology. Overcoming surface brightness and stellar mass biases
is important for assessment of the sub-structure problem. In order to estimate
galaxy stellar masses, a new code for the calculation of galaxy photometric
redshifts, zMedIC, is also presented, and shown to be particularly useful for
small samples of galaxies.


Peculiar Velocity Constraints from Five-Band SZ Effect Measurements
  Towards RX J1347.5-1145 with MUSIC and Bolocam from the CSO

  We present Sunyaev-Zel'dovich (SZ) effect measurements from wide-field images
towards the galaxy cluster RX J1347.5-1145 obtained from the Caltech
Submillimeter Observatory with the Multiwavelength Submillimeter Inductance
Camera (MUSIC) at 147, 213, 281, and 337 GHz and with Bolocam at 140 GHz. As
part of our analysis, we have used higher frequency data from Herschel-SPIRE
and previously published lower frequency radio data to subtract the signal from
the brightest dusty star-forming galaxies behind RX J1347.5-1145 and from the
AGN in RX J1347.5-1145's BCG. Using these five-band SZ effect images, combined
with X-ray spectroscopic measurements of the temperature of the intra-cluster
medium (ICM) from Chandra, we constrain the ICM optical depth to be $\tau_e =
7.33^{+0.96}_{-0.97} \times 10^{-3}$ and the ICM line of sight peculiar
velocity to be $v_{pec} = -1040^{+870}_{-840}$ km s$^{-1}$. The errors for both
quantities are limited by measurement noise rather than calibration
uncertainties or astrophysical contamination, and significant improvements are
possible with deeper observations. Our best-fit velocity is in good agreement
with one previously published SZ effect analysis and in mild tension with the
other, although some or all of that tension may be because that measurement
samples a much smaller cluster volume. Furthermore, our best-fit optical depth
implies a gas mass slightly larger than the Chandra-derived value, implying the
cluster is elongated along the line of sight.


The Relation Between Quasar and Merging Galaxy Luminosity Functions and
  the Merger-Induced Star Formation Rate of the Universe

  Using a model for self-regulated growth of black holes (BHs) in mergers
involving gas-rich galaxies, we study the relationship between quasars and the
population of merging galaxies and predict the merger-induced star formation
rate density of the Universe. Mergers drive nuclear gas inflows, fueling
starbursts and 'buried quasars' until accretion feedback expels the gas,
rendering a briefly visible optical quasar. Star formation is shut down and
accretion declines, leaving a passively evolving remnant with properties
typical of red, elliptical galaxies. Based on evolution of these events in our
simulations, we demonstrate that the observed statistics of merger rates,
luminosity functions (LFs) and mass functions, SFR distributions, specific
SFRs, quasar and quasar host galaxy LFs, and elliptical/red galaxy LFs are
self-consistent and follow from one another as predicted by the merger
hypothesis. We use our simulations to de-convolve both quasar and merging
galaxy LFs to determine the birthrate of black holes of a given final mass and
merger rates as a function of stellar mass. We use this to predict the merging
galaxy LF in several observed wavebands, color-magnitude relations, mass
functions, absolute and specific SFR distributions and SFR density, and quasar
host galaxy LFs, as a function of redshift from z=0-6. We invert this and
predict e.g. quasar LFs from observed merger LFs or SFR distributions. Our
results agree well with observations, but idealized models of quasar
lightcurves are ruled out by comparison of merger and quasar observations at
>99.9% confidence. Using only observations of quasars, we estimate the
contribution of mergers to the SFR density of the Universe even to high
redshifts z~4.


Dissipation and Extra Light in Galactic Nuclei: III. 'Core' Ellipticals
  and 'Missing' Light

  We investigate how 'extra' central light in the surface brightness profiles
of cusp ellipticals relates to the profiles of ellipticals with cores. Cusp
elliptical envelopes are formed by violent relaxation in mergers acting on
stars in progenitor disks, while their centers are structured by dissipational
starbursts. Core ellipticals are formed by subsequent merging of (now gas-poor)
cusp ellipticals, with the fossil starburst components combining to preserve a
compact component in the remnant (although the 'transition' is smoothed).
Comparing hydrodynamical simulations and observed profiles, we show how to
observationally isolate the relic starburst components in core ellipticals. We
demonstrate that these survive re-mergers and reliably trace the dissipation in
the initial gas-rich merger(s). The typical degree of dissipation is a strong
function of stellar mass, tracing observed disk gas fractions. We find a
correlation between dissipation and effective radius: systems with more
dissipation are more compact. The survival of this component and scattering of
stars into the envelope naturally explain high-Sersic index profiles
characteristic of massive core ellipticals. This is also closely related to the
kinematics and isophotal shapes: only systems with matched starburst components
from their profile fits also reproduce the observed kinematics of boxy/core
ellipticals. We show that it is critical to adopt physically motivated profiles
when attempting to quantify how much mass has been 'scoured' or scattered out
of the inner regions by binary black holes. Estimates of scoured mass ignoring
multi-component structure can be strongly biased, potentially explaining
observed systems with large inferred core masses in apparent conflict with
core-scouring models.


The Effects of Gas on Morphological Transformation in Mergers:
  Implications for Bulge and Disk Demographics

  Transformation of disks into spheroids via mergers is a well-accepted element
of galaxy formation models. However, recent simulations have shown that bulge
formation is suppressed in increasingly gas-rich mergers. We investigate the
global implications of these results in a cosmological framework, using
independent approaches: empirical halo-occupation models (where galaxies are
populated in halos according to observations) and semi-analytic models. In
both, ignoring the effects of gas in mergers leads to the over-production of
spheroids: low and intermediate-mass galaxies are predicted to be
bulge-dominated (B/T~0.5 at <10^10 M_sun), with almost no bulgeless systems),
even if they have avoided major mergers. Including the different physical
behavior of gas in mergers immediately leads to a dramatic change: bulge
formation is suppressed in low-mass galaxies, observed to be gas-rich (giving
B/T~0.1 at <10^10 M_sun, with a number of bulgeless galaxies in good agreement
with observations). Simulations and analytic models which neglect the
similarity-breaking behavior of gas have difficulty reproducing the strong
observed morphology-mass relation. However, the observed dependence of gas
fractions on mass, combined with suppression of bulge formation in gas-rich
mergers, naturally leads to the observed trends. Discrepancies between
observations and models that ignore the role of gas increase with redshift; in
models that treat gas properly, galaxies are predicted to be less
bulge-dominated at high redshifts, in agreement with the observations. We
discuss implications for the global bulge mass density and future observational
tests.


The Herschel Orion Protostar Survey: Luminosity and Envelope Evolution

  The Herschel Orion Protostar Survey obtained well-sampled 1.2 - 870 micron
spectral energy distributions (SEDs) of over 300 protostars in the Orion
molecular clouds, home to most of the young stellar objects (YSOs) in the
nearest 500 pc. We plot the bolometric luminosities and temperatures for 330
Orion YSOs, 315 of which have bolometric temperatures characteristic of
protostars. The histogram of bolometric temperature is roughly flat; 29% of the
protostars are in Class 0. The median luminosity decreases by a factor of four
with increasing bolometric temperature; consequently, the Class 0 protostars
are systematically brighter than the Class I protostars, with a median
luminosity of 2.3 L_sun as opposed to 0.87 L_sun. At a given bolometric
temperature, the scatter in luminosities is three orders of magnitude. Using
fits to the SEDs, we analyze how the luminosities corrected for inclination and
foreground reddening relate to the mass in the inner 2500 AU of the best-fit
model envelopes. The histogram of envelope mass is roughly flat, while the
median corrected luminosity peaks at 15 L_sun for young envelopes and falls to
1.7 L_sun for late-stage protostars with remnant envelopes. The spread in
luminosity at each envelope mass is three orders of magnitude. Envelope masses
that decline exponentially with time explain the flat mass histogram and the
decrease in luminosity, while the formation of a range of stellar masses
explains the dispersion in luminosity.


The Evolution of Protostars: Insights from Ten Years of Infrared Surveys
  with Spitzer and Herschel

  Stars form from the gravitational collapse of dense molecular cloud cores. In
the protostellar phase, mass accretes from the core onto a protostar, likely
through an accretion disk, and it is during this phase that the initial masses
of stars and the initial conditions for planet formation are set. Over the past
decade, new observational capabilities provided by the Spitzer Space Telescope
and Herschel Space Observatory have enabled wide-field surveys of entire
star-forming clouds with unprecedented sensitivity, resolution, and infrared
wavelength coverage. We review resulting advances in the field, focusing both
on the observations themselves and the constraints they place on theoretical
models of star formation and protostellar evolution. We also emphasize open
questions and outline new directions needed to further advance the field.


A programmable two-qubit quantum processor in silicon

  With qubit measurement and control fidelities above the threshold of
fault-tolerance, much attention is moving towards the daunting task of scaling
up the number of physical qubits to the large numbers needed for fault tolerant
quantum computing. Here, quantum dot based spin qubits may offer significant
advantages due to their potential for high densities, all-electrical operation,
and integration onto an industrial platform. In this system, the
initialisation, readout, single- and two-qubit gates have been demonstrated in
various qubit representations. However, as seen with other small scale quantum
computer demonstrations, combining these elements leads to new challenges
involving qubit crosstalk, state leakage, calibration, and control hardware
which provide invaluable insight towards scaling up. Here we address these
challenges and demonstrate a programmable two-qubit quantum processor in
silicon by performing both the Deutsch-Josza and the Grover search algorithms.
In addition, we characterise the entanglement in our processor through quantum
state tomography of Bell states measuring state fidelities between 85-89% and
concurrences between 73-80%. These results pave the way for larger scale
quantum computers using spins confined to quantum dots.


A Spitzer View of Mon OB1 East/NGC 2264

  We present Spitzer 3.6, 4.5, 5.8, 8.0, and 24 micron images of the Mon OB1
East giant molecular cloud, which contains the young star forming region NGC
2264, as well as more extended star formation. With Spitzer data and 2MASS
photometry, we identify and classify young stellar objects (YSOs) with dusty
circumstellar disks and/or envelopes in Mon OB1 East by their infrared-excess
emission and study their distribution with respect to cloud material. We find a
correlation between the local surface density of YSOs and column density of
molecular gas as traced by dust extinction that is roughly described as a power
law in these quantities. NGC 2264 follows a power law index of ~2.7, exhibiting
a large YSO surface density for a given gas column density. Outside of NGC 2264
where the surface density of YSOs is lower, the power law is shallower and the
region exhibits a larger gas column density for a YSO surface density,
suggesting the star formation is more recent. In order to measure the fraction
of cloud members with circumstellar disks/envelopes, we estimate the number of
diskless pre-main sequence stars by statistical removal of background star
detections. We find that the disk fraction of the NGC 2264 region is 45%, while
the surrounding more distributed regions show a disk fraction of 19%. This may
be explained by the presence an older, more dispersed population of stars. In
total, the Spitzer observations provide evidence for heterogenous, non-coeval
star formation throughout the Mon OB1 cloud.


A Catalog of Young Stellar Groups and Clusters Within 1kpc of the Sun

  We present a catalog of near-infrared surveys of young (<= a few 10^6 yr)
stellar groups and clusters within 1 kpc from the Sun, based on an extensive
search of the literature from the past ten years. We find 143 surveys from 69
published articles, covering 73 different regions. The number distribution of
stars in a region has a median of 28 and a mean of 100. About 80% of the stars
are in clusters with at least 100 members. By a rough classification of the
groups and clusters based on the number of their associated stars, we show that
most of the stars form in large clusters. The spatial distribution of cataloged
regions in the Galactic plane shows a relative lack of observed stellar groups
and clusters in the range 270 deg < l < 60 deg of Galactic longitude,
reflecting our location between the Local and Sagittarius arms. This
compilation is intended as a useful resource for future studies of nearby young
regions of multiple star formation.


A Semi-Analytic Model for the Co-evolution of Galaxies, Black Holes, and
  Active Galactic Nuclei

  We present a new semi-analytic model that self-consistently traces the growth
of supermassive black holes (BH) and their host galaxies within the context of
the LCDM cosmological framework. In our model, the energy emitted by accreting
black holes regulates the growth of the black holes themselves, drives galactic
scale winds that can remove cold gas from galaxies, and produces powerful jets
that heat the hot gas atmospheres surrounding groups and clusters. We present a
comprehensive comparison of our model predictions with observational
measurements of key physical properties of low-redshift galaxies, such as cold
gas fractions, stellar metallicities and ages, and specific star formation
rates. We find that our new models successfully reproduce the exponential
cutoff in the stellar mass function and the stellar and cold gas mass densities
at z~0, and predict that star formation should be largely, but not entirely,
quenched in massive galaxies at the present day. We also find that our model of
self-regulated BH growth naturally reproduces the observed relation between BH
mass and bulge mass. We explore the global formation history of galaxies in our
models, presenting predictions for the cosmic histories of star formation,
stellar mass assembly, cold gas, and metals. We find that models assuming the
"concordance" LCDM cosmology overproduce star formation and stellar mass at
high redshift (z>2). A model with less small-scale power predicts less star
formation at high redshift, and excellent agreement with the observed stellar
mass assembly history, but may have difficulty accounting for the cold gas in
quasar absorption systems at high redshift (z~3-4).


BLAST Observations of the South Ecliptic Pole field: Number Counts and
  Source Catalogs

  We present results from a survey carried out by the Balloon-borne Large
Aperture Submillimeter Telescope (BLAST) on a 9 deg^2 field near the South
Ecliptic Pole at 250, 350 and 500 {\mu}m. The median 1{\sigma} depths of the
maps are 36.0, 26.4 and 18.4 mJy, respectively. We apply a statistical method
to estimate submillimeter galaxy number counts and find that they are in
agreement with other measurements made with the same instrument and with the
more recent results from Herschel/SPIRE. Thanks to the large field observed,
the new measurements give additional constraints on the bright end of the
counts. We identify 132, 89 and 61 sources with S/N>4 at 250, 350, 500 {\mu}m,
respectively and provide a multi-wavelength combined catalog of 232 sources
with a significance >4{\sigma} in at least one BLAST band. The new BLAST maps
and catalogs are available publicly at http://blastexperiment.info.


Stimulated emission from NV centres in diamond

  Stimulated emission is the process fundamental to laser operation, thereby
producing coherent photon output. Despite negatively-charged nitrogen-vacancy
(NV$^-$) centres being discussed as a potential laser medium since the 1980's,
there have been no definitive observations of stimulated emission from
ensembles of NV$^-$ to date. Reasons for this lack of demonstration include the
short excited state lifetime and the occurrence of photo-ionisation to the
neutral charge state by light around the zero-phonon line. Here we show both
theoretical and experimental evidence for stimulated emission from NV$^-$
states using light in the phonon-sidebands. Our system uses a continuous wave
pump laser at 532 nm and a pulsed stimulating laser that is swept across the
phononic sidebands of the NV$^-$. Optimal stimulated emission is demonstrated
in the vicinity of the three-phonon line at 700 nm. Furthermore, we show the
transition from stimulated emission to photoionisation as the stimulating laser
wavelength is reduced from 700nm to 620 nm. While lasing at the zero-phonon
line is suppressed by ionisation, our results open the possibility of diamond
lasers based on NV centres, tuneable over the phonon-sideband. This broadens
the applications of NV magnetometers from single centre nanoscale sensors to a
new generation of ultra-precise ensemble laser sensors, which exploit the
contrast and signal amplification of a lasing system.


astroquery: An Astronomical Web-Querying Package in Python

  astroquery is a collection of tools for requesting data from databases hosted
on remote servers with interfaces exposed on the internet, including those with
web pages but without formal application program interfaces (APIs). These tools
are built on the Python requests package, which is used to make HTTP requests,
and astropy, which provides most of the data parsing functionality. astroquery
modules generally attempt to replicate the web page interface provided by a
given service as closely as possible, making the transition from browser-based
to command-line interaction easy. astroquery has received significant
contributions from throughout the astronomical community, including several
significant contributions from telescope archives. astroquery enables the
creation of fully reproducible workflows from data acquisition through
publication. This paper describes the philosophy, basic structure, and
development model of the astroquery package. The complete documentation for
astroquery can be found at http://astroquery.readthedocs.io/.


Efficient Relaxations for Dense CRFs with Sparse Higher Order Potentials

  Dense conditional random fields (CRFs) have become a popular framework for
modelling several problems in computer vision such as stereo correspondence and
multi-class semantic segmentation. By modelling long-range interactions, dense
CRFs provide a labelling that captures finer detail than their sparse
counterparts. Currently, the state-of-the-art algorithm performs mean-field
inference using a filter-based method but fails to provide a strong theoretical
guarantee on the quality of the solution. A question naturally arises as to
whether it is possible to obtain a maximum a posteriori (MAP) estimate of a
dense CRF using a principled method. Within this paper, we show that this is
indeed possible. We will show that, by using a filter-based method, continuous
relaxations of the MAP problem can be optimised efficiently using
state-of-the-art algorithms. Specifically, we will solve a quadratic
programming (QP) relaxation using the Frank-Wolfe algorithm and a linear
programming (LP) relaxation by developing a proximal minimisation framework. By
exploiting labelling consistency in the higher-order potentials and utilising
the filter-based method, we are able to formulate the above algorithms such
that each iteration has a complexity linear in the number of classes and random
variables. The presented algorithms can be applied to any labelling problem
using a dense CRF with sparse higher-order potentials. In this paper, we use
semantic segmentation as an example application as it demonstrates the ability
of the algorithm to scale to dense CRFs with large dimensions. We perform
experiments on the Pascal dataset to indicate that the presented algorithms are
able to attain lower energies than the mean-field inference method.


Radio and mid-infrared identification of BLAST source counterparts in
  the Chandra Deep Field South

  We have identified radio and/or mid-infrared counterparts to 198 out of 350
sources detected at >=5 sigma over ~ 9 square degrees centered on the Chandra
Deep Field South (CDFS) by the Balloon-borne Large Aperture Submillimeter
Telescope (BLAST) at 250, 350 and 500 um. We have matched 114 of these
counterparts to optical sources with previously derived photometric redshifts
and fitted SEDs to the BLAST fluxes and fluxes at 70 and 160 um acquired with
the Spitzer Space Telescope. In this way, we have constrained dust
temperatures, total far-infrared/sub-millimeter luminosities and star formation
rates for each source. Our findings show that on average, the BLAST sources lie
at significantly lower redshifts and have significantly lower rest-frame dust
temperatures compared to submm sources detected in surveys conducted at 850 um.
We demonstrate that an apparent increase in dust temperature with redshift in
our sample arises as a result of selection effects. Finally, we provide the
full multi-wavelength catalog of >= 5 sigma BLAST sources contained within the
complete ~ 9 square degree survey area.


Spectral features of Earth-like planets and their detectability at
  different orbital distances around F, G, and K-type stars

  We investigate the spectral appearance of Earth-like exoplanets in the HZ of
different main sequence stars at different orbital distances. We furthermore
discuss for which of these scenarios biomarker absorption bands may be detected
during primary or secondary transit with near-future telescopes and
instruments.We analyze the spectra taking into account different filter
bandpasses of two photometric instruments planned to be mounted to the JWST. We
analyze in which filters and for which scenarios molecular absorption bands are
detectable when using the space-borne JWST or the ground-based telescope E-ELT.
Absorption bands of CO2, H2O, CH4 and O3 are clearly visible in high-resolution
spectra as well as in the filters of photometric instruments. However, only
during primary eclipse bands of CO2, H2O and O3 are detectable for all
scenarios when using photometric instruments and an E-ELT telescope setup. CH4
is only detectable at the outer HZ of the K star since here the atmospheric
modeling results in very high abundances. Since the detectable CO2 and H2O
bands overlap, separate bands need to be observed to prove their existence in
the atmosphere. In order to detect H2O in a separate band, a S/N>7 needs to be
achieved for E-ELT observations, e.g. by co-adding at least 10 transit
observations. Using a spaceborne telescope like the JWST enables the detection
of CO2 at 4.3mu, which is not possible for ground-based observations due to the
Earth's atmospheric absorption. Hence combining observations of spaceborne and
groundbased telescopes might allow to detect the presence of the biomarker
molecule O3 and the related compounds H2O and CO2 in a planetary atmosphere.
Other absorption bands using the JWST can only be detected for much higher
S/Ns, which is not achievable by just co-adding transit observations since this
would be far beyond the planned mission time of JWST.(abridged)


Universal Properties of Galactic Rotation Curves and a First Principles
  Derivation of the Tully-Fisher Relation

  In a recent paper McGaugh, Lelli, and Schombert showed that in an empirical
plot of the observed centripetal accelerations in spiral galaxies against those
predicted by the Newtonian gravity of the luminous matter in those galaxies the
data points occupied a remarkably narrow band. While one could summarize the
mean properties of the band by drawing a single mean curve through it, by
fitting the band with the illustrative conformal gravity theory with fits that
fill out the width of the band we show here that the width of the band is just
as physically significant. We show that at very low luminous Newtonian
accelerations the plot can become independent of the luminous Newtonian
contribution altogether, but still be non-trivial due to the contribution of
matter outside of the galaxies (viz. the rest of the visible universe). We
present a new empirical plot of the difference between the observed centripetal
accelerations and the luminous Newtonian expectations as a function of distance
from the centers of galaxies, and show that at distances greater than 10 kpc
the plot also occupies a remarkably narrow band, one even close to constant.
Using the conformal gravity theory we provide a first principles derivation of
the empirical Tully-Fisher relation.


Mapping polar atmospheric features on Titan with VIMS: from the
  dissipation of the northern cloud to the onset of a southern polar vortex

  We have analyzed the complete archive of the Visual and Infrared Mapping
Spectrometer (VIMS) data in order to monitor and analyze the evolution of the
clouds and haze coverage at both poles of Titan during the entire Cassini
mission. Our objective is to give a cartographic synopsis from a VIMS
perspective, to provide a global view of the seasonal evolution of Titan's
atmosphere over the poles. We leave the detailed comparison with the Imaging
Science Subsystem (ISS) and the Composite Infrared Spectrometer (CIRS) data
sets to further studies. We have computed global hyperspectral mosaics for each
of the 127 targeted flybys of Titan to produce synthetic color maps emphasizing
the main atmospheric features. The north pole appears fully covered by a huge
cloud as soon as the first observations in 2004 and up to the equinox in 2009
(Le Mou\'elic et al. 2012). The northern skies then became progressively
clearer, after the circulation turnover in 2009, revealing the underlying lakes
and seas to the optical instruments up to 2017. The reverse situation is
observed over the south pole, which was mostly clear of such a high obscuring
cloud during the first years of the mission, but started to develop a polar
cloud in 2012. This feature grew up month after month until the end of the
mission in 2017, with a poleward latitudinal extent of 75$^\circ$S in 2013 up
to 58$^\circ$S in April 2017. Thanks to the spectral capabilities of VIMS, we
have detected HCN spectral signatures over the north pole in almost all flybys
between 2004 and 2008. These HCN signatures started then to show up over the
south pole in almost all flybys between 2012 and 2017, so perfectly matching
the timing and spatial extent of the northern and southern polar atmospheric
features.


PTF11eon/SN2011dh: Discovery of a Type IIb Supernova From a Compact
  Progenitor in the Nearby Galaxy M51

  On May 31, 2011 UT a supernova (SN) exploded in the nearby galaxy M51 (the
Whirlpool Galaxy). We discovered this event using small telescopes equipped
with CCD cameras, as well as by the Palomar Transient Factory (PTF) survey, and
rapidly confirmed it to be a Type II supernova. Our early light curve and
spectroscopy indicates that PTF11eon resulted from the explosion of a
relatively compact progenitor star as evidenced by the rapid shock-breakout
cooling seen in the light curve, the relatively low temperature in early-time
spectra and the prompt appearance of low-ionization spectral features. The
spectra of PTF11eon are dominated by H lines out to day 10 after explosion, but
initial signs of He appear to be present. Assuming that He lines continue to
develop in the near future, this SN is likely a member of the cIIb (compact
IIb; Chevalier and Soderberg 2010) class, with progenitor radius larger than
that of SN 2008ax and smaller than the eIIb (extended IIb) SN 1993J progenitor.
Our data imply that the object identified in pre-explosion Hubble Space
Telescope images at the SN location is possibly a companion to the progenitor
or a blended source, and not the progenitor star itself, as its radius (~10^13
cm) would be highly inconsistent with constraints from our post-explosion
photometric and spectroscopic data.


The Nature of CO Emission From z~6 Quasars

  We investigate the nature of CO emission from z~6 quasars by combining
non-LTE radiative transfer calculations with merger-driven models of z~6 quasar
formation that arise naturally in LCDM cosmological simulations. We consider
four model quasars formed in 10^12-10^13 M_sun halos from different merging
histories. Our main results follow. Owing to massive starbursts and funneling
of dense gas into the nuclear regions of merging galaxies, the CO is highly
excited and the flux density peaks between J=5-8. The CO morphology of z~6
quasars often exhibits multiple emission peaks which arise from H2
concentrations which have not yet fully coalesced. Quasars at z~6 display a
large range of sightline dependent line widths such that the lines are
narrowest when the rotating H2 gas associated with the quasar is viewed face-on
(when L_B is largest), and broadest when the gas is seen edge-on (when L_B is
lowest). Thus for all models selection effects exist such that quasars selected
for optical luminosity are preferentially face-on which may result in detected
CO line widths narrower than the median. The sightline averaged line width is
reflective of the circular velocity (V_c) of the host halo, and ranges from
sigma~300-650 km/s. For optically selected QSOs, 10-25% (halo-mass dependant)
of sightlines have narrow line widths compatible with the sole CO detection at
z>6, J1148+5251. When accounting for both the temporal evolution of CO line
widths, as well as the redshift evolution of halo V_c, these models
self-consistently account for the CO line widths of both z~2 sub-mm galaxies
and QSO's. Finally, the dynamical mass derived from the sightline averaged line
widths provides a good estimate of the total mass, and allows for a stellar
bulge and SMBH consistent with the local M_BH-M_bulge relation. [abridged]


Young stellar clusters and star formation throughout the Galaxy

  Most stars are born in rich young stellar clusters (YSCs) embedded in giant
molecular clouds. The most massive stars live out their short lives there,
profoundly influencing their natal environments by ionizing HII regions,
inflating wind-blown bubbles, and soon exploding as supernovae. Thousands of
lower-mass pre-main sequence stars accompany the massive stars, and the
expanding HII regions paradoxically trigger new star formation as they destroy
their natal clouds. While this schematic picture is established, our
understanding of the complex astrophysical processes involved in clustered star
formation have only just begun to be elucidated. The technologies are
challenging, requiring both high spatial resolution and wide fields at
wavelengths that penetrate obscuring molecular material and remove
contaminating Galactic field stars. We outline several important projects for
the coming decade: the IMFs and structures of YSCs; triggered star formation
around YSC; the fate of OB winds; the stellar populations of Infrared Dark
Clouds; the most massive star clusters in the Galaxy; tracing star formation
throughout the Galactic Disk; the Galactic Center region and YSCs in the
Magellanic Clouds. Programmatic recommendations include: developing a 30m-class
adaptive optics infrared telescope; support for high-resolution and wide field
X-ray telescopes; large-aperture sub-millimeter and far-infrared telescopes;
multi-object infrared spectrographs; and both numerical and analytical theory.


