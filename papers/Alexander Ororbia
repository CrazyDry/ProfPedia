Column2Vec: Structural Understanding via Distributed Representations of  Database Schemas

  We present Column2Vec, a distributed representation of database columns basedon column metadata. Our distributed representation has several applications.Using known names for groups of columns (i.e., a table name), we train a modelto generate an appropriate name for columns in an unnamed table. We demonstratethe viability of our approach using schema information collected from opensource applications on GitHub.

Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and  Denoising Autoencoders

  Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine andthe Deep Hybrid Denoising Auto-encoder, are proposed for handlingsemi-supervised learning problems. The models combine experts that modelrelevant distributions at different levels of abstraction to improve overallpredictive performance on discriminative tasks. Theoretical motivations andalgorithms for joint learning for each are presented. We apply the new modelsto the domain of data-streams in work towards life-long learning. The proposedarchitectures show improved performance compared to a pseudo-labeled, drop-outrectifier network.

Unifying Adversarial Training Algorithms with Flexible Deep Data  Gradient Regularization

  Many previous proposals for adversarial training of deep neural nets haveincluded di- rectly modifying the gradient, training on a mix of original andadversarial examples, using contractive penalties, and approximately optimizingconstrained adversarial ob- jective functions. In this paper, we show theseproposals are actually all instances of optimizing a general, regularizedobjective we call DataGrad. Our proposed DataGrad framework, which can beviewed as a deep extension of the layerwise contractive au- toencoder penalty,cleanly simplifies prior work and easily allows extensions such as adversarialtraining with multi-task cues. In our experiments, we find that the deep gra-dient regularization of DataGrad (which also has L1 and L2 flavors ofregularization) outperforms alternative forms of regularization, includingclassical L1, L2, and multi- task, both on the original dataset as well as onadversarial sets. Furthermore, we find that combining multi-task optimizationwith DataGrad adversarial training results in the most robust performance.

Learning Simpler Language Models with the Differential State Framework

  Learning useful information across long time lags is a critical and difficultproblem for temporal neural models in tasks such as language modeling. Existingarchitectures that address the issue are often complex and costly to train. TheDifferential State Framework (DSF) is a simple and high-performing design thatunifies previously introduced gated neural models. DSF models maintainlonger-term memory by learning to interpolate between a fast-changingdata-driven representation and a slowly changing, implicitly stable state. Thisrequires hardly any more parameters than a classical, simple recurrent network.Within the DSF framework, a new architecture is presented, the Delta-RNN. Inlanguage modeling at the word and character levels, the Delta-RNN outperformspopular complex architectures, such as the Long Short Term Memory (LSTM) andthe Gated Recurrent Unit (GRU), and, when regularized, performs comparably toseveral state-of-the-art baselines. At the subword level, the Delta-RNN'sperformance is comparable to that of complex gated architectures.

Learning to Adapt by Minimizing Discrepancy

  We explore whether useful temporal neural generative models can be learnedfrom sequential data without back-propagation through time. We investigate theviability of a more neurocognitively-grounded approach in the context ofunsupervised generative modeling of sequences. Specifically, we build on theconcept of predictive coding, which has gained influence in cognitive science,in a neural framework. To do so we develop a novel architecture, the TemporalNeural Coding Network, and its learning algorithm, Discrepancy Reduction. Theunderlying directed generative model is fully recurrent, meaning that itemploys structural feedback connections and temporal feedback connections,yielding information propagation cycles that create local learning signals.This facilitates a unified bottom-up and top-down approach for informationtransfer inside the architecture. Our proposed algorithm shows promise on thebouncing balls generative modeling problem. Further experiments could beconducted to explore the strengths and weaknesses of our approach.

Conducting Credit Assignment by Aligning Local Representations

  Using back-propagation and its variants to train deep networks is oftenproblematic for new users. Issues such as exploding gradients, vanishinggradients, and high sensitivity to weight initialization strategies often makenetworks difficult to train, especially when users are experimenting with newarchitectures. Here, we present Local Representation Alignment (LRA), atraining procedure that is much less sensitive to bad initializations, does notrequire modifications to the network architecture, and can be adapted tonetworks with highly nonlinear and discrete-valued activation functions.Furthermore, we show that one variation of LRA can start with a nullinitialization of network weights and still successfully train networks with awide variety of nonlinearities, including tanh, ReLU-6, softplus, signum andothers that may draw their inspiration from biology.  A comprehensive set of experiments on MNIST and the much harder Fashion MNISTdata sets show that LRA can be used to train networks robustly and effectively,succeeding even when back-propagation fails and outperforming other alternativelearning algorithms, such as target propagation and feedback alignment.

Learned Neural Iterative Decoding for Lossy Image Compression Systems

  For lossy image compression systems, we develop an algorithm, iterativerefinement, to improve the decoder's reconstruction compared to standarddecoding techniques. Specifically, we propose a recurrent neural networkapproach for nonlinear, iterative decoding. Our decoder, which works with anyencoder, employs self-connected memory units that make use of causal andnon-causal spatial context information to progressively reduce reconstructionerror over a fixed number of steps. We experiment with variants of ourestimator and find that iterative refinement consistently creates lowerdistortion images of higher perceptual quality compared to other approaches.Specifically, on the Kodak Lossless True Color Image Suite, we observe as muchas a 0.871 decibel (dB) gain over JPEG, a 1.095 dB gain over JPEG 2000, and a0.971 dB gain over a competitive neural model.

Visually Grounded, Situated Learning in Neural Models

  The theory of situated cognition postulates that language is inseparable fromits physical context--words, phrases, and sentences must be learned in thecontext of the objects or concepts to which they refer. Yet, statisticallanguage models are trained on words alone. This makes it impossible forlanguage models to connect to the real world--the world described in thesentences presented to the model. In this paper, we examine the generalizationability of neural language models trained with a visual context. A multimodalconnectionist language architecture based on the Differential State Frameworkis proposed, which outperforms its equivalent trained on language alone, evenwhen no visual context is available at test time. Superior performance forlanguage models trained with a visual context is robust across differentlanguages and models.

Biologically Motivated Algorithms for Propagating Local Target  Representations

  Finding biologically plausible alternatives to back-propagation of errors isa fundamentally important challenge in artificial neural network research. Inthis paper, we propose a learning algorithm called error-driven LocalRepresentation Alignment (LRA-E), which has strong connections to predictivecoding, a theory that offers a mechanistic way of describing neurocomputationalmachinery. In addition, we propose an improved variant of Difference TargetPropagation, another procedure that comes from the same family of algorithms asLRA-E. We compare our procedures to several other biologically-motivatedalgorithms, including two feedback alignment algorithms and EquilibriumPropagation. In two benchmarks, we find that both of our proposed algorithmsyield stable performance and strong generalization compared to other competingback-propagation alternatives when training deeper, highly nonlinear networks,with LRA-E performing the best overall.

Investigating Recurrent Neural Network Memory Structures using  Neuro-Evolution

  This paper presents a new algorithm, Evolutionary eXploration of AugmentingMemory Models (EXAMM), which is capable of evolving recurrent neural networks(RNNs) using a wide variety of memory structures, such as Delta-RNN, GRU, LSTM,MGU and UGRNN cells. EXAMM evolved RNNs to perform prediction of large-scale,real world time series data from the aviation and power industries. These datasets consist of very long time series (thousands of readings), each with alarge number of potentially correlated and dependent parameters. Four differentparameters were selected for prediction and EXAMM runs were performed usingeach memory cell type alone, each cell type with feed forward nodes, and withall possible memory cell types. Evolved RNN performance was measured usingrepeated k-fold cross validation, resulting in 1210 EXAMM runs which evolved2,420,000 RNNs in 12,100 CPU hours on a high performance computing cluster.Generalization of the evolved RNNs was examined statistically, providinginteresting findings that can help refine the RNN memory cell design as well asinform future neuro-evolution algorithms development.

Continual Learning of Recurrent Neural Networks by Locally Aligning  Distributed Representations

  Temporal models based on recurrent neural networks have proven to be quitepowerful in a wide variety of applications, including language modeling andspeech processing. However, training these models relies on back-propagationthrough time, which entails unfolding the network over many time steps, makingthe process of conducting credit assignment considerably more challenging.Furthermore, the nature of back-propagation itself does not permit the use ofnon-differentiable activation functions and is inherently sequential, makingparallelization of the training process very difficult.  In this work, we propose the Parallel Temporal Neural Coding Network(P-TNCN), a biologically inspired model trained by the learning algorithm knownas Local Representation Alignment, that aims to resolve the difficulties thatplague recurrent networks trained by back-propagation through time. Mostnotably, this architecture requires neither unrolling nor the derivatives ofits internal activation functions. We compare our model and learning procedureto other online back-propagation-through-time alternatives (which tend to becomputationally expensive), including real-time recurrent learning, echo statenetworks, and unbiased online recurrent optimization, and show that itoutperforms them on sequence benchmarks such as Bouncing MNIST, a new benchmarkwe call Bouncing NotMNIST, and Penn Treebank. Notably, our approach can, insome instances, outperform full back-propagation through time and variants suchas sparse attentive back-tracking.  Significantly, the hidden unit correction phase of P-TNCN allows it to adaptto new datasets even if its synaptic weights are held fixed (zero-shotadaptation) and facilitates retention of prior knowledge when faced with a tasksequence. We present results that show the P-TNCN's ability to conductzero-shot adaptation and continual sequence modeling.

Piecewise Latent Variables for Neural Variational Text Processing

  Advances in neural variational inference have facilitated the learning ofpowerful directed graphical models with continuous latent variables, such asvariational autoencoders. The hope is that such models will learn to representrich, multi-modal latent factors in real-world data, such as natural languagetext. However, current models often assume simplistic priors on the latentvariables - such as the uni-modal Gaussian distribution - which are incapableof representing complex latent factors efficiently. To overcome thisrestriction, we propose the simple, but highly flexible, piecewise constantdistribution. This distribution has the capacity to represent an exponentialnumber of modes of a latent target distribution, while remaining mathematicallytractable. Our results demonstrate that incorporating this new latentdistribution into different models yields substantial improvements in naturallanguage processing tasks such as document modeling and natural languagegeneration for dialogue.

Learning a Hierarchical Latent-Variable Model of 3D Shapes

  We propose the Variational Shape Learner (VSL), a generative model thatlearns the underlying structure of voxelized 3D shapes in an unsupervisedfashion. Through the use of skip-connections, our model can successfully learnand infer a latent, hierarchical representation of objects. Furthermore,realistic 3D objects can be easily generated by sampling the VSL's latentprobabilistic manifold. We show that our generative model can be trainedend-to-end from 2D images to perform single image 3D model retrieval.Experiments show, both quantitatively and qualitatively, the improvedgeneralization of our proposed model over a range of tasks, performing betteror comparable to various state-of-the-art alternatives.

An Empirical Evaluation of Rule Extraction from Recurrent Neural  Networks

  Rule extraction from black-box models is critical in domains that requiremodel validation before implementation, as can be the case in credit scoringand medical diagnosis. Though already a challenging problem in statisticallearning in general, the difficulty is even greater when highly non-linear,recursive models, such as recurrent neural networks (RNNs), are fit to data.Here, we study the extraction of rules from second-order recurrent neuralnetworks trained to recognize the Tomita grammars. We show that productionrules can be stably extracted from trained RNNs and that in certain cases therules outperform the trained RNNs.

Using Neural Generative Models to Release Synthetic Twitter Corpora with  Reduced Stylometric Identifiability of Users

  We present a method for generating synthetic versions of Twitter data usingneural generative models. The goal is protecting individuals in the source datafrom stylometric re-identification attacks while still releasing data thatcarries research value. Specifically, we generate tweet corpora that maintainuser-level word distributions by augmenting the neural language models withuser-specific components. We compare our approach to two standard text dataprotection methods: redaction and iterative translation. We evaluate the threemethods on measures of risk and utility. We define risk following thestylometric models of re-identification, and we define utility based on twogeneral word distribution measures and two common text analysis research tasks.We find that neural models are able to significantly lower risk over previousmethods with little cost to utility. We also demonstrate that the neural modelsallow data providers to actively control the risk-utility trade-off throughmodel tuning parameters. This work presents promising results for a new tooladdressing the problem of privacy for free text and sharing social media datain a way that respects privacy and is ethically responsible.

Using Non-invertible Data Transformations to Build Adversarial-Robust  Neural Networks

  Deep neural networks have proven to be quite effective in a wide variety ofmachine learning tasks, ranging from improved speech recognition systems toadvancing the development of autonomous vehicles. However, despite theirsuperior performance in many applications, these models have been recentlyshown to be susceptible to a particular type of attack possible through thegeneration of particular synthetic examples referred to as adversarial samples.These samples are constructed by manipulating real examples from the trainingdata distribution in order to "fool" the original neural model, resulting inmisclassification (with high confidence) of previously correctly classifiedsamples. Addressing this weakness is of utmost importance if deep neuralarchitectures are to be applied to critical applications, such as those in thedomain of cybersecurity. In this paper, we present an analysis of thisfundamental flaw lurking in all neural architectures to uncover limitations ofpreviously proposed defense mechanisms. More importantly, we present a unifyingframework for protecting deep neural models using a non-invertible datatransformation--developing two adversary-resilient architectures utilizing bothlinear and nonlinear dimensionality reduction. Empirical results indicate thatour framework provides better robustness compared to state-of-art solutionswhile having negligible degradation in accuracy.

A Comparative Study of Rule Extraction for Recurrent Neural Networks

  Understanding recurrent networks through rule extraction has a long history.This has taken on new interests due to the need for interpreting or verifyingneural networks. One basic form for representing stateful rules isdeterministic finite automata (DFA). Previous research shows that extractingDFAs from trained second-order recurrent networks is not only possible but alsorelatively stable. Recently, several new types of recurrent networks with morecomplicated architectures have been introduced. These handle challenginglearning tasks usually involving sequential data. However, it remains an openproblem whether DFAs can be adequately extracted from these models.Specifically, it is not clear how DFA extraction will be affected when appliedto different recurrent networks trained on data sets with different levels ofcomplexity. Here, we investigate DFA extraction on several widely adoptedrecurrent networks that are trained to learn a set of seven regular Tomitagrammars. We first formally analyze the complexity of Tomita grammars andcategorize these grammars according to that complexity. Then we empiricallyevaluate different recurrent networks for their performance of DFA extractionon all Tomita grammars. Our experiments show that for most recurrent networks,their extraction performance decreases as the complexity of the underlyinggrammar increases. On grammars of lower complexity, most recurrent networksobtain desirable extraction performance. As for grammars with the highest levelof complexity, while several complicated models fail with only certainrecurrent networks having satisfactory extraction performance.

A Neural Temporal Model for Human Motion Prediction

  We propose novel neural temporal models for predicting and synthesizing humanmotion, achieving state-of-the-art in modeling long-term motion trajectorieswhile being competitive with prior work in short-term prediction, withsignificantly less required computation. Key aspects of our proposed systeminclude: 1) a novel, two-level processing architecture that aids in generatingplanned trajectories, 2) a simple set of easily computable features thatintegrate derivative information into the model, and 3) a novel multi-objectiveloss function that helps the model to slowly progress from the simpler task ofnext-step prediction to the harder task of multi-step closed-loop prediction.Our results demonstrate that these innovations facilitate improved modeling oflong-term motion trajectories. Finally, we propose a novel metric, calledNormalized Power Spectrum Similarity (NPSS), to evaluate the long-termpredictive ability of motion synthesis models, complementing the popularmean-squared error (MSE) measure of the Euler joint angles over time. Weconduct a user study to determine if the proposed NPSS correlates with humanevaluation of long-term motion more strongly than MSE and find that it indeeddoes.

ExpertSeer: a Keyphrase Based Expert Recommender for Digital Libraries

  We describe ExpertSeer, a generic framework for expert recommendation basedon the contents of a digital library. Given a query term q, ExpertSeerrecommends experts of q by retrieving authors who published relevant papersdetermined by related keyphrases and the quality of papers. The system is basedon a simple yet effective keyphrase extractor and the Bayes' rule for expertrecommendation. ExpertSeer is domain independent and can be applied todifferent disciplines and applications since the system is automated and nottailored to a specific discipline. Digital library providers can employ thesystem to enrich their services and organizations can discover experts ofinterest within an organization. To demonstrate the power of ExpertSeer, weapply the framework to build two expert recommender systems. The first, CSSeer,utilizes the CiteSeerX digital library to recommend experts primarily incomputer science. The second, ChemSeer, uses publicly available documents fromthe Royal Society of Chemistry (RSC) to recommend experts in chemistry. Usingone thousand computer science terms as benchmark queries, we compared the top-nexperts (n=3, 5, 10) returned by CSSeer to two other expert recommenders --Microsoft Academic Search and ArnetMiner -- and a simulator that imitates theranking function of Google Scholar. Although CSSeer, Microsoft Academic Search,and ArnetMiner mostly return prestigious researchers who published severalpapers related to the query term, it was found that different expertrecommenders return moderately different recommendations. To further studytheir performance, we obtained a widely used benchmark dataset as the groundtruth for comparison. The results show that our system outperforms MicrosoftAcademic Search and ArnetMiner in terms of Precision-at-k (P@k) for k=3, 5, 10.We also conducted several case studies to validate the usefulness of oursystem.

Adversary Resistant Deep Neural Networks with an Application to Malware  Detection

  Beyond its highly publicized victories in Go, there have been numeroussuccessful applications of deep learning in information retrieval, computervision and speech recognition. In cybersecurity, an increasing number ofcompanies have become excited about the potential of deep learning, and havestarted to use it for various security incidents, the most popular beingmalware detection. These companies assert that deep learning (DL) could helpturn the tide in the battle against malware infections. However, deep neuralnetworks (DNNs) are vulnerable to adversarial samples, a flaw that plagues mostif not all statistical learning models. Recent research has demonstrated thatthose with malicious intent can easily circumvent deep learning-powered malwaredetection by exploiting this flaw.  In order to address this problem, previous work has developed various defensemechanisms that either augmenting training data or enhance model's complexity.However, after a thorough analysis of the fundamental flaw in DNNs, we discoverthat the effectiveness of current defenses is limited and, more importantly,cannot provide theoretical guarantees as to their robustness againstadversarial sampled-based attacks. As such, we propose a new adversaryresistant technique that obstructs attackers from constructing impactfuladversarial samples by randomly nullifying features within samples. In thiswork, we evaluate our proposed technique against a real world dataset with14,679 malware variants and 17,399 benign programs. We theoretically validatethe robustness of our technique, and empirically show that our techniquesignificantly boosts DNN robustness to adversarial samples while maintaininghigh accuracy in classification. To demonstrate the general applicability ofour proposed method, we also conduct experiments using the MNIST and CIFAR-10datasets, generally used in image recognition research.

Learning Adversary-Resistant Deep Neural Networks

  Deep neural networks (DNNs) have proven to be quite effective in a vast arrayof machine learning tasks, with recent examples in cyber security andautonomous vehicles. Despite the superior performance of DNNs in theseapplications, it has been recently shown that these models are susceptible to aparticular type of attack that exploits a fundamental flaw in their design.This attack consists of generating particular synthetic examples referred to asadversarial samples. These samples are constructed by slightly manipulatingreal data-points in order to "fool" the original DNN model, forcing it tomis-classify previously correctly classified samples with high confidence.Addressing this flaw in the model is essential if DNNs are to be used incritical applications such as those in cyber security.  Previous work has provided various learning algorithms to enhance therobustness of DNN models, and they all fall into the tactic of "securitythrough obscurity". This means security can be guaranteed only if one canobscure the learning algorithms from adversaries. Once the learning techniqueis disclosed, DNNs protected by these defense mechanisms are still susceptibleto adversarial samples. In this work, we investigate this issue shared acrossprevious research work and propose a generic approach to escalate a DNN'sresistance to adversarial samples. More specifically, our approach integrates adata transformation module with a DNN, making it robust even if we reveal theunderlying learning algorithm. To demonstrate the generality of our proposedapproach and its potential for handling cyber security applications, weevaluate our method and several other existing solutions on datasets publiclyavailable. Our results indicate that our approach typically provides superiorclassification performance and resistance in comparison with state-of-artsolutions.

