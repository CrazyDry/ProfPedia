Column2Vec: Structural Understanding via Distributed Representations of
  Database Schemas

  We present Column2Vec, a distributed representation of database columns based
on column metadata. Our distributed representation has several applications.
Using known names for groups of columns (i.e., a table name), we train a model
to generate an appropriate name for columns in an unnamed table. We demonstrate
the viability of our approach using schema information collected from open
source applications on GitHub.


Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and
  Denoising Autoencoders

  Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine and
the Deep Hybrid Denoising Auto-encoder, are proposed for handling
semi-supervised learning problems. The models combine experts that model
relevant distributions at different levels of abstraction to improve overall
predictive performance on discriminative tasks. Theoretical motivations and
algorithms for joint learning for each are presented. We apply the new models
to the domain of data-streams in work towards life-long learning. The proposed
architectures show improved performance compared to a pseudo-labeled, drop-out
rectifier network.


Unifying Adversarial Training Algorithms with Flexible Deep Data
  Gradient Regularization

  Many previous proposals for adversarial training of deep neural nets have
included di- rectly modifying the gradient, training on a mix of original and
adversarial examples, using contractive penalties, and approximately optimizing
constrained adversarial ob- jective functions. In this paper, we show these
proposals are actually all instances of optimizing a general, regularized
objective we call DataGrad. Our proposed DataGrad framework, which can be
viewed as a deep extension of the layerwise contractive au- toencoder penalty,
cleanly simplifies prior work and easily allows extensions such as adversarial
training with multi-task cues. In our experiments, we find that the deep gra-
dient regularization of DataGrad (which also has L1 and L2 flavors of
regularization) outperforms alternative forms of regularization, including
classical L1, L2, and multi- task, both on the original dataset as well as on
adversarial sets. Furthermore, we find that combining multi-task optimization
with DataGrad adversarial training results in the most robust performance.


Learning Simpler Language Models with the Differential State Framework

  Learning useful information across long time lags is a critical and difficult
problem for temporal neural models in tasks such as language modeling. Existing
architectures that address the issue are often complex and costly to train. The
Differential State Framework (DSF) is a simple and high-performing design that
unifies previously introduced gated neural models. DSF models maintain
longer-term memory by learning to interpolate between a fast-changing
data-driven representation and a slowly changing, implicitly stable state. This
requires hardly any more parameters than a classical, simple recurrent network.
Within the DSF framework, a new architecture is presented, the Delta-RNN. In
language modeling at the word and character levels, the Delta-RNN outperforms
popular complex architectures, such as the Long Short Term Memory (LSTM) and
the Gated Recurrent Unit (GRU), and, when regularized, performs comparably to
several state-of-the-art baselines. At the subword level, the Delta-RNN's
performance is comparable to that of complex gated architectures.


Learning to Adapt by Minimizing Discrepancy

  We explore whether useful temporal neural generative models can be learned
from sequential data without back-propagation through time. We investigate the
viability of a more neurocognitively-grounded approach in the context of
unsupervised generative modeling of sequences. Specifically, we build on the
concept of predictive coding, which has gained influence in cognitive science,
in a neural framework. To do so we develop a novel architecture, the Temporal
Neural Coding Network, and its learning algorithm, Discrepancy Reduction. The
underlying directed generative model is fully recurrent, meaning that it
employs structural feedback connections and temporal feedback connections,
yielding information propagation cycles that create local learning signals.
This facilitates a unified bottom-up and top-down approach for information
transfer inside the architecture. Our proposed algorithm shows promise on the
bouncing balls generative modeling problem. Further experiments could be
conducted to explore the strengths and weaknesses of our approach.


Conducting Credit Assignment by Aligning Local Representations

  Using back-propagation and its variants to train deep networks is often
problematic for new users. Issues such as exploding gradients, vanishing
gradients, and high sensitivity to weight initialization strategies often make
networks difficult to train, especially when users are experimenting with new
architectures. Here, we present Local Representation Alignment (LRA), a
training procedure that is much less sensitive to bad initializations, does not
require modifications to the network architecture, and can be adapted to
networks with highly nonlinear and discrete-valued activation functions.
Furthermore, we show that one variation of LRA can start with a null
initialization of network weights and still successfully train networks with a
wide variety of nonlinearities, including tanh, ReLU-6, softplus, signum and
others that may draw their inspiration from biology.
  A comprehensive set of experiments on MNIST and the much harder Fashion MNIST
data sets show that LRA can be used to train networks robustly and effectively,
succeeding even when back-propagation fails and outperforming other alternative
learning algorithms, such as target propagation and feedback alignment.


Learned Neural Iterative Decoding for Lossy Image Compression Systems

  For lossy image compression systems, we develop an algorithm, iterative
refinement, to improve the decoder's reconstruction compared to standard
decoding techniques. Specifically, we propose a recurrent neural network
approach for nonlinear, iterative decoding. Our decoder, which works with any
encoder, employs self-connected memory units that make use of causal and
non-causal spatial context information to progressively reduce reconstruction
error over a fixed number of steps. We experiment with variants of our
estimator and find that iterative refinement consistently creates lower
distortion images of higher perceptual quality compared to other approaches.
Specifically, on the Kodak Lossless True Color Image Suite, we observe as much
as a 0.871 decibel (dB) gain over JPEG, a 1.095 dB gain over JPEG 2000, and a
0.971 dB gain over a competitive neural model.


Visually Grounded, Situated Learning in Neural Models

  The theory of situated cognition postulates that language is inseparable from
its physical context--words, phrases, and sentences must be learned in the
context of the objects or concepts to which they refer. Yet, statistical
language models are trained on words alone. This makes it impossible for
language models to connect to the real world--the world described in the
sentences presented to the model. In this paper, we examine the generalization
ability of neural language models trained with a visual context. A multimodal
connectionist language architecture based on the Differential State Framework
is proposed, which outperforms its equivalent trained on language alone, even
when no visual context is available at test time. Superior performance for
language models trained with a visual context is robust across different
languages and models.


Biologically Motivated Algorithms for Propagating Local Target
  Representations

  Finding biologically plausible alternatives to back-propagation of errors is
a fundamentally important challenge in artificial neural network research. In
this paper, we propose a learning algorithm called error-driven Local
Representation Alignment (LRA-E), which has strong connections to predictive
coding, a theory that offers a mechanistic way of describing neurocomputational
machinery. In addition, we propose an improved variant of Difference Target
Propagation, another procedure that comes from the same family of algorithms as
LRA-E. We compare our procedures to several other biologically-motivated
algorithms, including two feedback alignment algorithms and Equilibrium
Propagation. In two benchmarks, we find that both of our proposed algorithms
yield stable performance and strong generalization compared to other competing
back-propagation alternatives when training deeper, highly nonlinear networks,
with LRA-E performing the best overall.


Investigating Recurrent Neural Network Memory Structures using
  Neuro-Evolution

  This paper presents a new algorithm, Evolutionary eXploration of Augmenting
Memory Models (EXAMM), which is capable of evolving recurrent neural networks
(RNNs) using a wide variety of memory structures, such as Delta-RNN, GRU, LSTM,
MGU and UGRNN cells. EXAMM evolved RNNs to perform prediction of large-scale,
real world time series data from the aviation and power industries. These data
sets consist of very long time series (thousands of readings), each with a
large number of potentially correlated and dependent parameters. Four different
parameters were selected for prediction and EXAMM runs were performed using
each memory cell type alone, each cell type with feed forward nodes, and with
all possible memory cell types. Evolved RNN performance was measured using
repeated k-fold cross validation, resulting in 1210 EXAMM runs which evolved
2,420,000 RNNs in 12,100 CPU hours on a high performance computing cluster.
Generalization of the evolved RNNs was examined statistically, providing
interesting findings that can help refine the RNN memory cell design as well as
inform future neuro-evolution algorithms development.


Continual Learning of Recurrent Neural Networks by Locally Aligning
  Distributed Representations

  Temporal models based on recurrent neural networks have proven to be quite
powerful in a wide variety of applications, including language modeling and
speech processing. However, training these models relies on back-propagation
through time, which entails unfolding the network over many time steps, making
the process of conducting credit assignment considerably more challenging.
Furthermore, the nature of back-propagation itself does not permit the use of
non-differentiable activation functions and is inherently sequential, making
parallelization of the training process very difficult.
  In this work, we propose the Parallel Temporal Neural Coding Network
(P-TNCN), a biologically inspired model trained by the learning algorithm known
as Local Representation Alignment, that aims to resolve the difficulties that
plague recurrent networks trained by back-propagation through time. Most
notably, this architecture requires neither unrolling nor the derivatives of
its internal activation functions. We compare our model and learning procedure
to other online back-propagation-through-time alternatives (which tend to be
computationally expensive), including real-time recurrent learning, echo state
networks, and unbiased online recurrent optimization, and show that it
outperforms them on sequence benchmarks such as Bouncing MNIST, a new benchmark
we call Bouncing NotMNIST, and Penn Treebank. Notably, our approach can, in
some instances, outperform full back-propagation through time and variants such
as sparse attentive back-tracking.
  Significantly, the hidden unit correction phase of P-TNCN allows it to adapt
to new datasets even if its synaptic weights are held fixed (zero-shot
adaptation) and facilitates retention of prior knowledge when faced with a task
sequence. We present results that show the P-TNCN's ability to conduct
zero-shot adaptation and continual sequence modeling.


Piecewise Latent Variables for Neural Variational Text Processing

  Advances in neural variational inference have facilitated the learning of
powerful directed graphical models with continuous latent variables, such as
variational autoencoders. The hope is that such models will learn to represent
rich, multi-modal latent factors in real-world data, such as natural language
text. However, current models often assume simplistic priors on the latent
variables - such as the uni-modal Gaussian distribution - which are incapable
of representing complex latent factors efficiently. To overcome this
restriction, we propose the simple, but highly flexible, piecewise constant
distribution. This distribution has the capacity to represent an exponential
number of modes of a latent target distribution, while remaining mathematically
tractable. Our results demonstrate that incorporating this new latent
distribution into different models yields substantial improvements in natural
language processing tasks such as document modeling and natural language
generation for dialogue.


Learning a Hierarchical Latent-Variable Model of 3D Shapes

  We propose the Variational Shape Learner (VSL), a generative model that
learns the underlying structure of voxelized 3D shapes in an unsupervised
fashion. Through the use of skip-connections, our model can successfully learn
and infer a latent, hierarchical representation of objects. Furthermore,
realistic 3D objects can be easily generated by sampling the VSL's latent
probabilistic manifold. We show that our generative model can be trained
end-to-end from 2D images to perform single image 3D model retrieval.
Experiments show, both quantitatively and qualitatively, the improved
generalization of our proposed model over a range of tasks, performing better
or comparable to various state-of-the-art alternatives.


An Empirical Evaluation of Rule Extraction from Recurrent Neural
  Networks

  Rule extraction from black-box models is critical in domains that require
model validation before implementation, as can be the case in credit scoring
and medical diagnosis. Though already a challenging problem in statistical
learning in general, the difficulty is even greater when highly non-linear,
recursive models, such as recurrent neural networks (RNNs), are fit to data.
Here, we study the extraction of rules from second-order recurrent neural
networks trained to recognize the Tomita grammars. We show that production
rules can be stably extracted from trained RNNs and that in certain cases the
rules outperform the trained RNNs.


Using Neural Generative Models to Release Synthetic Twitter Corpora with
  Reduced Stylometric Identifiability of Users

  We present a method for generating synthetic versions of Twitter data using
neural generative models. The goal is protecting individuals in the source data
from stylometric re-identification attacks while still releasing data that
carries research value. Specifically, we generate tweet corpora that maintain
user-level word distributions by augmenting the neural language models with
user-specific components. We compare our approach to two standard text data
protection methods: redaction and iterative translation. We evaluate the three
methods on measures of risk and utility. We define risk following the
stylometric models of re-identification, and we define utility based on two
general word distribution measures and two common text analysis research tasks.
We find that neural models are able to significantly lower risk over previous
methods with little cost to utility. We also demonstrate that the neural models
allow data providers to actively control the risk-utility trade-off through
model tuning parameters. This work presents promising results for a new tool
addressing the problem of privacy for free text and sharing social media data
in a way that respects privacy and is ethically responsible.


Using Non-invertible Data Transformations to Build Adversarial-Robust
  Neural Networks

  Deep neural networks have proven to be quite effective in a wide variety of
machine learning tasks, ranging from improved speech recognition systems to
advancing the development of autonomous vehicles. However, despite their
superior performance in many applications, these models have been recently
shown to be susceptible to a particular type of attack possible through the
generation of particular synthetic examples referred to as adversarial samples.
These samples are constructed by manipulating real examples from the training
data distribution in order to "fool" the original neural model, resulting in
misclassification (with high confidence) of previously correctly classified
samples. Addressing this weakness is of utmost importance if deep neural
architectures are to be applied to critical applications, such as those in the
domain of cybersecurity. In this paper, we present an analysis of this
fundamental flaw lurking in all neural architectures to uncover limitations of
previously proposed defense mechanisms. More importantly, we present a unifying
framework for protecting deep neural models using a non-invertible data
transformation--developing two adversary-resilient architectures utilizing both
linear and nonlinear dimensionality reduction. Empirical results indicate that
our framework provides better robustness compared to state-of-art solutions
while having negligible degradation in accuracy.


A Comparative Study of Rule Extraction for Recurrent Neural Networks

  Understanding recurrent networks through rule extraction has a long history.
This has taken on new interests due to the need for interpreting or verifying
neural networks. One basic form for representing stateful rules is
deterministic finite automata (DFA). Previous research shows that extracting
DFAs from trained second-order recurrent networks is not only possible but also
relatively stable. Recently, several new types of recurrent networks with more
complicated architectures have been introduced. These handle challenging
learning tasks usually involving sequential data. However, it remains an open
problem whether DFAs can be adequately extracted from these models.
Specifically, it is not clear how DFA extraction will be affected when applied
to different recurrent networks trained on data sets with different levels of
complexity. Here, we investigate DFA extraction on several widely adopted
recurrent networks that are trained to learn a set of seven regular Tomita
grammars. We first formally analyze the complexity of Tomita grammars and
categorize these grammars according to that complexity. Then we empirically
evaluate different recurrent networks for their performance of DFA extraction
on all Tomita grammars. Our experiments show that for most recurrent networks,
their extraction performance decreases as the complexity of the underlying
grammar increases. On grammars of lower complexity, most recurrent networks
obtain desirable extraction performance. As for grammars with the highest level
of complexity, while several complicated models fail with only certain
recurrent networks having satisfactory extraction performance.


A Neural Temporal Model for Human Motion Prediction

  We propose novel neural temporal models for predicting and synthesizing human
motion, achieving state-of-the-art in modeling long-term motion trajectories
while being competitive with prior work in short-term prediction, with
significantly less required computation. Key aspects of our proposed system
include: 1) a novel, two-level processing architecture that aids in generating
planned trajectories, 2) a simple set of easily computable features that
integrate derivative information into the model, and 3) a novel multi-objective
loss function that helps the model to slowly progress from the simpler task of
next-step prediction to the harder task of multi-step closed-loop prediction.
Our results demonstrate that these innovations facilitate improved modeling of
long-term motion trajectories. Finally, we propose a novel metric, called
Normalized Power Spectrum Similarity (NPSS), to evaluate the long-term
predictive ability of motion synthesis models, complementing the popular
mean-squared error (MSE) measure of the Euler joint angles over time. We
conduct a user study to determine if the proposed NPSS correlates with human
evaluation of long-term motion more strongly than MSE and find that it indeed
does.


ExpertSeer: a Keyphrase Based Expert Recommender for Digital Libraries

  We describe ExpertSeer, a generic framework for expert recommendation based
on the contents of a digital library. Given a query term q, ExpertSeer
recommends experts of q by retrieving authors who published relevant papers
determined by related keyphrases and the quality of papers. The system is based
on a simple yet effective keyphrase extractor and the Bayes' rule for expert
recommendation. ExpertSeer is domain independent and can be applied to
different disciplines and applications since the system is automated and not
tailored to a specific discipline. Digital library providers can employ the
system to enrich their services and organizations can discover experts of
interest within an organization. To demonstrate the power of ExpertSeer, we
apply the framework to build two expert recommender systems. The first, CSSeer,
utilizes the CiteSeerX digital library to recommend experts primarily in
computer science. The second, ChemSeer, uses publicly available documents from
the Royal Society of Chemistry (RSC) to recommend experts in chemistry. Using
one thousand computer science terms as benchmark queries, we compared the top-n
experts (n=3, 5, 10) returned by CSSeer to two other expert recommenders --
Microsoft Academic Search and ArnetMiner -- and a simulator that imitates the
ranking function of Google Scholar. Although CSSeer, Microsoft Academic Search,
and ArnetMiner mostly return prestigious researchers who published several
papers related to the query term, it was found that different expert
recommenders return moderately different recommendations. To further study
their performance, we obtained a widely used benchmark dataset as the ground
truth for comparison. The results show that our system outperforms Microsoft
Academic Search and ArnetMiner in terms of Precision-at-k (P@k) for k=3, 5, 10.
We also conducted several case studies to validate the usefulness of our
system.


Adversary Resistant Deep Neural Networks with an Application to Malware
  Detection

  Beyond its highly publicized victories in Go, there have been numerous
successful applications of deep learning in information retrieval, computer
vision and speech recognition. In cybersecurity, an increasing number of
companies have become excited about the potential of deep learning, and have
started to use it for various security incidents, the most popular being
malware detection. These companies assert that deep learning (DL) could help
turn the tide in the battle against malware infections. However, deep neural
networks (DNNs) are vulnerable to adversarial samples, a flaw that plagues most
if not all statistical learning models. Recent research has demonstrated that
those with malicious intent can easily circumvent deep learning-powered malware
detection by exploiting this flaw.
  In order to address this problem, previous work has developed various defense
mechanisms that either augmenting training data or enhance model's complexity.
However, after a thorough analysis of the fundamental flaw in DNNs, we discover
that the effectiveness of current defenses is limited and, more importantly,
cannot provide theoretical guarantees as to their robustness against
adversarial sampled-based attacks. As such, we propose a new adversary
resistant technique that obstructs attackers from constructing impactful
adversarial samples by randomly nullifying features within samples. In this
work, we evaluate our proposed technique against a real world dataset with
14,679 malware variants and 17,399 benign programs. We theoretically validate
the robustness of our technique, and empirically show that our technique
significantly boosts DNN robustness to adversarial samples while maintaining
high accuracy in classification. To demonstrate the general applicability of
our proposed method, we also conduct experiments using the MNIST and CIFAR-10
datasets, generally used in image recognition research.


Learning Adversary-Resistant Deep Neural Networks

  Deep neural networks (DNNs) have proven to be quite effective in a vast array
of machine learning tasks, with recent examples in cyber security and
autonomous vehicles. Despite the superior performance of DNNs in these
applications, it has been recently shown that these models are susceptible to a
particular type of attack that exploits a fundamental flaw in their design.
This attack consists of generating particular synthetic examples referred to as
adversarial samples. These samples are constructed by slightly manipulating
real data-points in order to "fool" the original DNN model, forcing it to
mis-classify previously correctly classified samples with high confidence.
Addressing this flaw in the model is essential if DNNs are to be used in
critical applications such as those in cyber security.
  Previous work has provided various learning algorithms to enhance the
robustness of DNN models, and they all fall into the tactic of "security
through obscurity". This means security can be guaranteed only if one can
obscure the learning algorithms from adversaries. Once the learning technique
is disclosed, DNNs protected by these defense mechanisms are still susceptible
to adversarial samples. In this work, we investigate this issue shared across
previous research work and propose a generic approach to escalate a DNN's
resistance to adversarial samples. More specifically, our approach integrates a
data transformation module with a DNN, making it robust even if we reveal the
underlying learning algorithm. To demonstrate the generality of our proposed
approach and its potential for handling cyber security applications, we
evaluate our method and several other existing solutions on datasets publicly
available. Our results indicate that our approach typically provides superior
classification performance and resistance in comparison with state-of-art
solutions.


