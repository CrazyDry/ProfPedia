A Scalable Asynchronous Distributed Algorithm for Topic Modeling

  Learning meaningful topic models with massive document collections whichcontain millions of documents and billions of tokens is challenging because oftwo reasons: First, one needs to deal with a large number of topics (typicallyin the order of thousands). Second, one needs a scalable and efficient way ofdistributing the computation across multiple machines. In this paper we presenta novel algorithm F+Nomad LDA which simultaneously tackles both these problems.In order to handle large number of topics we use an appropriately modifiedFenwick tree. This data structure allows us to sample from a multinomialdistribution over $T$ items in $O(\log T)$ time. Moreover, when topic countschange the data structure can be updated in $O(\log T)$ time. In order todistribute the computation across multiple processor we present a novelasynchronous framework inspired by the Nomad algorithm of\cite{YunYuHsietal13}. We show that F+Nomad LDA significantly outperformstate-of-the-art on massive problems which involve millions of documents,billions of words, and thousands of topics.

Metric and Kernel Learning using a Linear Transformation

  Metric and kernel learning are important in several machine learningapplications. However, most existing metric learning algorithms are limited tolearning metrics over low-dimensional data, while existing kernel learningalgorithms are often limited to the transductive setting and do not generalizeto new data points. In this paper, we study metric learning as a problem oflearning a linear transformation of the input data. We show that forhigh-dimensional data, a particular framework for learning a lineartransformation of the data based on the LogDet divergence can be efficientlykernelized to learn a metric (or equivalently, a kernel function) over anarbitrarily high dimensional space. We further demonstrate that a wide class ofconvex loss functions for learning linear transformations can similarly bekernelized, thereby considerably expanding the potential applications of metriclearning. We demonstrate our learning approach by applying it to large-scalereal world problems in computer vision and text mining.

Multi-Scale Link Prediction

  The automated analysis of social networks has become an important problem dueto the proliferation of social networks, such as LiveJournal, Flickr andFacebook. The scale of these social networks is massive and continues to growrapidly. An important problem in social network analysis is proximityestimation that infers the closeness of different users. Link prediction, inturn, is an important application of proximity estimation. However, manymethods for computing proximity measures have high computational complexity andare thus prohibitive for large-scale link prediction problems. One way toaddress this problem is to estimate proximity measures via low-rankapproximation. However, a single low-rank approximation may not be sufficientto represent the behavior of the entire network. In this paper, we proposeMulti-Scale Link Prediction (MSLP), a framework for link prediction, which canhandle massive networks. The basis idea of MSLP is to construct low rankapproximations of the network at multiple scales in an efficient manner. Basedon this approach, MSLP combines predictions at multiple scales to make robustand accurate predictions. Experimental results on real-life datasets with morethan a million nodes show the superior performance and scalability of ourmethod.

Sparse Inverse Covariance Matrix Estimation Using Quadratic  Approximation

  The L1-regularized Gaussian maximum likelihood estimator (MLE) has been shownto have strong statistical guarantees in recovering a sparse inverse covariancematrix, or alternatively the underlying graph structure of a Gaussian MarkovRandom Field, from very limited samples. We propose a novel algorithm forsolving the resulting optimization problem which is a regularizedlog-determinant program. In contrast to recent state-of-the-art methods thatlargely use first order gradient information, our algorithm is based onNewton's method and employs a quadratic approximation, but with somemodifications that leverage the structure of the sparse Gaussian MLE problem.We show that our method is superlinearly convergent, and present experimentalresults using synthetic and real-world application data that demonstrate theconsiderable improvements in performance of our method when compared to otherstate-of-the-art methods.

NOMAD: Non-locking, stOchastic Multi-machine algorithm for Asynchronous  and Decentralized matrix completion

  We develop an efficient parallel distributed algorithm for matrix completion,named NOMAD (Non-locking, stOchastic Multi-machine algorithm for Asynchronousand Decentralized matrix completion). NOMAD is a decentralized algorithm withnon-blocking communication between processors. One of the key features of NOMADis that the ownership of a variable is asynchronously transferred betweenprocessors in a decentralized fashion. As a consequence it is a lock-freeparallel algorithm. In spite of being an asynchronous algorithm, the variableupdates of NOMAD are serializable, that is, there is an equivalent updateordering in a serial implementation. NOMAD outperforms synchronous algorithmswhich require explicit bulk synchronization after every iteration: ourextensive empirical evaluation shows that not only does our algorithm performwell in distributed setting on commodity hardware, but also outperformsstate-of-the-art algorithms on a HPC cluster both in multi-core and distributedmemory settings.

Proximal Quasi-Newton for Computationally Intensive L1-regularized  M-estimators

  We consider the class of optimization problems arising from computationallyintensive L1-regularized M-estimators, where the function or gradient valuesare very expensive to compute. A particular instance of interest is theL1-regularized MLE for learning Conditional Random Fields (CRFs), which are apopular class of statistical models for varied structured prediction problemssuch as sequence labeling, alignment, and classification with label taxonomy.L1-regularized MLEs for CRFs are particularly expensive to optimize sincecomputing the gradient values requires an expensive inference step. In thiswork, we propose the use of a carefully constructed proximal quasi-Newtonalgorithm for such computationally intensive M-estimation problems, where weemploy an aggressive active set selection technique. In a key contribution ofthe paper, we show that the proximal quasi-Newton method is provablysuper-linearly convergent, even in the absence of strong convexity, byleveraging a restricted variant of strong convexity. In our experiments, theproposed algorithm converges considerably faster than current state-of-the-arton the problems of sequence labeling and hierarchical classification.

Optimal Decision-Theoretic Classification Using Non-Decomposable  Performance Metrics

  We provide a general theoretical analysis of expected out-of-sample utility,also referred to as decision-theoretic classification, for non-decomposablebinary classification metrics such as F-measure and Jaccard coefficient. Ourkey result is that the expected out-of-sample utility for many performancemetrics is provably optimized by a classifier which is equivalent to a signedthresholding of the conditional probability of the positive class. Our analysisbridges a gap in the literature on binary classification, revealed in light ofrecent results for non-decomposable metrics in population utility maximizationstyle classification. Our results identify checkable properties of aperformance metric which are sufficient to guarantee a probability rankingprinciple. We propose consistent estimators for optimal expected out-of-sampleclassification. As a consequence of the probability ranking principle,computational requirements can be reduced from exponential to cubic complexityin the general case, and further reduced to quadratic complexity in specialcases. We provide empirical results on simulated and benchmark datasetsevaluating the performance of the proposed algorithms for decision-theoreticclassification and comparing them to baseline and state-of-the-art methods inpopulation utility maximization for non-decomposable metrics.

Preference Completion: Large-scale Collaborative Ranking from Pairwise  Comparisons

  In this paper we consider the collaborative ranking setting: a pool of userseach provides a small number of pairwise preferences between $d$ possibleitems; from these we need to predict preferences of the users for items theyhave not yet seen. We do so by fitting a rank $r$ score matrix to the pairwisedata, and provide two main contributions: (a) we show that an algorithm basedon convex optimization provides good generalization guarantees once each userprovides as few as $O(r\log^2 d)$ pairwise comparisons -- essentially matchingthe sample complexity required in the related matrix completion setting (whichuses actual numerical as opposed to pairwise information), and (b) we develop alarge-scale non-convex implementation, which we call AltSVM, that trains afactored form of the matrix via alternating minimization (which we show reducesto alternating SVM problems), and scales and parallelizes very well to largeproblem settings. It also outperforms common baselines on many moderately largepopular collaborative filtering datasets in both NDCG and in other measures ofranking performance.

High-dimensional Time Series Prediction with Missing Values

  High-dimensional time series prediction is needed in applications as diverseas demand forecasting and climatology. Often, such applications require methodsthat are both highly scalable, and deal with noisy data in terms of corruptionsor missing values. Classical time series methods usually fall short of handlingboth these issues. In this paper, we propose to adapt matrix matrix completionapproaches that have previously been successfully applied to large scale noisydata, but which fail to adequately model high-dimensional time series due totemporal dependencies. We present a novel temporal regularized matrixfactorization (TRMF) framework which supports data-driven temporal dependencylearning and enables forecasting ability to our new matrix factorizationapproach. TRMF is highly general, and subsumes many existing matrixfactorization approaches for time series data. We make interesting connectionsto graph regularized matrix factorization methods in the context of learningthe dependencies. Experiments on both real and synthetic data show that TRMFoutperforms several existing approaches for common time series tasks.

Square Root Graphical Models: Multivariate Generalizations of Univariate  Exponential Families that Permit Positive Dependencies

  We develop Square Root Graphical Models (SQR), a novel class of parametricgraphical models that provides multivariate generalizations of univariateexponential family distributions. Previous multivariate graphical models [Yanget al. 2015] did not allow positive dependencies for the exponential andPoisson generalizations. However, in many real-world datasets, variablesclearly have positive dependencies. For example, the airport delay time in NewYork---modeled as an exponential distribution---is positively related to thedelay time in Boston. With this motivation, we give an example of our modelclass derived from the univariate exponential distribution that allows foralmost arbitrary positive and negative dependencies with only a mild conditionon the parameter matrix---a condition akin to the positive definiteness of theGaussian covariance matrix. Our Poisson generalization allows for both positiveand negative dependencies without any constraints on the parameter values. Wealso develop parameter estimation methods using node-wise regressions with$\ell_1$ regularization and likelihood approximation methods using sampling.Finally, we demonstrate our exponential generalization on a synthetic datasetand a real-world dataset of airport delay times.

A Greedy Approach for Budgeted Maximum Inner Product Search

  Maximum Inner Product Search (MIPS) is an important task in many machinelearning applications such as the prediction phase of a low-rank matrixfactorization model for a recommender system. There have been some works on howto perform MIPS in sub-linear time recently. However, most of them do not havethe flexibility to control the trade-off between search efficient and searchquality. In this paper, we study the MIPS problem with a computational budget.By carefully studying the problem structure of MIPS, we develop a novelGreedy-MIPS algorithm, which can handle budgeted MIPS by design. While simpleand intuitive, Greedy-MIPS yields surprisingly superior performance compared tostate-of-the-art approaches. As a specific example, on a candidate setcontaining half a million vectors of dimension 200, Greedy-MIPS runs 200xfaster than the naive approach while yielding search results with the top-5precision greater than 75\%.

Learning Non-overlapping Convolutional Neural Networks with Multiple  Kernels

  In this paper, we consider parameter recovery for non-overlappingconvolutional neural networks (CNNs) with multiple kernels. We show that whenthe inputs follow Gaussian distribution and the sample size is sufficientlylarge, the squared loss of such CNNs is $\mathit{~locally~strongly~convex}$ ina basin of attraction near the global optima for most popular activationfunctions, like ReLU, Leaky ReLU, Squared ReLU, Sigmoid and Tanh. The requiredsample complexity is proportional to the dimension of the input and polynomialin the number of kernels and a condition number of the parameters. We also showthat tensor methods are able to initialize the parameters to the local strongconvex region. Hence, for most smooth activations, gradient descent followingtensor initialization is guaranteed to converge to the global optimal with timethat is linear in input dimension, logarithmic in precision and polynomial inother factors. To the best of our knowledge, this is the first work thatprovides recovery guarantees for CNNs with multiple kernels under polynomialsample and computational complexities.

Learning Long Term Dependencies via Fourier Recurrent Units

  It is a known fact that training recurrent neural networks for tasks thathave long term dependencies is challenging. One of the main reasons is thevanishing or exploding gradient problem, which prevents gradient informationfrom propagating to early layers. In this paper we propose a simple recurrentarchitecture, the Fourier Recurrent Unit (FRU), that stabilizes the gradientsthat arise in its training while giving us stronger expressive power.Specifically, FRU summarizes the hidden states $h^{(t)}$ along the temporaldimension with Fourier basis functions. This allows gradients to easily reachany layer due to FRU's residual learning structure and the global support oftrigonometric functions. We show that FRU has gradient lower and upper boundsindependent of temporal dimension. We also show the strong expressivity ofsparse Fourier basis, from which FRU obtains its strong expressive power. Ourexperimental study also demonstrates that with fewer parameters the proposedarchitecture outperforms other recurrent architectures on many tasks.

Extreme Stochastic Variational Inference: Distributed and Asynchronous

  Stochastic variational inference (SVI), the state-of-the-art algorithm forscaling variational inference to large-datasets, is inherently serial.Moreover, it requires the parameters to fit in the memory of a singleprocessor; this is problematic when the number of parameters is in billions. Inthis paper, we propose extreme stochastic variational inference (ESVI), anasynchronous and lock-free algorithm to perform variational inference formixture models on massive real world datasets. ESVI overcomes the limitationsof SVI by requiring that each processor only access a subset of the data and asubset of the parameters, thus providing data and model parallelismsimultaneously. We demonstrate the effectiveness of ESVI by running LatentDirichlet Allocation (LDA) on UMBC-3B, a dataset that has a vocabulary of 3million and a token size of 3 billion. In our experiments, we found that ESVInot only outperforms VI and SVI in wallclock-time, but also achieves a betterquality solution. In addition, we propose a strategy to speed up computationand save memory when fitting large number of topics.

Guaranteed Rank Minimization via Singular Value Projection

  Minimizing the rank of a matrix subject to affine constraints is afundamental problem with many important applications in machine learning andstatistics. In this paper we propose a simple and fast algorithm SVP (SingularValue Projection) for rank minimization with affine constraints (ARMP) and showthat SVP recovers the minimum rank solution for affine constraints that satisfythe "restricted isometry property" and show robustness of our method to noise.Our results improve upon a recent breakthrough by Recht, Fazel and Parillo(RFP07) and Lee and Bresler (LB09) in three significant ways:  1) our method (SVP) is significantly simpler to analyze and easier toimplement,  2) we give recovery guarantees under strictly weaker isometry assumptions  3) we give geometric convergence guarantees for SVP even in presense of noiseand, as demonstrated empirically, SVP is significantly faster on real-world andsynthetic problems.  In addition, we address the practically important problem of low-rank matrixcompletion (MCP), which can be seen as a special case of ARMP. We empiricallydemonstrate that our algorithm recovers low-rank incoherent matrices from analmost optimal number of uniformly sampled entries. We make partial progresstowards proving exact recovery and provide some intuition for the strongperformance of SVP applied to matrix completion by showing a more restrictedisometry property. Our algorithm outperforms existing methods, such as those of\cite{RFP07,CR08,CT09,CCS08,KOM09,LB09}, for ARMP and the matrix-completionproblem by an order of magnitude and is also significantly more robust tonoise.

Orthogonal Matching Pursuit with Replacement

  In this paper, we consider the problem of compressed sensing where the goalis to recover almost all the sparse vectors using a small number of fixedlinear measurements. For this problem, we propose a novel partialhard-thresholding operator that leads to a general family of iterativealgorithms. While one extreme of the family yields well known hard thresholdingalgorithms like ITI (Iterative Thresholding with Inversion) and HTP (HardThresholding Pursuit), the other end of the spectrum leads to a novel algorithmthat we call Orthogonal Matching Pursuit with Replacement (OMPR). OMPR, likethe classic greedy algorithm OMP, adds exactly one coordinate to the support ateach iteration, based on the correlation with the current residual. However,unlike OMP, OMPR also removes one coordinate from the support. This simplechange allows us to prove that OMPR has the best known guarantees for sparserecovery in terms of the Restricted Isometry Property (a condition on themeasurement matrix). In contrast, OMP is known to have very weak performanceguarantees under RIP. Given its simple structure, we are able to extend OMPRusing locality sensitive hashing to get OMPR-Hash, the first provablysub-linear (in dimensionality) algorithm for sparse recovery. Our prooftechniques are novel and flexible enough to also permit the tightest knownanalysis of popular iterative algorithms such as CoSaMP and Subspace Pursuit.We provide experimental results on large problems providing recovery forvectors of size up to million dimensions. We demonstrate that for large-scaleproblems our proposed methods are more robust and faster than existing methods.

Provable Inductive Matrix Completion

  Consider a movie recommendation system where apart from the ratingsinformation, side information such as user's age or movie's genre is alsoavailable. Unlike standard matrix completion, in this setting one should beable to predict inductively on new users/movies. In this paper, we study theproblem of inductive matrix completion in the exact recovery setting. That is,we assume that the ratings matrix is generated by applying feature vectors to alow-rank matrix and the goal is to recover back the underlying matrix.Furthermore, we generalize the problem to that of low-rank matrix estimationusing rank-1 measurements. We study this generic problem and provide conditionsthat the set of measurements should satisfy so that the alternatingminimization method (which otherwise is a non-convex method with no convergenceguarantees) is able to recover back the {\em exact} underlying low-rank matrix.  In addition to inductive matrix completion, we show that two other low-rankestimation problems can be studied in our framework: a) general low-rank matrixsensing using rank-1 measurements, and b) multi-label regression with missinglabels. For both the problems, we provide novel and interesting bounds on thenumber of measurements required by alternating minimization to provablyconverges to the {\em exact} low-rank matrix. In particular, our analysis forthe general low rank matrix sensing problem significantly improves the requiredstorage and computational cost than that required by the RIP-based matrixsensing methods \cite{RechtFP2007}. Finally, we provide empirical validation ofour approach and demonstrate that alternating minimization is able to recoverthe true matrix for the above mentioned problems using a small number ofmeasurements.

Large-scale Multi-label Learning with Missing Labels

  The multi-label classification problem has generated significant interest inrecent years. However, existing approaches do not adequately address two keychallenges: (a) the ability to tackle problems with a large number (saymillions) of labels, and (b) the ability to handle data with missing labels. Inthis paper, we directly address both these problems by studying the multi-labelproblem in a generic empirical risk minimization (ERM) framework. Ourframework, despite being simple, is surprisingly able to encompass severalrecent label-compression based methods which can be derived as special cases ofour method. To optimize the ERM problem, we develop techniques that exploit thestructure of specific loss functions - such as the squared loss function - tooffer efficient algorithms. We further show that our learning framework admitsformal excess risk bounds even in the presence of missing labels. Our riskbounds are tight and demonstrate better generalization performance for low-rankpromoting trace-norm regularization when compared to (rank insensitive)Frobenius norm regularization. Finally, we present extensive empirical resultson a variety of benchmark datasets and show that our methods performsignificantly better than existing label compression based methods and canscale up to very large datasets such as the Wikipedia dataset.

A Divide-and-Conquer Solver for Kernel Support Vector Machines

  The kernel support vector machine (SVM) is one of the most widely usedclassification methods; however, the amount of computation required becomes thebottleneck when facing millions of samples. In this paper, we propose andanalyze a novel divide-and-conquer solver for kernel SVMs (DC-SVM). In thedivision step, we partition the kernel SVM problem into smaller subproblems byclustering the data, so that each subproblem can be solved independently andefficiently. We show theoretically that the support vectors identified by thesubproblem solution are likely to be support vectors of the entire kernel SVMproblem, provided that the problem is partitioned appropriately by kernelclustering. In the conquer step, the local solutions from the subproblems areused to initialize a global coordinate descent solver, which converges quicklyas suggested by our analysis. By extending this idea, we develop a multilevelDivide-and-Conquer SVM algorithm with adaptive clustering and early predictionstrategy, which outperforms state-of-the-art methods in terms of trainingspeed, testing accuracy, and memory usage. As an example, on the covtypedataset with half-a-million samples, DC-SVM is 7 times faster than LIBSVM inobtaining the exact SVM solution (to within $10^{-6}$ relative error) whichachieves 96.15% prediction accuracy. Moreover, with our proposed earlyprediction strategy, DC-SVM achieves about 96% accuracy in only 12 minutes,which is more than 100 times faster than LIBSVM.

Overlapping Community Detection Using Neighborhood-Inflated Seed  Expansion

  Community detection is an important task in network analysis. A community(also referred to as a cluster) is a set of cohesive vertices that have moreconnections inside the set than outside. In many social and informationnetworks, these communities naturally overlap. For instance, in a socialnetwork, each vertex in a graph corresponds to an individual who usuallyparticipates in multiple communities. In this paper, we propose an efficientoverlapping community detection algorithm using a seed expansion approach. Thekey idea of our algorithm is to find good seeds, and then greedily expand theseseeds based on a community metric. Within this seed expansion method, weinvestigate the problem of how to determine good seed nodes in a graph. Inparticular, we develop new seeding strategies for a personalized PageRankclustering scheme that optimizes the conductance community score. Experimentalresults show that our seed expansion algorithm outperforms otherstate-of-the-art overlapping community detection methods in terms of producingcohesive clusters and identifying ground-truth communities. We also show thatour new seeding strategies are better than existing strategies, and are thuseffective in finding good overlapping communities in real-world networks.

PASSCoDe: Parallel ASynchronous Stochastic dual Co-ordinate Descent

  Stochastic Dual Coordinate Descent (SDCD) has become one of the mostefficient ways to solve the family of $\ell_2$-regularized empirical riskminimization problems, including linear SVM, logistic regression, and manyothers. The vanilla implementation of DCD is quite slow; however, bymaintaining primal variables while updating dual variables, the time complexityof SDCD can be significantly reduced. Such a strategy forms the core algorithmin the widely-used LIBLINEAR package. In this paper, we parallelize the SDCDalgorithms in LIBLINEAR. In recent research, several synchronized parallel SDCDalgorithms have been proposed, however, they fail to achieve good speedup inthe shared memory multi-core setting. In this paper, we propose a family ofasynchronous stochastic dual coordinate descent algorithms (ASDCD). Each threadrepeatedly selects a random dual variable and conducts coordinate updates usingthe primal variables that are stored in the shared memory. We analyze theconvergence properties when different locking/atomic mechanisms are applied.For implementation with atomic operations, we show linear convergence undermild conditions. For implementation without any atomic operations or locking,we present the first {\it backward error analysis} for ASDCD under themulti-core environment, showing that the converged solution is the exactsolution for a primal problem with perturbed regularizer. Experimental resultsshow that our methods are much faster than previous parallel coordinate descentsolvers.

Fast Multiplier Methods to Optimize Non-exhaustive, Overlapping  Clustering

  Clustering is one of the most fundamental and important tasks in data mining.Traditional clustering algorithms, such as K-means, assign every data point toexactly one cluster. However, in real-world datasets, the clusters may overlapwith each other. Furthermore, often, there are outliers that should not belongto any cluster. We recently proposed the NEO-K-Means (Non-Exhaustive,Overlapping K-Means) objective as a way to address both issues in an integratedfashion. Optimizing this discrete objective is NP-hard, and even though thereis a convex relaxation of the objective, straightforward convex optimizationapproaches are too expensive for large datasets. A practical alternative is touse a low-rank factorization of the solution matrix in the convex formulation.The resulting optimization problem is non-convex, and we can locally optimizethe objective function using an augmented Lagrangian method. In this paper, weconsider two fast multiplier methods to accelerate the convergence of anaugmented Lagrangian scheme: a proximal method of multipliers and analternating direction method of multipliers (ADMM). For the proximal augmentedLagrangian or proximal method of multipliers, we show a convergence result forthe non-convex case with bound-constrained subproblems. These methods are up to13 times faster---with no change in quality---compared with a standardaugmented Lagrangian method on problems with over 10,000 variables and bringruntimes down from over an hour to around 5 minutes.

Generalized Root Models: Beyond Pairwise Graphical Models for Univariate  Exponential Families

  We present a novel k-way high-dimensional graphical model called theGeneralized Root Model (GRM) that explicitly models dependencies betweenvariable sets of size k > 2---where k = 2 is the standard pairwise graphicalmodel. This model is based on taking the k-th root of the original sufficientstatistics of any univariate exponential family with positive sufficientstatistics, including the Poisson and exponential distributions. As in therecent work with square root graphical (SQR) models [Inouye et al.2016]---which was restricted to pairwise dependencies---we give the conditionsof the parameters that are needed for normalization using the radialconditionals similar to the pairwise case [Inouye et al. 2016]. In particular,we show that the Poisson GRM has no restrictions on the parameters and theexponential GRM only has a restriction akin to negative definiteness. Wedevelop a simple but general learning algorithm based on L1-regularizednode-wise regressions. We also present a general way of numericallyapproximating the log partition function and associated derivatives of the GRMunivariate node conditionals---in contrast to [Inouye et al. 2016], which onlyprovided algorithm for estimating the exponential SQR. To illustrate GRM, wemodel word counts with a Poisson GRM and show the associated k-sized variablesets. We finish by discussing methods for reducing the parameter space invarious situations.

Communication-Efficient Parallel Block Minimization for Kernel Machines

  Kernel machines often yield superior predictive performance on various tasks;however, they suffer from severe computational challenges. In this paper, weshow how to overcome the important challenge of speeding up kernel machines. Inparticular, we develop a parallel block minimization framework for solvingkernel machines, including kernel SVM and kernel logistic regression. Ourframework proceeds by dividing the problem into smaller subproblems by forminga block-diagonal approximation of the Hessian matrix. The subproblems are thensolved approximately in parallel. After that, a communication efficient linesearch procedure is developed to ensure sufficient reduction of the objectivefunction value at each iteration. We prove global linear convergence rate ofthe proposed method with a wide class of subproblem solvers, and our analysiscovers strongly convex and some non-strongly convex functions. We apply ouralgorithm to solve large-scale kernel SVM problems on distributed systems, andshow a significant improvement over existing parallel solvers. As an example,on the covtype dataset with half-a-million samples, our algorithm can obtain anapproximate solution with 96% accuracy in 20 seconds using 32 machines, whileall the other parallel kernel SVM solvers require more than 2000 seconds toachieve a solution with 95% accuracy. Moreover, our algorithm can scale to verylarge data sets, such as the kdd algebra dataset with 8 million samples and 20million features.

Similarity Preserving Representation Learning for Time Series Analysis

  A considerable amount of machine learning algorithms take instance-featurematrices as their inputs. As such, they cannot directly analyze time seriesdata due to its temporal nature, usually unequal lengths, and complexproperties. This is a great pity since many of these algorithms are effective,robust, efficient, and easy to use. In this paper, we bridge this gap byproposing an efficient representation learning framework that is able toconvert a set of time series with equal or unequal lengths to a matrix format.In particular, we guarantee that the pairwise similarities between time seriesare well preserved after the transformation. The learned feature representationis particularly suitable to the class of learning problems that are sensitiveto data similarities. Given a set of $n$ time series, we first construct an$n\times n$ partially observed similarity matrix by randomly sampling $O(n \logn)$ pairs of time series and computing their pairwise similarities. We thenpropose an extremely efficient algorithm that solves a highly non-convex andNP-hard problem to learn new features based on the partially observedsimilarity matrix. We use the learned features to conduct experiments on bothdata classification and clustering tasks. Our extensive experimental resultsdemonstrate that the proposed framework is both effective and efficient.

Recovery Guarantees for One-hidden-layer Neural Networks

  In this paper, we consider regression problems with one-hidden-layer neuralnetworks (1NNs). We distill some properties of activation functions that leadto $\mathit{local~strong~convexity}$ in the neighborhood of the ground-truthparameters for the 1NN squared-loss objective. Most popular nonlinearactivation functions satisfy the distilled properties, including rectifiedlinear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activationfunctions that are also smooth, we show $\mathit{local~linear~convergence}$guarantees of gradient descent under a resampling rule. For homogeneousactivations, we show tensor methods are able to initialize the parameters tofall into the local strong convexity region. As a result, tensor initializationfollowed by gradient descent is guaranteed to recover the ground truth withsample complexity $ d \cdot \log(1/\epsilon) \cdot \mathrm{poly}(k,\lambda )$and computational complexity $n\cdot d \cdot \mathrm{poly}(k,\lambda) $ forsmooth homogeneous activations with high probability, where $d$ is thedimension of the input, $k$ ($k\leq d$) is the number of hidden nodes,$\lambda$ is a conditioning property of the ground-truth parameter matrixbetween the input layer and the hidden layer, $\epsilon$ is the targetedprecision and $n$ is the number of samples. To the best of our knowledge, thisis the first work that provides recovery guarantees for 1NNs with both samplecomplexity and computational complexity $\mathit{linear}$ in the inputdimension and $\mathit{logarithmic}$ in the precision.

Stabilizing Gradients for Deep Neural Networks via Efficient SVD  Parameterization

  Vanishing and exploding gradients are two of the main obstacles in trainingdeep neural networks, especially in capturing long range dependencies inrecurrent neural networks~(RNNs). In this paper, we present an efficientparametrization of the transition matrix of an RNN that allows us to stabilizethe gradients that arise in its training. Specifically, we parameterize thetransition matrix by its singular value decomposition(SVD), which allows us toexplicitly track and control its singular values. We attain efficiency by usingtools that are common in numerical linear algebra, namely Householderreflectors for representing the orthogonal matrices that arise in the SVD. Byexplicitly controlling the singular values, our proposed Spectral-RNN methodallows us to easily solve the exploding gradient problem and we observe that itempirically solves the vanishing gradient issue to a large extent. We note thatthe SVD parameterization can be used for any rectangular weight matrix, henceit can be easily extended to any deep neural network, such as a multi-layerperceptron. Theoretically, we demonstrate that our parameterization does notlose any expressive power, and show how it controls generalization of RNN forthe classification task. %, and show how it potentially makes the optimizationprocess easier. Our extensive experimental results also demonstrate that theproposed framework converges faster, and has good generalization, especially incapturing long range dependencies, as shown on the synthetic addition and copytasks, as well as on MNIST and Penn Tree Bank data sets.

Discrete Adversarial Attacks and Submodular Optimization with  Applications to Text Classification

  Adversarial examples are carefully constructed modifications to an input thatcompletely change the output of a classifier but are imperceptible to humans.Despite these successful attacks for continuous data (such as image and audiosamples), generating adversarial examples for discrete structures such as texthas proven significantly more challenging. In this paper we formulate theattacks with discrete input on a set function as an optimization task. We provethat this set function is submodular for some popular neural network textclassifiers under simplifying assumption. This finding guarantees a $1-1/e$approximation factor for attacks that use the greedy algorithm. Meanwhile, weshow how to use the gradient of the attacked classifier to guide the greedysearch. Empirical studies with our proposed optimization scheme showsignificantly improved attack ability and efficiency, on three different textclassification tasks over various baselines. We also use a joint sentence andword paraphrasing technique to maintain the original semantics and syntax ofthe text. This is validated by a human subject evaluation in subjective metricson the quality and semantic coherence of our generated adversarial text.

The Limitations of Adversarial Training and the Blind-Spot Attack

  The adversarial training procedure proposed by Madry et al. (2018) is one ofthe most effective methods to defend against adversarial examples in deepneural networks (DNNs). In our paper, we shed some lights on the practicalityand the hardness of adversarial training by showing that the effectiveness(robustness on test set) of adversarial training has a strong correlation withthe distance between a test point and the manifold of training data embedded bythe network. Test examples that are relatively far away from this manifold aremore likely to be vulnerable to adversarial attacks. Consequentially, anadversarial training based defense is susceptible to a new class of attacks,the "blind-spot attack", where the input images reside in "blind-spots" (lowdensity regions) of the empirical distribution of training data but is still onthe ground-truth data manifold. For MNIST, we found that these blind-spots canbe easily found by simply scaling and shifting image pixel values. Mostimportantly, for large datasets with high dimensional and complex data manifold(CIFAR, ImageNet, etc), the existence of blind-spots in adversarial trainingmakes defending on any valid test examples difficult due to the curse ofdimensionality and the scarcity of training data. Additionally, we find thatblind-spots also exist on provable defenses including (Wong & Kolter, 2018) and(Sinha et al., 2018) because these trainable robustness certificates can onlybe practically optimized on a limited set of training data.

Prediction and Clustering in Signed Networks: A Local to Global  Perspective

  The study of social networks is a burgeoning research area. However, mostexisting work deals with networks that simply encode whether relationshipsexist or not. In contrast, relationships in signed networks can be positive("like", "trust") or negative ("dislike", "distrust"). The theory of socialbalance shows that signed networks tend to conform to some local patterns that,in turn, induce certain global characteristics. In this paper, we exploit bothlocal as well as global aspects of social balance theory for two fundamentalproblems in the analysis of signed networks: sign prediction and clustering.Motivated by local patterns of social balance, we first propose two families ofsign prediction methods: measures of social imbalance (MOIs), and supervisedlearning using high order cycles (HOCs). These methods predict signs of edgesbased on triangles and \ell-cycles for relatively small values of \ell.Interestingly, by examining measures of social imbalance, we show that theclassic Katz measure, which is used widely in unsigned link prediction,actually has a balance theoretic interpretation when applied to signednetworks. Furthermore, motivated by the global structure of balanced networks,we propose an effective low rank modeling approach for both sign prediction andclustering. For the low rank modeling approach, we provide theoreticalperformance guarantees via convex relaxations, scale it up to large problemsizes using a matrix factorization based algorithm, and provide extensiveexperimental validation including comparisons with local approaches. Ourexperimental results indicate that, by adopting a more global viewpoint ofbalance structure, we get significant performance and computational gains inprediction and clustering tasks on signed networks. Our work thereforehighlights the usefulness of the global aspect of balance theory for theanalysis of signed networks.

PU Learning for Matrix Completion

  In this paper, we consider the matrix completion problem when theobservations are one-bit measurements of some underlying matrix M, and inparticular the observed samples consist only of ones and no zeros. This problemis motivated by modern applications such as recommender systems and socialnetworks where only "likes" or "friendships" are observed. The problem oflearning from only positive and unlabeled examples, called PU(positive-unlabeled) learning, has been studied in the context of binaryclassification. We consider the PU matrix completion problem, where anunderlying real-valued matrix M is first quantized to generate one-bitobservations and then a subset of positive entries is revealed. Under theassumption that M has bounded nuclear norm, we provide recovery guarantees fortwo different observation models: 1) M parameterizes a distribution thatgenerates a binary matrix, 2) M is thresholded to obtain a binary matrix. Forthe first case, we propose a "shifted matrix completion" method that recovers Musing only a subset of indices corresponding to ones, while for the secondcase, we propose a "biased matrix completion" method that recovers the(thresholded) binary matrix. Both methods yield strong error bounds --- if M isn by n, the Frobenius error is bounded as O(1/((1-rho)n), where 1-rho denotesthe fraction of ones observed. This implies a sample complexity of O(n\log n)ones to achieve a small error, when M is dense and n is large. We extend ourmethods and guarantees to the inductive matrix completion problem, where rowsand columns of M have associated features. We provide efficient and scalableoptimization procedures for both the methods and demonstrate the effectivenessof the proposed methods for link prediction (on real-world networks consistingof over 2 million nodes and 90 million links) and semi-supervised clusteringtasks.

Towards Fast Computation of Certified Robustness for ReLU Networks

  Verifying the robustness property of a general Rectified Linear Unit (ReLU)network is an NP-complete problem [Katz, Barrett, Dill, Julian and KochenderferCAV17]. Although finding the exact minimum adversarial distortion is hard,giving a certified lower bound of the minimum distortion is possible. Currentavailable methods of computing such a bound are either time-consuming ordelivering low quality bounds that are too loose to be useful. In this paper,we exploit the special structure of ReLU networks and provide twocomputationally efficient algorithms Fast-Lin and Fast-Lip that are able tocertify non-trivial lower bounds of minimum distortions, by bounding the ReLUunits with appropriate linear functions Fast-Lin, or by bounding the localLipschitz constant Fast-Lip. Experiments show that (1) our proposed methodsdeliver bounds close to (the gap is 2-3X) exact minimum distortion found byReluplex in small MNIST networks while our algorithms are more than 10,000times faster; (2) our methods deliver similar quality of bounds (the gap iswithin 35% and usually around 10%; sometimes our bounds are even better) forlarger networks compared to the methods based on solving linear programmingproblems but our algorithms are 33-14,000 times faster; (3) our method iscapable of solving large MNIST and CIFAR networks up to 7 layers with more than10,000 neurons within tens of seconds on a single CPU core.  In addition, we show that, in fact, there is no polynomial time algorithmthat can approximately find the minimum $\ell_1$ adversarial distortion of aReLU network with a $0.99\ln n$ approximation ratio unless$\mathsf{NP}$=$\mathsf{P}$, where $n$ is the number of neurons in the network.

Nonlinear Inductive Matrix Completion based on One-layer Neural Networks

  The goal of a recommendation system is to predict the interest of a user in agiven item by exploiting the existing set of ratings as well as certainuser/item features. A standard approach to modeling this problem is InductiveMatrix Completion where the predicted rating is modeled as an inner product ofthe user and the item features projected onto a latent space. In order to learnthe parameters effectively from a small number of observed ratings, the latentspace is constrained to be low-dimensional which implies that the parametermatrix is constrained to be low-rank. However, such bilinear modeling of theratings can be limiting in practice and non-linear prediction functions canlead to significant improvements. A natural approach to introducingnon-linearity in the prediction function is to apply a non-linear activationfunction on top of the projected user/item features. Imposition ofnon-linearities further complicates an already challenging problem that has twosources of non-convexity: a) low-rank structure of the parameter matrix, and b)non-linear activation function. We show that one can still solve the non-linearInductive Matrix Completion problem using gradient descent type methods as longas the solution is initialized well. That is, close to the optima, theoptimization function is strongly convex and hence admits standard optimizationtechniques, at least for certain activation functions, such as Sigmoid andtanh. We also highlight the importance of the activation function and show howReLU can behave significantly differently than say a sigmoid function. Finally,we apply our proposed technique to recommendation systems and semi-supervisedclustering, and show that our method can lead to much better performance thanstandard linear Inductive Matrix Completion methods.

SysML: The New Frontier of Machine Learning Systems

  Machine learning (ML) techniques are enjoying rapidly increasing adoption.However, designing and implementing the systems that support ML models inreal-world deployments remains a significant obstacle, in large part due to theradically different development and deployment profile of modern ML methods,and the range of practical concerns that come with broader adoption. We proposeto foster a new systems machine learning research community at the intersectionof the traditional systems and ML communities, focused on topics such ashardware systems for ML, software systems for ML, and ML optimized for metricsbeyond predictive accuracy. To do this, we describe a new conference, SysML,that explicitly targets research at the intersection of systems and machinelearning with a program committee split evenly between experts in systems andML, and an explicit focus on topics at the intersection of the two.

