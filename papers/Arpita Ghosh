A study on some combinatorial sets in partial semigroup

  In the partial semigroup framework, this article deals with the close
investigation of the combinatorial sets which play an important role in the
study of combinatorics. Also, we study the pullback and push-forward properties
of those sets.


The Study of Magnetically Deformed Atoms in the Outer Crust of Neutron
  Stars in Presence of Strong Quantizing Magnetic Field

  We have studied the various properties of magnetically deformed atoms,
replaced by deformed Wigner-Seitz cells, at the outer crust region of strongly
magnetized neutron stars (magnetars) using a relativistic version of
Thomas-Fermi model in cylindrical coordinates.


A Generalized Central Sets Theorem In Partial Semigroups

  The most powerful formulation of the Central Sets Theorem in an arbitrary
semigroup was proved in the work of De, Hindman, and Strauss. The sets which
satisfy the conclusion of the above Central Sets Theorem are called $C$-sets.
The original Central Sets Theorem was extended by J. McLeod for adequate
commutative partial semigroups. In this work, we will extend the Central Sets
Theorem obtained by taking all possible adequate sequences in a commutative
adequate partial semigroup. We shall also discuss a sufficient condition for
being a set $C$-set in our context.


Work Function of Strongly Magnetized Neutron Star Crustal Matter and the
  Associated Magneto-Sphere

  Following an extremely interesting idea \cite{R1}, published long ago, the
work function at the outer crust region of a strongly magnetized neutron star
is obtained using relativistic version of Thomas-Fermi type model. In the
present scenario, the work function becomes anisotropic; the longitudinal part
is an increasing function of magnetic field strength, whereas the transverse
part diverges. An approximate estimate of the electron density in the
magnetosphere due to field emission and photo emission current, from the polar
cap region are obtained.


Anisotropic Nature of Work Function in Strong Quantizing Magnetic Field

  Following an extremely interesting idea \cite{R1}, published long ago, the
work function associated with the emission of ultra-relativistic electrons from
magnetically deformed metallic crystal of astrophysical relevance is obtained
using relativistic version of Thomas-Fermi type model. In the present scenario,
surprisingly, the work function becomes anisotropic; the longitudinal part is
an increasing function of magnetic field strength, whereas the transverse part
diverges.


A Relativistic Generalization of Fowler-Nordheim Cold Emission in
  Presence of Strong Magnetic Field

  A relativistic version of cold emission of electrons in presence of strong
magnetic field, relevant for strongly magnetized neutron stars is obtained. It
is found that in this scenario, a scalar type potential barrier does not allow
quantum tunneling through the surface. Whereas, in presence of a vector type
surface barrier, the probability of electron emission is much larger compared
to the original Fowler-Nordheim cold emission of electrons. It is found that
the relativistic version in presence of strong magnetic field does not follow
exponential decay.


A Theoretical Study of the Magnetically Deformed Inner Crust Matter of
  Magnetars

  We have studied various physical properties of magnetically deformed atoms
and the associated matter, replacing the atoms by the deformed Wigner-Seitz
(WS) cells at the crustal region of strongly magnetized neutron stars
(magnetars). A relativistic version of Thomas-Fermi (TF) model in presence of
strong magnetic field in cylindrical coordinates is used to study the
properties of such matter.


Decay dynamics in a strongly driven atom-molecule coupled system

  Within the framework of master equation, we study decay dynamics of an
atom-molecule system strongly coupled by two photoassociation lasers. Summing
over the infinite number of electromagnetic vacuum modes that are coupled to
the laser-dressed atom-molecule system, we obtain an integro-differential
master equation for the the system's reduced density matrix. The equation is
numerically solved to describe system dynamics in the presence of decay. In
particular, we discuss correlated spontaneous emission from a pair of
electronically excited diatomic ro-vibrational states due to their laser
induced coupling to the ground continuum of atomic scattering states. This
allows us to calculate time-dependence of emitted radiation intensity. It
exhibits quantum beats due to coherent dynamics. The phase difference between
the two driving fields is found to significantly affect the decay dynamics and
the beats. Our results demonstrate the possibility to control decay from the
molecular excited states and the decoherence between them by changing the
relative intensity and the phase between the lasers. We further show that, if
the ground-state continuum has a shape resonance at a low energy, then the
quantum beats show two distinctive time scales of oscillations in the strong
coupling regime. One of the time scales originates from the energy gap between
the two excited states while the other time scale corresponds to the collision
energy at which free-bound Franck-Condon overlap is resonantly peaked due to
the shape resonance.


Implementing Optimal Outcomes in Social Computing: A Game-Theoretic
  Approach

  In many social computing applications such as online Q&A forums, the best
contribution for each task receives some high reward, while all remaining
contributions receive an identical, lower reward irrespective of their actual
qualities. Suppose a mechanism designer (site owner) wishes to optimize an
objective that is some function of the number and qualities of received
contributions. When potential contributors are strategic agents, who decide
whether to contribute or not to selfishly maximize their own utilities, is such
a "best contribution" mechanism, M_B, adequate to implement an outcome that is
optimal for the mechanism designer?
  We first show that in settings where a contribution's value is determined
primarily by an agent's expertise, and agents only strategically choose whether
to contribute or not, contests can implement optimal outcomes: for any
reasonable objective, the rewards for the best and remaining contributions in
M_B can always be chosen so that the outcome in the unique symmetric
equilibrium of M_B maximizes the mechanism designer's utility. We also show how
the mechanism designer can learn these optimal rewards when she does not know
the parameters of the agents' utilities, as might be the case in practice. We
next consider settings where a contribution's value depends on both the
contributor's expertise as well as her effort, and agents endogenously choose
how much effort to exert in addition to deciding whether to contribute. Here,
we show that optimal outcomes can never be implemented by contests if the
system can rank the qualities of contributions perfectly. However, if there is
noise in the contributions' rankings, then the mechanism designer can again
induce agents to follow strategies that maximize his utility. Thus imperfect
rankings can actually help achieve implementability of optimal outcomes when
effort is endogenous and influences quality.


Crowdsourcing with Endogenous Entry

  We investigate the design of mechanisms to incentivize high quality in
crowdsourcing environments with strategic agents, when entry is an endogenous,
strategic choice. Modeling endogenous entry in crowdsourcing is important
because there is a nonzero cost to making a contribution of any quality which
can be avoided by not participating, and indeed many sites based on
crowdsourced content do not have adequate participation. We use a mechanism
with monotone, rank-based, rewards in a model where agents strategically make
participation and quality choices to capture a wide variety of crowdsourcing
environments, ranging from conventional crowdsourcing contests to crowdsourced
content as in online Q&A forums.
  We first explicitly construct the unique mixed-strategy equilibrium for such
monotone rank-order mechanisms, and use these participation probabilities and
quality distribution to address the design of incentives for two kinds of
rewards that arise in crowdsourcing. We first show that for attention rewards
as in crowdsourced content, the entire equilibrium distribution improves when
the rewards for every rank but the last are as high as possible. In particular,
when producing the lowest quality content has low cost, the optimal mechanism
displays all but the worst contribution. We next investigate settings where
there is a total reward that can be arbitrarily distributed amongst all
participants, as in crowdsourcing contests. Unlike with exogenous entry, here
the expected number of participants can be increased by subsidizing entry,
which could potentially improve the expected quality of the best contribution.
However, we show that free entry is dominated by taxing entry- making all
entrants pay a small fee, which is rebated to the winner along with whatever
rewards were already assigned, can improve the quality of the best contribution
over a winner-take-all contest with no taxes.


Crowdsourced Judgement Elicitation with Endogenous Proficiency

  Crowdsourcing is now widely used to replace judgement by an expert authority
with an aggregate evaluation from a number of non-experts, in applications
ranging from rating and categorizing online content to evaluation of student
assignments in massively open online courses via peer grading. A key issue in
these settings, where direct monitoring is infeasible, is incentivizing agents
in the `crowd' to put in effort to make good evaluations, as well as to
truthfully report their evaluations. This leads to a new family of information
elicitation problems with unobservable ground truth, where an agent's
proficiency- the probability with which she correctly evaluates the underlying
ground truth- is endogenously determined by her strategic choice of how much
effort to put into the task.
  Our main contribution is a simple, new, mechanism for binary information
elicitation for multiple tasks when agents have endogenous proficiencies, with
the following properties: (i) Exerting maximum effort followed by truthful
reporting of observations is a Nash equilibrium. (ii) This is the equilibrium
with maximum payoff to all agents, even when agents have different maximum
proficiencies, can use mixed strategies, and can choose a different strategy
for each of their tasks. Our information elicitation mechanism requires only
minimal bounds on the priors, asks agents to only report their own evaluations,
and does not require any conditions on a diverging number of agent reports per
task to achieve its incentive properties. The main idea behind our mechanism is
to use the presence of multiple tasks and ratings to identify and penalize
low-effort agreement: the mechanism rewards agents for agreeing with a
`reference' rater on a task but also penalizes for blind agreement by
subtracting out a statistic term designed so that agents obtain reward only
when they put effort into their observations.


Bidding for Representative Allocations for Display Advertising

  Display advertising has traditionally been sold via guaranteed contracts -- a
guaranteed contract is a deal between a publisher and an advertiser to allocate
a certain number of impressions over a certain period, for a pre-specified
price per impression. However, as spot markets for display ads, such as the
RightMedia Exchange, have grown in prominence, the selection of advertisements
to show on a given page is increasingly being chosen based on price, using an
auction. As the number of participants in the exchange grows, the price of an
impressions becomes a signal of its value. This correlation between price and
value means that a seller implementing the contract through bidding should
offer the contract buyer a range of prices, and not just the cheapest
impressions necessary to fulfill its demand.
  Implementing a contract using a range of prices, is akin to creating a mutual
fund of advertising impressions, and requires {\em randomized bidding}. We
characterize what allocations can be implemented with randomized bidding,
namely those where the desired share obtained at each price is a non-increasing
function of price. In addition, we provide a full characterization of when a
set of campaigns are compatible and how to implement them with randomized
bidding strategies.


Towards Design and Implementation of Space Efficient and Secured
  Transmission scheme on EGovernance data

  We know that large amount of data and information should be transmitted
through internet during transactions in E-Governance. Smart E-Governance system
should deliver speedy, space efficient, cost effective and secure services
among other governments and its citizens utilizing benefits of Information and
Communication Technologies (ICT). This paper proposes to develop a space
efficient and secured data transmission scheme using Modified Huffman algorithm
for compression, which will also yield better bandwidth utilization and inner
encryption technique with one way hash function SHA (Secured Hash Algorithm) to
ensure Message integrity.


Bargaining for Revenue Shares on Tree Trading Networks

  We study trade networks with a tree structure, where a seller with a single
indivisible good is connected to buyers, each with some value for the good, via
a unique path of intermediaries. Agents in the tree make multiplicative revenue
share offers to their parent nodes, who choose the best offer and offer part of
it to their parent, and so on; the winning path is determined by who finally
makes the highest offer to the seller. In this paper, we investigate how these
revenue shares might be set via a natural bargaining process between agents on
the tree, specifically, egalitarian bargaining between endpoints of each edge
in the tree. We investigate the fixed point of this system of bargaining
equations and prove various desirable for this solution concept, including (i)
existence, (ii) uniqueness, (iii) efficiency, (iv) membership in the core, (v)
strict monotonicity, (vi) polynomial-time computability to any given accuracy.
Finally, we present numerical evidence that asynchronous dynamics with randomly
ordered updates always converges to the fixed point, indicating that the fixed
point shares might arise from decentralized bargaining amongst agents on the
trade network.


Nonclassical properties of states engineered by superpositions of
  quantum operations on classical states

  We consider an experimentally realizable scheme for manipulating quantum
states using a general superposition of products of field annihilation
($\hat{a}$) and creation ($\hat{a}^\dag$) operators of the type ($s
\hat{a}\hat{a}^\dag+ t \hat{a}^\dag \hat{a}$), with $s^2 + t^2 = 1$. Such an
operation, when applied on states with classical features, is shown to
introduce strong nonclassicality. We quantify the generated degree of
nonclassicality by the negative volume of Wigner distribution in the phase
space and investigate two other observable nonclassical features,
sub-Poissonian statistics and squeezing. We find that the operation introduces
negativity in the Wigner distribution of an input coherent state and changes
the Gaussianity of an input thermal state. This provides the possibility of
engineering quantum states with specific nonclassical features.


Fowler-Nordheim Electron Cold Emission Formalism in Presence of Strong
  Magnetic Field

  Formalisms for both non-relativistic as well as relativistic versions of
field emission of electrons in presence of strong quantizing magnetic field,
relevant for strongly magnetized neutron stars or magnetars are developed. In
the non-relativistic scenario, where electrons obey Schr{$\ddot{\rm{o}}$}dinger
equation, we have noticed that when Landau levels are populated for electrons
in presence of strong quantizing magnetic field the transmission probability
exactly vanishes unless the electrons are spin polarized in the opposite
direction to the external magnetic field. On the other hand, the cold electron
emission under the influence of strong electrostatic field at the poles is
totally forbidden from the surface of those compact objects for which the
surface magnetic field strength is $\gg 10^{15}$G (in the eventuality that they
may exist). Whereas in the relativistic case, where the electrons obey Dirac
equation, the presence of strong quantizing magnetic field completely forbids
the emission of electrons from the surface of compact objects if $B >10^{13}$G.


Device Independent Quantum Private Query with Finite Number of Entangled
  Qubits

  In a recent work by Maitra et al. (Phys. Rev. A, 2017), it was shown that the
existing Quantum Private Query (QPQ) protocols fail to maintain the database
security if the entangled states shared between Alice and Bob are not of a
certain form. So it is necessary to certify the states a priori. In this
regard, the local CHSH test was proposed. However, the proposed scheme works
perfectly for the asymptotic case when we have infinite number of qubits. In
this brief report, we upgrade the protocol for finite number of qubits and
connect the sample size to the success probability of CHSH test. We also
perform a rigorous security analysis of the proposed protocol.


Games With Tolerant Players

  A notion of pi-tolerant equilibrium is defined that takes into account that
players have some tolerance regarding payoffs in a game. This solution concept
generalizes Nash and refines epsilon-Nash equilibrium in a natural way. We show
that pi-tolerant equilibrium can explain cooperation in social dilemmas such as
Prisoner's Dilemma and the Public Good game. We then examine the structure of
particularly cooperative pi-tolerant equilibria, where players are as
cooperative as they can be, subject to their tolerances, in Prisoner's Dilemma.
To the extent that cooperation is due to tolerance, these results provide
guidance to a mechanism designer who has some control over the payoffs in a
game, and suggest ways in which cooperation can be increased.


Improvement in Cell Imaging by Applying a New Natural Dye from Beet Root
  Extraction

  Fluorescent dyes are getting popularity for last few decades due to their
extraordinary applications in cell imaging. We have discovered organic Beet
root extracted fluorescent (BREF) dye as an efficient pigment for effective
cell imaging. By applying this dye to different types of human cells we
obtained very good results in fluorescence cell imaging in case of all types of
cells. We also have seen that this dye takes very less internalization time to
give very good image of cells and remains stable for sufficiently long period.


Universally Utility-Maximizing Privacy Mechanisms

  A mechanism for releasing information about a statistical database with
sensitive data must resolve a trade-off between utility and privacy. Privacy
can be rigorously quantified using the framework of {\em differential privacy},
which requires that a mechanism's output distribution is nearly the same
whether or not a given database row is included or excluded. The goal of this
paper is strong and general utility guarantees, subject to differential
privacy.
  We pursue mechanisms that guarantee near-optimal utility to every potential
user, independent of its side information (modeled as a prior distribution over
query results) and preferences (modeled via a loss function).
  Our main result is: for each fixed count query and differential privacy
level, there is a {\em geometric mechanism} $M^*$ -- a discrete variant of the
simple and well-studied Laplace mechanism -- that is {\em simultaneously
expected loss-minimizing} for every possible user, subject to the differential
privacy constraint. This is an extremely strong utility guarantee: {\em every}
potential user $u$, no matter what its side information and preferences,
derives as much utility from $M^*$ as from interacting with a differentially
private mechanism $M_u$ that is optimally tailored to $u$.


Controllable quantum correlations of two-photon states generated using
  classically driven three-level atoms

  We investigate the dynamics of two-photon correlations generated by the
interaction of a three-level atom in the $\Xi$, $\Lambda$ or V configuration,
with two classical external driving fields, under the rotating-wave
approximation, in the presence of level decays. Using the example of a rubidium
atom in each configuration, with field strengths validating the single-photon
approximation, we compute measurement based correlations, such as measurement
induced disturbance (MID), quantum discord (QD), and quantum work deficit (WD),
and compare the results with that of quantum entanglement (concurrence).
Certain correlation properties observed are generic, model independent and
consistent with known results, e.g., MID is an upper bound on QD, QD and WD are
monotonic, and the generic correlation behavior is strongly affected by the
purity of the photon states. We observe that the qualitative hierarchy,
monotonicity and steady-state behavior of the correlations can be controlled by
the choice of parameters such as atomic decay constants and external driving
field strengths. We point out how particular configurations are better suited
at generating monotonic correlations in specific regimes and how the
steady-state correlation behavior and hierarchy are affected by the population
dynamics of the density matrix for different parameters. The possibility of
using well studied quantum optical systems such as the three-level atom to
generate, characterize and parametrically control mixed state quantum
correlations establishes an important step in the direction of their
implementation in quantum information tasks.


Buying Private Data without Verification

  We consider the problem of designing a survey to aggregate non-verifiable
information from a privacy-sensitive population: an analyst wants to compute
some aggregate statistic from the private bits held by each member of a
population, but cannot verify the correctness of the bits reported by
participants in his survey. Individuals in the population are strategic agents
with a cost for privacy, \ie, they not only account for the payments they
expect to receive from the mechanism, but also their privacy costs from any
information revealed about them by the mechanism's outcome---the computed
statistic as well as the payments---to determine their utilities. How can the
analyst design payments to obtain an accurate estimate of the population
statistic when individuals strategically decide both whether to participate and
whether to truthfully report their sensitive information?
  We design a differentially private peer-prediction mechanism that supports
accurate estimation of the population statistic as a Bayes-Nash equilibrium in
settings where agents have explicit preferences for privacy. The mechanism
requires knowledge of the marginal prior distribution on bits $b_i$, but does
not need full knowledge of the marginal distribution on the costs $c_i$,
instead requiring only an approximate upper bound. Our mechanism guarantees
$\epsilon$-differential privacy to each agent $i$ against any adversary who can
observe the statistical estimate output by the mechanism, as well as the
payments made to the $n-1$ other agents $j\neq i$. Finally, we show that with
slightly more structured assumptions on the privacy cost functions of each
agent, the cost of running the survey goes to $0$ as the number of agents
diverges.


Inferential Privacy Guarantees for Differentially Private Mechanisms

  The correlations and network structure amongst individuals in datasets
today---whether explicitly articulated, or deduced from biological or
behavioral connections---pose new issues around privacy guarantees, because of
inferences that can be made about one individual from another's data. This
motivates quantifying privacy in networked contexts in terms of "inferential
privacy"---which measures the change in beliefs about an individual's data from
the result of a computation---as originally proposed by Dalenius in the 1970's.
Inferential privacy is implied by differential privacy when data are
independent, but can be much worse when data are correlated; indeed, simple
examples, as well as a general impossibility theorem of Dwork and Naor,
preclude the possibility of achieving non-trivial inferential privacy when the
adversary can have arbitrary auxiliary information. In this paper, we ask how
differential privacy guarantees translate to guarantees on inferential privacy
in networked contexts: specifically, under what limitations on the adversary's
information about correlations, modeled as a prior distribution over datasets,
can we deduce an inferential guarantee from a differential one?
  We prove two main results. The first result pertains to distributions that
satisfy a natural positive-affiliation condition, and gives an upper bound on
the inferential privacy guarantee for any differentially private mechanism.
This upper bound is matched by a simple mechanism that adds Laplace noise to
the sum of the data. The second result pertains to distributions that have weak
correlations, defined in terms of a suitable "influence matrix". The result
provides an upper bound for inferential privacy in terms of the differential
privacy parameter and the spectral norm of this matrix.


Truthful Assignment without Money

  We study the design of truthful mechanisms that do not use payments for the
generalized assignment problem (GAP) and its variants. An instance of the GAP
consists of a bipartite graph with jobs on one side and machines on the other.
Machines have capacities and edges have values and sizes; the goal is to
construct a welfare maximizing feasible assignment. In our model of private
valuations, motivated by impossibility results, the value and sizes on all
job-machine pairs are public information; however, whether an edge exists or
not in the bipartite graph is a job's private information.
  We study several variants of the GAP starting with matching. For the
unweighted version, we give an optimal strategyproof mechanism; for maximum
weight bipartite matching, however, we show give a 2-approximate strategyproof
mechanism and show by a matching lowerbound that this is optimal. Next we study
knapsack-like problems, which are APX-hard. For these problems, we develop a
general LP-based technique that extends the ideas of Lavi and Swamy to reduce
designing a truthful mechanism without money to designing such a mechanism for
the fractional version of the problem, at a loss of a factor equal to the
integrality gap in the approximation ratio. We use this technique to obtain
strategyproof mechanisms with constant approximation ratios for these problems.
We then design an O(log n)-approximate strategyproof mechanism for the GAP by
reducing, with logarithmic loss in the approximation, to our solution for the
value-invariant GAP. Our technique may be of independent interest for designing
truthful mechanisms without money for other LP-based problems.


Competitive Equilibria in Matching Markets with Budgets

  We study competitive equilibria in the classic Shapley-Shubik assignment
model with indivisible goods and unit-demand buyers, with budget constraints:
buyers can specify a maximum price they are willing to pay for each item,
beyond which they cannot afford the item. This single discontinuity introduced
by the budget constraint fundamentally changes the properties of equilibria: in
the assignment model without budget constraints, a competitive equilibrium
always exists, and corresponds exactly to a stable matching. With budgets, a
competitive equilibrium need not always exist. In addition, there are now two
distinct notions of stability, depending on whether both or only one of the
buyer and seller can strictly benefit in a blocking pair, that no longer
coincide due to the budget-induced discontinuity. We define weak and strong
stability for the assignment model with transferable utilities, and show that
competitive equilibria correspond exactly to strongly stable matchings.
  We consider the algorithmic question of efficiently computing competitive
equilibria in an extension of the assignment model with budgets, where each
buyer specifies his preferences over items using utility functions $u_{ij}$,
where $u_{ij}(p_j)$ is the utility of buyer $i$ for item $j$ when its price is
$p_j$. Our main result is a strongly polynomial time algorithm that decides
whether or not a competitive equilibrium exists and if yes, computes a minimum
one, for a general class of utility functions $u_{ij}$. This class of utility
functions includes the standard quasi-linear utility model with a budget
constraint, and in addition, allows modeling marketplaces where, for example,
buyers only have a preference ranking amongst items subject to a maximum
payment limit for each item, or where buyers want to optimize return on
investment (ROI) instead of a quasi-linear utility and only know items'
relative values.


Selling Privacy at Auction

  We initiate the study of markets for private data, though the lens of
differential privacy. Although the purchase and sale of private data has
already begun on a large scale, a theory of privacy as a commodity is missing.
In this paper, we propose to build such a theory. Specifically, we consider a
setting in which a data analyst wishes to buy information from a population
from which he can estimate some statistic. The analyst wishes to obtain an
accurate estimate cheaply. On the other hand, the owners of the private data
experience some cost for their loss of privacy, and must be compensated for
this loss. Agents are selfish, and wish to maximize their profit, so our goal
is to design truthful mechanisms. Our main result is that such auctions can
naturally be viewed and optimally solved as variants of multi-unit procurement
auctions. Based on this result, we derive auctions for two natural settings
which are optimal up to small constant factors:
  1. In the setting in which the data analyst has a fixed accuracy goal, we
show that an application of the classic Vickrey auction achieves the analyst's
accuracy goal while minimizing his total payment.
  2. In the setting in which the data analyst has a fixed budget, we give a
mechanism which maximizes the accuracy of the resulting estimate while
guaranteeing that the resulting sum payments do not exceed the analysts budget.
  In both cases, our comparison class is the set of envy-free mechanisms, which
correspond to the natural class of fixed-price mechanisms in our setting.
  In both of these results, we ignore the privacy cost due to possible
correlations between an individuals private data and his valuation for privacy
itself. We then show that generically, no individually rational mechanism can
compensate individuals for the privacy loss incurred due to their reported
valuations for privacy.


Mapping generalized Jaynes-Cummings interaction into correlated
  finite-sized systems

  We consider a generalized Jaynes-Cummings model of a two-level atom
interacting with a multimode nondegenerate coherent field. The sum of the mode
frequencies is equal to the two-level transition frequency, creating the
resonance condition. The intermediate levels associated with the multi-photon
process are adiabatically eliminated using the non-resonant conditions for
these transitions. Under such general conditions, the infinite atom-multiphoton
interaction is effectively mapped onto an equivalent reduced
\textit{2}$\times$\textit{2} bipartite qubit system that facilitates the study
of the nonclassical features of the interaction using known
information-theoretic measures. We observe that the bipartite pure system is
highly entangled as quantified by its entanglement of formation. Further, it is
shown that the dynamics of the mapped system can be generated using optically
truncated, quantum scissored states that reduce the infinite atom-multiphoton
interaction to a finite \textit{2}$\times$\textit{k} system, where $k$ is a
suitable truncation number. This allows us to introduce atomic dephasing and
study the mixed state dynamics, characterized by the decay of quantum
correlations such as quantum discord, which is observed to be more robust than
entanglement. The quantum correlation dynamics of the dissipative system
qualitatively complements the behavior of collapse and revival of the Rabi
oscillations in the system. The effective mapping of the composite system
proves to be an efficient tool for measuring information-theoretic properties.


Behavioral Mechanism Design: Optimal Contests for Simple Agents

  Incentives are more likely to elicit desired outcomes when they are designed
based on accurate models of agents' strategic behavior. A growing literature,
however, suggests that people do not quite behave like standard economic agents
in a variety of environments, both online and offline. What consequences might
such differences have for the optimal design of mechanisms in these
environments? In this paper, we explore this question in the context of optimal
contest design for simple agents---agents who strategically reason about
whether or not to participate in a system, but not about the input they provide
to it. Specifically, consider a contest where $n$ potential contestants with
types $(q_i,c_i)$ each choose between participating and producing a submission
of quality $q_i$ at cost $c_i$, versus not participating at all, to maximize
their utilities. How should a principal distribute a total prize $V$ amongst
the $n$ ranks to maximize some increasing function of the qualities of elicited
submissions in a contest with such simple agents?
  We first solve the optimal contest design problem for settings with
homogenous participation costs $c_i = c$. Here, the optimal contest is always a
simple contest, awarding equal prizes to the top $j^*$ contestants for a
suitable choice of $j^*$. (In comparable models with strategic effort choices,
the optimal contest is either a winner-take-all contest or awards possibly
unequal prizes, depending on the curvature of agents' effort cost functions.)
We next address the general case with heterogeneous costs where agents' types
are inherently two-dimensional, significantly complicating equilibrium
analysis. Our main result here is that the winner-take-all contest is a
3-approximation of the optimal contest when the principal's objective is to
maximize the quality of the best elicited contribution.


Generating continuous variable entangled states for quantum
  teleportation using a superposition of number-conserving operations

  We investigate the states generated in continuous variable (CV) optical
fields on operating them with a number-conserving operator of the type
$s\hat{a}\hat{a}^\dag + t\hat{a}^\dag\hat{a}$, formed by the generalised
superposition of products of field annihilation ($\hat{a}$) and creation
($\hat{a}^\dag$) operators, with $s^2+t^2=1$. Such an operator is
experimentally realizable and can be suitably manipulated to generate
nonclassical optical states when applied on single- and two-mode coherent,
thermal, and squeezed input states. At low intensities, these nonclassical
states can interact with a secondary mode via a linear optical device to
generate two-mode discrete entangled states, which can serve as a resource in
quantum information protocols. The advantage of these operations are tested by
applying the generated entangled states as quantum channels in CV quantum
teleportation, under the Braunstein and Kimble protocol. We observe that, under
these operations, while the average fidelity of CV teleportation is enhanced
for the nonclassical channel formed using input squeezed states, it remains at
the classical threshold for input coherent and thermal states. This is due to
the fact that though these operations can introduce discrete entanglement in
all input states, it enhances the Einstein-Podolosky-Rosen (EPR) correlations
only in the nonclassical squeezed state inputs, leading to an advantage in CV
teleportation. This shows that nonclassical optical states generated using the
above operations on classical coherent and thermal state inputs are not
resourceful for CV teleportation. This investigation could prove useful in
efficient implementation of noisy non-Gaussian channels, formed by linear
operations, in future teleportation protocols.


