Variable Elimination in the Fourier Domain

  The ability to represent complex high dimensional probability distributions
in a compact form is one of the key insights in the field of graphical models.
Factored representations are ubiquitous in machine learning and lead to major
computational advantages. We explore a different type of compact representation
based on discrete Fourier representations, complementing the classical approach
based on conditional independencies. We show that a large class of
probabilistic graphical models have a compact Fourier representation. This
theoretical result opens up an entirely new way of approximating a probability
distribution. We demonstrate the significance of this approach by applying it
to the variable elimination algorithm. Compared with the traditional bucket
representation and other approximate inference algorithms, we obtain
significant improvements.


Solving Marginal MAP Problems with NP Oracles and Parity Constraints

  Arising from many applications at the intersection of decision making and
machine learning, Marginal Maximum A Posteriori (Marginal MAP) Problems unify
the two main classes of inference, namely maximization (optimization) and
marginal inference (counting), and are believed to have higher complexity than
both of them. We propose XOR_MMAP, a novel approach to solve the Marginal MAP
Problem, which represents the intractable counting subproblem with queries to
NP oracles, subject to additional parity constraints. XOR_MMAP provides a
constant factor approximation to the Marginal MAP Problem, by encoding it as a
single optimization in polynomial size of the original problem. We evaluate our
approach in several machine learning and decision making applications, and show
that our approach outperforms several state-of-the-art Marginal MAP solvers.


Phase-Mapper: An AI Platform to Accelerate High Throughput Materials
  Discovery

  High-Throughput materials discovery involves the rapid synthesis,
measurement, and characterization of many different but structurally-related
materials. A key problem in materials discovery, the phase map identification
problem, involves the determination of the crystal phase diagram from the
materials' composition and structural characterization data. We present
Phase-Mapper, a novel AI platform to solve the phase map identification problem
that allows humans to interact with both the data and products of AI
algorithms, including the incorporation of human feedback to constrain or
initialize solutions. Phase-Mapper affords incorporation of any spectral
demixing algorithm, including our novel solver, AgileFD, which is based on a
convolutive non-negative matrix factorization algorithm. AgileFD can
incorporate constraints to capture the physics of the materials as well as
human feedback. We compare three solver variants with previously proposed
methods in a large-scale experiment involving 20 synthetic systems,
demonstrating the efficacy of imposing physical constrains using AgileFD.
Phase-Mapper has also been used by materials scientists to solve a wide variety
of phase diagrams, including the previously unsolved Nb-Mn-V oxide system,
which is provided here as an illustrative example.


XOR-Sampling for Network Design with Correlated Stochastic Events

  Many network optimization problems can be formulated as stochastic network
design problems in which edges are present or absent stochastically.
Furthermore, protective actions can guarantee that edges will remain present.
We consider the problem of finding the optimal protection strategy under a
budget limit in order to maximize some connectivity measurements of the
network. Previous approaches rely on the assumption that edges are independent.
In this paper, we consider a more realistic setting where multiple edges are
not independent due to natural disasters or regional events that make the
states of multiple edges stochastically correlated. We use Markov Random Fields
to model the correlation and define a new stochastic network design framework.
We provide a novel algorithm based on Sample Average Approximation (SAA)
coupled with a Gibbs or XOR sampler. The experimental results on real road
network data show that the policies produced by SAA with the XOR sampler have
higher quality and lower variance compared to SAA with Gibbs sampler.


Multi-Entity Dependence Learning with Rich Context via Conditional
  Variational Auto-encoder

  Multi-Entity Dependence Learning (MEDL) explores conditional correlations
among multiple entities. The availability of rich contextual information
requires a nimble learning scheme that tightly integrates with deep neural
networks and has the ability to capture correlation structures among
exponentially many outcomes. We propose MEDL_CVAE, which encodes a conditional
multivariate distribution as a generating process. As a result, the variational
lower bound of the joint likelihood can be optimized via a conditional
variational auto-encoder and trained end-to-end on GPUs. Our MEDL_CVAE was
motivated by two real-world applications in computational sustainability: one
studies the spatial correlation among multiple bird species using the eBird
data and the other models multi-dimensional landscape composition and human
footprint in the Amazon rainforest with satellite images. We show that
MEDL_CVAE captures rich dependency structures, scales better than previous
methods, and further improves on the joint likelihood taking advantage of very
large datasets that are beyond the capacity of previous methods.


End-to-End Learning for the Deep Multivariate Probit Model

  The multivariate probit model (MVP) is a popular classic model for studying
binary responses of multiple entities. Nevertheless, the computational
challenge of learning the MVP model, given that its likelihood involves
integrating over a multidimensional constrained space of latent variables,
significantly limits its application in practice. We propose a flexible deep
generalization of the classic MVP, the Deep Multivariate Probit Model (DMVP),
which is an end-to-end learning scheme that uses an efficient parallel sampling
process of the multivariate probit model to exploit GPU-boosted deep neural
networks. We present both theoretical and empirical analysis of the convergence
behavior of DMVP's sampling process with respect to the resolution of the
correlation structure. We provide convergence guarantees for DMVP and our
empirical analysis demonstrates the advantages of DMVP's sampling compared with
standard MCMC-based methods. We also show that when applied to multi-entity
modelling problems, which are natural DMVP applications, DMVP trains faster
than classical MVP, by at least an order of magnitude, captures rich
correlations among entities, and further improves the joint likelihood of
entities compared with several competitive models.


Deep Multi-Species Embedding

  Understanding how species are distributed across landscapes over time is a
fundamental question in biodiversity research. Unfortunately, most species
distribution models only target a single species at a time, despite strong
ecological evidence that species are not independently distributed. We propose
Deep Multi-Species Embedding (DMSE), which jointly embeds vectors corresponding
to multiple species as well as vectors representing environmental covariates
into a common high-dimensional feature space via a deep neural network. Applied
to bird observational data from the citizen science project \textit{eBird}, we
demonstrate how the DMSE model discovers inter-species relationships to
outperform single-species distribution models (random forests and SVMs) as well
as competing multi-label models. Additionally, we demonstrate the benefit of
using a deep neural network to extract features within the embedding and show
how they improve the predictive performance of species distribution modelling.
An important domain contribution of the DMSE model is the ability to discover
and describe species interactions while simultaneously learning the shared
habitat preferences among species. As an additional contribution, we provide a
graphical embedding of hundreds of bird species in the Northeast US.


Automated Phase Mapping with AgileFD and its Application to Light
  Absorber Discovery in the V-Mn-Nb Oxide System

  Rapid construction of phase diagrams is a central tenet of combinatorial
materials science with accelerated materials discovery efforts often hampered
by challenges in interpreting combinatorial x-ray diffraction datasets, which
we address by developing AgileFD, an artificial intelligence algorithm that
enables rapid phase mapping from a combinatorial library of x-ray diffraction
patterns. AgileFD models alloying-based peak shifting through a novel expansion
of convolutional nonnegative matrix factorization, which not only improves the
identification of constituent phases but also maps their concentration and
lattice parameter as a function of composition. By incorporating Gibbs phase
rule into the algorithm, physically meaningful phase maps are obtained with
unsupervised operation, and more refined solutions are attained by injecting
expert knowledge of the system. The algorithm is demonstrated through
investigation of the V-Mn-Nb oxide system where decomposition of eight oxide
phases, including two with substantial alloying, provides the first phase map
for this pseudo-ternary system. This phase map enables interpretation of
high-throughput band gap data, leading to the discovery of new solar light
absorbers and the alloying-based tuning of the direct-allowed band-gap energy
of MnV2O6. The open-source family of AgileFD algorithms can be implemented into
a broad range of high throughput workflows to accelerate materials discovery.


Scalable Relaxations of Sparse Packing Constraints: Optimal Biocontrol
  in Predator-Prey Network

  Cascades represent rapid changes in networks. A cascading phenomenon of
ecological and economic impact is the spread of invasive species in geographic
landscapes. The most promising management strategy is often biocontrol, which
entails introducing a natural predator able to control the invading population,
a setting that can be treated as two interacting cascades of predator and prey
populations. We formulate and study a nonlinear problem of optimal biocontrol:
optimally seeding the predator cascade over time to minimize the harmful prey
population. Recurring budgets, which typically face conservation organizations,
naturally leads to sparse constraints which make the problem amenable to
approximation algorithms. Available methods based on continuous relaxations
scale poorly, to remedy this we develop a novel and scalable randomized
algorithm based on a width relaxation, applicable to a broad class of
combinatorial optimization problems. We evaluate our contributions in the
context of biocontrol for the insect pest Hemlock Wolly Adelgid (HWA) in
eastern North America. Our algorithm outperforms competing methods in terms of
scalability and solution quality, and finds near optimal strategies for the
control of the HWA for fine-grained networks -- an important problem in
computational sustainability.


End-to-End Refinement Guided by Pre-trained Prototypical Classifier

  Many real-world tasks involve identifying patterns from data satisfying
background or prior knowledge. In domains like materials discovery, due to the
flaws and biases in raw experimental data, the identification of X-ray
diffraction patterns (XRD) often requires a huge amount of manual work in
finding refined phases that are similar to the ideal theoretical ones.
Automatically refining the raw XRDs utilizing the simulated theoretical data is
thus desirable. We propose imitation refinement, a novel approach to refine
imperfect input patterns, guided by a pre-trained classifier incorporating
prior knowledge from simulated theoretical data, such that the refined patterns
imitate the ideal data. The classifier is trained on the ideal simulated data
to classify patterns and learns an embedding space where each class is
represented by a prototype. The refiner learns to refine the imperfect patterns
with small modifications, such that their embeddings are closer to the
corresponding prototypes. We show that the refiner can be trained in both
supervised and unsupervised fashions. We further illustrate the effectiveness
of the proposed approach both qualitatively and quantitatively in a digit
refinement task and an X-ray diffraction pattern refinement task in materials
discovery.


DESK: A Robotic Activity Dataset for Dexterous Surgical Skills Transfer
  to Medical Robots

  Datasets are an essential component for training effective machine learning
models. In particular, surgical robotic datasets have been key to many advances
in semi-autonomous surgeries, skill assessment, and training. Simulated
surgical environments can enhance the data collection process by making it
faster, simpler and cheaper than real systems. In addition, combining data from
multiple robotic domains can provide rich and diverse training data for
transfer learning algorithms. In this paper, we present the DESK (Dexterous
Surgical Skill) dataset. It comprises a set of surgical robotic skills
collected during a surgical training task using three robotic platforms: the
Taurus II robot, Taurus II simulated robot, and the YuMi robot. This dataset
was used to test the idea of transferring knowledge across different domains
(e.g. from Taurus to YuMi robot) for a surgical gesture classification task
with seven gestures. We explored three different scenarios: 1) No transfer, 2)
Transfer from simulated Taurus to real Taurus and 3) Transfer from Simulated
Taurus to the YuMi robot. We conducted extensive experiments with three
supervised learning models and provided baselines in each of these scenarios.
Results show that using simulation data during training enhances the
performance on the real robot where limited real data is available. In
particular, we obtained an accuracy of 55% on the real Taurus data using a
model that is trained only on the simulator data. Furthermore, we achieved an
accuracy improvement of 34% when 3% of the real data is added into the training
process.


