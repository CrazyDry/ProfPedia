Computational Social Choice Meets Databases

  We develop a novel framework that aims to create bridges between thecomputational social choice and the database management communities. Thisframework enriches the tasks currently supported in computational social choicewith relational database context, thus making it possible to formulatesophisticated queries about voting rules, candidates, voters, issues, andpositions. At the conceptual level, we give rigorous semantics to queries inthis framework by introducing the notions of necessary answers and possibleanswers to queries. At the technical level, we embark on an investigation ofthe computational complexity of the necessary answers. We establish a number ofresults about the complexity of the necessary answers of conjunctive queriesinvolving positional scoring rules that contrast sharply with earlier resultsabout the complexity of the necessary winners.

Zooming in on NYC taxi data with Portal

  In this paper we develop a methodology for analyzing transportation data atdifferent levels of temporal and geographic granularity, and apply ourmethodology to the TLC Trip Record Dataset, made publicly available by the NYCTaxi & Limousine Commission. This data is naturally represented by a set oftrajectories, annotated with time and with additional information such aspassenger count and cost. We analyze TLC data to identify hotspots, which pointto lack of convenient public transportation options, and popular routes, whichmotivate ride-sharing solutions or addition of a bus route.  Our methodology is based on using a system called Portal, which implementsefficient representations and principled analysis methods for evolving graphs.Portal is implemented on top of Apache Spark, a popular distributed dataprocessing system, is inter-operable with other Spark libraries like SparkSQL,and supports sophisticated kinds of analysis of evolving graphs efficiently.Portal is currently under development in the Data, Responsibly Lab at Drexel.We plan to release Portal in the open source in Fall 2017.

Transparency, Fairness, Data Protection, Neutrality: Data Management  Challenges in the Face of New Regulation

  The data revolution continues to transform every sector of science, industryand government. Due to the incredible impact of data-driven technology onsociety, we are becoming increasingly aware of the imperative to use data andalgorithms responsibly -- in accordance with laws and ethical norms. In thisarticle we discuss three recent regulatory frameworks: the European Union'sGeneral Data Protection Regulation (GDPR), the New York City AutomatedDecisions Systems (ADS) Law, and the Net Neutrality principle, that aim toprotect the rights of individuals who are impacted by data collection andanalysis. These frameworks are prominent examples of a global trend:Governments are starting to recognize the need to regulate data-drivenalgorithmic technology.  Our goal in this paper is to bring these regulatory frameworks to theattention of the data management community, and to underscore the technicalchallenges they raise and which we, as a community, are well-equipped toaddress. The main take-away of this article is that legal and ethical normscannot be incorporated into data-driven systems as an afterthought. Rather, wemust think in terms of responsibility by design, viewing it as a systemsrequirement.

Rule-Based Application Development using Webdamlog

  We present the WebdamLog system for managing distributed data on the Web in apeer-to-peer manner. We demonstrate the main features of the system through anapplication called Wepic for sharing pictures between attendees of the sigmodconference. Using Wepic, the attendees will be able to share, download, rateand annotate pictures in a highly decentralized manner. We show how WebdamLoghandles heterogeneity of the devices and services used to share data in such aWeb setting. We exhibit the simple rules that define the Wepic application andshow how to easily modify the Wepic application.

Introducing Access Control in Webdamlog

  We survey recent work on the specification of an access control mechanism ina collaborative environment. The work is presented in the context of theWebdamLog language, an extension of datalog to a distributed context. Wediscuss a fine-grained access control mechanism for intentional data based onprovenance as well as a control mechanism for delegation, i.e., for deployingrules at remote peers.

Putting Lipstick on Pig: Enabling Database-style Workflow Provenance

  Workflow provenance typically assumes that each module is a "black-box", sothat each output depends on all inputs (coarse-grained dependencies).Furthermore, it does not model the internal state of a module, which can changebetween repeated executions. In practice, however, an output may depend on onlya small subset of the inputs (fine-grained dependencies) as well as on theinternal state of the module. We present a novel provenance framework thatmarries database-style and workflow-style provenance, by using Pig Latin toexpose the functionality of modules, thus capturing internal state andfine-grained dependencies. A critical ingredient in our solution is the use ofa novel form of provenance graph that models module invocations and yields acompact representation of fine-grained workflow provenance. It also enables anumber of novel graph transformation operations, allowing to choose the desiredlevel of granularity in provenance querying (ZoomIn and ZoomOut), andsupporting "what-if" workflow analytic queries. We implemented our approach inthe Lipstick system and developed a benchmark in support of a systematicperformance evaluation. Our results demonstrate the feasibility of tracking andquerying fine-grained workflow provenance.

On Obtaining Stable Rankings

  Decision making is challenging when there is more than one criterion toconsider. In such cases, it is common to assign a goodness score to each itemas a weighted sum of its attribute values and rank them accordingly. Clearly,the ranking obtained depends on the weights used for this summation. Ideally,one would want the ranked order not to change if the weights are changedslightly. We call this property {\em stability} of the ranking. A consumer of aranked list may trust the ranking more if it has high stability. A producer ofa ranked list prefers to choose weights that result in a stable ranking, bothto earn the trust of potential consumers and because a stable ranking isintrinsically likely to be more meaningful. In this paper, we develop aframework that can be used to assess the stability of a provided ranking and toobtain a stable ranking within an "acceptable" range of weight values (called"the region of interest"). We address the case where the user cares about therank order of the entire set of items, and also the case where the user caresonly about the top-$k$ items. Using a geometric interpretation, we proposealgorithms that produce stable rankings. In addition to theoretical analyses,we conduct extensive experiments on real datasets that validate our proposal.

The Webdamlog System Managing Distributed Knowledge on the Web

  We study the use of WebdamLog, a declarative high-level lan- guage in thestyle of datalog, to support the distribution of both data and knowledge (i.e.,programs) over a network of au- tonomous peers. The main novelty of WebdamLogcompared to datalog is its use of delegation, that is, the ability for a peerto communicate a program to another peer. We present results of a user study,showing that users can write WebdamLog programs quickly and correctly, and witha minimal amount of training. We present an implementation of the WebdamLoginference engine relying on the Bud dat- alog engine. We describe anexperimental evaluation of the WebdamLog engine, demonstrating that WebdamLogcan be im- plemented efficiently. We conclude with a discussion of ongoing andfuture work.

Search and Result Presentation in Scientific Workflow Repositories

  We study the problem of searching a repository of complex hierarchicalworkflows whose component modules, both composite and atomic, have beenannotated with keywords. Since keyword search does not use the graph structureof a workflow, we develop a model of workflows using context-free bag grammars.We then give efficient polynomial-time algorithms that, given a workflow and akeyword query, determine whether some execution of the workflow matches thequery. Based on these algorithms we develop a search and ranking solution thatefficiently retrieves the top-k grammars from a repository. Finally, we proposea novel result presentation method for grammars matching a keyword query, basedon representative parse-trees. The effectiveness of our approach is validatedthrough an extensive experimental evaluation.

Querying Evolving Graphs with Portal

  Graphs are used to represent a plethora of phenomena, from the Web and socialnetworks, to biological pathways, to semantic knowledge bases. Arguably themost interesting and important questions one can ask about graphs have to dowith their evolution. Which Web pages are showing an increasing popularitytrend? How does influence propagate in social networks? How does knowledgeevolve?  This paper proposes a logical model of an evolving graph called a TGraph,which captures evolution of graph topology and of its vertex and edgeattributes. We present a compositional temporal graph algebra TGA, and show areduction of TGA to temporal relational algebra with graph-specific primitives.We formally study the properties of TGA, and also show that it is sufficient toconcisely express a wide range of common use cases. We describe animplementation of our model and algebra in Portal, built on top of Apache Spark/ GraphX. We conduct extensive experiments on real datasets, and show thatPortal scales.

Measuring Fairness in Ranked Outputs

  Ranking and scoring are ubiquitous. We consider the setting in which aninstitution, called a ranker, evaluates a set of individuals based ondemographic, behavioral or other characteristics. The final output is a rankingthat represents the relative quality of the individuals. While automatic andtherefore seemingly objective, rankers can, and often do, discriminate againstindividuals and systematically disadvantage members of protected groups. Thiswarrants a careful study of the fairness of a ranking scheme.  In this paper we propose fairness measures for ranked outputs. We develop adata generation procedure that allows us to systematically control the degreeof unfairness in the output, and study the behavior of our measures on thesedatasets. We then apply our proposed measures to several real datasets, anddemonstrate cases of unfairness. Finally, we show preliminary results ofincorporating our ranked fairness measures into an optimization framework, andshow potential for improving fairness of ranked outputs while maintainingaccuracy.

Research Directions for Principles of Data Management (Dagstuhl  Perspectives Workshop 16151)

  In April 2016, a community of researchers working in the area of Principlesof Data Management (PDM) joined in a workshop at the Dagstuhl Castle inGermany. The workshop was organized jointly by the Executive Committee of theACM Symposium on Principles of Database Systems (PODS) and the Council of theInternational Conference on Database Theory (ICDT). The mission of thisworkshop was to identify and explore some of the most important researchdirections that have high relevance to society and to Computer Science today,and where the PDM community has the potential to make significantcontributions. This report describes the family of research directions that theworkshop focused on from three perspectives: potential practical relevance,results already obtained, and research questions that appear surmountable inthe short and medium term.

A Nutritional Label for Rankings

  Algorithmic decisions often result in scoring and ranking individuals todetermine credit worthiness, qualifications for college admissions andemployment, and compatibility as dating partners. While automatic and seeminglyobjective, ranking algorithms can discriminate against individuals andprotected groups, and exhibit low diversity. Furthermore, ranked results areoften unstable --- small changes in the input data or in the rankingmethodology may lead to drastic changes in the output, making the resultuninformative and easy to manipulate. Similar concerns apply in cases whereitems other than individuals are ranked, including colleges, academicdepartments, or products.  In this demonstration we present Ranking Facts, a Web-based application thatgenerates a "nutritional label" for rankings. Ranking Facts is made up of acollection of visual widgets that implement our latest research results onfairness, stability, and transparency for rankings, and that communicatedetails of the ranking methodology, or of the output, to the end user. We willshowcase Ranking Facts on real datasets from different domains, includingcollege rankings, criminal risk assessment, and financial services.

Synthetic Data for Social Good

  Data for good implies unfettered access to data. But data owners must beconservative about how, when, and why they share data or risk violating thetrust of the people they aim to help, losing their funding, or breaking thelaw. Data sharing agreements can help prevent privacy violations, but require alevel of specificity that is premature during preliminary discussions, and cantake over a year to establish.  We consider the generation and use of synthetic data to facilitate ad hoccollaborations involving sensitive data. A good synthetic dataset has twoproperties: it is representative of the original data, and it provides strongguarantees about privacy.  In this paper, we discuss important use cases for synthetic data thatchallenge the state of the art in privacy-preserving data generation, anddescribe DataSynthesizer, a dataset generation tool that takes a sensitivedataset as input and generates a structurally and statistically similarsynthetic dataset, with strong privacy guarantees, as output. The data ownersneed not release their data, while potential collaborators can begin developingmodels and methods with some confidence that their results will work similarlyon the real dataset. The distinguishing feature of DataSynthesizer is itsusability - in most cases, the data owner need not specify any parameters tostart generating and sharing data safely and effectively.  The code implementing DataSynthesizer is publicly available on GitHub athttps://github.com/DataResponsibly. The work on DataSynthesizer is part of theData, Responsibly project, where the goal is to operationalize responsibilityin data sharing, integration, analysis and use.

Designing Fair Ranking Schemes

  Items from a database are often ranked based on a combination of multiplecriteria. A user may have the flexibility to accept combinations that weighthese criteria differently, within limits. On the other hand, this choice ofweights can greatly affect the fairness of the produced ranking. In this paper,we develop a system that helps users choose criterion weights that lead togreater fairness.  We consider ranking functions that compute the score of each item as aweighted sum of (numeric) attribute values, and then sort items on their score.Each ranking function can be expressed as a vector of weights, or as a point ina multi-dimensional space. For a broad range of fairness criteria, we show howto efficiently identify regions in this space that satisfy these criteria.Using this identification method, our system is able to tell users whethertheir proposed ranking function satisfies the desired fairness criteria and, ifit does not, to suggest the smallest modification that does. We developuser-controllable approximation that and indexing techniques that are appliedduring preprocessing, and support sub-second response times during the onlinephase. Our extensive experiments on real datasets demonstrate that our methodsare able to find solutions that satisfy fairness criteria effectively andefficiently.

MobilityMirror: Bias-Adjusted Transportation Datasets

  We describe customized synthetic datasets for publishing mobility data.Private companies are providing new transportation modalities, and their datais of high value for integrative transportation research, policy enforcement,and public accountability. However, these companies are disincentivized fromsharing data not only to protect the privacy of individuals (drivers and/orpassengers), but also to protect their own competitive advantage. Moreover,demographic biases arising from how the services are delivered may be amplifiedif released data is used in other contexts.  We describe a model and algorithm for releasing origin-destination histogramsthat removes selected biases in the data using causality-based methods. Wecompute the origin-destination histogram of the original dataset then adjustthe counts to remove undesirable causal relationships that can lead todiscrimination or violate contractual obligations with data owners. We evaluatethe utility of the algorithm on real data from a dockless bike share program inSeattle and taxi data in New York, and show that these adjusted transportationdatasets can retain utility while removing bias in the underlying data.

