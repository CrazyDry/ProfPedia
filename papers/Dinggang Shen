Population-Guided Large Margin Classifier for High-Dimension Low  -Sample-Size Problems

  Various applications in different fields, such as gene expression analysis orcomputer vision, suffer from data sets with high-dimensional low-sample-size(HDLSS), which has posed significant challenges for standard statistical andmodern machine learning methods. In this paper, we propose a novel linearbinary classifier, denoted by population-guided large margin classifier(PGLMC), which is applicable to any sorts of data, including HDLSS. PGLMC isconceived with a projecting direction w given by the comprehensiveconsideration of local structural information of the hyperplane and thestatistics of the training samples. Our proposed model has several advantagescompared to those widely used approaches. First, it is not sensitive to theintercept term b. Second, it operates well with imbalanced data. Third, it isrelatively simple to be implemented based on Quadratic Programming. Fourth, itis robust to the model specification for various real applications. Thetheoretical properties of PGLMC are proven. We conduct a series of evaluationson two simulated and six real-world benchmark data sets, including DNAclassification, digit recognition, medical image analysis, and facerecognition. PGLMC outperforms the state-of-the-art classification methods inmost cases, or at least obtains comparable results.

Tensor Generalized Estimating Equations for Longitudinal Imaging  Analysis

  In an increasing number of neuroimaging studies, brain images, which are inthe form of multidimensional arrays (tensors), have been collected on multiplesubjects at multiple time points. Of scientific interest is to analyze suchmassive and complex longitudinal images to diagnose neurodegenerative disordersand to identify disease relevant brain regions. In this article, we treat thoseproblems in a unifying regression framework with image predictors, and proposetensor generalized estimating equations (GEE) for longitudinal imaginganalysis. The GEE approach takes into account intra-subject correlation ofresponses, whereas a low rank tensor decomposition of the coefficient arrayenables effective estimation and prediction with limited sample size. Wepropose an efficient estimation algorithm, study the asymptotics in both fixed$p$ and diverging $p$ regimes, and also investigate tensor GEE withregularization that is particularly useful for region selection. The efficacyof the proposed tensor GEE is demonstrated on both simulated data and a realdata set from the Alzheimer's Disease Neuroimaging Initiative (ADNI).

Medical Image Synthesis with Context-Aware Generative Adversarial  Networks

  Computed tomography (CT) is critical for various clinical applications, e.g.,radiotherapy treatment planning and also PET attenuation correction. However,CT exposes radiation during acquisition, which may cause side effects topatients. Compared to CT, magnetic resonance imaging (MRI) is much safer anddoes not involve any radiations. Therefore, recently, researchers are greatlymotivated to estimate CT image from its corresponding MR image of the samesubject for the case of radiotherapy planning. In this paper, we propose adata-driven approach to address this challenging problem. Specifically, wetrain a fully convolutional network to generate CT given an MR image. To bettermodel the nonlinear relationship from MRI to CT and to produce more realisticimages, we propose to use the adversarial training strategy and an imagegradient difference loss function. We further apply AutoContext Model toimplement a context-aware generative adversarial network. Experimental resultsshow that our method is accurate and robust for predicting CT images from MRIimages, and also outperforms three state-of-the-art methods under comparison.

BIRNet: Brain Image Registration Using Dual-Supervised Fully  Convolutional Networks

  In this paper, we propose a deep learning approach for image registration bypredicting deformation from image appearance. Since obtaining ground-truthdeformation fields for training can be challenging, we design a fullyconvolutional network that is subject to dual-guidance: (1) Coarse guidanceusing deformation fields obtained by an existing registration method; and (2)Fine guidance using image similarity. The latter guidance helps avoid overlyrelying on the supervision from the training deformation fields, which could beinaccurate. For effective training, we further improve the deep convolutionalnetwork with gap filling, hierarchical loss, and multi-source strategies.Experiments on a variety of datasets show promising registration accuracy andefficiency compared with state-of-the-art methods.

Robust Group Comparison Using Non-Parametric Block-Based Statistics

  Voxel-based analysis methods localize brain structural differences byperforming voxel-wise statistical comparisons on two groups of images alignedto a common space. This procedure requires highly accurate registration as wellas a sufficiently large dataset. However, in practice, the registrationalgorithms are not perfect due to noise, artifacts, and complex structuralvariations. The sample size is also limited due to low disease prevalence,recruitment difficulties, and demographic matching issues. To address theseissues, in this paper, we propose a method, called block-based statistic (BBS),for robust group comparison. BBS consists of two major components: Blockmatching and permutation test. Specifically, based on two group of imagesaligned to a common space, we first perform block matching so that structuralmisalignments can be corrected. Then, based on results given by block matching,we conduct robust non-parametric statistical inference based on permutationtest. Extensive experiments were performed on synthetic data and the realdiffusion MR data of mild cognitive impairment patients. The experimentalresults indicate that BBS significantly improves statistical power,notwithstanding the small sample size.

Global Deep Learning Methods for Multimodality Isointense Infant Brain  Image Segmentation

  An important step in early brain development study is to perform automaticsegmentation of infant brain magnetic resonance (MR) images into cerebrospinalfluid (CSF), gray matter (GM) and white matter (WM) regions. This task isespecially challenging in the isointense stage (approximately 6-8 months ofage) when GM and WM exhibit similar levels of intensities in MR images. Deeplearning has shown its great promise in various image segmentation tasks.However, existing models do not have an efficient and effective way toaggregate global information. They also suffer from information loss duringup-sampling operations. In this work, we address these problems by proposing aglobal aggregation block, which can be flexibly used for global informationfusion. We build a novel model based on 3D U-Net to make fast and accuratevoxel-wise dense prediction. We perform thorough experiments, and resultsindicate that our model outperforms previous best models significantly on 3Dmultimodality isointense infant brain MR image segmentation.

Mitigating Gyral Bias in Cortical Tractography via Asymmetric Fiber  Orientation Distributions

  Diffusion tractography in brain connectomics often involves tracing axonaltrajectories across gray-white matter boundaries in gyral blades of complexcortical convolutions. To date, gyral bias is observed in most tractographyalgorithms with streamlines predominantly terminating at gyral crowns insteadof sulcal banks. This work demonstrates that asymmetric fiber orientationdistribution functions (AFODFs), computed via a multi-tissue global estimationframework, can mitigate the effects of gyral bias, enabling fiber streamlinesat gyral blades to make sharper turns into the cortical gray matter. We useex-vivo data of an adult rhesus macaque and in-vivo data from the HumanConnectome Project (HCP) to show that the fiber streamlines given by AFODFsbend more naturally into the cortex than the conventional symmetric FODFs intypical gyral blades. We demonstrate that AFODF tractography improvescortico-cortical connectivity and provides highly consistent outcomes betweentwo different field strengths (3T and 7T).

Real-Time Quality Assessment of Pediatric MRI via Semi-Supervised Deep  Nonlocal Residual Neural Networks

  In this paper, we introduce an image quality assessment (IQA) method forpediatric T1- and T2-weighted MR images. IQA is first performed slice-wiseusing a nonlocal residual neural network (NR-Net) and then volume-wise byagglomerating the slice QA results using random forest. Our method requiresonly a small amount of quality-annotated images for training and is designed tobe robust to annotation noise that might occur due to rater errors and theinevitable mix of good and bad slices in an image volume. Using a small set ofquality-assessed images, we pre-train NR-Net to annotate each image slice withan initial quality rating (i.e., pass, questionable, fail), which we thenrefine by semi-supervised learning and iterative self-training. Experimentalresults demonstrate that our method, trained using only samples of modest size,exhibit great generalizability, capable of real-time (milliseconds per volume)large-scale IQA with near-perfect accuracy.

FRNET: Flattened Residual Network for Infant MRI Skull Stripping

  Skull stripping for brain MR images is a basic segmentation task. Althoughmany methods have been proposed, most of them focused mainly on the adult MRimages. Skull stripping for infant MR images is more challenging due to thesmall size and dynamic intensity changes of brain tissues during the earlyages. In this paper, we propose a novel CNN based framework to robustly extractbrain region from infant MR image without any human assistance. Specifically,we propose a simplified but more robust flattened residual network architecture(FRnet). We also introduce a new boundary loss function to highlight ambiguousand low contrast regions between brain and non-brain regions. To make the wholeframework more robust to MR images with different imaging quality, we furtherintroduce an artifact simulator for data augmentation. We have trained andtested our proposed framework on a large dataset (N=343), covering newborns to48-month-olds, and obtained performance better than the state-of-the-artmethods in all age groups.

Learning Discriminative Bayesian Networks from High-dimensional  Continuous Neuroimaging Data

  Due to its causal semantics, Bayesian networks (BN) have been widely employedto discover the underlying data relationship in exploratory studies, such asbrain research. Despite its success in modeling the probability distribution ofvariables, BN is naturally a generative model, which is not necessarilydiscriminative. This may cause the ignorance of subtle but critical networkchanges that are of investigation values across populations. In this paper, wepropose to improve the discriminative power of BN models for continuousvariables from two different perspectives. This brings two generaldiscriminative learning frameworks for Gaussian Bayesian networks (GBN). In thefirst framework, we employ Fisher kernel to bridge the generative models of GBNand the discriminative classifiers of SVMs, and convert the GBN parameterlearning to Fisher kernel learning via minimizing a generalization error boundof SVMs. In the second framework, we employ the max-margin criterion and buildit directly upon GBN models to explicitly optimize the classificationperformance of the GBNs. The advantages and disadvantages of the two frameworksare discussed and experimentally compared. Both of them demonstrate strongpower in learning discriminative parameters of GBNs for neuroimaging basedbrain network analysis, as well as maintaining reasonable representationcapacity. The contributions of this paper also include a new Directed AcyclicGraph (DAG) constraint with theoretical guarantee to ensure the graph validityof GBN.

Deep Embedding Convolutional Neural Network for Synthesizing CT Image  from T1-Weighted MR Image

  Recently, more and more attention is drawn to the field of medical imagesynthesis across modalities. Among them, the synthesis of computed tomography(CT) image from T1-weighted magnetic resonance (MR) image is of greatimportance, although the mapping between them is highly complex due to largegaps of appearances of the two modalities. In this work, we aim to tackle thisMR-to-CT synthesis by a novel deep embedding convolutional neural network(DECNN). Specifically, we generate the feature maps from MR images, and thentransform these feature maps forward through convolutional layers in thenetwork. We can further compute a tentative CT synthesis from the midway of theflow of feature maps, and then embed this tentative CT synthesis back to thefeature maps. This embedding operation results in better feature maps, whichare further transformed forward in DECNN. After repeat-ing this embeddingprocedure for several times in the network, we can eventually synthesize afinal CT image in the end of the DECNN. We have validated our proposed methodon both brain and prostate datasets, by also compar-ing with thestate-of-the-art methods. Experimental results suggest that our DECNN (withrepeated embedding op-erations) demonstrates its superior performances, interms of both the perceptive quality of the synthesized CT image and therun-time cost for synthesizing a CT image.

Interactive Medical Image Segmentation via Point-Based Interaction and  Sequential Patch Learning

  Due to low tissue contrast, irregular object appearance, and unpredictablelocation variation, segmenting the objects from different medical imagingmodalities (e.g., CT, MR) is considered as an important yet challenging task.In this paper, we present a novel method for interactive medical imagesegmentation with the following merits. (1) Our design is fundamentallydifferent from previous pure patch-based and image-based segmentation methods.We observe that during delineation, the physician repeatedly check theinside-outside intensity changing to determine the boundary, which indicatesthat comparison in an inside-outside manner is extremely important. Thus, weinnovatively model our segmentation task as learning the representation of thebi-directional sequential patches, starting from (or ending in) the givencentral point of the object. This can be realized by our proposed ConvRNNnetwork embedded with a gated memory propagation unit. (2) Unlike previousinteractive methods (requiring bounding box or seed points), we only ask thephysician to merely click on the rough central point of the object beforesegmentation, which could simultaneously enhance the performance and reduce thesegmentation time. (3) We utilize our method in a multi-level framework forbetter performance. We systematically evaluate our method in three differentsegmentation tasks including CT kidney tumor, MR prostate, and PROMISE12challenge, showing promising results compared with state-of-the-art methods.The code is available here:\href{https://github.com/sunalbert/Sequential-patch-based-segmentation}{Sequential-patch-based-segmentation}.

Deep Learning based Inter-Modality Image Registration Supervised by  Intra-Modality Similarity

  Non-rigid inter-modality registration can facilitate accurate informationfusion from different modalities, but it is challenging due to the verydifferent image appearances across modalities. In this paper, we propose totrain a non-rigid inter-modality image registration network, which can directlypredict the transformation field from the input multimodal images, such as CTand MR images. In particular, the training of our inter-modality registrationnetwork is supervised by intra-modality similarity metric based on theavailable paired data, which is derived from a pre-aligned CT and MR dataset.Specifically, in the training stage, to register the input CT and MR images,their similarity is evaluated on the warped MR image and the MR image that ispaired with the input CT. So that, the intra-modality similarity metric can bedirectly applied to measure whether the input CT and MR images are wellregistered. Moreover, we use the idea of dual-modality fashion, in which wemeasure the similarity on both CT modality and MR modality. In this way, thecomplementary anatomies in both modalities can be jointly considered to moreaccurately train the inter-modality registration network. In the testing stage,the trained inter-modality registration network can be directly applied toregister the new multimodal images without any paired data. Experimentalresults have shown that, the proposed method can achieve promising accuracy andefficiency for the challenging non-rigid inter-modality registration task andalso outperforms the state-of-the-art approaches.

Angular Upsampling in Infant Diffusion MRI Using Neighborhood Matching  in x-q Space

  Diffusion MRI requires sufficient coverage of the diffusion wavevector space,also known as the q-space, to adequately capture the pattern of water diffusionin various directions and scales. As a result, the acquisition time can beprohibitive for individuals who are unable to stay still in the scanner for anextensive period of time, such as infants. To address this problem, in thispaper we harness non-local self-similar information in the x-q space ofdiffusion MRI data for q-space upsampling. Specifically, we first performneighborhood matching to establish the relationships of signals in x-q space.The signal relationships are then used to regularize an ill-posed inverseproblem related to the estimation of high angular resolution diffusion MRI datafrom its low-resolution counterpart. Our framework allows information fromcurved white matter structures to be used for effective regularization of theotherwise ill-posed problem. Extensive evaluations using synthetic and infantdiffusion MRI data demonstrate the effectiveness of our method. Compared withthe widely adopted interpolation methods using spherical radial basis functionsand spherical harmonics, our method is able to produce high angular resolutiondiffusion MRI data with greater quality, both qualitatively and quantitatively.

Noise Reduction in Diffusion MRI Using Non-Local Self-Similar  Information in Joint x-q Space

  Diffusion MRI affords valuable insights into white matter microstructures,but suffers from low signal-to-noise ratio (SNR), especially at high diffusionweighting (i.e., b-value). To avoid time-intensive repeated acquisition,post-processing algorithms are often used to reduce noise. Among existingmethods, non-local means (NLM) has been shown to be particularly effective.However, most NLM algorithms for diffusion MRI focus on patch matching in thespatial domain (i.e., x-space) and disregard the fact that the data live in acombined 6D space covering both spatial domain and diffusion wavevector domain(i.e., q-space). This drawback leads to inaccurate patch matching in curvedwhite matter structures and hence the inability to effectively use recurrentinformation for noise reduction. The goal of this paper is to overcome thislimitation by extending NLM to the joint x-q space. Specifically, we define foreach point in the x-q space a spherical patch from which we extractrotation-invariant features for patch matching. The ability to perform patchmatching across q-samples allows patches from differentially orientatedstructures to be used for effective noise removal. Extensive experiments onsynthetic, repeated acquisition, and real data demonstrate that our methodoutperforms state-of-the-art methods, both qualitatively and quantitatively.

Deep Chronnectome Learning via Full Bidirectional Long Short-Term Memory  Networks for MCI Diagnosis

  Brain functional connectivity (FC) extracted from resting-state fMRI(RS-fMRI) has become a popular approach for disease diagnosis, wherediscriminating subjects with mild cognitive impairment (MCI) from normalcontrols (NC) is still one of the most challenging problems. Dynamic functionalconnectivity (dFC), consisting of time-varying spatiotemporal dynamics, maycharacterize "chronnectome" diagnostic information for improving MCIclassification. However, most of the current dFC studies are based on detectingdiscrete major brain status via spatial clustering, which ignores richspatiotemporal dynamics contained in such chronnectome. We propose DeepChronnectome Learning for exhaustively mining the comprehensive information,especially the hidden higher-level features, i.e., the dFC time series that mayadd critical diagnostic power for MCI classification. To this end, we devise anew Fully-connected Bidirectional Long Short-Term Memory Network (Full-BiLSTM)to effectively learn the periodic brain status changes using both past andfuture information for each brief time segment and then fuse them to form thefinal output. We have applied our method to a rigorously built large-scalemulti-site database (i.e., with 164 data from NCs and 330 from MCIs, which canbe further augmented by 25 folds). Our method outperforms otherstate-of-the-art approaches with an accuracy of 73.6% under solidcross-validations. We also made extensive comparisons among multiple variantsof LSTM models. The results suggest high feasibility of our method withpromising value also for other brain disorder diagnoses.

Deep Morphological Simplification Network (MS-Net) for Guided  Registration of Brain Magnetic Resonance Images

  Objective: Deformable brain MR image registration is challenging due to largeinter-subject anatomical variation. For example, the highly complex corticalfolding pattern makes it hard to accurately align corresponding corticalstructures of individual images. In this paper, we propose a novel deeplearning way to simplify the difficult registration problem of brain MR images.Methods: We train a morphological simplification network (MS-Net), which cangenerate a "simple" image with less anatomical details based on the "complex"input. With MS-Net, the complexity of the fixed image or the moving image underregistration can be reduced gradually, thus building an individual(simplification) trajectory represented by MS-Net outputs. Since the generatedimages at the ends of the two trajectories (of the fixed and moving images) areso simple and very similar in appearance, they are easy to register. Thus, thetwo trajectories can act as a bridge to link the fixed and the moving images,and guide their registration. Results: Our experiments show that the proposedmethod can achieve highly accurate registration performance on differentdatasets (i.e., NIREP, LPBA, IBSR, CUMC, and MGH). Moreover, the method can bealso easily transferred across diverse image datasets and obtain superioraccuracy on surface alignment. Conclusion and Significance: We propose MS-Netas a powerful and flexible tool to simplify brain MR images and theirregistration. To our knowledge, this is the first work to simplify brain MRimage registration by deep learning, instead of estimating deformation fielddirectly.

Spherical U-Net on Cortical Surfaces: Methods and Applications

  Convolutional Neural Networks (CNNs) have been providing the state-of-the-artperformance for learning-related problems involving 2D/3D images in Euclideanspace. However, unlike in the Euclidean space, the shapes of many structures inmedical imaging have a spherical topology in a manifold space, e.g., braincortical or subcortical surfaces represented by triangular meshes, with largeinter-subject and intrasubject variations in vertex number and localconnectivity. Hence, there is no consistent neighborhood definition and thus nostraightforward convolution/transposed convolution operations forcortical/subcortical surface data. In this paper, by leveraging the regular andconsistent geometric structure of the resampled cortical surface mapped ontothe spherical space, we propose a novel convolution filter analogous to thestandard convolution on the image grid. Accordingly, we develop correspondingoperations for convolution, pooling, and transposed convolution for sphericalsurface data and thus construct spherical CNNs. Specifically, we propose theSpherical U-Net architecture by replacing all operations in the standard U-Netwith their spherical operation counterparts. We then apply the Spherical U-Netto two challenging and neuroscientifically important tasks in infant brains:cortical surface parcellation and cortical attribute map developmentprediction. Both applications demonstrate the competitive performance in theaccuracy, computational efficiency, and effectiveness of our proposed SphericalU-Net, in comparison with the state-of-the-art methods.

Regularized Spherical Polar Fourier Diffusion MRI with Optimal  Dictionary Learning

  Compressed Sensing (CS) takes advantage of signal sparsity or compressibilityand allows superb signal reconstruction from relatively few measurements. Basedon CS theory, a suitable dictionary for sparse representation of the signal isrequired. In diffusion MRI (dMRI), CS methods were proposed to reconstructdiffusion-weighted signal and the Ensemble Average Propagator (EAP), and thereare two kinds of Dictionary Learning (DL) methods: 1) Discrete RepresentationDL (DR-DL), and 2) Continuous Representation DL (CR-DL). DR-DL is susceptibleto numerical inaccuracy owing to interpolation and regridding errors in adiscretized q-space. In this paper, we propose a novel CR-DL approach, calledDictionary Learning - Spherical Polar Fourier Imaging (DL-SPFI) for effectivecompressed-sensing reconstruction of the q-space diffusion-weighted signal andthe EAP. In DL-SPFI, an dictionary that sparsifies the signal is learned fromthe space of continuous Gaussian diffusion signals. The learned dictionary isthen adaptively applied to different voxels using a weighted LASSO frameworkfor robust signal reconstruction. The adaptive dictionary is proved to beoptimal. Compared with the start-of-the-art CR-DL and DR-DL methods proposed byMerlet et al. and Bilgic et al., espectively, our work offers the followingadvantages. First, the learned dictionary is proved to be optimal for Gaussiandiffusion signals. Second, to our knowledge, this is the first work to learn avoxel-adaptive dictionary. The importance of the adaptive dictionary in EAPreconstruction will be demonstrated theoretically and empirically. Third,optimization in DL-SPFI is only performed in a small subspace resided by theSPF coefficients, as opposed to the q-space approach utilized by Merlet et al.The experiment results demonstrate the advantages of DL-SPFI over the originalSPF basis and Bilgic et al.'s method.

Single- and Multiple-Shell Uniform Sampling Schemes for Diffusion MRI  Using Spherical Codes

  In diffusion MRI (dMRI), a good sampling scheme is important for efficientacquisition and robust reconstruction. Diffusion weighted signal is normallyacquired on single or multiple shells in q-space. Signal samples are typicallydistributed uniformly on different shells to make them invariant to theorientation of structures within tissue, or the laboratory coordinate frame.The Electrostatic Energy Minimization (EEM) method, originally proposed forsingle shell sampling scheme in dMRI, was recently generalized to multi-shellschemes, called Generalized EEM (GEEM). GEEM has been successfully used in theHuman Connectome Project (HCP). However, EEM does not directly address the goalof optimal sampling, i.e., achieving large angular separation between samplingpoints. In this paper, we propose a more natural formulation, called SphericalCode (SC), to directly maximize the minimal angle between different samples insingle or multiple shells. We consider not only continuous problems to designsingle or multiple shell sampling schemes, but also discrete problems touniformly extract sub-sampled schemes from an existing single or multiple shellscheme, and to order samples in an existing scheme. We propose five algorithmsto solve the above problems, including an incremental SC (ISC), a sophisticatedgreedy algorithm called Iterative Maximum Overlap Construction (IMOC), an 1-Optgreedy method, a Mixed Integer Linear Programming (MILP) method, and aConstrained Non-Linear Optimization (CNLO) method. To our knowledge, this isthe first work to use the SC formulation for single or multiple shell samplingschemes in dMRI. Experimental results indicate that SC methods obtain largerangular separation and better rotational invariance than the state-of-the-artEEM and GEEM. The related codes and a tutorial have been released in DMRITool.

Deep CNN ensembles and suggestive annotations for infant brain MRI  segmentation

  Precise 3D segmentation of infant brain tissues is an essential step towardscomprehensive volumetric studies and quantitative analysis of early braindevelopement. However, computing such segmentations is very challenging,especially for 6-month infant brain, due to the poor image quality, among otherdifficulties inherent to infant brain MRI, e.g., the isointense contrastbetween white and gray matter and the severe partial volume effect due to smallbrain sizes. This study investigates the problem with an ensemble of semi-densefully convolutional neural networks (CNNs), which employs T1-weighted andT2-weighted MR images as input. We demonstrate that the ensemble agreement ishighly correlated with the segmentation errors. Therefore, our method providesmeasures that can guide local user corrections. To the best of our knowledge,this work is the first ensemble of 3D CNNs for suggesting annotations withinimages. Furthermore, inspired by the very recent success of dense networks, wepropose a novel architecture, SemiDenseNet, which connects all convolutionallayers directly to the end of the network. Our architecture allows theefficient propagation of gradients during training, while limiting the numberof parameters, requiring one order of magnitude less parameters than popularmedical image segmentation networks such as 3D U-Net. Another contribution ofour work is the study of the impact that early or late fusions of multipleimage modalities might have on the performances of deep architectures. Wereport evaluations of our method on the public data of the MICCAI iSEG-2017Challenge on 6-month infant brain MRI segmentation, and show very competitiveresults among 21 teams, ranking first or second in most metrics.

Identifying the Best Machine Learning Algorithms for Brain Tumor  Segmentation, Progression Assessment, and Overall Survival Prediction in the  BRATS Challenge

  Gliomas are the most common primary brain malignancies, with differentdegrees of aggressiveness, variable prognosis and various heterogeneoushistologic sub-regions, i.e., peritumoral edematous/invaded tissue, necroticcore, active and non-enhancing core. This intrinsic heterogeneity is alsoportrayed in their radio-phenotype, as their sub-regions are depicted byvarying intensity profiles disseminated across multi-parametric magneticresonance imaging (mpMRI) scans, reflecting varying biological properties.Their heterogeneous shape, extent, and location are some of the factors thatmake these tumors difficult to resect, and in some cases inoperable. The amountof resected tumor is a factor also considered in longitudinal scans, whenevaluating the apparent tumor for potential diagnosis of progression.Furthermore, there is mounting evidence that accurate segmentation of thevarious tumor sub-regions can offer the basis for quantitative image analysistowards prediction of patient overall survival. This study assesses thestate-of-the-art machine learning (ML) methods used for brain tumor imageanalysis in mpMRI scans, during the last seven instances of the InternationalBrain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, wefocus on i) evaluating segmentations of the various glioma sub-regions inpre-operative mpMRI scans, ii) assessing potential tumor progression by virtueof longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANOcriteria, and iii) predicting the overall survival from pre-operative mpMRIscans of patients that underwent gross total resection. Finally, we investigatethe challenge of identifying the best ML algorithms for each of these tasks,considering that apart from being diverse on each instance of the challenge,the multi-institutional mpMRI BraTS dataset has also been a continuouslyevolving/growing dataset.

