Security Games with Information Leakage: Modeling and Computation

  Most models of Stackelberg security games assume that the attacker only knowsthe defender's mixed strategy, but is not able to observe (even partially) theinstantiated pure strategy. Such partial observation of the deployed purestrategy -- an issue we refer to as information leakage -- is a significantconcern in practical applications. While previous research on patrolling gameshas considered the attacker's real-time surveillance, our settings, thereforemodels and techniques, are fundamentally different. More specifically, afterdescribing the information leakage model, we start with an LP formulation tocompute the defender's optimal strategy in the presence of leakage. Perhapssurprisingly, we show that a key subproblem to solve this LP (more precisely,the defender oracle) is NP-hard even for the simplest of security game models.We then approach the problem from three possible directions: efficientalgorithms for restricted cases, approximation algorithms, and heuristicalgorithms for sampling that improves upon the status quo. Our experimentsconfirm the necessity of handling information leakage and the advantage of ouralgorithms.

Pilot Testing an Artificial Intelligence Algorithm That Selects Homeless  Youth Peer Leaders Who Promote HIV Testing

  Objective. To pilot test an artificial intelligence (AI) algorithm thatselects peer change agents (PCA) to disseminate HIV testing messaging in apopulation of homeless youth. Methods. We recruited and assessed 62 youth atbaseline, 1 month (n = 48), and 3 months (n = 38). A Facebook app collectedpreliminary social network data. Eleven PCAs selected by AI attended a 1-daytraining and 7 weekly booster sessions. Mixed-effects models with randomeffects were used to assess change over time. Results. Significant change overtime was observed in past 6-month HIV testing (57.9%, 82.4%, 76.3%; p < .05)but not condom use (63.9%, 65.7%, 65.8%). Most youth reported speaking to a PCAabout HIV prevention (72.0% at 1 month, 61.5% at 3 months). Conclusions. AI isa promising avenue for implementing PCA models for homeless youth. Increasingrates of regular HIV testing is critical to HIV prevention and linking homelessyouth to treatment.

Mitigating the Curse of Correlation in Security Games by Entropy  Maximization

  In Stackelberg security games, a defender seeks to randomly allocate limitedsecurity resources to protect critical targets from an attack. In this paper,we study a fundamental, yet underexplored, phenomenon in security games, whichwe term the \emph{Curse of Correlation} (CoC). Specifically, we observe thatthere are inevitable correlations among the protection status of differenttargets. Such correlation is a crucial concern, especially in\emph{spatio-temporal} domains like conservation area patrolling, whereattackers can surveil patrollers at certain areas and then infer theirpatrolling routes using such correlations. To mitigate this issue, we proposeto design entropy-maximizing defending strategies for spatio-temporal securitygames, which frequently suffer from CoC. We prove that the problem is \#P-hardin general. However, it admits efficient algorithms in well-motivated specialsettings. Our experiments show significant advantages of max-entropy algorithmsover previous algorithms. A scalable implementation of our algorithm iscurrently under pre-deployment testing for integration into FAMS software toimprove the scheduling of US federal air marshals.

Practical Scalability for Stackelberg Security Games

  Stackelberg Security Games (SSGs) have been adopted widely for modelingadversarial interactions. With increasing size of the applications of SSGs,scalability of equilibrium computation is an important research problem. Whileprior research has made progress with regards to scalability, many real worldproblems cannot be solved satisfactorily yet as per current requirements; theseinclude the deployed federal air marshals (FAMS) application and the threatscreening (TSG) problem at airports. Further, these problem domains areinherently limited by NP hardness shown in prior literature. We initiate aprincipled study of approximations in zero-sum SSGs. Our contribution includesthe following: (1) a unified model of SSGs called adversarial randomizedallocation (ARA) games that allows studying most SSGs in one model, (2)hardness of approximation results for zero-sum ARA, as well as for thesub-problem of allocating federal air marshal (FAMS) and threat screeningproblem (TSG) at airports, (3) an approximation framework for zero-sum ARA withprovable approximation guarantees and (4) experiments demonstrating thesignificant scalability of up to 1000x improvement in runtime with anacceptable 5% solution quality loss.

Decentralized dynamic task allocation for UAVs with limited  communication range

  We present the Limited-range Online Routing Problem (LORP), which involves ateam of Unmanned Aerial Vehicles (UAVs) with limited communication range thatmust autonomously coordinate to service task requests. We first show a generalapproach to cast this dynamic problem as a sequence of decentralized taskallocation problems. Then we present two solutions both based on modeling theallocation task as a Markov Random Field to subsequently assess decisions bymeans of the decentralized Max-Sum algorithm. Our first solution assumesindependence between requests, whereas our second solution also considers theUAVs' workloads. A thorough empirical evaluation shows that our workload-basedsolution consistently outperforms current state-of-the-art methods in a widerange of scenarios, lowering the average service time up to 16%. In thebest-case scenario there is no gap between our decentralized solution andcentralized techniques. In the worst-case scenario we manage to reduce by 25%the gap between current decentralized and centralized techniques. Thus, oursolution becomes the method of choice for our problem.

Artificial Intelligence for Social Good

  The Computing Community Consortium (CCC), along with the White House Officeof Science and Technology Policy (OSTP), and the Association for theAdvancement of Artificial Intelligence (AAAI), co-sponsored a public workshopon Artificial Intelligence for Social Good on June 7th, 2016 in Washington, DC.This was one of five workshops that OSTP co-sponsored and held around thecountry to spur public dialogue on artificial intelligence, machine learning,and to identify challenges and opportunities related to AI. In the AI forSocial Good workshop, the successful deployments and the potential use of AI invarious topics that are essential for social good were discussed, including butnot limited to urban computing, health, environmental sustainability, andpublic welfare. This report highlights each of these as well as a number ofcrosscutting issues.

Decision-Focused Learning of Adversary Behavior in Security Games

  Stackelberg security games are a critical tool for maximizing the utility oflimited defense resources to protect important targets from an intelligentadversary. Motivated by green security, where the defender may only observe anadversary's response to defense on a limited set of targets, we study theproblem of defending against the same adversary on a larger set of targets fromthe same distribution. We give a theoretical justification for why standardtwo-stage learning approaches, where a model of the adversary is trained forpredictive accuracy and then optimized against, may fail to maximize thedefender's expected utility in this setting. We develop a decision-focusedlearning approach, where the adversary behavior model is optimized for decisionquality, and show empirically that it achieves higher defender expected utilitythan the two-stage approach when there is limited training data and a largenumber of target features.

Group-Fairness in Influence Maximization

  Influence maximization is a widely used model for information disseminationin social networks. Recent work has employed such interventions across a widerange of social problems, spanning public health, substance abuse, andinternational development (to name a few examples). A critical but understudiedquestion is whether the benefits of such interventions are fairly distributedacross different groups in the population; e.g., avoiding discrimination withrespect to sensitive attributes such as race or gender. Drawing on legal andgame-theoretic concepts, we introduce formal definitions of fairness ininfluence maximization. We provide an algorithmic framework to find solutionswhich satisfy fairness constraints, and in the process improve the state of theart for general multi-objective submodular maximization problems. Experimentalresults on real data from an HIV prevention intervention for homeless youthshow that standard influence maximization techniques oftentimes neglect smallergroups which contribute less to overall utility, resulting in a disparity whichour proposed algorithms substantially reduce.

Who and When to Screen: Multi-Round Active Screening for Recurrent  Infectious Diseases Under Uncertainty

  Controlling recurrent infectious diseases is a vital yet complicated problem.In this paper, we propose a novel active screening model (ACTS) and algorithmsto facilitate active screening for recurrent diseases (no permanent immunity)under infection uncertainty. Our contributions are: (1) A new approach tomodeling multi-round network-based screening/contact tracing under uncertainty,which is a common real-life practice in a variety of diseases; (2) Two novelalgorithms, Full- and Fast-REMEDY. Full-REMEDY considers the effect of futureactions and finds a policy that provides high solution quality, whereFast-REMEDY scales linearly in the size of the network; (3) We evaluate Full-and Fast-REMEDY on several real-world datasets which emulate human contact andfind that they control diseases better than the baselines. To the best of ourknowledge, this is the first work on multi-round active screening withuncertainty for diseases with no permanent immunity.

Stackelberg vs. Nash in Security Games: An Extended Investigation of  Interchangeability, Equivalence, and Uniqueness

  There has been significant recent interest in game-theoretic approaches tosecurity, with much of the recent research focused on utilizing theleader-follower Stackelberg game model. Among the major applications are theARMOR program deployed at LAX Airport and the IRIS program in use by the USFederal Air Marshals (FAMS). The foundational assumption for using Stackelberggames is that security forces (leaders), acting first, commit to a randomizedstrategy; while their adversaries (followers) choose their best response aftersurveillance of this randomized strategy. Yet, in many situations, a leader mayface uncertainty about the follower's surveillance capability. Previous workfails to address how a leader should compute her strategy given suchuncertainty. We provide five contributions in the context of a general class ofsecurity games. First, we show that the Nash equilibria in security games areinterchangeable, thus alleviating the equilibrium selection problem. Second,under a natural restriction on security games, any Stackelberg strategy is alsoa Nash equilibrium strategy; and furthermore, the solution is unique in a classof security games of which ARMOR is a key exemplar. Third, when faced with afollower that can attack multiple targets, many of these properties no longerhold. Fourth, we show experimentally that in most (but not all) games where therestriction does not hold, the Stackelberg strategy is still a Nash equilibriumstrategy, but this is no longer true when the attacker can attack multipletargets. Finally, as a possible direction for future research, we propose anextensive-form game model that makes the defender's uncertainty about theattacker's ability to observe explicit.

Learning Adversary Behavior in Security Games: A PAC Model Perspective

  Recent applications of Stackelberg Security Games (SSG), from wildlife crimeto urban crime, have employed machine learning tools to learn and predictadversary behavior using available data about defender-adversary interactions.Given these recent developments, this paper commits to an approach of directlylearning the response function of the adversary. Using the PAC model, thispaper lays a firm theoretical foundation for learning in SSGs (e.g.,theoretically answer questions about the numbers of samples required to learnadversary behavior) and provides utility guarantees when the learned adversarymodel is used to plan the defender's strategy. The paper also aims to answerpractical questions such as how much more data is needed to improve anadversary model's accuracy. Additionally, we explain a recently observedphenomenon that prediction accuracy of learned adversary behavior is not enoughto discover the utility maximizing defender strategy. We provide four maincontributions: (1) a PAC model of learning adversary response functions inSSGs; (2) PAC-model analysis of the learning of key, existing boundedrationality models in SSGs; (3) an entirely new approach to adversary modelingbased on a non-parametric class of response functions with PAC-model analysisand (4) identification of conditions under which computing the best defenderstrategy against the learned adversary behavior is indeed the optimal strategy.Finally, we conduct experiments with real-world data from a national park inUganda, showing the benefit of our new adversary modeling approach andverification of our PAC model predictions.

Using Social Networks to Aid Homeless Shelters: Dynamic Influence  Maximization under Uncertainty - An Extended Version

  This paper presents HEALER, a software agent that recommends sequentialintervention plans for use by homeless shelters, who organize theseinterventions to raise awareness about HIV among homeless youth. HEALER'ssequential plans (built using knowledge of social networks of homeless youth)choose intervention participants strategically to maximize influence spread,while reasoning about uncertainties in the network. While previous workpresents influence maximizing techniques to choose intervention participants,they do not address three real-world issues: (i) they completely fail to scaleup to real-world sizes; (ii) they do not handle deviations in execution ofintervention plans; (iii) constructing real-world social networks is anexpensive process. HEALER handles these issues via four major contributions:(i) HEALER casts this influence maximization problem as a POMDP and solves itusing a novel planner which scales up to previously unsolvable real-worldsizes; (ii) HEALER allows shelter officials to modify its recommendations, andupdates its future plans in a deviation-tolerant manner; (iii) HEALERconstructs social networks of homeless youth at low cost, using a Facebookapplication. Finally, (iv) we show hardness results for the problem that HEALERsolves. HEALER will be deployed in the real world in early Spring 2016 and iscurrently undergoing testing at a homeless shelter.

Activating the "Breakfast Club": Modeling Influence Spread in  Natural-World Social Networks

  While reigning models of diffusion have privileged the structure of a givensocial network as the key to informational exchange, real human interactions donot appear to take place on a single graph of connections. Using data collectedfrom a pilot study of the spread of HIV awareness in social networks ofhomeless youth, we show that health information did not diffuse in the fieldaccording to the processes outlined by dominant models. Since physical networkdiffusion scenarios often diverge from their more well-studied counterparts ondigital networks, we propose an alternative Activation Jump Model (AJM) thatdescribes information diffusion on physical networks from a multi-agent teamperspective. Our model exhibits two main differentiating features from leadingcascade and threshold models of influence spread: 1) The structural compositionof a seed set team impacts each individual node's influencing behavior, and 2)an influencing node may spread information to non-neighbors. We show that theAJM significantly outperforms existing models in its fit to the observednode-level influence data on the youth networks. We then prove theoreticalresults, showing that the AJM exhibits many well-behaved properties shared bydominant models. Our results suggest that the AJM presents a flexible and moreaccurate model of network diffusion that may better inform influencemaximization in the field.

Video Labeling for Automatic Video Surveillance in Security Domains

  Beyond traditional security methods, unmanned aerial vehicles (UAVs) havebecome an important surveillance tool used in security domains to collect therequired annotated data. However, collecting annotated data from videos takenby UAVs efficiently, and using these data to build datasets that can be usedfor learning payoffs or adversary behaviors in game-theoretic approaches andsecurity applications, is an under-explored research question. This paperpresents VIOLA, a novel labeling application that includes (i) a workloaddistribution framework to efficiently gather human labels from videos in asecured manner; (ii) a software interface with features designed for labelingvideos taken by UAVs in the domain of wildlife security. We also present theevolution of VIOLA and analyze how the changes made in the development processrelate to the efficiency of labeling, including when seemingly obviousimprovements did not lead to increased efficiency. VIOLA enables collectingmassive amounts of data with detailed information from challenging securityvideos such as those collected aboard UAVs for wildlife security. VIOLA willlead to the development of new approaches that integrate deep learning forreal-time detection and response.

Melding the Data-Decisions Pipeline: Decision-Focused Learning for  Combinatorial Optimization

  Creating impact in real-world settings requires artificial intelligencetechniques to span the full pipeline from data, to predictive models, todecisions. These components are typically approached separately: a machinelearning model is first trained via a measure of predictive accuracy, and thenits predictions are used as input into an optimization algorithm which producesa decision. However, the loss function used to train the model may easily bemisaligned with the end goal, which is to make the best decisions possible.Hand-tuning the loss function to align with optimization is a difficult anderror-prone process (which is often skipped entirely).  We focus on combinatorial optimization problems and introduce a generalframework for decision-focused learning, where the machine learning model isdirectly trained in conjunction with the optimization algorithm to producehigh-quality decisions. Technically, our contribution is a means of integratingcommon classes of discrete optimization problems into deep learning or otherpredictive models, which are typically trained via gradient descent. The mainidea is to use a continuous relaxation of the discrete problem to propagategradients through the optimization procedure. We instantiate this framework fortwo broad classes of combinatorial problems: linear programs and submodularmaximization. Experimental results across a variety of domains show thatdecision-focused learning often leads to improved optimization performancecompared to traditional methods. We find that standard measures of accuracy arenot a reliable proxy for a predictive model's utility in optimization, and ourmethod's ability to specify the true goal as the model's training objectiveyields substantial dividends across a range of decision problems.

On the Inducibility of Stackelberg Equilibrium for Security Games

  Strong Stackelberg equilibrium (SSE) is the standard solution concept ofStackelberg security games. As opposed to the weak Stackelberg equilibrium(WSE), the SSE assumes that the follower breaks ties in favor of the leader andthis is widely acknowledged and justified by the assertion that the defendercan often induce the attacker to choose a preferred action by making aninfinitesimal adjustment to her strategy. Unfortunately, in security games withresource assignment constraints, the assertion might not be valid; it ispossible that the defender cannot induce the desired outcome. As a result, manyresults claimed in the literature may be overly optimistic. To remedy, we firstformally define the utility guarantee of a defender strategy and provideexamples to show that the utility of SSE can be higher than its utilityguarantee. Second, inspired by the analysis of leader's payoff by Von Stengeland Zamir (2004), we provide the solution concept called the inducibleStackelberg equilibrium (ISE), which owns the highest utility guarantee andalways exists. Third, we show the conditions when ISE coincides with SSE andthe fact that in general case, SSE can be extremely worse with respect toutility guarantee. Moreover, introducing the ISE does not invalidate existingalgorithmic results as the problem of computing an ISE polynomially reduces tothat of computing an SSE. We also provide an algorithmic implementation forcomputing ISE, with which our experiments unveil the empirical advantage of theISE over the SSE.

Learning to Prescribe Interventions for Tuberculosis Patients using  Digital Adherence Data

  Digital Adherence Technologies (DATs) are an increasingly popular method forverifying patient adherence to many medications. We analyze data from one cityserved by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB)treatment in India where nearly 3 million people are afflicted with the diseaseeach year. The data contains nearly 17,000 patients and 2.1M phone calls. Welay the groundwork for learning from this real-world data, including a methodfor avoiding the effects of unobserved interventions in training data used formachine learning. We then construct a deep learning model, demonstrate itsinterpretability, and show how it can be adapted and trained in three differentclinical scenarios to better target and improve patient care. In the real-timerisk prediction setting our model could be used to proactively intervene with21% more patients and before 76% more missed doses than current heuristicbaselines. For outcome prediction, our model performs 40% better than baselinemethods, allowing cities to target more resources to clinics with a heavierburden of patients at risk of failure. Finally, we present a case studydemonstrating how our model can be trained in an end-to-end decision focusedlearning setting to achieve 15% better solution quality in an example decisionproblem faced by health workers.

Stay Ahead of Poachers: Illegal Wildlife Poaching Prediction and Patrol  Planning Under Uncertainty with Field Test Evaluations

  Illegal wildlife poaching threatens ecosystems and drives endangered speciestoward extinction. However, efforts for wildlife monitoring and protection inconservation areas are constrained by the limited resources of law enforcementagencies. To aid in wildlife protection, PAWS is an ML pipeline that has beendeveloped as an end-to-end, data-driven approach to combat illegal poaching.PAWS assists park managers by identifying areas at high risk of poachingthroughout protected areas based on real-world data and generating optimalpatrol routes for deployment in the field. In this paper, we addresssignificant challenges including extreme class imbalance (up to 1:200), bias,and uncertainty in wildlife poaching data to enhance PAWS and apply itsmethodology to several national parks with diverse characteristics. (i) We useGaussian processes to quantify predictive uncertainty, which we exploit toincrease the robustness of our prescribed patrols. We evaluate our approach onreal-world historic poaching data from Murchison Falls and Queen ElizabethNational Parks in Uganda and, for the first time, Srepok Wildlife Sanctuary inCambodia. (ii) We present the results of large-scale field tests conducted inMurchison Falls and Srepok Wildlife Sanctuary which confirm that the predictivepower of PAWS extends promisingly to multiple parks. This paper is part of aneffort to expand PAWS to 600 parks around the world through integration withSMART conservation software.

Social Network Based Substance Abuse Prevention via Network Modification  (A Preliminary Study)

  Substance use and abuse is a significant public health problem in the UnitedStates. Group-based intervention programs offer a promising means of preventingand reducing substance abuse. While effective, unfortunately, inappropriateintervention groups can result in an increase in deviant behaviors amongparticipants, a process known as deviancy training. This paper investigates theproblem of optimizing the social influence related to the deviant behavior viacareful construction of the intervention groups. We propose a Mixed IntegerOptimization formulation that decides on the intervention groups, captures theimpact of the groups on the structure of the social network, and models theimpact of these changes on behavior propagation. In addition, we propose ascalable hybrid meta-heuristic algorithm that combines Mixed IntegerProgramming and Large Neighborhood Search to find near-optimal networkpartitions. Our algorithm is packaged in the form of GUIDE, an AI-baseddecision aid that recommends intervention groups. Being the first quantitativedecision aid of this kind, GUIDE is able to assist practitioners, in particularsocial workers, in three key areas: (a) GUIDE proposes near-optimal solutionsthat are shown, via extensive simulations, to significantly improve over thetraditional qualitative practices for forming intervention groups; (b) GUIDE isable to identify circumstances when an intervention will lead to deviancytraining, thus saving time, money, and effort; (c) GUIDE can evaluate currentstrategies of group formation and discard strategies that will lead to deviancytraining. In developing GUIDE, we are primarily interested in substance useinterventions among homeless youth as a high risk and vulnerable population.GUIDE is developed in collaboration with Urban Peak, a homeless-youth servingorganization in Denver, CO, and is under preparation for deployment.

