Security Games with Information Leakage: Modeling and Computation

  Most models of Stackelberg security games assume that the attacker only knows
the defender's mixed strategy, but is not able to observe (even partially) the
instantiated pure strategy. Such partial observation of the deployed pure
strategy -- an issue we refer to as information leakage -- is a significant
concern in practical applications. While previous research on patrolling games
has considered the attacker's real-time surveillance, our settings, therefore
models and techniques, are fundamentally different. More specifically, after
describing the information leakage model, we start with an LP formulation to
compute the defender's optimal strategy in the presence of leakage. Perhaps
surprisingly, we show that a key subproblem to solve this LP (more precisely,
the defender oracle) is NP-hard even for the simplest of security game models.
We then approach the problem from three possible directions: efficient
algorithms for restricted cases, approximation algorithms, and heuristic
algorithms for sampling that improves upon the status quo. Our experiments
confirm the necessity of handling information leakage and the advantage of our
algorithms.


Pilot Testing an Artificial Intelligence Algorithm That Selects Homeless
  Youth Peer Leaders Who Promote HIV Testing

  Objective. To pilot test an artificial intelligence (AI) algorithm that
selects peer change agents (PCA) to disseminate HIV testing messaging in a
population of homeless youth. Methods. We recruited and assessed 62 youth at
baseline, 1 month (n = 48), and 3 months (n = 38). A Facebook app collected
preliminary social network data. Eleven PCAs selected by AI attended a 1-day
training and 7 weekly booster sessions. Mixed-effects models with random
effects were used to assess change over time. Results. Significant change over
time was observed in past 6-month HIV testing (57.9%, 82.4%, 76.3%; p < .05)
but not condom use (63.9%, 65.7%, 65.8%). Most youth reported speaking to a PCA
about HIV prevention (72.0% at 1 month, 61.5% at 3 months). Conclusions. AI is
a promising avenue for implementing PCA models for homeless youth. Increasing
rates of regular HIV testing is critical to HIV prevention and linking homeless
youth to treatment.


Mitigating the Curse of Correlation in Security Games by Entropy
  Maximization

  In Stackelberg security games, a defender seeks to randomly allocate limited
security resources to protect critical targets from an attack. In this paper,
we study a fundamental, yet underexplored, phenomenon in security games, which
we term the \emph{Curse of Correlation} (CoC). Specifically, we observe that
there are inevitable correlations among the protection status of different
targets. Such correlation is a crucial concern, especially in
\emph{spatio-temporal} domains like conservation area patrolling, where
attackers can surveil patrollers at certain areas and then infer their
patrolling routes using such correlations. To mitigate this issue, we propose
to design entropy-maximizing defending strategies for spatio-temporal security
games, which frequently suffer from CoC. We prove that the problem is \#P-hard
in general. However, it admits efficient algorithms in well-motivated special
settings. Our experiments show significant advantages of max-entropy algorithms
over previous algorithms. A scalable implementation of our algorithm is
currently under pre-deployment testing for integration into FAMS software to
improve the scheduling of US federal air marshals.


Practical Scalability for Stackelberg Security Games

  Stackelberg Security Games (SSGs) have been adopted widely for modeling
adversarial interactions. With increasing size of the applications of SSGs,
scalability of equilibrium computation is an important research problem. While
prior research has made progress with regards to scalability, many real world
problems cannot be solved satisfactorily yet as per current requirements; these
include the deployed federal air marshals (FAMS) application and the threat
screening (TSG) problem at airports. Further, these problem domains are
inherently limited by NP hardness shown in prior literature. We initiate a
principled study of approximations in zero-sum SSGs. Our contribution includes
the following: (1) a unified model of SSGs called adversarial randomized
allocation (ARA) games that allows studying most SSGs in one model, (2)
hardness of approximation results for zero-sum ARA, as well as for the
sub-problem of allocating federal air marshal (FAMS) and threat screening
problem (TSG) at airports, (3) an approximation framework for zero-sum ARA with
provable approximation guarantees and (4) experiments demonstrating the
significant scalability of up to 1000x improvement in runtime with an
acceptable 5% solution quality loss.


Decentralized dynamic task allocation for UAVs with limited
  communication range

  We present the Limited-range Online Routing Problem (LORP), which involves a
team of Unmanned Aerial Vehicles (UAVs) with limited communication range that
must autonomously coordinate to service task requests. We first show a general
approach to cast this dynamic problem as a sequence of decentralized task
allocation problems. Then we present two solutions both based on modeling the
allocation task as a Markov Random Field to subsequently assess decisions by
means of the decentralized Max-Sum algorithm. Our first solution assumes
independence between requests, whereas our second solution also considers the
UAVs' workloads. A thorough empirical evaluation shows that our workload-based
solution consistently outperforms current state-of-the-art methods in a wide
range of scenarios, lowering the average service time up to 16%. In the
best-case scenario there is no gap between our decentralized solution and
centralized techniques. In the worst-case scenario we manage to reduce by 25%
the gap between current decentralized and centralized techniques. Thus, our
solution becomes the method of choice for our problem.


Artificial Intelligence for Social Good

  The Computing Community Consortium (CCC), along with the White House Office
of Science and Technology Policy (OSTP), and the Association for the
Advancement of Artificial Intelligence (AAAI), co-sponsored a public workshop
on Artificial Intelligence for Social Good on June 7th, 2016 in Washington, DC.
This was one of five workshops that OSTP co-sponsored and held around the
country to spur public dialogue on artificial intelligence, machine learning,
and to identify challenges and opportunities related to AI. In the AI for
Social Good workshop, the successful deployments and the potential use of AI in
various topics that are essential for social good were discussed, including but
not limited to urban computing, health, environmental sustainability, and
public welfare. This report highlights each of these as well as a number of
crosscutting issues.


Decision-Focused Learning of Adversary Behavior in Security Games

  Stackelberg security games are a critical tool for maximizing the utility of
limited defense resources to protect important targets from an intelligent
adversary. Motivated by green security, where the defender may only observe an
adversary's response to defense on a limited set of targets, we study the
problem of defending against the same adversary on a larger set of targets from
the same distribution. We give a theoretical justification for why standard
two-stage learning approaches, where a model of the adversary is trained for
predictive accuracy and then optimized against, may fail to maximize the
defender's expected utility in this setting. We develop a decision-focused
learning approach, where the adversary behavior model is optimized for decision
quality, and show empirically that it achieves higher defender expected utility
than the two-stage approach when there is limited training data and a large
number of target features.


Group-Fairness in Influence Maximization

  Influence maximization is a widely used model for information dissemination
in social networks. Recent work has employed such interventions across a wide
range of social problems, spanning public health, substance abuse, and
international development (to name a few examples). A critical but understudied
question is whether the benefits of such interventions are fairly distributed
across different groups in the population; e.g., avoiding discrimination with
respect to sensitive attributes such as race or gender. Drawing on legal and
game-theoretic concepts, we introduce formal definitions of fairness in
influence maximization. We provide an algorithmic framework to find solutions
which satisfy fairness constraints, and in the process improve the state of the
art for general multi-objective submodular maximization problems. Experimental
results on real data from an HIV prevention intervention for homeless youth
show that standard influence maximization techniques oftentimes neglect smaller
groups which contribute less to overall utility, resulting in a disparity which
our proposed algorithms substantially reduce.


Who and When to Screen: Multi-Round Active Screening for Recurrent
  Infectious Diseases Under Uncertainty

  Controlling recurrent infectious diseases is a vital yet complicated problem.
In this paper, we propose a novel active screening model (ACTS) and algorithms
to facilitate active screening for recurrent diseases (no permanent immunity)
under infection uncertainty. Our contributions are: (1) A new approach to
modeling multi-round network-based screening/contact tracing under uncertainty,
which is a common real-life practice in a variety of diseases; (2) Two novel
algorithms, Full- and Fast-REMEDY. Full-REMEDY considers the effect of future
actions and finds a policy that provides high solution quality, where
Fast-REMEDY scales linearly in the size of the network; (3) We evaluate Full-
and Fast-REMEDY on several real-world datasets which emulate human contact and
find that they control diseases better than the baselines. To the best of our
knowledge, this is the first work on multi-round active screening with
uncertainty for diseases with no permanent immunity.


Stackelberg vs. Nash in Security Games: An Extended Investigation of
  Interchangeability, Equivalence, and Uniqueness

  There has been significant recent interest in game-theoretic approaches to
security, with much of the recent research focused on utilizing the
leader-follower Stackelberg game model. Among the major applications are the
ARMOR program deployed at LAX Airport and the IRIS program in use by the US
Federal Air Marshals (FAMS). The foundational assumption for using Stackelberg
games is that security forces (leaders), acting first, commit to a randomized
strategy; while their adversaries (followers) choose their best response after
surveillance of this randomized strategy. Yet, in many situations, a leader may
face uncertainty about the follower's surveillance capability. Previous work
fails to address how a leader should compute her strategy given such
uncertainty. We provide five contributions in the context of a general class of
security games. First, we show that the Nash equilibria in security games are
interchangeable, thus alleviating the equilibrium selection problem. Second,
under a natural restriction on security games, any Stackelberg strategy is also
a Nash equilibrium strategy; and furthermore, the solution is unique in a class
of security games of which ARMOR is a key exemplar. Third, when faced with a
follower that can attack multiple targets, many of these properties no longer
hold. Fourth, we show experimentally that in most (but not all) games where the
restriction does not hold, the Stackelberg strategy is still a Nash equilibrium
strategy, but this is no longer true when the attacker can attack multiple
targets. Finally, as a possible direction for future research, we propose an
extensive-form game model that makes the defender's uncertainty about the
attacker's ability to observe explicit.


Using Social Networks to Aid Homeless Shelters: Dynamic Influence
  Maximization under Uncertainty - An Extended Version

  This paper presents HEALER, a software agent that recommends sequential
intervention plans for use by homeless shelters, who organize these
interventions to raise awareness about HIV among homeless youth. HEALER's
sequential plans (built using knowledge of social networks of homeless youth)
choose intervention participants strategically to maximize influence spread,
while reasoning about uncertainties in the network. While previous work
presents influence maximizing techniques to choose intervention participants,
they do not address three real-world issues: (i) they completely fail to scale
up to real-world sizes; (ii) they do not handle deviations in execution of
intervention plans; (iii) constructing real-world social networks is an
expensive process. HEALER handles these issues via four major contributions:
(i) HEALER casts this influence maximization problem as a POMDP and solves it
using a novel planner which scales up to previously unsolvable real-world
sizes; (ii) HEALER allows shelter officials to modify its recommendations, and
updates its future plans in a deviation-tolerant manner; (iii) HEALER
constructs social networks of homeless youth at low cost, using a Facebook
application. Finally, (iv) we show hardness results for the problem that HEALER
solves. HEALER will be deployed in the real world in early Spring 2016 and is
currently undergoing testing at a homeless shelter.


Learning Adversary Behavior in Security Games: A PAC Model Perspective

  Recent applications of Stackelberg Security Games (SSG), from wildlife crime
to urban crime, have employed machine learning tools to learn and predict
adversary behavior using available data about defender-adversary interactions.
Given these recent developments, this paper commits to an approach of directly
learning the response function of the adversary. Using the PAC model, this
paper lays a firm theoretical foundation for learning in SSGs (e.g.,
theoretically answer questions about the numbers of samples required to learn
adversary behavior) and provides utility guarantees when the learned adversary
model is used to plan the defender's strategy. The paper also aims to answer
practical questions such as how much more data is needed to improve an
adversary model's accuracy. Additionally, we explain a recently observed
phenomenon that prediction accuracy of learned adversary behavior is not enough
to discover the utility maximizing defender strategy. We provide four main
contributions: (1) a PAC model of learning adversary response functions in
SSGs; (2) PAC-model analysis of the learning of key, existing bounded
rationality models in SSGs; (3) an entirely new approach to adversary modeling
based on a non-parametric class of response functions with PAC-model analysis
and (4) identification of conditions under which computing the best defender
strategy against the learned adversary behavior is indeed the optimal strategy.
Finally, we conduct experiments with real-world data from a national park in
Uganda, showing the benefit of our new adversary modeling approach and
verification of our PAC model predictions.


Activating the "Breakfast Club": Modeling Influence Spread in
  Natural-World Social Networks

  While reigning models of diffusion have privileged the structure of a given
social network as the key to informational exchange, real human interactions do
not appear to take place on a single graph of connections. Using data collected
from a pilot study of the spread of HIV awareness in social networks of
homeless youth, we show that health information did not diffuse in the field
according to the processes outlined by dominant models. Since physical network
diffusion scenarios often diverge from their more well-studied counterparts on
digital networks, we propose an alternative Activation Jump Model (AJM) that
describes information diffusion on physical networks from a multi-agent team
perspective. Our model exhibits two main differentiating features from leading
cascade and threshold models of influence spread: 1) The structural composition
of a seed set team impacts each individual node's influencing behavior, and 2)
an influencing node may spread information to non-neighbors. We show that the
AJM significantly outperforms existing models in its fit to the observed
node-level influence data on the youth networks. We then prove theoretical
results, showing that the AJM exhibits many well-behaved properties shared by
dominant models. Our results suggest that the AJM presents a flexible and more
accurate model of network diffusion that may better inform influence
maximization in the field.


Video Labeling for Automatic Video Surveillance in Security Domains

  Beyond traditional security methods, unmanned aerial vehicles (UAVs) have
become an important surveillance tool used in security domains to collect the
required annotated data. However, collecting annotated data from videos taken
by UAVs efficiently, and using these data to build datasets that can be used
for learning payoffs or adversary behaviors in game-theoretic approaches and
security applications, is an under-explored research question. This paper
presents VIOLA, a novel labeling application that includes (i) a workload
distribution framework to efficiently gather human labels from videos in a
secured manner; (ii) a software interface with features designed for labeling
videos taken by UAVs in the domain of wildlife security. We also present the
evolution of VIOLA and analyze how the changes made in the development process
relate to the efficiency of labeling, including when seemingly obvious
improvements did not lead to increased efficiency. VIOLA enables collecting
massive amounts of data with detailed information from challenging security
videos such as those collected aboard UAVs for wildlife security. VIOLA will
lead to the development of new approaches that integrate deep learning for
real-time detection and response.


Melding the Data-Decisions Pipeline: Decision-Focused Learning for
  Combinatorial Optimization

  Creating impact in real-world settings requires artificial intelligence
techniques to span the full pipeline from data, to predictive models, to
decisions. These components are typically approached separately: a machine
learning model is first trained via a measure of predictive accuracy, and then
its predictions are used as input into an optimization algorithm which produces
a decision. However, the loss function used to train the model may easily be
misaligned with the end goal, which is to make the best decisions possible.
Hand-tuning the loss function to align with optimization is a difficult and
error-prone process (which is often skipped entirely).
  We focus on combinatorial optimization problems and introduce a general
framework for decision-focused learning, where the machine learning model is
directly trained in conjunction with the optimization algorithm to produce
high-quality decisions. Technically, our contribution is a means of integrating
common classes of discrete optimization problems into deep learning or other
predictive models, which are typically trained via gradient descent. The main
idea is to use a continuous relaxation of the discrete problem to propagate
gradients through the optimization procedure. We instantiate this framework for
two broad classes of combinatorial problems: linear programs and submodular
maximization. Experimental results across a variety of domains show that
decision-focused learning often leads to improved optimization performance
compared to traditional methods. We find that standard measures of accuracy are
not a reliable proxy for a predictive model's utility in optimization, and our
method's ability to specify the true goal as the model's training objective
yields substantial dividends across a range of decision problems.


On the Inducibility of Stackelberg Equilibrium for Security Games

  Strong Stackelberg equilibrium (SSE) is the standard solution concept of
Stackelberg security games. As opposed to the weak Stackelberg equilibrium
(WSE), the SSE assumes that the follower breaks ties in favor of the leader and
this is widely acknowledged and justified by the assertion that the defender
can often induce the attacker to choose a preferred action by making an
infinitesimal adjustment to her strategy. Unfortunately, in security games with
resource assignment constraints, the assertion might not be valid; it is
possible that the defender cannot induce the desired outcome. As a result, many
results claimed in the literature may be overly optimistic. To remedy, we first
formally define the utility guarantee of a defender strategy and provide
examples to show that the utility of SSE can be higher than its utility
guarantee. Second, inspired by the analysis of leader's payoff by Von Stengel
and Zamir (2004), we provide the solution concept called the inducible
Stackelberg equilibrium (ISE), which owns the highest utility guarantee and
always exists. Third, we show the conditions when ISE coincides with SSE and
the fact that in general case, SSE can be extremely worse with respect to
utility guarantee. Moreover, introducing the ISE does not invalidate existing
algorithmic results as the problem of computing an ISE polynomially reduces to
that of computing an SSE. We also provide an algorithmic implementation for
computing ISE, with which our experiments unveil the empirical advantage of the
ISE over the SSE.


Learning to Prescribe Interventions for Tuberculosis Patients using
  Digital Adherence Data

  Digital Adherence Technologies (DATs) are an increasingly popular method for
verifying patient adherence to many medications. We analyze data from one city
served by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB)
treatment in India where nearly 3 million people are afflicted with the disease
each year. The data contains nearly 17,000 patients and 2.1M phone calls. We
lay the groundwork for learning from this real-world data, including a method
for avoiding the effects of unobserved interventions in training data used for
machine learning. We then construct a deep learning model, demonstrate its
interpretability, and show how it can be adapted and trained in three different
clinical scenarios to better target and improve patient care. In the real-time
risk prediction setting our model could be used to proactively intervene with
21% more patients and before 76% more missed doses than current heuristic
baselines. For outcome prediction, our model performs 40% better than baseline
methods, allowing cities to target more resources to clinics with a heavier
burden of patients at risk of failure. Finally, we present a case study
demonstrating how our model can be trained in an end-to-end decision focused
learning setting to achieve 15% better solution quality in an example decision
problem faced by health workers.


Stay Ahead of Poachers: Illegal Wildlife Poaching Prediction and Patrol
  Planning Under Uncertainty with Field Test Evaluations

  Illegal wildlife poaching threatens ecosystems and drives endangered species
toward extinction. However, efforts for wildlife monitoring and protection in
conservation areas are constrained by the limited resources of law enforcement
agencies. To aid in wildlife protection, PAWS is an ML pipeline that has been
developed as an end-to-end, data-driven approach to combat illegal poaching.
PAWS assists park managers by identifying areas at high risk of poaching
throughout protected areas based on real-world data and generating optimal
patrol routes for deployment in the field. In this paper, we address
significant challenges including extreme class imbalance (up to 1:200), bias,
and uncertainty in wildlife poaching data to enhance PAWS and apply its
methodology to several national parks with diverse characteristics. (i) We use
Gaussian processes to quantify predictive uncertainty, which we exploit to
increase the robustness of our prescribed patrols. We evaluate our approach on
real-world historic poaching data from Murchison Falls and Queen Elizabeth
National Parks in Uganda and, for the first time, Srepok Wildlife Sanctuary in
Cambodia. (ii) We present the results of large-scale field tests conducted in
Murchison Falls and Srepok Wildlife Sanctuary which confirm that the predictive
power of PAWS extends promisingly to multiple parks. This paper is part of an
effort to expand PAWS to 600 parks around the world through integration with
SMART conservation software.


Social Network Based Substance Abuse Prevention via Network Modification
  (A Preliminary Study)

  Substance use and abuse is a significant public health problem in the United
States. Group-based intervention programs offer a promising means of preventing
and reducing substance abuse. While effective, unfortunately, inappropriate
intervention groups can result in an increase in deviant behaviors among
participants, a process known as deviancy training. This paper investigates the
problem of optimizing the social influence related to the deviant behavior via
careful construction of the intervention groups. We propose a Mixed Integer
Optimization formulation that decides on the intervention groups, captures the
impact of the groups on the structure of the social network, and models the
impact of these changes on behavior propagation. In addition, we propose a
scalable hybrid meta-heuristic algorithm that combines Mixed Integer
Programming and Large Neighborhood Search to find near-optimal network
partitions. Our algorithm is packaged in the form of GUIDE, an AI-based
decision aid that recommends intervention groups. Being the first quantitative
decision aid of this kind, GUIDE is able to assist practitioners, in particular
social workers, in three key areas: (a) GUIDE proposes near-optimal solutions
that are shown, via extensive simulations, to significantly improve over the
traditional qualitative practices for forming intervention groups; (b) GUIDE is
able to identify circumstances when an intervention will lead to deviancy
training, thus saving time, money, and effort; (c) GUIDE can evaluate current
strategies of group formation and discard strategies that will lead to deviancy
training. In developing GUIDE, we are primarily interested in substance use
interventions among homeless youth as a high risk and vulnerable population.
GUIDE is developed in collaboration with Urban Peak, a homeless-youth serving
organization in Denver, CO, and is under preparation for deployment.


