Cartoonish sketch-based face editing in videos using identity
  deformation transfer

  We address the problem of using hand-drawn sketches to create exaggerated
deformations to faces in videos, such as enlarging the shape or modifying the
position of eyes or mouth. This task is formulated as a 3D face model
reconstruction and deformation problem. We first recover the facial identity
and expressions from the video by fitting a face morphable model for each
frame. At the same time, user's editing intention is recognized from input
sketches as a set of facial modifications. Then a novel identity deformation
algorithm is proposed to transfer these facial deformations from 2D space to
the 3D facial identity directly while preserving the facial expressions. After
an optional stage for further refining the 3D face model, these changes are
propagated to the whole video with the modified identity. Both the user study
and experimental results demonstrate that our sketching framework can help
users effectively edit facial identities in videos, while high consistency and
fidelity are ensured at the same time.


The Role of Data-driven Priors in Multi-agent Crowd Trajectory
  Estimation

  Trajectory interpolation, the process of filling-in the gaps and removing
noise from observed agent trajectories, is an essential task for the motion
inference in multi-agent setting. A desired trajectory interpolation method
should be robust to noise, changes in environments or agent densities, while
also being yielding realistic group movement behaviors. Such realistic
behaviors are, however, challenging to model as they require avoidance of
agent-agent or agent-environment collisions and, at the same time, seek
computational efficiency. In this paper, we propose a novel framework composed
of data-driven priors (local, global or combined) and an efficient optimization
strategy for multi-agent trajectory interpolation. The data-driven priors
implicitly encode the dependencies of movements of multiple agents and the
collision-avoiding desiderata, enabling elimination of costly pairwise
collision constraints and resulting in reduced computational complexity and
often improved estimation. Various combinations of priors and optimization
algorithms are evaluated in comprehensive simulated experiments. Our
experimental results reveal important insights, including the significance of
the global flow prior and the lesser-than-expected influence of data-driven
collision priors.


Learning to Forecast and Refine Residual Motion for Image-to-Video
  Generation

  We consider the problem of image-to-video translation, where an input image
is translated into an output video containing motions of a single object.
Recent methods for such problems typically train transformation networks to
generate future frames conditioned on the structure sequence. Parallel work has
shown that short high-quality motions can be generated by spatiotemporal
generative networks that leverage temporal knowledge from the training data. We
combine the benefits of both approaches and propose a two-stage generation
framework where videos are generated from structures and then refined by
temporal signals. To model motions more efficiently, we train networks to learn
residual motion between the current and future frames, which avoids learning
motion-irrelevant details. We conduct extensive experiments on two
image-to-video translation tasks: facial expression retargeting and human pose
forecasting. Superior results over the state-of-the-art methods on both tasks
demonstrate the effectiveness of our approach.


Affect-Driven Dialog Generation

  The majority of current systems for end-to-end dialog generation focus on
response quality without an explicit control over the affective content of the
responses. In this paper, we present an affect-driven dialog system, which
generates emotional responses in a controlled manner using a continuous
representation of emotions. The system achieves this by modeling emotions at a
word and sequence level using: (1) a vector representation of the desired
emotion, (2) an affect regularizer, which penalizes neutral words, and (3) an
affect sampling method, which forces the neural network to generate diverse
words that are emotionally relevant. During inference, we use a reranking
procedure that aims to extract the most emotionally relevant responses using a
human-in-the-loop optimization process. We study the performance of our system
in terms of both quantitative (BLEU score and response diversity), and
qualitative (emotional appropriateness) measures.


Topic Spotting using Hierarchical Networks with Self Attention

  Success of deep learning techniques have renewed the interest in development
of dialogue systems. However, current systems struggle to have consistent long
term conversations with the users and fail to build rapport. Topic spotting,
the task of automatically inferring the topic of a conversation, has been shown
to be helpful in making a dialog system more engaging and efficient. We propose
a hierarchical model with self attention for topic spotting. Experiments on the
Switchboard corpus show the superior performance of our model over previously
proposed techniques for topic spotting and deep models for text classification.
Additionally, in contrast to offline processing of dialog, we also analyze the
performance of our model in a more realistic setting i.e. in an online setting
where the topic is identified in real time as the dialog progresses. Results
show that our model is able to generalize even with limited information in the
online setting.


Domain Authoring Assistant for Intelligent Virtual Agents

  Developing intelligent virtual characters has attracted a lot of attention in
the recent years. The process of creating such characters often involves a team
of creative authors who describe different aspects of the characters in natural
language, and planning experts that translate this description into a planning
domain. This can be quite challenging as the team of creative authors should
diligently define every aspect of the character especially if it contains
complex human-like behavior. Also a team of engineers has to manually translate
the natural language description of a character's personality into the planning
domain knowledge. This can be extremely time and resource demanding and can be
an obstacle to author's creativity. The goal of this paper is to introduce an
authoring assistant tool to automate the process of domain generation from
natural language description of virtual characters, thus bridging between the
creative authoring team and the planning domain experts. Moreover, the proposed
tool also identifies possible missing information in the domain description and
iteratively makes suggestions to the author.


Semantic Graph Convolutional Networks for 3D Human Pose Regression

  In this paper, we study the problem of learning Graph Convolutional Networks
(GCNs) for regression. Current architectures of GCNs are limited to the small
receptive field of convolution filters and shared transformation matrix for
each node. To address these limitations, we propose Semantic Graph
Convolutional Networks (SemGCN), a novel neural network architecture that
operates on regression tasks with graph-structured data. SemGCN learns to
capture semantic information such as local and global node relationships, which
is not explicitly represented in the graph. These semantic relationships can be
learned through end-to-end training from the ground truth without additional
supervision or hand-crafted rules. We further investigate applying SemGCN to 3D
human pose regression. Our formulation is intuitive and sufficient since both
2D and 3D human poses can be represented as a structured graph encoding the
relationships between joints in the skeleton of a human body. We carry out
comprehensive studies to validate our method. The results prove that SemGCN
outperforms state of the art while using 90% fewer parameters.


Generating Animations from Screenplays

  Automatically generating animation from natural language text finds
application in a number of areas e.g. movie script writing, instructional
videos, and public safety. However, translating natural language text into
animation is a challenging task. Existing text-to-animation systems can handle
only very simple sentences, which limits their applications. In this paper, we
develop a text-to-animation system which is capable of handling complex
sentences. We achieve this by introducing a text simplification step into the
process. Building on an existing animation generation system for screenwriting,
we create a robust NLP pipeline to extract information from screenplays and map
them to the system's knowledge base. We develop a set of linguistic
transformation rules that simplify complex sentences. Information extracted
from the simplified sentences is used to generate a rough storyboard and video
depicting the text. Our sentence simplification module outperforms existing
systems in terms of BLEU and SARI metrics.We further evaluated our system via a
user study: 68 % participants believe that our system generates reasonable
animation from input screenplays.


Crowd Behaviour during High-Stress Evacuations in an Immersive Virtual
  Environment

  Understanding the collective dynamics of crowd movements during stressful
emergency situations is central to reducing the risk of deadly crowd disasters.
Yet, their systematic experimental study remains a challenging open problem due
to ethical and methodological constraints. In this paper, we demonstrate the
viability of shared 3D virtual environments as an experimental platform for
conducting crowd experiments with real people. In particular, we show that
crowds of real human subjects moving and interacting in an immersive 3D virtual
environment exhibit typical patterns of real crowds as observed in real-life
crowded situations. These include the manifestation of social conventions and
the emergence of self-organized patterns during egress scenarios. High-stress
evacuation experiments conducted in this virtual environment reveal movements
characterized by mass herding and dangerous overcrowding as they occur in crowd
disasters. We describe the behavioral mechanisms at play under such extreme
conditions and identify critical zones where overcrowding may occur.
Furthermore, we show that herding spontaneously emerges from a density effect
without the need to assume an increase of the individual tendency to imitate
peers. Our experiments reveal the promise of immersive virtual environments as
an ethical, cost-efficient, yet accurate platform for exploring crowd behaviour
in high-risk situations with real human subjects.


Interactive Diversity Optimization of Environments

  The design of a building requires an architect to balance a wide range of
constraints: aesthetic, geometric, usability, lighting, safety, etc. At the
same time, there are often a multiplicity of diverse designs that can meet
these constraints equally well. Architects must use their skills and artistic
vision to explore these rich but highly constrained design spaces. A number of
computer-aided design tools use automation to provide useful analytical data
and optimal designs with respect to certain fitness criteria. However, this
automation can come at the expense of a designer's creative control.
  We propose uDOME, a user-in-the-loop system for computer-aided design
exploration that balances automation and control by efficiently exploring,
analyzing, and filtering the space of environment layouts to better inform an
architect's decision-making. At each design iteration, uDOME provides a set of
diverse designs which satisfy user-defined constraints and optimality criteria
within a user defined parameterization of the design space. The user then
selects a design and performs a similar optimization with the same or different
parameters and objectives. This exploration process can be repeated as many
times as the designer wishes. Our user studies indicates that \DOME, with its
diversity-based approach, improves the efficiency and effectiveness of even
novice users with minimal training, without compromising the quality of their
designs.


