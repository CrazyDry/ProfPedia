On Spectral Analysis of Directed Signed Graphs

  It has been shown that the adjacency eigenspace of a network contains keyinformation of its underlying structure. However, there has been no study onspectral analysis of the adjacency matrices of directed signed graphs. In thispaper, we derive theoretical approximations of spectral projections from suchdirected signed networks using matrix perturbation theory. We use the derivedtheoretical results to study the influences of negative intra cluster and intercluster directed edges on node spectral projections. We then develop a spectralclustering based graph partition algorithm, SC-DSG, and conduct evaluations onboth synthetic and real datasets. Both theoretical analysis and empiricalevaluation demonstrate the effectiveness of the proposed algorithm.

FairGAN: Fairness-aware Generative Adversarial Networks

  Fairness-aware learning is increasingly important in data mining.Discrimination prevention aims to prevent discrimination in the training databefore it is used to conduct predictive analysis. In this paper, we focus onfair data generation that ensures the generated data is discrimination free.Inspired by generative adversarial networks (GAN), we present fairness-awaregenerative adversarial networks, called FairGAN, which are able to learn agenerator producing fair data and also preserving good data utility. Comparedwith the naive fair data generation models, FairGAN further ensures theclassifiers which are trained on generated data can achieve fair classificationon real data. Experiments on a real dataset show the effectiveness of FairGAN.

Fairness-aware Classification: Criterion, Convexity, and Bounds

  Fairness-aware classification is receiving increasing attention in themachine learning fields. Recently research proposes to formulate thefairness-aware classification as constrained optimization problems. However,several limitations exist in previous works due to the lack of a theoreticalframework for guiding the formulation. In this paper, we propose a generalframework for learning fair classifiers which addresses previous limitations.The framework formulates various commonly-used fairness metrics as convexconstraints that can be directly incorporated into classic classificationmodels. Within the framework, we propose a constraint-free criterion on thetraining data which ensures that any classifier learned from the data is fair.We also derive the constraints which ensure that the real fairness metric issatisfied when surrogate functions are used to achieve convexity. Our frameworkcan be used to for formulating fairness-aware classification with fairnessguarantee and computational efficiency. The experiments using real-worlddatasets demonstrate our theoretical results and show the effectiveness ofproposed framework and methods.

SNE: Signed Network Embedding

  Several network embedding models have been developed for unsigned networks.However, these models based on skip-gram cannot be applied to signed networksbecause they can only deal with one type of link. In this paper, we present oursigned network embedding model called SNE. Our SNE adopts the log-bilinearmodel, uses node representations of all nodes along a given path, and furtherincorporates two signed-type vectors to capture the positive or negativerelationship of each edge along the path. We conduct two experiments, nodeclassification and link prediction, on both directed and undirected signednetworks and compare with four baselines including a matrix factorizationmethod and three state-of-the-art unsigned network embedding models. Theexperimental results demonstrate the effectiveness of our signed networkembedding.

Wikipedia Vandal Early Detection: from User Behavior to User Embedding

  Wikipedia is the largest online encyclopedia that allows anyone to editarticles. In this paper, we propose the use of deep learning to detect vandalsbased on their edit history. In particular, we develop a multi-sourcelong-short term memory network (M-LSTM) to model user behaviors by using avariety of user edit aspects as inputs, including the history of edit reversioninformation, edit page titles and categories. With M-LSTM, we can encode eachuser into a low dimensional real vector, called user embedding. Meanwhile, as asequential model, M-LSTM updates the user embedding each time after the usercommits a new edit. Thus, we can predict whether a user is benign or vandaldynamically based on the up-to-date user embedding. Furthermore, those userembeddings are crucial to discover collaborative vandals.

Spectrum-based deep neural networks for fraud detection

  In this paper, we focus on fraud detection on a signed graph with only asmall set of labeled training data. We propose a novel framework that combinesdeep neural networks and spectral graph analysis. In particular, we use thenode projection (called as spectral coordinate) in the low dimensional spectralspace of the graph's adjacency matrix as input of deep neural networks.Spectral coordinates in the spectral space capture the most useful topologyinformation of the network. Due to the small dimension of spectral coordinates(compared with the dimension of the adjacency matrix derived from a graph),training deep neural networks becomes feasible. We develop and evaluate twoneural networks, deep autoencoder and convolutional neural network, in ourfraud detection framework. Experimental results on a real signed graph showthat our spectrum based deep neural networks are effective in fraud detection.

One-Class Adversarial Nets for Fraud Detection

  Many online applications, such as online social networks or knowledge bases,are often attacked by malicious users who commit different types of actionssuch as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, mostof the fraud detection approaches require a training dataset that containsrecords of both benign and malicious users. However, in practice, there areoften no or very few records of malicious users. In this paper, we developone-class adversarial nets (OCAN) for fraud detection using training data withonly benign users. OCAN first uses LSTM-Autoencoder to learn therepresentations of benign users from their sequences of online activities. Itthen detects malicious users by training a discriminator with a complementaryGAN model that is different from the regular GAN model. Experimental resultsshow that our OCAN outperforms the state-of-the-art one-class classificationmodels and achieves comparable performance with the latest multi-source LSTMmodel that requires both benign and malicious users in the training phase.

On Discrimination Discovery and Removal in Ranked Data using Causal  Graph

  Predictive models learned from historical data are widely used to helpcompanies and organizations make decisions. However, they may digitallyunfairly treat unwanted groups, raising concerns about fairness anddiscrimination. In this paper, we study the fairness-aware ranking problemwhich aims to discover discrimination in ranked datasets and reconstruct thefair ranking. Existing methods in fairness-aware ranking are mainly based onstatistical parity that cannot measure the true discriminatory effect sincediscrimination is causal. On the other hand, existing methods in causal-basedanti-discrimination learning focus on classification problems and cannot bedirectly applied to handle the ranked data. To address these limitations, wepropose to map the rank position to a continuous score variable that representsthe qualification of the candidates. Then, we build a causal graph thatconsists of both the discrete profile attributes and the continuous score. Thepath-specific effect technique is extended to the mixed-variable causal graphto identify both direct and indirect discrimination. The relationship betweenthe path-specific effects for the ranked data and those for the binary decisionis theoretically analyzed. Finally, algorithms for discovering and removingdiscrimination from a ranked dataset are developed. Experiments using the realdataset show the effectiveness of our approaches.

Task-specific Word Identification from Short Texts Using a Convolutional  Neural Network

  Task-specific word identification aims to choose the task-related words thatbest describe a short text. Existing approaches require well-defined seed wordsor lexical dictionaries (e.g., WordNet), which are often unavailable for manyapplications such as social discrimination detection and fake review detection.However, we often have a set of labeled short texts where each short text has atask-related class label, e.g., discriminatory or non-discriminatory, specifiedby users or learned by classification algorithms. In this paper, we focus onidentifying task-specific words and phrases from short texts by exploitingtheir class labels rather than using seed words or lexical dictionaries. Weconsider the task-specific word and phrase identification as feature learning.We train a convolutional neural network over a set of labeled texts and usescore vectors to localize the task-specific words and phrases. Experimentalresults on sentiment word identification show that our approach significantlyoutperforms existing methods. We further conduct two case studies to show theeffectiveness of our approach. One case study on a crawled tweets datasetdemonstrates that our approach can successfully capture thediscrimination-related words/phrases. The other case study on fake reviewdetection shows that our approach can identify the fake-review words/phrases.

ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks

  The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal workthat is capable of generating realistic textures during single imagesuper-resolution. However, the hallucinated details are often accompanied withunpleasant artifacts. To further enhance the visual quality, we thoroughlystudy three key components of SRGAN - network architecture, adversarial lossand perceptual loss, and improve each of them to derive an Enhanced SRGAN(ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block(RRDB) without batch normalization as the basic network building unit.Moreover, we borrow the idea from relativistic GAN to let the discriminatorpredict relative realness instead of the absolute value. Finally, we improvethe perceptual loss by using the features before activation, which couldprovide stronger supervision for brightness consistency and texture recovery.Benefiting from these improvements, the proposed ESRGAN achieves consistentlybetter visual quality with more realistic and natural textures than SRGAN andwon the first place in the PIRM2018-SR Challenge. The code is available athttps://github.com/xinntao/ESRGAN .

Achieving non-discrimination in data release

  Discrimination discovery and prevention/removal are increasingly importanttasks in data mining. Discrimination discovery aims to unveil discriminatorypractices on the protected attribute (e.g., gender) by analyzing the dataset ofhistorical decision records, and discrimination prevention aims to removediscrimination by modifying the biased data before conducting predictiveanalysis. In this paper, we show that the key to discrimination discovery andprevention is to find the meaningful partitions that can be used to providequantitative evidences for the judgment of discrimination. With the support ofthe causal graph, we present a graphical condition for identifying a meaningfulpartition. Based on that, we develop a simple criterion for the claim ofnon-discrimination, and propose discrimination removal algorithms whichaccurately remove discrimination while retaining good data utility. Experimentsusing real datasets show the effectiveness of our approaches.

A causal framework for discovering and removing direct and indirect  discrimination

  Anti-discrimination is an increasingly important task in data science. Inthis paper, we investigate the problem of discovering both direct and indirectdiscrimination from the historical data, and removing the discriminatoryeffects before the data is used for predictive analysis (e.g., buildingclassifiers). We make use of the causal network to capture the causal structureof the data. Then we model direct and indirect discrimination as thepath-specific effects, which explicitly distinguish the two types ofdiscrimination as the causal effects transmitted along different paths in thenetwork. Based on that, we propose an effective algorithm for discoveringdirect and indirect discrimination, as well as an algorithm for preciselyremoving both types of discrimination while retaining good data utility.Different from previous works, our approaches can ensure that the predictivemodels built from the modified data will not incur discrimination in decisionmaking. Experiments using real datasets show the effectiveness of ourapproaches.

Achieving non-discrimination in prediction

  Discrimination-aware classification is receiving an increasing attention indata science fields. The pre-process methods for constructing adiscrimination-free classifier first remove discrimination from the trainingdata, and then learn the classifier from the cleaned data. However, they lack atheoretical guarantee for the potential discrimination when the classifier isdeployed for prediction. In this paper, we fill this gap by mathematicallybounding the probability of the discrimination in prediction being within agiven interval in terms of the training data and classifier. We adopt thecausal model for modeling the data generation mechanism, and formally definingdiscrimination in population, in a dataset, and in prediction. We obtain twoimportant theoretical results: (1) the discrimination in prediction can stillexist even if the discrimination in the training data is completely removed;and (2) not all pre-process methods can ensure non-discrimination in predictioneven though they can achieve non-discrimination in the modified training data.Based on the results, we develop a two-phase framework for constructing adiscrimination-free classifier with a theoretical guarantee. The experimentsdemonstrate the theoretical results and show the effectiveness of our two-phaseframework.

Approximate Inverse Frequent Itemset Mining: Privacy, Complexity, and  Approximation

  In order to generate synthetic basket data sets for better benchmark testing,it is important to integrate characteristics from real-life databases into thesynthetic basket data sets. The characteristics that could be used for thispurpose include the frequent itemsets and association rules. The problem ofgenerating synthetic basket data sets from frequent itemsets is generallyreferred to as inverse frequent itemset mining. In this paper, we show that theproblem of approximate inverse frequent itemset mining is {\bf NP}-complete.Then we propose and analyze an approximate algorithm for approximate inversefrequent itemset mining, and discuss privacy issues related to the syntheticbasket data set. In particular, we propose an approximate algorithm todetermine the privacy leakage in a synthetic basket data set.

Adaptive Laplace Mechanism: Differential Privacy Preservation in Deep  Learning

  In this paper, we focus on developing a novel mechanism to preservedifferential privacy in deep neural networks, such that: (1) The privacy budgetconsumption is totally independent of the number of training steps; (2) It hasthe ability to adaptively inject noise into features based on the contributionof each to the output; and (3) It could be applied in a variety of differentdeep neural networks. To achieve this, we figure out a way to perturb affinetransformations of neurons, and loss functions used in deep neural networks. Inaddition, our mechanism intentionally adds "more noise" into features which are"less relevant" to the model output, and vice-versa. Our theoretical analysisfurther derives the sensitivities and error bounds of our mechanism. Rigorousexperiments conducted on MNIST and CIFAR-10 datasets show that our mechanism ishighly effective and outperforms existing solutions.

Preserving Differential Privacy in Convolutional Deep Belief Networks

  The remarkable development of deep learning in medicine and healthcare domainpresents obvious privacy issues, when deep neural networks are built on users'personal and highly sensitive data, e.g., clinical records, user profiles,biomedical images, etc. However, only a few scientific studies on preservingprivacy in deep learning have been conducted. In this paper, we focus ondeveloping a private convolutional deep belief network (pCDBN), whichessentially is a convolutional deep belief network (CDBN) under differentialprivacy. Our main idea of enforcing epsilon-differential privacy is to leveragethe functional mechanism to perturb the energy-based objective functions oftraditional CDBNs, rather than their results. One key contribution of this workis that we propose the use of Chebyshev expansion to derive the approximatepolynomial representation of objective functions. Our theoretical analysisshows that we can further derive the sensitivity and error bounds of theapproximate polynomial representation. As a result, preserving differentialprivacy in CDBNs is feasible. We applied our model in a health social network,i.e., YesiWell data, and in a handwriting digit dataset, i.e., MNIST data, forhuman behavior prediction, human behavior classification, and handwriting digitrecognition tasks. Theoretical analysis and rigorous experimental evaluationsshow that the pCDBN is highly effective. It significantly outperforms existingsolutions.

SAFE: A Neural Survival Analysis Model for Fraud Early Detection

  Many online platforms have deployed anti-fraud systems to detect and preventfraudulent activities. However, there is usually a gap between the time that auser commits a fraudulent action and the time that the user is suspended by theplatform. How to detect fraudsters in time is a challenging problem. Most ofthe existing approaches adopt classifiers to predict fraudsters given theiractivity sequences along time. The main drawback of classification models isthat the prediction results between consecutive timestamps are ofteninconsistent. In this paper, we propose a survival analysis based fraud earlydetection model, SAFE, which maps dynamic user activities to survivalprobabilities that are guaranteed to be monotonically decreasing along time.SAFE adopts recurrent neural network (RNN) to handle user activity sequencesand directly outputs hazard values at each timestamp, and then, survivalprobability derived from hazard values is deployed to achieve consistentpredictions. Because we only observe the user suspended time instead of thefraudulent activity time in the training data, we revise the loss function ofthe regular survival model to achieve fraud early detection. Experimentalresults on two real world datasets demonstrate that SAFE outperforms both thesurvival analysis model and recurrent neural network model alone as well asstate-of-the-art fraud early detection approaches.

