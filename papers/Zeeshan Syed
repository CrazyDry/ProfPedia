Contributions of PDM Systems in Organizational Technical Data Management

  Product Data Management (PDM) claims of producing desktop and web based
systems to maintain the organizational data to increase the quality of products
by improving the process of development, business process flows, change
management, product structure management, project tracking and resource
planning. Moreover PDM helps in reducing the cost and effort required in
engineering. This paper discusses PDM desktop and web based system, needed
information and important guidelines for PDM system development, functional
requirements, basic components in detail and some already implemented PDM
Sys-tems. In the end paper investigates and briefly concludes major currently
faced challenges to Product Data Management (PDM) community.


An accelerated CLPSO algorithm

  The particle swarm approach provides a low complexity solution to the
optimization problem among various existing heuristic algorithms. Recent
advances in the algorithm resulted in improved performance at the cost of
increased computational complexity, which is undesirable. Literature shows that
the particle swarm optimization algorithm based on comprehensive learning
provides the best complexity-performance trade-off. We show how to reduce the
complexity of this algorithm further, with a slight but acceptable performance
loss. This enhancement allows the application of the algorithm in time critical
applications, such as, real-time tracking, equalization etc.


Association of Networked Flying Platforms with Small Cells for Network
  Centric 5G+ C-RAN

  5G+ systems expect enhancement in data rate and coverage area under limited
power constraint. Such requirements can be fulfilled by the densification of
small cells (SCs). However, a major challenge is the management of fronthaul
links connected with an ultra dense network of SCs. A cost effective and
scalable idea of using network flying platforms (NFPs) is employed here, where
the NFPs are used as fronthaul hubs that connect the SCs to the core network.
The association problem of NFPs and SCs is formulated considering a number of
practical constraints such as backhaul data rate limit, maximum supported links
and bandwidth by NFPs and quality of service requirement of the system. The
network centric case of the system is considered that aims to maximize the
number of associated SCs without any biasing, i.e., no preference for high
priority SCs. Then, two new efficient greedy algorithms are designed to solve
the presented association problem. Numerical results show a favorable
performance of our proposed methods in comparison to exhaustive search.


A Distributed Approach for Networked Flying Platform Association with
  Small Cells in 5G+ Networks

  The densification of small-cell base stations in a 5G architecture is a
promising approach to enhance the coverage area and facilitate the ever
increasing capacity demand of end users. However, the bottleneck is an
intelligent management of a backhaul/fronthaul network for these small-cell
base stations. This involves efficient association and placement of the
backhaul hubs that connects these small-cells with the core network.
Terrestrial hubs suffer from an inefficient non line of sight link limitations
and unavailability of a proper infrastructure in an urban area. Seeing the
popularity of flying platforms, we employ here an idea of using networked
flying platform (NFP) such as unmanned aerial vehicles (UAVs), drones, unmanned
balloons flying at different altitudes, as aerial backhaul hubs. The
association problem of these NFP-hubs and small-cell base stations is
formulated considering backhaul link and NFP related limitations such as
maximum number of supported links and bandwidth. Then, this paper presents an
efficient and distributed solution of the designed problem, which performs a
greedy search in order to maximize the sum rate of the overall network. A
favorable performance is observed via a numerical comparison of our proposed
method with optimal exhaustive search algorithm in terms of sum rate and
run-time speed.


Small Cell Association with Networked Flying Platforms: Novel Algorithms
  and Performance Bounds

  Fifth generation (5G) and beyond-5G (B5G) systems expect coverage and
capacity enhancements along with the consideration of limited power, cost and
spectrum. Densification of small cells (SCs) is a promising approach to cater
these demands of 5G and B5G systems. However, such an ultra dense network of
SCs requires provision of smart backhaul and fronthaul networks. In this paper,
we employ a scalable idea of using networked flying platforms (NFPs) as aerial
hubs to provide fronthaul connectivity to the SCs. We consider the association
problem of SCs and NFPs in a SC network and study the effect of practical
constraints related to the system and NFPs. Mainly, we show that the
association problem is related to the generalized assignment problem (GAP).
Using this relation with the GAP, we show the NP-hard complexity of the
association problem and further derive an upper bound for the maximum
achievable sum data rate. Linear Programming relaxation of the problem is also
studied to compare the results with the derived bounds. Finally, two efficient
(less complex) greedy solutions of the association problem are presented, where
one of them is a distributed solution and the other one is its centralized
version. Numerical results show a favorable performance of the presented
algorithms with respect to the exhaustive search and derived bounds. The
computational complexity comparison of the algorithms with the exhaustive
search is also presented to show that the presented algorithms can be
practically implemented.


Low-Complexity Particle Swarm Optimization for Time-Critical
  Applications

  Particle swam optimization (PSO) is a popular stochastic optimization method
that has found wide applications in diverse fields. However, PSO suffers from
high computational complexity and slow convergence speed. High computational
complexity hinders its use in applications that have limited power resources
while slow convergence speed makes it unsuitable for time critical
applications. In this paper, we propose two techniques to overcome these
limitations. The first technique reduces the computational complexity of PSO
while the second technique speeds up its convergence. These techniques can be
applied, either separately or in conjunction, to any existing PSO variant. The
proposed techniques are robust to the number of dimensions of the optimization
problem. Simulation results are presented for the proposed techniques applied
to the standard PSO as well as to several PSO variants. The results show that
the use of both these techniques in conjunction results in a reduction in the
number of computations required as well as faster convergence speed while
maintaining an acceptable error performance for time-critical applications.


Uncovering Voice Misuse Using Symbolic Mismatch

  Voice disorders affect an estimated 14 million working-aged Americans, and
many more worldwide. We present the first large scale study of vocal misuse
based on long-term ambulatory data collected by an accelerometer placed on the
neck. We investigate an unsupervised data mining approach to uncovering latent
information about voice misuse.
  We segment signals from over 253 days of data from 22 subjects into over a
hundred million single glottal pulses (closures of the vocal folds), cluster
segments into symbols, and use symbolic mismatch to uncover differences between
patients and matched controls, and between patients pre- and post-treatment.
Our results show significant behavioral differences between patients and
controls, as well as between some pre- and post-treatment patients. Our
proposed approach provides an objective basis for helping diagnose behavioral
voice disorders, and is a first step towards a more data-driven understanding
of the impact of voice therapy.


EEG Spatial Decoding and Classification with Logit Shrinkage Regularized
  Directed Information Assessment (L-SODA)

  There is an increasing interest in studying the neural interaction mechanisms
behind patterns of cognitive brain activity. This paper proposes a new approach
to infer such interaction mechanisms from electroencephalographic (EEG) data
using a new estimator of directed information (DI) called logit shrinkage
optimized directed information assessment (L-SODA). Unlike previous directed
information measures applied to neural decoding, L-SODA uses shrinkage
regularization on multinomial logistic regression to deal with the high
dimensionality of multi-channel EEG signals and the small sizes of many
real-world datasets. It is designed to make few a priori assumptions and can
handle both non-linear and non-Gaussian flows among electrodes. Our L-SODA
estimator of the DI is accompanied by robust statistical confidence intervals
on the true DI that make it especially suitable for hypothesis testing on the
information flow patterns. We evaluate our work in the context of two different
problems where interaction localization is used to determine highly interactive
areas for EEG signals spatially and temporally. First, by mapping the areas
that have high DI into Brodmann area, we identify that the areas with high DI
are associated with motor-related functions. We demonstrate that L-SODA
provides better accuracy for neural decoding of EEG signals as compared to
several state-of-the-art approaches on the Brain Computer Interface (BCI) EEG
motor activity dataset. Second, the proposed L-SODA estimator is evaluated on
the CHB-MIT Scalp EEG database. We demonstrate that compared to the
state-of-the-art approaches, the proposed method provides better performance in
detecting the epileptic seizure.


Design and Implementation of iMacros-based Data Crawler for Behavioral
  Analysis of Facebook Users

  Obtaining the desired dataset is still a prime challenge faced by researchers
while analysing Online Social Network (OSN) sites. Application Programming
Interfaces (APIs) provided by OSN service providers for retrieving data impose
several unavoidable restrictions which make it difficult to get a desirable
dataset. In this paper, we present an iMacros technology-based data crawler
called IMcrawler,capable of collecting every piece of information which is
accessible through a browser from the Facebook website within the legal
framework reauthorized by Facebook.The proposed crawler addresses most of the
challenges allied with web data extraction approaches and most of the APIs
provided by OSN service providers. Two broad sections have been extracted from
Facebook user profiles, namely, Personal Information and Wall Activities. The
collected data is pre-processed into two datasets and each data set is
statistically analysed to draw semantic knowledge and understand the several
behavioral aspects of Facebook users such as kind of information mostly
disclosed by users, gender differences in the pattern of revealed information,
highly posted content on the network, highly performed activities on the
network, the relationships among personal and post attributes, etc. To the best
of our knowledge, the present work is the first attempt towards providing the
detailed description of crawler design and gender-based information revealing
behaviour of Facebook users.


Clinically Meaningful Comparisons Over Time: An Approach to Measuring
  Patient Similarity based on Subsequence Alignment

  Longitudinal patient data has the potential to improve clinical risk
stratification models for disease. However, chronic diseases that progress
slowly over time are often heterogeneous in their clinical presentation.
Patients may progress through disease stages at varying rates. This leads to
pathophysiological misalignment over time, making it difficult to consistently
compare patients in a clinically meaningful way. Furthermore, patients present
clinically for the first time at different stages of disease. This eliminates
the possibility of simply aligning patients based on their initial
presentation. Finally, patient data may be sampled at different rates due to
differences in schedules or missed visits. To address these challenges, we
propose a robust measure of patient similarity based on subsequence alignment.
Compared to global alignment techniques that do not account for
pathophysiological misalignment, focusing on the most relevant subsequences
allows for an accurate measure of similarity between patients. We demonstrate
the utility of our approach in settings where longitudinal data, while useful,
are limited and lack a clear temporal alignment for comparison. Applied to the
task of stratifying patients for risk of progression to probable Alzheimer's
Disease, our approach outperforms models that use only snapshot data (AUROC of
0.839 vs. 0.812) and models that use global alignment techniques (AUROC of
0.822). Our results support the hypothesis that patients' trajectories are
useful for quantifying inter-patient similarities and that using subsequence
matching and can help account for heterogeneity and misalignment in
longitudinal data.


A closer look at Intrusion Detection System for web applications

  Intrusion Detection System (IDS) is one of the security measures being used
as an additional defence mechanism to prevent the security breaches on web. It
has been well known methodology for detecting network-based attacks but still
immature in the domain of securing web application. The objective of the paper
is to thoroughly understand the design methodology of the detection system in
respect to web applications. In this paper, we discuss several specific aspects
of a web application in detail that makes challenging for a developer to build
an efficient web IDS. The paper also provides a comprehensive overview of the
existing detection systems exclusively designed to observe web traffic.
Furthermore, we identify various dimensions for comparing the IDS from
different perspectives based on their design and functionalities. We also
provide a conceptual framework of an IDS with prevention mechanism to offer a
systematic guidance for the implementation of the system specific to the web
applications. We compare its features with five existing detection systems,
namely AppSensor, PHPIDS, ModSecurity, Shadow Daemon and AQTRONIX WebKnight.
The paper will highly facilitate the interest groups with the cutting edge
information to understand the stronger and weaker sections of the web IDS and
provide a firm foundation for developing an intelligent and efficient system.


Identification of Flaws in the Design of Signatures for Intrusion
  Detection Systems

  Signature-based Intrusion Detection System (SIDS) provides a promising
solution to the problem of web application security. However, the performance
of the system highly relies on the quality of the signatures designed to detect
attacks. A weak signature set may considerably cause an increase in false alarm
rate, making impractical to deploy the system. The objective of the paper is to
identify the flaws in the signature structure which are responsible to reduce
the efficiency of the detection system. The paper targets SQL injection
signatures particularly. Initially, some essential concepts of the domain of
the attack that should be focused by the developer in prior to designing the
signatures have been discussed. Afterwards, we conducted a case study on the
well known PHPIDS tool for analyzing the quality of its SQL signatures. Based
on the analysis, we identify various flaws in the designing practice that yield
inefficient signatures. We divide the weak signatures into six categories,
namely incomplete, irrelevant, semi-relevant, susceptible, redundant and
inconsistent signatures. Moreover, we quantify these weaknesses and define them
mathematically in terms of set theory. To the best of our knowledge, we have
identified some novel signature design issues. The paper will basically assist
the signature developer to know what level of expertise is required for
devising a quality signature set and how a little ignorance may lead to
deterioration in the performance of the SIDS. Furthermore, a security expert
may evaluate the detector against the identified flaws by conducting structural
analysis on its signature set.


