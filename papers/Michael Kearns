A Clustering Coefficient Network Formation Game

  For the most up-to-date version please visit
http://www.cis.upenn.edu/~brautbar/ccgame.pdf


Efficient Nash Computation in Large Population Games with Bounded
  Influence

  We introduce a general representation of large-population games in which each
player s influence ON the others IS centralized AND limited, but may otherwise
be arbitrary.This representation significantly generalizes the class known AS
congestion games IN a natural way.Our main results are provably correct AND
efficient algorithms FOR computing AND learning approximate Nash equilibria IN
this general framework.


Exact Inference of Hidden Structure from Sample Data in Noisy-OR
  Networks

  In the literature on graphical models, there has been increased attention
paid to the problems of learning hidden structure (see Heckerman [H96] for
survey) and causal mechanisms from sample data [H96, P88, S93, P95, F98]. In
most settings we should expect the former to be difficult, and the latter
potentially impossible without experimental intervention. In this work, we
examine some restricted settings in which perfectly reconstruct the hidden
structure solely on the basis of observed sample data.


An Empirical Study of Rich Subgroup Fairness for Machine Learning

  Kearns et al. [2018] recently proposed a notion of rich subgroup fairness
intended to bridge the gap between statistical and individual notions of
fairness. Rich subgroup fairness picks a statistical fairness constraint (say,
equalizing false positive rates across protected groups), but then asks that
this constraint hold over an exponentially or infinitely large collection of
subgroups defined by a class of functions with bounded VC dimension. They give
an algorithm guaranteed to learn subject to this constraint, under the
condition that it has access to oracles for perfectly learning absent a
fairness constraint. In this paper, we undertake an extensive empirical
evaluation of the algorithm of Kearns et al. On four real datasets for which
fairness is a concern, we investigate the basic convergence of the algorithm
when instantiated with fast heuristics in place of learning oracles, measure
the tradeoffs between fairness and accuracy, and compare this approach with the
recent algorithm of Agarwal et al. [2018], which implements weaker and more
traditional marginal fairness constraints defined by individual protected
attributes. We find that in general, the Kearns et al. algorithm converges
quickly, large gains in fairness can be obtained with mild costs to accuracy,
and that optimizing accuracy subject only to marginal fairness leads to
classifiers with substantial subgroup unfairness. We also provide a number of
analyses and visualizations of the dynamics and behavior of the Kearns et al.
algorithm. Overall we find this algorithm to be effective on real data, and
rich subgroup fairness to be a viable notion in practice.


Fast Planning in Stochastic Games

  Stochastic games generalize Markov decision processes (MDPs) to a multiagent
setting by allowing the state transitions to depend jointly on all player
actions, and having rewards determined by multiplayer matrix games at each
state. We consider the problem of computing Nash equilibria in stochastic
games, the analogue of planning in MDPs. We begin by providing a generalization
of finite-horizon value iteration that computes a Nash strategy for each player
in generalsum stochastic games. The algorithm takes an arbitrary Nash selection
function as input, which allows the translation of local choices between
multiple Nash equilibria into the selection of a single global Nash
equilibrium.
  Our main technical result is an algorithm for computing near-Nash equilibria
in large or infinite state spaces. This algorithm builds on our finite-horizon
value iteration algorithm, and adapts the sparse sampling methods of Kearns,
Mansour and Ng (1999) to stochastic games. We conclude by descrbing a
counterexample showing that infinite-horizon discounted value iteration, which
was shown by shaplely to converge in the zero-sum case (a result we give extend
slightly here), does not converge in the general-sum case.


Empirical Limitations on High Frequency Trading Profitability

  Addressing the ongoing examination of high-frequency trading practices in
financial markets, we report the results of an extensive empirical study
estimating the maximum possible profitability of the most aggressive such
practices, and arrive at figures that are surprisingly modest. By "aggressive"
we mean any trading strategy exclusively employing market orders and relatively
short holding periods. Our findings highlight the tension between execution
costs and trading horizon confronted by high-frequency traders, and provide a
controlled and large-scale empirical perspective on the high-frequency debate
that has heretofore been absent. Our study employs a number of novel empirical
methods, including the simulation of an "omniscient" high-frequency trader who
can see the future and act accordingly.


Large Deviation Methods for Approximate Probabilistic Inference

  We study two-layer belief networks of binary random variables in which the
conditional probabilities Pr[childlparents] depend monotonically on weighted
sums of the parents. In large networks where exact probabilistic inference is
intractable, we show how to compute upper and lower bounds on many
probabilities of interest. In particular, using methods from large deviation
theory, we derive rigorous bounds on marginal probabilities such as
Pr[children] and prove rates of convergence for the accuracy of our bounds as a
function of network size. Our results apply to networks with generic transfer
function parameterizations of the conditional probability tables, such as
sigmoid and noisy-OR. They also explicitly illustrate the types of averaging
behavior that can simplify the problem of inference in large networks.


Graphical Models for Bandit Problems

  We introduce a rich class of graphical models for multi-armed bandit problems
that permit both the state or context space and the action space to be very
large, yet succinctly specify the payoffs for any context-action pair. Our main
result is an algorithm for such models whose regret is bounded by the number of
parameters and whose running time depends only on the treewidth of the graph
substructure induced by the action space.


Budget Optimization for Sponsored Search: Censored Learning in MDPs

  We consider the budget optimization problem faced by an advertiser
participating in repeated sponsored search auctions, seeking to maximize the
number of clicks attained under that budget. We cast the budget optimization
problem as a Markov Decision Process (MDP) with censored observations, and
propose a learning algorithm based on the wellknown Kaplan-Meier or
product-limit estimator. We validate the performance of this algorithm by
comparing it to several others on a large set of search auction data from
Microsoft adCenter, demonstrating fast convergence to optimal performance.


Dynamic Actuation of Single-Crystal Diamond Nanobeams

  We show the dielectrophoretic actuation of single-crystal diamond
nanomechanical devices. Gradient radio-frequency electromagnetic forces are
used to achieve actuation of both cantilever and doubly clamped beam
structures, with operation frequencies ranging from a few MHz to ~50MHz.
Frequency tuning and parametric actuation are also studied.


Predicting with Distributions

  We consider a new learning model in which a joint distribution over vector
pairs $(x,y)$ is determined by an unknown function $c(x)$ that maps input
vectors $x$ not to individual outputs, but to entire {\em distributions\/} over
output vectors $y$. Our main results take the form of rather general reductions
from our model to algorithms for PAC learning the function class and the
distribution class separately, and show that virtually every such combination
yields an efficient algorithm in our model. Our methods include a randomized
reduction to classification noise and an application of Le Cam's method to
obtain robust learning algorithms.


An Information-Theoretic Analysis of Hard and Soft Assignment Methods
  for Clustering

  Assignment methods are at the heart of many algorithms for unsupervised
learning and clustering - in particular, the well-known K-means and
Expectation-Maximization (EM) algorithms. In this work, we study several
different methods of assignment, including the "hard" assignments used by
K-means and the ?soft' assignments used by EM. While it is known that K-means
minimizes the distortion on the data and EM maximizes the likelihood, little is
known about the systematic differences of behavior between the two algorithms.
Here we shed light on these differences via an information-theoretic analysis.
The cornerstone of our results is a simple decomposition of the expected
distortion, showing that K-means (and its extension for inferring general
parametric densities from unlabeled sample data) must implicitly manage a
trade-off between how similar the data assigned to each cluster are, and how
the data are balanced among the clusters. How well the data are balanced is
measured by the entropy of the partition defined by the hard assignments. In
addition to letting us predict and verify systematic differences between
K-means and EM on specific examples, the decomposition allows us to give a
rather general argument showing that K ?means will consistently find densities
with less "overlap" than EM. We also study a third natural assignment method
that we call posterior assignment, that is close in spirit to the soft
assignments of EM, but leads to a surprisingly different algorithm.


Competitive Contagion in Networks

  We develop a game-theoretic framework for the study of competition between
firms who have budgets to "seed" the initial adoption of their products by
consumers located in a social network. The payoffs to the firms are the
eventual number of adoptions of their product through a competitive stochastic
diffusion process in the network. This framework yields a rich class of
competitive strategies, which depend in subtle ways on the stochastic dynamics
of adoption, the relative budgets of the players, and the underlying structure
of the social network.
  We identify a general property of the adoption dynamics --- namely,
decreasing returns to local adoption --- for which the inefficiency of resource
use at equilibrium (the Price of Anarchy) is uniformly bounded above, across
all networks. We also show that if this property is violated the Price of
Anarchy can be unbounded, thus yielding sharp threshold behavior for a broad
class of dynamics.
  We also introduce a new notion, the Budget Multiplier, that measures the
extent that imbalances in player budgets can be amplified at equilibrium. We
again identify a general property of the adoption dynamics --- namely,
proportional local adoption between competitors --- for which the (pure
strategy) Budget Multiplier is uniformly bounded above, across all networks. We
show that a violation of this property can lead to unbounded Budget Multiplier,
again yielding sharp threshold behavior for a broad class of dynamics.


Graphical Models for Game Theory

  In this work, we introduce graphical modelsfor multi-player game theory, and
give powerful algorithms for computing their Nash equilibria in certain cases.
An n-player game is given by an undirected graph on n nodes and a set of n
local matrices. The interpretation is that the payoff to player i is determined
entirely by the actions of player i and his neighbors in the graph, and thus
the payoff matrix to player i is indexed only by these players. We thus view
the global n-player game as being composed of interacting local games, each
involving many fewer players. Each player's action may have global impact, but
it occurs through the propagation of local influences.Our main technical result
is an efficient algorithm for computing Nash equilibria when the underlying
graph is a tree (or can be turned into a tree with few node mergings). The
algorithm runs in time polynomial in the size of the representation (the graph
and theassociated local game matrices), and comes in two related but distinct
flavors. The first version involves an approximation step, and computes a
representation of all approximate Nash equilibria (of which there may be an
exponential number in general). The second version allows the exact computation
of Nash equilibria at the expense of weakened complexity bounds. The algorithm
requires only local message-passing between nodes (and thus can be implemented
by the players themselves in a distributed manner). Despite an analogy to
inference in Bayes nets that we develop, the analysis of our algorithm is more
involved than that for the polytree algorithm in, owing partially to the fact
that we must either compute, or select from, an exponential number of potential
solutions. We discuss a number of extensions, such as the computation of
equilibria with desirable global properties (e.g. maximizing global return),
and directions for further research.


Synaptic Transmission: An Information-Theoretic Perspective

  Here we analyze synaptic transmission from an information-theoretic
perspective. We derive closed-form expressions for the lower-bounds on the
capacity of a simple model of a cortical synapse under two explicit coding
paradigms. Under the ``signal estimation'' paradigm, we assume the signal to be
encoded in the mean firing rate of a Poisson neuron. The performance of an
optimal linear estimator of the signal then provides a lower bound on the
capacity for signal estimation. Under the ``signal detection'' paradigm, the
presence or absence of the signal has to be detected. Performance of the
optimal spike detector allows us to compute a lower bound on the capacity for
signal detection. We find that single synapses (for empirically measured
parameter values) transmit information poorly but significant improvement can
be achieved with a small amount of redundancy.


Triplet Lifetime in Gaseous Argon

  MiniCLEAN is a single-phase liquid argon dark matter experiment. During the
initial cooling phase, impurities within the cold gas ($<$140 K) were monitored
by measuring the scintillation light triplet lifetime, and ultimately a triplet
lifetime of 3.480 $\pm$ 0.001 (stat.) $\pm$ 0.064 (sys.) $\mu$s was obtained,
indicating ultra-pure argon. This is the longest argon triplet time constant
ever reported. The effect of quenching of separate components of the
scintillation light is also investigated.


Censored Exploration and the Dark Pool Problem

  We introduce and analyze a natural algorithm for multi-venue exploration from
censored data, which is motivated by the Dark Pool Problem of modern
quantitative finance. We prove that our algorithm converges in polynomial time
to a near-optimal allocation policy; prior results for similar problems in
stochastic inventory control guaranteed only asymptotic convergence and
examined variants in which each venue could be treated independently. Our
analysis bears a strong resemblance to that of efficient exploration/
exploitation schemes in the reinforcement learning literature. We describe an
extensive experimental evaluation of our algorithm on the Dark Pool Problem
using real trading data.


Nash Convergence of Gradient Dynamics in Iterated General-Sum Games

  Multi-agent games are becoming an increasing prevalent formalism for the
study of electronic commerce and auctions. The speed at which transactions can
take place and the growing complexity of electronic marketplaces makes the
study of computationally simple agents an appealing direction. In this work, we
analyze the behavior of agents that incrementally adapt their strategy through
gradient ascent on expected payoff, in the simple setting of two-player,
two-action, iterated general-sum games, and present a surprising result. We
show that either the agents will converge to Nash equilibrium, or if the
strategies themselves do not converge, then their average payoffs will
nevertheless converge to the payoffs of a Nash equilibrium.


Planning the Future of U.S. Particle Physics (Snowmass 2013): Chapter 2:
  Intensity Frontier

  These reports present the results of the 2013 Community Summer Study of the
APS Division of Particles and Fields ("Snowmass 2013") on the future program of
particle physics in the U.S. Chapter 2, on the Intensity Frontier, discusses
the program of research with high-intensity beams and rare processes. This area
includes experiments on neutrinos, proton decay, charged-lepton and quark weak
interactions, atomic and nuclear probes of fundamental symmetries, and searches
for new, light, weakly-interacting particles.


A Computational Study of Feasible Repackings in the FCC Incentive
  Auctions

  We report the results of a computational study of repacking in the FCC
Incentive Auctions. Our interest lies in the structure and constraints of the
solution space of feasible repackings. Our analyses are "mechanism-free", in
the sense that they identify constraints that must hold regardless of the
reverse auction mechanism chosen or the prices offered for broadcaster
clearing. We examine topics such as the amount of spectrum that can be cleared
nationwide, the geographic distribution of broadcaster clearings required to
reach a clearing target, and the likelihood of reaching clearing targets under
various models for broadcaster participation. Our study uses FCC interference
data and a satisfiability-checking approach, and elucidates both the
unavoidable mathematical constraints on solutions imposed by interference, as
well as additional constraints imposed by assumptions on the participation
decisions of broadcasters.


Robust Mediators in Large Games

  A mediator is a mechanism that can only suggest actions to players, as a
function of all agents' reported types, in a given game of incomplete
information. We study what is achievable by two kinds of mediators, "strong"
and "weak." Players can choose to opt-out of using a strong mediator but cannot
misrepresent their type if they opt-in. Such a mediator is "strong" because we
can view it as having the ability to verify player types. Weak mediators lack
this ability--- players are free to misrepresent their type to a weak mediator.
We show a striking result---in a prior-free setting, assuming only that the
game is large and players have private types, strong mediators can implement
approximate equilibria of the complete-information game. If the game is a
congestion game, then the same result holds using only weak mediators. Our
result follows from a novel application of differential privacy, in particular,
a variant we propose called joint differential privacy.


Online Learning and Profit Maximization from Revealed Preferences

  We consider the problem of learning from revealed preferences in an online
setting. In our framework, each period a consumer buys an optimal bundle of
goods from a merchant according to her (linear) utility function and current
prices, subject to a budget constraint. The merchant observes only the
purchased goods, and seeks to adapt prices to optimize his profits. We give an
efficient algorithm for the merchant's problem that consists of a learning
phase in which the consumer's utility function is (perhaps partially) inferred,
followed by a price optimization step. We also consider an alternative online
learning algorithm for the setting where prices are set exogenously, but the
merchant would still like to predict the bundle that will be bought by the
consumer for purposes of inventory or supply chain management. In contrast with
most prior work on the revealed preferences problem, we demonstrate that by
making stronger assumptions on the form of utility functions, efficient
algorithms for both learning and profit maximization are possible, even in
adaptive, online settings.


Privacy for the Protected (Only)

  Motivated by tensions between data privacy for individual citizens, and
societal priorities such as counterterrorism and the containment of infectious
disease, we introduce a computational model that distinguishes between parties
for whom privacy is explicitly protected, and those for whom it is not (the
targeted subpopulation). The goal is the development of algorithms that can
effectively identify and take action upon members of the targeted subpopulation
in a way that minimally compromises the privacy of the protected, while
simultaneously limiting the expense of distinguishing members of the two groups
via costly mechanisms such as surveillance, background checks, or medical
testing. Within this framework, we provide provably privacy-preserving
algorithms for targeted search in social networks. These algorithms are natural
variants of common graph search methods, and ensure privacy for the protected
by the careful injection of noise in the prioritization of potential targets.
We validate the utility of our algorithms with extensive computational
experiments on two large-scale social network datasets.


Fair Algorithms for Infinite and Contextual Bandits

  We study fairness in linear bandit problems. Starting from the notion of
meritocratic fairness introduced in Joseph et al. [2016], we carry out a more
refined analysis of a more general problem, achieving better performance
guarantees with fewer modelling assumptions on the number and structure of
available choices as well as the number selected. We also analyze the
previously-unstudied question of fairness in infinite linear bandit problems,
obtaining instance-dependent regret upper bounds as well as lower bounds
demonstrating that this instance-dependence is necessary. The result is a
framework for meritocratic fairness in an online linear setting that is
substantially more powerful, general, and realistic than the current state of
the art.


Fairness in Reinforcement Learning

  We initiate the study of fairness in reinforcement learning, where the
actions of a learning algorithm may affect its environment and future rewards.
Our fairness constraint requires that an algorithm never prefers one action
over another if the long-term (discounted) reward of choosing the latter action
is higher. Our first result is negative: despite the fact that fairness is
consistent with the optimal policy, any learning algorithm satisfying fairness
must take time exponential in the number of states to achieve non-trivial
approximation to the optimal policy. We then provide a provably fair polynomial
time algorithm under an approximate notion of fairness, thus establishing an
exponential gap between exact and approximate fairness


Fairness in Criminal Justice Risk Assessments: The State of the Art

  Objectives: Discussions of fairness in criminal justice risk assessments
typically lack conceptual precision. Rhetoric too often substitutes for careful
analysis. In this paper, we seek to clarify the tradeoffs between different
kinds of fairness and between fairness and accuracy.
  Methods: We draw on the existing literatures in criminology, computer science
and statistics to provide an integrated examination of fairness and accuracy in
criminal justice risk assessments. We also provide an empirical illustration
using data from arraignments.
  Results: We show that there are at least six kinds of fairness, some of which
are incompatible with one another and with accuracy.
  Conclusions: Except in trivial cases, it is impossible to maximize accuracy
and fairness at the same time, and impossible simultaneously to satisfy all
kinds of fairness. In practice, a major complication is different base rates
across different legally protected groups. There is a need to consider
challenging tradeoffs.


A Convex Framework for Fair Regression

  We introduce a flexible family of fairness regularizers for (linear and
logistic) regression problems. These regularizers all enjoy convexity,
permitting fast optimization, and they span the rang from notions of group
fairness to strong individual fairness. By varying the weight on the fairness
regularizer, we can compute the efficient frontier of the accuracy-fairness
trade-off on any given dataset, and we measure the severity of this trade-off
via a numerical quantity we call the Price of Fairness (PoF). The centerpiece
of our results is an extensive comparative study of the PoF across six
different datasets in which fairness is a primary consideration.


Online Learning with an Unknown Fairness Metric

  We consider the problem of online learning in the linear contextual bandits
setting, but in which there are also strong individual fairness constraints
governed by an unknown similarity metric. These constraints demand that we
select similar actions or individuals with approximately equal probability
(arXiv:1104.3913), which may be at odds with optimizing reward, thus modeling
settings where profit and social policy are in tension. We assume we learn
about an unknown Mahalanobis similarity metric from only weak feedback that
identifies fairness violations, but does not quantify their extent. This is
intended to represent the interventions of a regulator who "knows unfairness
when he sees it" but nevertheless cannot enunciate a quantitative fairness
metric over individuals. Our main result is an algorithm in the adversarial
context setting that has a number of fairness violations that depends only
logarithmically on $T$, while obtaining an optimal $O(\sqrt{T})$ regret bound
to the best fair policy.


PEGASUS: A Policy Search Method for Large MDPs and POMDPs

  We propose a new approach to the problem of searching a space of policies for
a Markov decision process (MDP) or a partially observable Markov decision
process (POMDP), given a model. Our approach is based on the following
observation: Any (PO)MDP can be transformed into an "equivalent" POMDP in which
all state transitions (given the current state and action) are deterministic.
This reduces the general problem of policy search to one in which we need only
consider POMDPs with deterministic transitions. We give a natural way of
estimating the value of all policies in these transformed POMDPs. Policy search
is then simply performed by searching for a policy with high estimated value.
We also establish conditions under which our value estimates will be good,
recovering theoretical results similar to those of Kearns, Mansour and Ng
(1999), but with "sample complexity" bounds that have only a polynomial rather
than exponential dependence on the horizon time. Our method applies to
arbitrary POMDPs, including ones with infinite state and action spaces. We also
present empirical results for our approach on a small discrete problem, and on
a complex continuous state/continuous action problem involving learning to ride
a bicycle.


On Sparse Discretization for Graphical Games

  This short paper concerns discretization schemes for representing and
computing approximate Nash equilibria, with emphasis on graphical games, but
briefly touching on normal-form and poly-matrix games. The main technical
contribution is a representation theorem that informally states that to account
for every exact Nash equilibrium using a nearby approximate Nash equilibrium on
a grid over mixed strategies, a uniform discretization size linear on the
inverse of the approximation quality and natural game-representation parameters
suffices. For graphical games, under natural conditions, the discretization is
logarithmic in the game-representation size, a substantial improvement over the
linear dependency previously required. The paper has five other objectives: (1)
given the venue, to highlight the important, but often ignored, role that work
on constraint networks in AI has in simplifying the derivation and analysis of
algorithms for computing approximate Nash equilibria; (2) to summarize the
state-of-the-art on computing approximate Nash equilibria, with emphasis on
relevance to graphical games; (3) to help clarify the distinction between
sparse-discretization and sparse-support techniques; (4) to illustrate and
advocate for the deliberate mathematical simplicity of the formal proof of the
representation theorem; and (5) to list and discuss important open problems,
emphasizing graphical-game generalizations, which the AI community is most
suitable to solve.


Fairness in Learning: Classic and Contextual Bandits

  We introduce the study of fairness in multi-armed bandit problems. Our
fairness definition can be interpreted as demanding that given a pool of
applicants (say, for college admission or mortgages), a worse applicant is
never favored over a better one, despite a learning algorithm's uncertainty
over the true payoffs. We prove results of two types.
  First, in the important special case of the classic stochastic bandits
problem (i.e., in which there are no contexts), we provide a provably fair
algorithm based on "chained" confidence intervals, and provide a cumulative
regret bound with a cubic dependence on the number of arms. We further show
that any fair algorithm must have such a dependence. When combined with regret
bounds for standard non-fair algorithms such as UCB, this proves a strong
separation between fair and unfair learning, which extends to the general
contextual case.
  In the general contextual case, we prove a tight connection between fairness
and the KWIK (Knows What It Knows) learning model: a KWIK algorithm for a class
of functions can be transformed into a provably fair contextual bandit
algorithm, and conversely any fair contextual bandit algorithm can be
transformed into a KWIK learning algorithm. This tight connection allows us to
provide a provably fair algorithm for the linear contextual bandit problem with
a polynomial dependence on the dimension, and to show (for a different class of
functions) a worst-case exponential gap in regret between fair and non-fair
learning algorithms


Fairness Incentives for Myopic Agents

  We consider settings in which we wish to incentivize myopic agents (such as
Airbnb landlords, who may emphasize short-term profits and property safety) to
treat arriving clients fairly, in order to prevent overall discrimination
against individuals or groups. We model such settings in both classical and
contextual bandit models in which the myopic agents maximize rewards according
to current empirical averages, but are also amenable to exogenous payments that
may cause them to alter their choices. Our notion of fairness asks that more
qualified individuals are never (probabilistically) preferred over less
qualified ones [Joseph et al].
  We investigate whether it is possible to design inexpensive {subsidy} or
payment schemes for a principal to motivate myopic agents to play fairly in all
or almost all rounds. When the principal has full information about the state
of the myopic agents, we show it is possible to induce fair play on every round
with a subsidy scheme of total cost $o(T)$ (for the classic setting with $k$
arms, $\tilde{O}(\sqrt{k^3T})$, and for the $d$-dimensional linear contextual
setting $\tilde{O}(d\sqrt{k^3 T})$). If the principal has much more limited
information (as might often be the case for an external regulator or watchdog),
and only observes the number of rounds in which members from each of the $k$
groups were selected, but not the empirical estimates maintained by the myopic
agent, the design of such a scheme becomes more complex. We show both positive
and negative results in the classic and linear bandit settings by upper and
lower bounding the cost of fair subsidy schemes.


Differentially Private Fair Learning

  Motivated by settings in which predictive models may be required to be
non-discriminatory with respect to certain attributes (such as race), but even
collecting the sensitive attribute may be forbidden or restricted, we initiate
the study of fair learning under the constraint of differential privacy. We
design two learning algorithms that simultaneously promise differential privacy
and equalized odds, a 'fairness' condition that corresponds to equalizing false
positive and negative rates across protected groups. Our first algorithm is a
private implementation of the equalized odds post-processing approach of [Hardt
et al., 2016]. This algorithm is appealingly simple, but must be able to use
protected group membership explicitly at test time, which can be viewed as a
form of 'disparate treatment'. Our second algorithm is a differentially private
version of the oracle-efficient in-processing approach of [Agarwal et al.,
2018] that can be used to find the optimal fair classifier, given access to a
subroutine that can solve the original (not necessarily fair) learning problem.
This algorithm is more complex but need not have access to protected group
membership at test time. We identify new tradeoffs between fairness, accuracy,
and privacy that emerge only when requiring all three properties, and show that
these tradeoffs can be milder if group membership may be used at test time. We
conclude with a brief experimental evaluation.


Report on the Depth Requirements for a Massive Detector at Homestake

  This report provides the technical justification for locating a large
detector underground in a US based Deep Underground Science and Engineering
Laboratory. A large detector with a fiducial mass in the mega-ton scale will
most likely be a multipurpose facility. The main physics justification for such
a device is detection of accelerator generated neutrinos, nucleon decay, and
natural sources of neutrinos such as solar, atmospheric and supernova
neutrinos. In addition to the physics justification there are practical issues
regarding the existing infrastructure at Homestake, and the stress
characteristics of the Homestake rock formations.
  The depth requirements associated with the various physics processes are
reported for water Cherenkov and liquid argon detector technologies. While some
of these physics processes can be adequately studied at shallower depths, none
of them require a depth greater than 4300 mwe which corresponds to the 4850 ft
level at Homestake. It is very important to note that the scale of the planned
detector is such that even for accelerator neutrino detection (which allows one
to use the accelerator duty factor to eliminate cosmics) a minimum depth is
needed to reduce risk of contamination from cosmic rays. After consideration of
the science and the practical issues regarding the Homestake site, we strongly
recommend that the geotechnical studies be commenced at the 4850ft level in a
timely manner.


Mechanism Design in Large Games: Incentives and Privacy

  We study the problem of implementing equilibria of complete information games
in settings of incomplete information, and address this problem using
"recommender mechanisms." A recommender mechanism is one that does not have the
power to enforce outcomes or to force participation, rather it only has the
power to suggestion outcomes on the basis of voluntary participation. We show
that despite these restrictions, recommender mechanisms can implement
equilibria of complete information games in settings of incomplete information
under the condition that the game is large---i.e. that there are a large number
of players, and any player's action affects any other's payoff by at most a
small amount.
  Our result follows from a novel application of differential privacy. We show
that any algorithm that computes a correlated equilibrium of a complete
information game while satisfying a variant of differential privacy---which we
call joint differential privacy---can be used as a recommender mechanism while
satisfying our desired incentive properties. Our main technical result is an
algorithm for computing a correlated equilibrium of a large game while
satisfying joint differential privacy.
  Although our recommender mechanisms are designed to satisfy game-theoretic
properties, our solution ends up satisfying a strong privacy property as well.
No group of players can learn "much" about the type of any player outside the
group from the recommendations of the mechanism, even if these players collude
in an arbitrary way. As such, our algorithm is able to implement equilibria of
complete information games, without revealing information about the realized
types.


Strategic Network Formation with Attack and Immunization

  Strategic network formation arises where agents receive benefit from
connections to other agents, but also incur costs for forming links. We
consider a new network formation game that incorporates an adversarial attack,
as well as immunization against attack. An agent's benefit is the expected size
of her connected component post-attack, and agents may also choose to immunize
themselves from attack at some additional cost. Our framework is a stylized
model of settings where reachability rather than centrality is the primary
concern and vertices vulnerable to attacks may reduce risk via costly measures.
  In the reachability benefit model without attack or immunization, the set of
equilibria is the empty graph and any tree. The introduction of attack and
immunization changes the game dramatically; new equilibrium topologies emerge,
some more sparse and some more dense than trees. We show that, under a mild
assumption on the adversary, every equilibrium network with $n$ agents contains
at most $2n-4$ edges for $n\geq 4$. So despite permitting topologies denser
than trees, the amount of overbuilding is limited. We also show that attack and
immunization don't significantly erode social welfare: every non-trivial
equilibrium with respect to several adversaries has welfare at least as that of
any equilibrium in the attack-free model.
  We complement our theory with simulations demonstrating fast convergence of a
new bounded rationality dynamic which generalizes linkstable best response but
is considerably more powerful in our game. The simulations further elucidate
the wide variety of asymmetric equilibria and demonstrate topological
consequences of the dynamics e.g. heavy-tailed degree distributions. Finally,
we report on a behavioral experiment on our game with over 100 participants,
where despite the complexity of the game, the resulting network was
surprisingly close to equilibrium.


Privacy and Truthful Equilibrium Selection for Aggregative Games

  We study a very general class of games --- multi-dimensional aggregative
games --- which in particular generalize both anonymous games and weighted
congestion games. For any such game that is also large, we solve the
equilibrium selection problem in a strong sense. In particular, we give an
efficient weak mediator: a mechanism which has only the power to listen to
reported types and provide non-binding suggested actions, such that (a) it is
an asymptotic Nash equilibrium for every player to truthfully report their type
to the mediator, and then follow its suggested action; and (b) that when
players do so, they end up coordinating on a particular asymptotic pure
strategy Nash equilibrium of the induced complete information game. In fact,
truthful reporting is an ex-post Nash equilibrium of the mediated game, so our
solution applies even in settings of incomplete information, and even when
player types are arbitrary or worst-case (i.e. not drawn from a common prior).
We achieve this by giving an efficient differentially private algorithm for
computing a Nash equilibrium in such games. The rates of convergence to
equilibrium in all of our results are inverse polynomial in the number of
players $n$. We also apply our main results to a multi-dimensional market game.
  Our results can be viewed as giving, for a rich class of games, a more robust
version of the Revelation Principle, in that we work with weaker informational
assumptions (no common prior), yet provide a stronger solution concept (ex-post
Nash versus Bayes Nash equilibrium). In comparison to previous work, our main
conceptual contribution is showing that weak mediators are a game theoretic
object that exist in a wide variety of games -- previously, they were only
known to exist in traffic routing games.


Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup
  Fairness

  The most prevalent notions of fairness in machine learning are statistical
definitions: they fix a small collection of pre-defined groups, and then ask
for parity of some statistic of the classifier across these groups. Constraints
of this form are susceptible to intentional or inadvertent "fairness
gerrymandering", in which a classifier appears to be fair on each individual
group, but badly violates the fairness constraint on one or more structured
subgroups defined over the protected attributes. We propose instead to demand
statistical notions of fairness across exponentially (or infinitely) many
subgroups, defined by a structured class of functions over the protected
attributes. This interpolates between statistical definitions of fairness and
recently proposed individual notions of fairness, but raises several
computational challenges. It is no longer clear how to audit a fixed classifier
to see if it satisfies such a strong definition of fairness. We prove that the
computational problem of auditing subgroup fairness for both equality of false
positive rates and statistical parity is equivalent to the problem of weak
agnostic learning, which means it is computationally hard in the worst case,
even for simple structured subclasses.
  We then derive two algorithms that provably converge to the best fair
classifier, given access to oracles which can solve the agnostic learning
problem. The algorithms are based on a formulation of subgroup fairness as a
two-player zero-sum game between a Learner and an Auditor. Our first algorithm
provably converges in a polynomial number of steps. Our second algorithm enjoys
only provably asymptotic convergence, but has the merit of simplicity and
faster per-step computation. We implement the simpler algorithm using linear
regression as a heuristic oracle, and show that we can effectively both audit
and learn fair classifiers on real datasets.


Fair Algorithms for Learning in Allocation Problems

  Settings such as lending and policing can be modeled by a centralized agent
allocating a resource (loans or police officers) amongst several groups, in
order to maximize some objective (loans given that are repaid or criminals that
are apprehended). Often in such problems fairness is also a concern. A natural
notion of fairness, based on general principles of equality of opportunity,
asks that conditional on an individual being a candidate for the resource, the
probability of actually receiving it is approximately independent of the
individual's group. In lending this means that equally creditworthy individuals
in different racial groups have roughly equal chances of receiving a loan. In
policing it means that two individuals committing the same crime in different
districts would have roughly equal chances of being arrested.
  We formalize this fairness notion for allocation problems and investigate its
algorithmic consequences. Our main technical results include an efficient
learning algorithm that converges to an optimal fair allocation even when the
frequency of candidates (creditworthy individuals or criminals) in each group
is unknown. The algorithm operates in a censored feedback model in which only
the number of candidates who received the resource in a given allocation can be
observed, rather than the true number of candidates. This models the fact that
we do not learn the creditworthiness of individuals we do not give loans to nor
learn about crimes committed if the police presence in a district is low.
  As an application of our framework, we consider the predictive policing
problem. The learning algorithm is trained on arrest data gathered from its own
deployments on previous days, resulting in a potential feedback loop that our
algorithm provably overcomes. We empirically investigate the performance of our
algorithm on the Philadelphia Crime Incidents dataset.


Solar Neutrino Measurements in Super-Kamiokande-IV

  Upgraded electronics, improved water system dynamics, better calibration and
analysis techniques allowed Super-Kamiokande-IV to clearly observe very
low-energy 8B solar neutrino interactions, with recoil electron kinetic
energies as low as 3.49 MeV. Super-Kamiokande-IV data-taking began in September
of 2008; this paper includes data until February 2014, a total livetime of 1664
days. The measured solar neutrino flux is (2.308+-0.020(stat.) +
0.039-0.040(syst.)) x 106/(cm2sec) assuming no oscillations. The observed
recoil electron energy spectrum is consistent with no distortions due to
neutrino oscillations. An extended maximum likelihood fit to the amplitude of
the expected solar zenith angle variation of the neutrino-electron elastic
scattering rate in SK-IV results in a day/night asymmetry of
(-3.6+-1.6(stat.)+-0.6(syst.))%. The SK-IV solar neutrino data determine the
solar mixing angle as sin2 theta_12 = 0.327+0.026-0.031, all SK solar data
(SK-I, SK-II, SK III and SKIV) measures this angle to be sin2 theta_12 =
0.334+0.027-0.023, the determined mass-squared splitting is Delta m2_21 =
4.8+1.5-0.8 x10-5 eV2.


The Long-Baseline Neutrino Experiment: Exploring Fundamental Symmetries
  of the Universe

  The preponderance of matter over antimatter in the early Universe, the
dynamics of the supernova bursts that produced the heavy elements necessary for
life and whether protons eventually decay --- these mysteries at the forefront
of particle physics and astrophysics are key to understanding the early
evolution of our Universe, its current state and its eventual fate. The
Long-Baseline Neutrino Experiment (LBNE) represents an extensively developed
plan for a world-class experiment dedicated to addressing these questions. LBNE
is conceived around three central components: (1) a new, high-intensity
neutrino source generated from a megawatt-class proton accelerator at Fermi
National Accelerator Laboratory, (2) a near neutrino detector just downstream
of the source, and (3) a massive liquid argon time-projection chamber deployed
as a far detector deep underground at the Sanford Underground Research
Facility. This facility, located at the site of the former Homestake Mine in
Lead, South Dakota, is approximately 1,300 km from the neutrino source at
Fermilab -- a distance (baseline) that delivers optimal sensitivity to neutrino
charge-parity symmetry violation and mass ordering effects. This ambitious yet
cost-effective design incorporates scalability and flexibility and can
accommodate a variety of upgrades and contributions. With its exceptional
combination of experimental configuration, technical capabilities, and
potential for transformative discoveries, LBNE promises to be a vital facility
for the field of particle physics worldwide, providing physicists from around
the globe with opportunities to collaborate in a twenty to thirty year program
of exciting science. In this document we provide a comprehensive overview of
LBNE's scientific objectives, its place in the landscape of neutrino physics
worldwide, the technologies it will incorporate and the capabilities it will
possess.


