Relational Learning and Feature Extraction by Querying over
  Heterogeneous Information Networks

  Many real world systems need to operate on heterogeneous information networks
that consist of numerous interacting components of different types. Examples
include systems that perform data analysis on biological information networks;
social networks; and information extraction systems processing unstructured
data to convert raw text to knowledge graphs. Many previous works describe
specialized approaches to perform specific types of analysis, mining and
learning on such networks. In this work, we propose a unified framework
consisting of a data model -a graph with a first order schema along with a
declarative language for constructing, querying and manipulating such networks
in ways that facilitate relational and structured machine learning. In
particular, we provide an initial prototype for a relational and graph
traversal query language where queries are directly used as relational features
for structured machine learning models. Feature extraction is performed by
making declarative graph traversal queries. Learning and inference models can
directly operate on this relational representation and augment it with new data
and knowledge that, in turn, is integrated seamlessly into the relational
structure to support new predictions. We demonstrate this system's capabilities
by showcasing tasks in natural language processing and computational biology
domains.


Deep Embedding for Spatial Role Labeling

  This paper introduces the visually informed embedding of word (VIEW), a
continuous vector representation for a word extracted from a deep neural model
trained using the Microsoft COCO data set to forecast the spatial arrangements
between visual objects, given a textual description. The model is composed of a
deep multilayer perceptron (MLP) stacked on the top of a Long Short Term Memory
(LSTM) network, the latter being preceded by an embedding layer. The VIEW is
applied to transferring multimodal background knowledge to Spatial Role
Labeling (SpRL) algorithms, which recognize spatial relations between objects
mentioned in the text. This work also contributes with a new method to select
complementary features and a fine-tuning method for MLP that improves the $F1$
measure in classifying the words into spatial roles. The VIEW is evaluated with
the Task 3 of SemEval-2013 benchmark data set, SpaceEval.


