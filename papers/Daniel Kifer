Postprocessing for Iterative Differentially Private Algorithms

  Iterative algorithms for differential privacy run for a fixed number of
iterations, where each iteration learns some information from data and produces
an intermediate output. However, the algorithm only releases the output of the
last iteration, and from which the accuracy of algorithm is judged. In this
paper, we propose a post-processing algorithm that seeks to improve the
accuracy by incorporating the knowledge on the data contained in intermediate
outputs.


A New Class of Private Chi-Square Tests

  In this paper, we develop new test statistics for private hypothesis testing.
These statistics are designed specifically so that their asymptotic
distributions, after accounting for noise added for privacy concerns, match the
asymptotics of the classical (non-private) chi-square tests for testing if the
multinomial data parameters lie in lower dimensional manifolds (examples
include goodness of fit and independence testing). Empirically, these new test
statistics outperform prior work, which focused on noisy versions of existing
statistics.


Differentially Private Confidence Intervals for Empirical Risk
  Minimization

  The process of data mining with differential privacy produces results that
are affected by two types of noise: sampling noise due to data collection and
privacy noise that is designed to prevent the reconstruction of sensitive
information. In this paper, we consider the problem of designing confidence
intervals for the parameters of a variety of differentially private machine
learning models. The algorithms can provide confidence intervals that satisfy
differential privacy (as well as the more recently proposed concentrated
differential privacy) and can be used with existing differentially private
mechanisms that train models using objective perturbation and output
perturbation.


Worst-Case Background Knowledge for Privacy-Preserving Data Publishing

  Recent work has shown the necessity of considering an attacker's background
knowledge when reasoning about privacy in data publishing. However, in
practice, the data publisher does not know what background knowledge the
attacker possesses. Thus, it is important to consider the worst-case. In this
paper, we initiate a formal study of worst-case background knowledge. We
propose a language that can express any background knowledge about the data. We
provide a polynomial time algorithm to measure the amount of disclosure of
sensitive information in the worst case, given that the attacker has at most a
specified number of pieces of information in this language. We also provide a
method to efficiently sanitize the data so that the amount of disclosure in the
worst case is less than a specified threshold.


A Framework for Extracting Semantic Guarantees from Privacy

  Statistical privacy views privacy definitions as contracts that guide the
behavior of algorithms that take in sensitive data and produce sanitized data.
For most existing privacy definitions, it is not clear what they actually
guarantee.
  In this paper, we propose the first (to the best of our knowledge) framework
for extracting semantic guarantees from privacy definitions. That is, instead
of answering narrow questions such as "does privacy definition Y protect X?"
the goal is to answer the more general question "what does privacy definition Y
protect?"
  The privacy guarantees we can extract are Bayesian in nature and deal with
changes in an attacker's beliefs. The key to our framework is an object we call
the row cone. Every privacy definition has a row cone, which is a convex set
that describes all the ways an attacker's prior beliefs can be turned into
posterior beliefs after observing an output of an algorithm satisfying that
privacy definition.
  The framework can be applied to privacy definitions or even to individual
algorithms to identify the types of inferences they defend against. We
illustrate the use of our framework with analyses of several definitions and
algorithms for which we can derive previously unknown semantics. These include
randomized response, FRAPP, and several algorithms that add integer-valued
noise to their inputs.


Revisiting Differentially Private Hypothesis Tests for Categorical Data

  In this paper, we consider methods for performing hypothesis tests on data
protected by a statistical disclosure control technology known as differential
privacy. Previous approaches to differentially private hypothesis testing
either perturbed the test statistic with random noise having large variance
(and resulted in a significant loss of power) or added smaller amounts of noise
directly to the data but failed to adjust the test in response to the added
noise (resulting in biased, unreliable $p$-values). In this paper, we develop a
variety of practical hypothesis tests that address these problems. Using a
different asymptotic regime that is more suited to hypothesis testing with
privacy, we show a modified equivalence between chi-squared tests and
likelihood ratio tests. We then develop differentially private likelihood ratio
and chi-squared tests for a variety of applications on tabular data (i.e.,
independence, sample proportions, and goodness-of-fit tests). Experimental
evaluations on small and large datasets using a wide variety of privacy
settings demonstrate the practicality and reliability of our methods.


Unifying Adversarial Training Algorithms with Flexible Deep Data
  Gradient Regularization

  Many previous proposals for adversarial training of deep neural nets have
included di- rectly modifying the gradient, training on a mix of original and
adversarial examples, using contractive penalties, and approximately optimizing
constrained adversarial ob- jective functions. In this paper, we show these
proposals are actually all instances of optimizing a general, regularized
objective we call DataGrad. Our proposed DataGrad framework, which can be
viewed as a deep extension of the layerwise contractive au- toencoder penalty,
cleanly simplifies prior work and easily allows extensions such as adversarial
training with multi-task cues. In our experiments, we find that the deep gra-
dient regularization of DataGrad (which also has L1 and L2 flavors of
regularization) outperforms alternative forms of regularization, including
classical L1, L2, and multi- task, both on the original dataset as well as on
adversarial sets. Furthermore, we find that combining multi-task optimization
with DataGrad adversarial training results in the most robust performance.


LightDP: Towards Automating Differential Privacy Proofs

  The growing popularity and adoption of differential privacy in academic and
industrial settings has resulted in the development of increasingly
sophisticated algorithms for releasing information while preserving privacy.
Accompanying this phenomenon is the natural rise in the development and
publication of incorrect algorithms, thus demonstrating the necessity of formal
verification tools. However, existing formal methods for differential privacy
face a dilemma: methods based on customized logics can verify sophisticated
algorithms but come with a steep learning curve and significant annotation
burden on the programmers, while existing programming platforms lack expressive
power for some sophisticated algorithms.
  In this paper, we present LightDP, a simple imperative language that strikes
a better balance between expressive power and usability. The core of LightDP is
a novel relational type system that separates relational reasoning from privacy
budget calculations. With dependent types, the type system is powerful enough
to verify sophisticated algorithms where the composition theorem falls short.
In addition, the inference engine of LightDP infers most of the proof details,
and even searches for the proof with minimal privacy cost bound when multiple
proofs exist. We show that LightDP verifies sophisticated algorithms with
little manual effort.


Predicting Demographics of High-Resolution Geographies with Geotagged
  Tweets

  In this paper, we consider the problem of predicting demographics of
geographic units given geotagged Tweets that are composed within these units.
Traditional survey methods that offer demographics estimates are usually
limited in terms of geographic resolution, geographic boundaries, and time
intervals. Thus, it would be highly useful to develop computational methods
that can complement traditional survey methods by offering demographics
estimates at finer geographic resolutions, with flexible geographic boundaries
(i.e. not confined to administrative boundaries), and at different time
intervals. While prior work has focused on predicting demographics and health
statistics at relatively coarse geographic resolutions such as the county-level
or state-level, we introduce an approach to predict demographics at finer
geographic resolutions such as the blockgroup-level. For the task of predicting
gender and race/ethnicity counts at the blockgroup-level, an approach adapted
from prior work to our problem achieves an average correlation of 0.389
(gender) and 0.569 (race) on a held-out test dataset. Our approach outperforms
this prior approach with an average correlation of 0.671 (gender) and 0.692
(race).


Learning to Extract Semantic Structure from Documents Using Multimodal
  Fully Convolutional Neural Network

  We present an end-to-end, multimodal, fully convolutional network for
extracting semantic structures from document images. We consider document
semantic structure extraction as a pixel-wise segmentation task, and propose a
unified model that classifies pixels based not only on their visual appearance,
as in the traditional page segmentation task, but also on the content of
underlying text. Moreover, we propose an efficient synthetic document
generation process that we use to generate pretraining data for our network.
Once the network is trained on a large set of synthetic documents, we fine-tune
the network on unlabeled real documents using a semi-supervised approach. We
systematically study the optimum network architecture and show that both our
multimodal approach and the synthetic data pretraining significantly boost the
performance.


Prolongation of SMAP to Spatio-temporally Seamless Coverage of
  Continental US Using a Deep Learning Neural Network

  The Soil Moisture Active Passive (SMAP) mission has delivered valuable
sensing of surface soil moisture since 2015. However, it has a short time span
and irregular revisit schedule. Utilizing a state-of-the-art time-series deep
learning neural network, Long Short-Term Memory (LSTM), we created a system
that predicts SMAP level-3 soil moisture data with atmospheric forcing,
model-simulated moisture, and static physiographic attributes as inputs. The
system removes most of the bias with model simulations and improves predicted
moisture climatology, achieving small test root-mean-squared error (<0.035) and
high correlation coefficient >0.87 for over 75\% of Continental United States,
including the forested Southeast. As the first application of LSTM in
hydrology, we show the proposed network avoids overfitting and is robust for
both temporal and spatial extrapolation tests. LSTM generalizes well across
regions with distinct climates and physiography. With high fidelity to SMAP,
LSTM shows great potential for hindcasting, data assimilation, and weather
forecasting.


Conducting Credit Assignment by Aligning Local Representations

  Using back-propagation and its variants to train deep networks is often
problematic for new users. Issues such as exploding gradients, vanishing
gradients, and high sensitivity to weight initialization strategies often make
networks difficult to train, especially when users are experimenting with new
architectures. Here, we present Local Representation Alignment (LRA), a
training procedure that is much less sensitive to bad initializations, does not
require modifications to the network architecture, and can be adapted to
networks with highly nonlinear and discrete-valued activation functions.
Furthermore, we show that one variation of LRA can start with a null
initialization of network weights and still successfully train networks with a
wide variety of nonlinearities, including tanh, ReLU-6, softplus, signum and
others that may draw their inspiration from biology.
  A comprehensive set of experiments on MNIST and the much harder Fashion MNIST
data sets show that LRA can be used to train networks robustly and effectively,
succeeding even when back-propagation fails and outperforming other alternative
learning algorithms, such as target propagation and feedback alignment.


Differentially Private Hierarchical Count-of-Counts Histograms

  We consider the problem of privately releasing a class of queries that we
call hierarchical count-of-counts histograms. Count-of-counts histograms
partition the rows of an input table into groups (e.g., group of people in the
same household), and for every integer j report the number of groups of size j.
Hierarchical count-of-counts queries report count-of-counts histograms at
different granularities as per hierarchy defined on an attribute in the input
data (e.g., geographical location of a household at the national, state and
county levels). In this paper, we introduce this problem, along with
appropriate error metrics and propose a differentially private solution that
generates count-of-counts histograms that are consistent across all levels of
the hierarchy.


Adversarial Training for Community Question Answer Selection Based on
  Multi-scale Matching

  Community-based question answering (CQA) websites represent an important
source of information. As a result, the problem of matching the most valuable
answers to their corresponding questions has become an increasingly popular
research topic. We frame this task as a binary (relevant/irrelevant)
classification problem, and present an adversarial training framework to
alleviate label imbalance issue. We employ a generative model to iteratively
sample a subset of challenging negative samples to fool our classification
model. Both models are alternatively optimized using REINFORCE algorithm. The
proposed method is completely different from previous ones, where negative
samples in training set are directly used or uniformly down-sampled. Further,
we propose using Multi-scale Matching which explicitly inspects the correlation
between words and ngrams of different levels of granularity. We evaluate the
proposed method on SemEval 2016 and SemEval 2017 datasets and achieves
state-of-the-art or similar performance.


Detecting Violations of Differential Privacy

  The widespread acceptance of differential privacy has led to the publication
of many sophisticated algorithms for protecting privacy. However, due to the
subtle nature of this privacy definition, many such algorithms have bugs that
make them violate their claimed privacy. In this paper, we consider the problem
of producing counterexamples for such incorrect algorithms. The counterexamples
are designed to be short and human-understandable so that the counterexample
generator can be used in the development process -- a developer could quickly
explore variations of an algorithm and investigate where they break down. Our
approach is statistical in nature. It runs a candidate algorithm many times and
uses statistical tests to try to detect violations of differential privacy. An
evaluation on a variety of incorrect published algorithms validates the
usefulness of our approach: it correctly rejects incorrect algorithms and
provides counterexamples for them within a few seconds.


Detecting Outliers in Data with Correlated Measures

  Advances in sensor technology have enabled the collection of large-scale
datasets. Such datasets can be extremely noisy and often contain a significant
amount of outliers that result from sensor malfunction or human operation
faults. In order to utilize such data for real-world applications, it is
critical to detect outliers so that models built from these datasets will not
be skewed by outliers.
  In this paper, we propose a new outlier detection method that utilizes the
correlations in the data (e.g., taxi trip distance vs. trip time). Different
from existing outlier detection methods, we build a robust regression model
that explicitly models the outliers and detects outliers simultaneously with
the model fitting.
  We validate our approach on real-world datasets against methods specifically
designed for each dataset as well as the state of the art outlier detectors.
Our outlier detection method achieves better performances, demonstrating the
robustness and generality of our method. Last, we report interesting case
studies on some outliers that result from atypical events.


Concentrated Differentially Private Gradient Descent with Adaptive
  per-Iteration Privacy Budget

  Iterative algorithms, like gradient descent, are common tools for solving a
variety of problems, such as model fitting. For this reason, there is interest
in creating differentially private versions of them. However, their conversion
to differentially private algorithms is often naive. For instance, a fixed
number of iterations are chosen, the privacy budget is split evenly among them,
and at each iteration, parameters are updated with a noisy gradient. In this
paper, we show that gradient-based algorithms can be improved by a more careful
allocation of privacy budget per iteration. Intuitively, at the beginning of
the optimization, gradients are expected to be large, so that they do not need
to be measured as accurately. However, as the parameters approach their optimal
values, the gradients decrease and hence need to be measured more accurately.
We add a basic line-search capability that helps the algorithm decide when more
accurate gradient measurements are necessary. Our gradient descent algorithm
works with the recently introduced zCDP version of differential privacy. It
outperforms prior algorithms for model fitting and is competitive with the
state-of-the-art for $(\epsilon,\delta)$-differential privacy, a strictly
weaker definition than zCDP.


TextContourNet: a Flexible and Effective Framework for Improving Scene
  Text Detection Architecture with a Multi-task Cascade

  We study the problem of extracting text instance contour information from
images and use it to assist scene text detection. We propose a novel and
effective framework for this and experimentally demonstrate that: (1) A CNN
that can be effectively used to extract instance-level text contour from
natural images. (2) The extracted contour information can be used for better
scene text detection. We propose two ways for learning the contour task
together with the scene text detection: (1) as an auxiliary task and (2) as
multi-task cascade. Extensive experiments with different benchmark datasets
demonstrate that both designs improve the performance of a state-of-the-art
scene text detector and that a multi-task cascade design achieves the best
performance.


Proving Differential Privacy with Shadow Execution

  Recent work on formal verification of differential privacy shows a trend
toward usability and expressiveness -- generating a correctness proof of
sophisticated algorithm while minimizing the annotation burden on programmers.
Sometimes, combining those two requires substantial changes to program logics:
one recent paper is able to verify Report Noisy Max automatically, but it
involves a complex verification system using customized program logics and
verifiers.
  In this paper, we propose a new proof technique, called shadow execution, and
embed it into a language called ShadowDP. ShadowDP uses shadow execution to
generate proofs of differential privacy with very few programmer annotations
and without relying on customized logics and verifiers. In addition to
verifying Report Noisy Max, we show that it can verify a new variant of Sparse
Vector that reports the gap between some noisy query answers and the noisy
threshold. Moreover, ShadowDP reduces the complexity of verification: for all
of the algorithms we have evaluated, type checking and verification in total
takes at most 3 seconds, while prior work takes minutes on the same algorithms.


Large Scale Scene Text Verification with Guided Attention

  Many tasks are related to determining if a particular text string exists in
an image. In this work, we propose a new framework that learns this task in an
end-to-end way. The framework takes an image and a text string as input and
then outputs the probability of the text string being present in the image.
This is the first end-to-end framework that learns such relationships between
text and images in scene text area. The framework does not require explicit
scene text detection or recognition and thus no bounding box annotations are
needed for it. It is also the first work in scene text area that tackles suh a
weakly labeled problem. Based on this framework, we developed a model called
Guided Attention. Our designed model achieves much better results than several
state-of-the-art scene text reading based solutions for a challenging Street
View Business Matching task. The task tries to find correct business names for
storefront images and the dataset we collected for it is substantially larger,
and more challenging than existing scene text dataset. This new real-world task
provides a new perspective for studying scene text related problems. We also
demonstrate the uniqueness of our task via a comparison between our problem and
a typical Visual Question Answering problem.


ET-Lasso: Efficient Tuning of Lasso for High-Dimensional Data

  The L1 regularization (Lasso) has proven to be a versatile tool to select
relevant features and estimate the model coefficients simultaneously. Despite
its popularity, it is very challenging to guarantee the feature selection
consistency of Lasso. One way to improve the feature selection consistency is
to select an ideal tuning parameter. Traditional tuning criteria mainly focus
on minimizing the estimated prediction error or maximizing the posterior model
probability, such as cross-validation and BIC, which may either be
time-consuming or fail to control the false discovery rate (FDR) when the
number of features is extremely large. The other way is to introduce
pseudo-features to learn the importance of the original ones. Recently, the
Knockoff filter is proposed to control the FDR when performing feature
selection. However, its performance is sensitive to the choice of the expected
FDR threshold. Motivated by these ideas, we propose a new method using
pseudo-features to obtain an ideal tuning parameter. In particular, we present
the Efficient Tuning of Lasso (ET-Lasso) to separate active and inactive
features by adding permuted features as pseudo-features in linear models. The
pseudo-features are constructed to be inactive by nature, which can be used to
obtain a cutoff to select the tuning parameter that separates active and
inactive features. Experimental studies on both simulations and real-world data
applications are provided to show that ET-Lasso can effectively and efficiently
select active features under a wide range of different scenarios.


Continual Learning of Recurrent Neural Networks by Locally Aligning
  Distributed Representations

  Temporal models based on recurrent neural networks have proven to be quite
powerful in a wide variety of applications, including language modeling and
speech processing. However, training these models relies on back-propagation
through time, which entails unfolding the network over many time steps, making
the process of conducting credit assignment considerably more challenging.
Furthermore, the nature of back-propagation itself does not permit the use of
non-differentiable activation functions and is inherently sequential, making
parallelization of the training process very difficult.
  In this work, we propose the Parallel Temporal Neural Coding Network
(P-TNCN), a biologically inspired model trained by the learning algorithm known
as Local Representation Alignment, that aims to resolve the difficulties that
plague recurrent networks trained by back-propagation through time. Most
notably, this architecture requires neither unrolling nor the derivatives of
its internal activation functions. We compare our model and learning procedure
to other online back-propagation-through-time alternatives (which tend to be
computationally expensive), including real-time recurrent learning, echo state
networks, and unbiased online recurrent optimization, and show that it
outperforms them on sequence benchmarks such as Bouncing MNIST, a new benchmark
we call Bouncing NotMNIST, and Penn Treebank. Notably, our approach can, in
some instances, outperform full back-propagation through time and variants such
as sparse attentive back-tracking.
  Significantly, the hidden unit correction phase of P-TNCN allows it to adapt
to new datasets even if its synaptic weights are held fixed (zero-shot
adaptation) and facilitates retention of prior knowledge when faced with a task
sequence. We present results that show the P-TNCN's ability to conduct
zero-shot adaptation and continual sequence modeling.


