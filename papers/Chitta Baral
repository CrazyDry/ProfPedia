Probabilistic reasoning with answer sets

  This paper develops a declarative language, P-log, that combines logical andprobabilistic arguments in its reasoning. Answer Set Prolog is used as thelogical foundation, while causal Bayes nets serve as a probabilisticfoundation. We give several non-trivial examples and illustrate the use ofP-log for knowledge representation and updating of knowledge. We argue that ourapproach to updates is more appealing than existing approaches. We givesufficiency conditions for the coherency of P-log programs and show that Bayesnets can be easily mapped to coherent P-log programs.

On Selecting a Conjunction Operation in Probabilistic Soft Logic

  Probabilistic Soft Logic has been proposed and used in several applicationsas an efficient way to deal with inconsistency, uncertainty and relationalrepresentation. In several applications, this approach has led to an adequatedescription of the corresponding human reasoning. In this paper, we provide atheoretical explanation for one of the semi-heuristic choices made in thisapproach: namely, we explain the choice of the corresponding conjunctionoperations. Our explanation leads to a more general family of operations whichmay be used in future applications of probabilistic soft logic.

Solving puzzles described in English by automated translation to answer  set programming and learning how to do that translation

  We present a system capable of automatically solving combinatorial logicpuzzles given in (simplified) English. It involves translating the Englishdescriptions of the puzzles into answer set programming(ASP) and using ASPsolvers to provide solutions of the puzzles. To translate the descriptions, weuse a lambda-calculus based approach using Probabilistic CombinatorialCategorial Grammars (PCCG) where the meanings of words are associated withparameters to be able to distinguish between multiple meanings of the sameword. Meaning of many words and the parameters are learned. The puzzles arerepresented in ASP using an ontology which is applicable to a large set oflogic puzzles.

Typed Answer Set Programming and Inverse Lambda Algorithms

  Our broader goal is to automatically translate English sentences intoformulas in appropriate knowledge representation languages as a step towardsunderstanding and thus answering questions with respect to English text. Ourfocus in this paper is on the language of Answer Set Programming (ASP). Ourapproach to translate sentences to ASP rules is inspired by Montague's use oflambda calculus formulas as meaning of words and phrases. With ASP as thetarget language the meaning of words and phrases are ASP-lambda formulas. In anearlier work we illustrated our approach by manually developing a dictionary ofwords and their ASP-lambda formulas. However such an approach is not scalable.In this paper our focus is on two algorithms that allow one to constructASP-lambda formulas in an inverse manner. In particular the two algorithms takeas input two lambda-calculus expressions G and H and compute a lambda-calculusexpression F such that F with input as G, denoted by F@G, is equal to H; andsimilarly G@F = H. We present correctness and complexity results about thesealgorithms. To do that we develop the notion of typed ASP-lambda calculustheories and their orders and use it in developing the completeness results.(To appear in Theory and Practice of Logic Programming.)

Regression with respect to sensing actions and partial states

  In this paper, we present a state-based regression function for planningdomains where an agent does not have complete information and may have sensingactions. We consider binary domains and employ the 0-approximation [Son & Baral2001] to define the regression function. In binary domains, the use of0-approximation means using 3-valued states. Although planning using thisapproach is incomplete with respect to the full semantics, we adopt it to havea lower complexity. We prove the soundness and completeness of our regressionformulation with respect to the definition of progression. More specifically,we show that (i) a plan obtained through regression for a planning problem isindeed a progression solution of that planning problem, and that (ii) for eachplan found through progression, using regression one obtains that plan or anequivalent one. We then develop a conditional planner that utilizes ourregression function. We prove the soundness and completeness of our planningalgorithm and present experimental results with respect to several well knownplanning problems in the literature.

Reasoning and Planning with Sensing Actions, Incomplete Information, and  Static Causal Laws using Answer Set Programming

  We extend the 0-approximation of sensing actions and incomplete informationin [Son and Baral 2000] to action theories with static causal laws and proveits soundness with respect to the possible world semantics. We also show thatthe conditional planning problem with respect to this approximation isNP-complete. We then present an answer set programming based conditionalplanner, called ASCP, that is capable of generating both conformant plans andconditional plans in the presence of sensing actions, incomplete informationabout the initial state, and static causal laws. We prove the correctness ofour implementation and argue that our planner is sound and complete withrespect to the proposed approximation. Finally, we present experimental resultscomparing ASCP to other planners.

Domain-Dependent Knowledge in Answer Set Planning

  In this paper we consider three different kinds of domain-dependent controlknowledge (temporal, procedural and HTN-based) that are useful in planning. Ourapproach is declarative and relies on the language of logic programming withanswer set semantics (AnsProlog*). AnsProlog* is designed to plan withoutcontrol knowledge. We show how temporal, procedural and HTN-based controlknowledge can be incorporated into AnsProlog* by the modular addition of asmall number of domain-dependent rules, without the need to modify the planner.We formally prove the correctness of our planner, both in the absence andpresence of the control knowledge. Finally, we perform some initialexperimentation that demonstrates the potential reduction in planning time thatcan be achieved when procedural domain knowledge is used to solve planningproblems with large plan length.

A State-Based Regression Formulation for Domains with Sensing  Actions<br> and Incomplete Information

  We present a state-based regression function for planning domains where anagent does not have complete information and may have sensing actions. Weconsider binary domains and employ a three-valued characterization of domainswith sensing actions to define the regression function. We prove the soundnessand completeness of our regression formulation with respect to the definitionof progression. More specifically, we show that (i) a plan obtained throughregression for a planning problem is indeed a progression solution of thatplanning problem, and that (ii) for each plan found through progression, usingregression one obtains that plan or an equivalent one.

Towards Effective Sentence Simplification for Automatic Processing of  Biomedical Text

  The complexity of sentences characteristic to biomedical articles poses achallenge to natural language parsers, which are typically trained onlarge-scale corpora of non-technical text. We propose a text simplificationprocess, bioSimplify, that seeks to reduce the complexity of sentences inbiomedical abstracts in order to improve the performance of syntactic parserson the processed sentences. Syntactic parsing is typically one of the firststeps in a text mining pipeline. Thus, any improvement in performance wouldhave a ripple effect over all processing steps. We evaluated our method using acorpus of biomedical sentences annotated with syntactic links. Our empiricalresults show an improvement of 2.90% for the Charniak-McClosky parser and of4.23% for the Link Grammar parser when processing simplified sentences ratherthan the original sentences in the corpus.

Logic Programming for Finding Models in the Logics of Knowledge and its  Applications: A Case Study

  The logics of knowledge are modal logics that have been shown to be effectivein representing and reasoning about knowledge in multi-agent domains.Relatively few computational frameworks for dealing with computation of modelsand useful transformations in logics of knowledge (e.g., to support multi-agentplanning with knowledge actions and degrees of visibility) have been proposed.This paper explores the use of logic programming (LP) to encode interestingforms of logics of knowledge and compute Kripke models. The LP modeling isexpanded with useful operators on Kripke structures, to support multi-agentplanning in the presence of both world-altering and knowledge actions. Thisresults in the first ever implementation of a planner for this type of complexmulti-agent domains.

Using Inverse lambda and Generalization to Translate English to Formal  Languages

  We present a system to translate natural language sentences to formulas in aformal or a knowledge representation language. Our system uses two inverselambda-calculus operators and using them can take as input the semanticrepresentation of some words, phrases and sentences and from that derive thesemantic representation of other words and phrases. Our inverse lambda operatorworks on many formal languages including first order logic, database querylanguages and answer set programming. Our system uses a syntactic combinatorialcategorial parser to parse natural language sentences and also to construct thesemantic meaning of the sentences as directed by their parsing. The same parseris used for both. In addition to the inverse lambda-calculus operators, oursystem uses a notion of generalization to learn semantic representation ofwords from the semantic representation of other words that are of the samecategory. Together with this, we use an existing statistical learning approachto assign weights to deal with multiple meanings of words. Our system producesimproved results on standard corpora on natural language interfaces for robotcommand and control and database queries.

Language understanding as a step towards human level intelligence -  automatizing the construction of the initial dictionary from example  sentences

  For a system to understand natural language, it needs to be able to takenatural language text and answer questions given in natural language withrespect to that text; it also needs to be able to follow instructions given innatural language. To achieve this, a system must be able to process naturallanguage and be able to capture the knowledge within that text. Thus it needsto be able to translate natural language text into a formal language. Wediscuss our approach to do this, where the translation is achieved by composingthe meaning of words in a sentence. Our initial approach uses an inverse lambdamethod that we developed (and other methods) to learn meaning of words frommeaning of sentences and an initial lexicon. We then present an improved methodwhere the initial lexicon is also learned by analyzing the training sentenceand meaning pairs. We evaluate our methods and compare them with other existingmethods on a corpora of database querying and robot command and control.

Encoding Petri Nets in Answer Set Programming for Simulation Based  Reasoning

  One of our long term research goals is to develop systems to answer realisticquestions (e.g., some mentioned in textbooks) about biological pathways that abiologist may ask. To answer such questions we need formalisms that can modelpathways, simulate their execution, model intervention to those pathways, andcompare simulations under different circumstances. We found Petri Nets to bethe starting point of a suitable formalism for the modeling and simulationneeds. However, we need to make extensions to the Petri Net model and alsoreason with multiple simulation runs and parallel state evolutions. Towardsthat end Answer Set Programming (ASP) implementation of Petri Nets would allowus to do both. In this paper we show how ASP can be used to encode basic PetriNets in an intuitive manner. We then show how we can modify this encoding tomodel several Petri Net extensions by making small changes. We then highlightsome of the reasoning capabilities that we will use to accomplish our ultimateresearch goal.

Encoding Higher Level Extensions of Petri Nets in Answer Set Programming

  Answering realistic questions about biological systems and pathways similarto the ones used by text books to test understanding of students aboutbiological systems is one of our long term research goals. Often thesequestions require simulation based reasoning. To answer such questions, we needformalisms to build pathway models, add extensions, simulate, and reason withthem. We chose Petri Nets and Answer Set Programming (ASP) as suitableformalisms, since Petri Net models are similar to biological pathway diagrams;and ASP provides easy extension and strong reasoning abilities. We found thatcertain aspects of biological pathways, such as locations and substance types,cannot be represented succinctly using regular Petri Nets. As a result, we needhigher level constructs like colored tokens. In this paper, we show how PetriNets with colored tokens can be encoded in ASP in an intuitive manner, howadditional Petri Net extensions can be added by making small code changes, andhow this work furthers our long term research goals. Our approach can beadapted to other domains with similar modeling needs.

Event-Object Reasoning with Curated Knowledge Bases: Deriving Missing  Information

  The broader goal of our research is to formulate answers to why and howquestions with respect to knowledge bases, such as AURA. One issue we face whenreasoning with many available knowledge bases is that at times neededinformation is missing. Examples of this include partially missing informationabout next sub-event, first sub-event, last sub-event, result of an event,input to an event, destination of an event, and raw material involved in anevent. In many cases one can recover part of the missing knowledge throughreasoning. In this paper we give a formal definition about how such missinginformation can be recovered and then give an ASP implementation of it. We thendiscuss the implication of this with respect to answering why and howquestions.

From Images to Sentences through Scene Description Graphs using  Commonsense Reasoning and Knowledge

  In this paper we propose the construction of linguistic descriptions ofimages. This is achieved through the extraction of scene description graphs(SDGs) from visual scenes using an automatically constructed knowledge base.SDGs are constructed using both vision and reasoning. Specifically, commonsensereasoning is applied on (a) detections obtained from existing perceptionmethods on given images, (b) a "commonsense" knowledge base constructed usingnatural language processing of image annotations and (c) lexical ontologicalknowledge from resources such as WordNet. Amazon Mechanical Turk(AMT)-basedevaluations on Flickr8k, Flickr30k and MS-COCO datasets show that in mostcases, sentences auto-constructed from SDGs obtained by our method give a morerelevant and thorough description of an image than a recent state-of-the-artimage caption based approach. Our Image-Sentence Alignment Evaluation resultsare also comparable to that of the recent state-of-the art approaches.

Answering Image Riddles using Vision and Reasoning through Probabilistic  Soft Logic

  In this work, we explore a genre of puzzles ("image riddles") which involvesa set of images and a question. Answering these puzzles require bothcapabilities involving visual detection (including object, activityrecognition) and, knowledge-based or commonsense reasoning. We compile adataset of over 3k riddles where each riddle consists of 4 images and agroundtruth answer. The annotations are validated using crowd-sourcedevaluation. We also define an automatic evaluation metric to track futureprogress. Our task bears similarity with the commonly known IQ tasks such asanalogy solving, sequence filling that are often used to test intelligence.  We develop a Probabilistic Reasoning-based approach that utilizesprobabilistic commonsense knowledge to answer these riddles with a reasonableaccuracy. We demonstrate the results of our approach using both automatic andhuman evaluations. Our approach achieves some promising results for theseriddles and provides a strong baseline for future attempts. We make the entiredataset and related materials publicly available to the community inImageRiddle Website (http://bit.ly/22f9Ala).

Incremental and Iterative Learning of Answer Set Programs from Mutually  Distinct Examples

  Over the years the Artificial Intelligence (AI) community has producedseveral datasets which have given the machine learning algorithms theopportunity to learn various skills across various domains. However, a subclassof these machine learning algorithms that aimed at learning logic programs,namely the Inductive Logic Programming algorithms, have often failed at thetask due to the vastness of these datasets. This has impacted the usability ofknowledge representation and reasoning techniques in the development of AIsystems. In this research, we try to address this scalability issue for thealgorithms that learn answer set programs. We present a sound and completealgorithm which takes the input in a slightly different manner and performs anefficient and more user controlled search for a solution. We show viaexperiments that our algorithm can learn from two popular datasets from machinelearning community, namely bAbl (a question answering dataset) and MNIST (adataset for handwritten digit recognition), which to the best of our knowledgewas not previously possible. The system is publicly available athttps://goo.gl/KdWAcV. This paper is under consideration for acceptance inTPLP.

Explicit Reasoning over End-to-End Neural Architectures for Visual  Question Answering

  Many vision and language tasks require commonsense reasoning beyonddata-driven image and natural language processing. Here we adopt VisualQuestion Answering (VQA) as an example task, where a system is expected toanswer a question in natural language about an image. Current state-of-the-artsystems attempted to solve the task using deep neural architectures andachieved promising performance. However, the resulting systems are generallyopaque and they struggle in understanding questions for which extra knowledgeis required. In this paper, we present an explicit reasoning layer on top of aset of penultimate neural network based systems. The reasoning layer enablesreasoning and answering questions where additional knowledge is required, andat the same time provides an interpretable interface to the end users.Specifically, the reasoning layer adopts a Probabilistic Soft Logic (PSL) basedengine to reason over a basket of inputs: visual relations, the semantic parseof the question, and background ontological knowledge from word2vec andConceptNet. Experimental analysis of the answers and the key evidentialpredicates generated on the VQA dataset validate our approach.

Proceedings of the 8th International Workshop on Non-Monotonic  Reasoning, NMR'2000

  The papers gathered in this collection were presented at the 8thInternational Workshop on Nonmonotonic Reasoning, NMR2000. The series wasstarted by John McCarthy in 1978. The first international NMR workshop was heldat Mohonk Mountain House, New Paltz, New York in June, 1984, and was organizedby Ray Reiter and Bonnie Webber.  In the last 10 years the area of nonmonotonic reasoning has seen a number ofimportant developments. Significant theoretical advances were made in theunderstanding of general abstract principles underlying nonmonotonicity. Keyresults on the expressibility and computational complexity of nonmonotoniclogics were established. The role of nonmonotonic reasoning in belief revision,abduction, reasoning about action, planing and uncertainty was furtherclarified. Several successful NMR systems were built and used in applicationssuch as planning, scheduling, logic programming and constraint satisfaction.  The papers in the proceedings reflect these recent advances in the field.They are grouped into sections corresponding to special sessions as they wereheld at the workshop:  1. General NMR track  2. Abductive reasonig  3. Belief revision: theory and practice  4. Representing action and planning  5. Systems descriptions and demonstrations  6. Uncertainty frameworks in NMR

Spatial Knowledge Distillation to aid Visual Reasoning

  For tasks involving language and vision, the current state-of-the-art methodstend not to leverage any additional information that might be present to gatherrelevant (commonsense) knowledge. A representative task is Visual QuestionAnswering where large diagnostic datasets have been proposed to test a system'scapability of answering questions about images. The training data is oftenaccompanied by annotations of individual object properties and spatiallocations. In this work, we take a step towards integrating this additionalprivileged information in the form of spatial knowledge to aid in visualreasoning. We propose a framework that combines recent advances in knowledgedistillation (teacher-student framework), relational reasoning andprobabilistic logical languages to incorporate such knowledge in existingneural networks for the task of Visual Question Answering. Specifically, for aquestion posed against an image, we use a probabilistic logical language toencode the spatial knowledge and the spatial understanding about the questionin the form of a mask that is directly provided to the teacher network. Thestudent network learns from the ground-truth information as well as theteachers prediction via distillation. We also demonstrate the impact ofpredicting such a mask inside the teachers network using attention.Empirically, we show that both the methods improve the test accuracy over astate-of-the-art approach on a publicly available dataset.

Developing and Using Special-Purpose Lexicons for Cohort Selection from  Clinical Notes

  Background and Significance: Selecting cohorts for a clinical trial typicallyrequires costly and time-consuming manual chart reviews resulting in poorparticipation. To help automate the process, National NLP Clinical Challenges(N2C2) conducted a shared challenge by defining 13 criteria for clinical trialcohort selection and by providing training and test datasets. This research wasmotivated by the N2C2 challenge.  Methods: We broke down the task into 13 independent subtasks corresponding toeach criterion and implemented subtasks using rules or a supervised machinelearning model. Each task critically depended on knowledge resources in theform of task-specific lexicons, for which we developed a novel model-drivenapproach. The approach allowed us to first expand the lexicon from a seed setand then remove noise from the list, thus improving the accuracy.  Results: Our system achieved an overall F measure of 0.9003 at the challenge,and was statistically tied for the first place out of 45 participants. Themodel-driven lexicon development and further debugging the rules/code on thetraining set improved overall F measure to 0.9140, overtaking the bestnumerical result at the challenge.  Discussion: Cohort selection, like phenotype extraction and classification,is amenable to rule-based or simple machine learning methods, however, thelexicons involved, such as medication names or medical terms referring to amedical problem, critically determine the overall accuracy. Automated lexicondevelopment has the potential for scalability and accuracy.

An Action Language for Multi-Agent Domains: Foundations

  In multi-agent domains (MADs), an agent's action may not just change theworld and the agent's knowledge and beliefs about the world, but also maychange other agents' knowledge and beliefs about the world and their knowledgeand beliefs about other agents' knowledge and beliefs about the world. Thegoals of an agent in a multi-agent world may involve manipulating the knowledgeand beliefs of other agents' and again, not just their knowledge/belief aboutthe world, but also their knowledge about other agents' knowledge about theworld. Our goal is to present an action language (mA+) that has the necessaryfeatures to address the above aspects in representing and RAC in MADs. mA+allows the representation of and reasoning about different types of actionsthat an agent can perform in a domain where many other agents might bepresent---such as world-altering actions, sensing actions, andannouncement/communication actions. It also allows the specification of agents'dynamic awareness of action occurrences which has future implications on whatagents' know about the world and other agents' knowledge about the world. mA+considers three different types of awareness: full,- partial- awareness, andcomplete oblivion of an action occurrence and its effects. This keeps thelanguage simple, yet powerful enough to address a large variety of knowledgemanipulation scenarios in MADs. The semantics of mA+ relies on the notion ofstate, which is described by a pointed Kripke model and is used to encode theagent's knowledge and the real state of the world. It is defined by atransition function that maps pairs of actions and states into sets of states.We illustrate properties of the action theories, including properties thatguarantee finiteness of the set of initial states and their practicalimplementability. Finally, we relate mA+ to other related formalisms thatcontribute to RAC in MADs.

