Evolving Deep Neural Networks

  The success of deep learning depends on finding an architecture to fit thetask. As deep learning has scaled up to more challenging tasks, thearchitectures have become difficult to design by hand. This paper proposes anautomated method, CoDeepNEAT, for optimizing deep learning architecturesthrough evolution. By extending existing neuroevolution methods to topology,components, and hyperparameters, this method achieves results comparable tobest human designs in standard benchmarks in object recognition and languagemodeling. It also supports building a real-world application of automated imagecaptioning on a magazine website. Given the anticipated increases in availablecomputing power, evolution of deep networks is promising approach toconstructing deep learning applications in the future.

Creative AI Through Evolutionary Computation

  In the last decade or so we have seen tremendous progress in ArtificialIntelligence (AI). AI is now in the real world, powering applications that havea large practical impact. Most of it is based on modeling, i.e. machinelearning of statistical models that make it possible to predict what the rightdecision might be in future situations. The next step for AI is machinecreativity, i.e. tasks where the correct, or even good, solutions are notknown, but need to be discovered. Methods for machine creativity have existedfor decades. I believe we are now in a similar situation as deep learning was afew years ago: with the million-fold increase in computational power, thosemethods can now be used to scale up to creativity in real-world tasks. Inparticular, Evolutionary Computation is in a unique position to take advantageof that power, and become the next deep learning.

Conversion Rate Optimization through Evolutionary Computation

  Conversion optimization means designing a web interface so that as many usersas possible take a desired action on it, such as register or purchase. Suchdesign is usually done by hand, testing one change at a time through A/Btesting, or a limited number of combinations through multivariate testing,making it possible to evaluate only a small fraction of designs in a vastdesign space. This paper describes Sentient Ascend, an automatic conversionoptimization system that uses evolutionary optimization to create effective webinterface designs. Ascend makes it possible to discover and utilizeinteractions between the design elements that are difficult to identifyotherwise. Moreover, evaluation of design candidates is done in parallelonline, i.e. with a large number of real users interacting with the system. Acase study on an existing media site shows that significant improvements (i.e.over 43%) are possible beyond human design. Ascend can therefore be seen as anapproach to massively multivariate conversion optimization, based on amassively parallel interactive evolution.

Increasing Behavioral Complexity for Evolved Virtual Creatures with the  ESP Method

  Since their introduction in 1994 (Sims), evolved virtual creatures (EVCs)have employed the coevolution of morphology and control to produce high-impactwork in multiple fields, including graphics, evolutionary computation,robotics, and artificial life. However, in contrast to fixed-morphologycreatures, there has been no clear increase in the behavioral complexity ofEVCs in those two decades. This paper describes a method for moving beyond thislimit, making use of high-level human input in the form of a syllabus ofintermediate learning tasks--along with mechanisms for preservation, reuse, andcombination of previously learned tasks. This method--named ESP for its threecomponents: encapsulation, syllabus, and pandemonium--is presented in twocomplementary versions: Fast ESP, which constrains later morphological changesto achieve linear growth in computation time as behavioral complexity is added,and General ESP, which allows this restriction to be removed when sufficientcomputational resources are available. Experiments demonstrate that the ESPmethod allows evolved virtual creatures to reach new levels of behavioralcomplexity in the co-evolution of morphology and control, approximatelydoubling the previous state of the art.

Reuse of Neural Modules for General Video Game Playing

  A general approach to knowledge transfer is introduced in which an agentcontrolled by a neural network adapts how it reuses existing networks as itlearns in a new domain. Networks trained for a new domain can improve theirperformance by routing activation selectively through previously learned neuralstructure, regardless of how or for what it was learned. A neuroevolutionimplementation of this approach is presented with application tohigh-dimensional sequential decision-making domains. This approach is moregeneral than previous approaches to neural transfer for reinforcement learning.It is domain-agnostic and requires no prior assumptions about the nature oftask relatedness or mappings. The method is analyzed in a stochastic version ofthe Arcade Learning Environment, demonstrating that it improves performance insome of the more complex Atari 2600 games, and that the success of transfer canbe predicted based on a high-level characterization of game dynamics.

Discovering Evolutionary Stepping Stones through Behavior Domination

  Behavior domination is proposed as a tool for understanding and harnessingthe power of evolutionary systems to discover and exploit useful steppingstones. Novelty search has shown promise in overcoming deception by collectingdiverse stepping stones, and several algorithms have been proposed that combinenovelty with a more traditional fitness measure to refocus search and helpnovelty search scale to more complex domains. However, combinations of noveltyand fitness do not necessarily preserve the stepping stone discovery thatnovelty search affords. In several existing methods, competition betweensolutions can lead to an unintended loss of diversity. Behavior dominationdefines a class of algorithms that avoid this problem, while inheritingtheoretical guarantees from multiobjective optimization. Several existingalgorithms are shown to be in this class, and a new algorithm is introducedbased on fast non-dominated sorting. Experimental results show that thisalgorithm outperforms existing approaches in domains that contain usefulstepping stones, and its advantage is sustained with scale. The conclusion isthat behavior domination can help illuminate the complex dynamics ofbehavior-driven search, and can thus lead to the design of more scalable androbust algorithms.

Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer  Ordering

  Existing deep multitask learning (MTL) approaches align layers shared betweentasks in a parallel ordering. Such an organization significantly constricts thetypes of shared structure that can be learned. The necessity of parallelordering for deep MTL is first tested by comparing it with permuted ordering ofshared layers. The results indicate that a flexible ordering can enable moreeffective sharing, thus motivating the development of a soft ordering approach,which learns how shared layers are applied in different ways for differenttasks. Deep MTL with soft ordering outperforms parallel ordering methods acrossa series of domains. These results suggest that the power of deep MTL comesfrom learning highly general building blocks that can be assembled to meet thedemands of each task.

Enhancing Evolutionary Conversion Rate Optimization via Multi-armed  Bandit Algorithms

  Conversion rate optimization means designing web interfaces such that morevisitors perform a desired action (such as register or purchase) on the site.One promising approach, implemented in Sentient Ascend, is to optimize thedesign using evolutionary algorithms, evaluating each candidate design onlinewith actual visitors. Because such evaluations are costly and noisy, severalchallenges emerge: How can available visitor traffic be used most efficiently?How can good solutions be identified most reliably? How can a high conversionrate be maintained during optimization? This paper proposes a new technique toaddress these issues. Traffic is allocated to candidate solutions using amulti-armed bandit algorithm, using more traffic on those evaluations that aremost useful. In a best-arm identification mode, the best candidate can beidentified reliably at the end of evolution, and in a campaign mode, theoverall conversion rate can be optimized throughout the entire evolutionprocess. Multi-armed bandit algorithms thus improve performance and reliabilityof machine discovery in noisy real-world environments.

Enhanced Optimization with Composite Objectives and Novelty Selection

  An important benefit of multi-objective search is that it maintains a diversepopulation of candidates, which helps in deceptive problems in particular. Notall diversity is useful, however: candidates that optimize only one objectivewhile ignoring others are rarely helpful. This paper proposes a solution: Theoriginal objectives are replaced by their linear combinations, thus focusingthe search on the most useful tradeoffs between objectives. To compensate forthe loss of diversity, this transformation is accompanied by a selectionmechanism that favors novelty. In the highly deceptive problem of discoveringminimal sorting networks, this approach finds better solutions, and finds themfaster and more consistently than standard methods. It is therefore a promisingapproach to solving deceptive problems through multi-objective optimization.

Evolutionary Architecture Search For Deep Multitask Networks

  Multitask learning, i.e. learning several tasks at once with the same neuralnetwork, can improve performance in each of the tasks. Designing deep neuralnetwork architectures for multitask learning is a challenge: There are manyways to tie the tasks together, and the design choices matter. The size andcomplexity of this problem exceeds human design ability, making it a compellingdomain for evolutionary optimization. Using the existing state of the art softordering architecture as the starting point, methods for evolving the modulesof this architecture and for evolving the overall topology or routing betweenmodules are evaluated in this paper. A synergetic approach of evolving customroutings with evolved, shared modules for each task is found to be verypowerful, significantly improving the state of the art in the Omniglotmultitask, multialphabet character recognition domain. This result demonstrateshow evolution can be instrumental in advancing deep neural network and complexsystem design in general.

Pseudo-task Augmentation: From Deep Multitask Learning to Intratask  Sharing---and Back

  Deep multitask learning boosts performance by sharing learned structureacross related tasks. This paper adapts ideas from deep multitask learning tothe setting where only a single task is available. The method is formalized aspseudo-task augmentation, in which models are trained with multiple decodersfor each task. Pseudo-tasks simulate the effect of training towardsclosely-related tasks drawn from the same universe. In a suite of experiments,pseudo-task augmentation is shown to improve performance on single-tasklearning problems. When combined with multitask learning, further improvementsare achieved, including state-of-the-art performance on the CelebA dataset,showing that pseudo-task augmentation and multitask learning have complementaryvalue. All in all, pseudo-task augmentation is a broadly applicable andefficient way to boost performance in deep learning systems.

From Nodes to Networks: Evolving Recurrent Neural Networks

  Gated recurrent networks such as those composed of Long Short-Term Memory(LSTM) nodes have recently been used to improve state of the art in manysequential processing tasks such as speech recognition and machine translation.However, the basic structure of the LSTM node is essentially the same as whenit was first conceived 25 years ago. Recently, evolutionary and reinforcementlearning mechanisms have been employed to create new variations of thisstructure. This paper proposes a new method, evolution of a tree-based encodingof the gated memory nodes, and shows that it makes it possible to explore newvariations more effectively than other methods. The method discovers nodes withmultiple recurrent paths and multiple memory cells, which lead to significantimprovement in the standard language modeling benchmark task. The paper alsoshows how the search process can be speeded up by training an LSTM network toestimate performance of candidate structures, and by encouraging exploration ofnovel solutions. Thus, evolutionary design of complex neural network structurespromises to improve performance of deep learning architectures beyond humanability to do so.

A Comparison of the Taguchi Method and Evolutionary Optimization in  Multivariate Testing

  Multivariate testing has recently emerged as a promising technique in webinterface design. In contrast to the standard A/B testing, multivariateapproach aims at evaluating a large number of values in a few key variablessystematically. The Taguchi method is a practical implementation of this idea,focusing on orthogonal combinations of values. This paper evaluates analternative method: population-based search, i.e. evolutionary optimization.Its performance is compared to that of the Taguchi method in several simulatedconditions, including an orthogonal one designed to favor the Taguchi method,and two realistic conditions with dependences between variables. Evolutionaryoptimization is found to perform significantly better especially in therealistic conditions, suggesting that it forms a good approach for webinterface design in the future.

Functional Generative Design of Mechanisms with Recurrent Neural  Networks and Novelty Search

  Consumer-grade 3D printers have made it easier to fabricate aesthetic objectsand static assemblies, opening the door to automated design of such objects.However, while static designs are easily produced with 3D printing, functionaldesigns with moving parts are more difficult to generate: The search space istoo high-dimensional, the resolution of the 3D-printed parts is not adequate,and it is difficult to predict the physical behavior of imperfect 3D-printedmechanisms. An example challenge is to produce a diverse set of reliable andeffective gear mechanisms that could be used after production without extensivepost-processing. To meet this challenge, an indirect encoding based on aRecurrent Neural Network (RNN) is created and evolved using novelty search. Theelite solutions of each generation are 3D printed to evaluate their functionalperformance on a physical test platform. The system is able to discoversequential design rules that are difficult to discover with other methods.Compared to direct encoding evolved with Genetic Algorithms (GAs), its designsare geometrically more diverse and functionally more effective. It thereforeforms a promising foundation for the generative design of 3D-printed,functional mechanisms.

Fault prediction in aircraft engines using Self-Organizing Maps

  Aircraft engines are designed to be used during several tens of years. Theirmaintenance is a challenging and costly task, for obvious security reasons. Thegoal is to ensure a proper operation of the engines, in all conditions, with azero probability of failure, while taking into account aging. The fact that thesame engine is sometimes used on several aircrafts has to be taken into accounttoo. The maintenance can be improved if an efficient procedure for theprediction of failures is implemented. The primary source of information on thehealth of the engines comes from measurement during flights. Several variablessuch as the core speed, the oil pressure and quantity, the fan speed, etc. aremeasured, together with environmental variables such as the outsidetemperature, altitude, aircraft speed, etc. In this paper, we describe thedesign of a procedure aiming at visualizing successive data measured onaircraft engines. The data are multi-dimensional measurements on the engines,which are projected on a self-organizing map in order to allow us to follow thetrajectories of these data over time. The trajectories consist in a successionof points on the map, each of them corresponding to the two-dimensionalprojection of the multi-dimensional vector of engine measurements. Analyzingthe trajectories aims at visualizing any deviation from a normal behavior,making it possible to anticipate an operation failure.

Functional Generative Design: An Evolutionary Approach to 3D-Printing

  Consumer-grade printers are widely available, but their ability to printcomplex objects is limited. Therefore, new designs need to be discovered thatserve the same function, but are printable. A representative such problem is toproduce a working, reliable mechanical spring. The proposed methodology fordiscovering solutions to this problem consists of three components: First, aneffective search space is learned through a variational autoencoder (VAE);second, a surrogate model for functional designs is built; and third, a geneticalgorithm is used to simultaneously update the hyperparameters of the surrogateand to optimize the designs using the updated surrogate. Using a car-launchermechanism as a test domain, spring designs were 3D-printed and evaluated toupdate the surrogate model. Two experiments were then performed: First, theinitial set of designs for the surrogate-based optimizer was selected randomlyfrom the training set that was used for training the VAE model, which resultedin an exploitative search behavior. On the other hand, in the secondexperiment, the initial set was composed of more uniformly selected designsfrom the same training set and a more explorative search behavior was observed.Both of the experiments showed that the methodology generates interesting,successful, and reliable spring geometries robust to the noise inherent in the3D printing process. The methodology can be generalized to other functionaldesign problems, thus making consumer-grade 3D printing more versatile.

Evolutionary Neural AutoML for Deep Learning

  Deep neural networks (DNNs) have produced state-of-the-art results in manybenchmarks and problem domains. However, the success of DNNs depends on theproper configuration of its architecture and hyperparameters. Such aconfiguration is difficult and as a result, DNNs are often not used to theirfull potential. In addition, DNNs in commercial applications often need tosatisfy real-world design constraints such as size or number of parameters. Tomake configuration easier, automatic machine learning (AutoML) systems for deeplearning have been developed, focusing mostly on optimization ofhyperparameters.  This paper takes AutoML a step further. It introduces an evolutionary AutoMLframework called LEAF that not only optimizes hyperparameters but also networkarchitectures and the size of the network. LEAF makes use of bothstate-of-the-art evolutionary algorithms (EAs) and distributed computingframeworks. Experimental results on medical image classification and naturallanguage analysis show that the framework can be used to achievestate-of-the-art performance. In particular, LEAF demonstrates thatarchitecture optimization provides a significant boost over hyperparameteroptimization, and that networks can be minimized at the same time with littledrop in performance. LEAF therefore forms a foundation for democratizing andimproving AI, as well as making AI practical in future applications.

Hierarchical Policy Design for Sample-Efficient Learning of Robot Table  Tennis Through Self-Play

  Training robots with physical bodies requires developing new methods andaction representations that allow the learning agents to explore the space ofpolicies efficiently. This work studies sample-efficient learning of complexpolicies in the context of robot table tennis. It incorporates learning into ahierarchical control framework using a model-free strategy layer (whichrequires complex reasoning about opponents that is difficult to do in amodel-based way), model-based prediction of external objects (which aredifficult to control directly with analytic control methods, but governed bylearnable and relatively simple laws of physics), and analytic controllers forthe robot itself. Human demonstrations are used to train dynamics models, whichtogether with the analytic controller allow any robot that is physicallycapable to play table tennis without training episodes. Using only about 7,000demonstrated trajectories, a striking policy can hit ball targets with about 20cm error. Self-play is used to train cooperative and adversarial strategies ontop of model-based striking skills trained from human demonstrations. Afteronly about 24,000 strikes in self-play the agent learns to best exploit thehuman dynamics models for longer cooperative games. Further experimentsdemonstrate that more flexible variants of the policy can discover new strikesnot demonstrated by humans and achieve higher performance at the expense oflower sample-efficiency. Experiments are carried out in a virtual realityenvironment using sensory observations that are obtainable in the real world.The high sample-efficiency demonstrated in the evaluations show that theproposed method is suitable for learning directly on physical robots withouttransfer of models or policies from simulation.  Supplementary material available athttps://sites.google.com/view/robottabletennis

The Surprising Creativity of Digital Evolution: A Collection of  Anecdotes from the Evolutionary Computation and Artificial Life Research  Communities

  Biological evolution provides a creative fount of complex and subtleadaptations, often surprising the scientists who discover them. However,because evolution is an algorithmic process that transcends the substrate inwhich it occurs, evolution's creativity is not limited to nature. Indeed, manyresearchers in the field of digital evolution have observed their evolvingalgorithms and organisms subverting their intentions, exposing unrecognizedbugs in their code, producing unexpected adaptations, or exhibiting outcomesuncannily convergent with ones in nature. Such stories routinely revealcreativity by evolution in these digital worlds, but they rarely fit into thestandard scientific narrative. Instead they are often treated as mere obstaclesto be overcome, rather than results that warrant study in their own right. Thestories themselves are traded among researchers through oral tradition, butthat mode of information transmission is inefficient and prone to error andoutright loss. Moreover, the fact that these stories tend to be shared onlyamong practitioners means that many natural scientists do not realize howinteresting and lifelike digital organisms are and how natural their evolutioncan be. To our knowledge, no collection of such anecdotes has been publishedbefore. This paper is the crowd-sourced product of researchers in the fields ofartificial life and evolutionary computation who have provided first-handaccounts of such cases. It thus serves as a written, fact-checked collection ofscientifically important and even entertaining stories. In doing so we alsopresent here substantial evidence that the existence and importance ofevolutionary surprises extends beyond the natural world, and may indeed be auniversal property of all complex evolving systems.

