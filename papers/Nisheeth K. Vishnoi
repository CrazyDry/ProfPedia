Extended Formulations for Polytopes of Regular Matroids

  We present a simple proof of the fact that the base (and independence)
polytope of a rank $n$ regular matroid over $m$ elements has an extension
complexity $O(mn)$.


On the Computational Complexity of Limit Cycles in Dynamical Systems

  We study the Poincare-Bendixson theorem for two-dimensional continuous
dynamical systems in compact domains from the point of view of computation,
seeking algorithms for finding the limit cycle promised by this classical
result. We start by considering a discrete analogue of this theorem and show
that both finding a point on a limit cycle, and determining if a given point is
on one, are PSPACE-complete.
  For the continuous version, we show that both problems are uncomputable in
the real complexity sense; i.e., their complexity is arbitrarily high.
Subsequently, we introduce a notion of an "approximate cycle" and prove an
"approximate" Poincar\'e-Bendixson theorem guaranteeing that some orbits come
very close to forming a cycle in the absence of approximate fixpoints;
surprisingly, it holds for all dimensions. The corresponding computational
problem defined in terms of arithmetic circuits is PSPACE-complete.


On Geodesically Convex Formulations for the Brascamp-Lieb Constant

  We consider two non-convex formulations for computing the optimal constant in
the Brascamp-Lieb inequality corresponding to a given datum, and show that they
are geodesically log-concave on the manifold of positive definite matrices
endowed with the Riemannian metric corresponding to the Hessian of the
log-determinant function. The first formulation is present in the work of Lieb
and the second is inspired by the work of Bennett et al. Recent works of Garg
et al.and Allen-Zhu et al. also imply a geodesically log-concave formulation of
the Brascamp-Lieb constant through a reduction to the operator scaling problem.
However, the dimension of the arising optimization problem in their reduction
depends exponentially on the number of bits needed to describe the
Brascamp-Lieb datum. The formulations presented here have dimensions that are
polynomial in the bit complexity of the input datum.


Fair Online Advertising

  Online advertising platforms are thriving due to the customizable audiences
they offer advertisers. However, recent studies show that the audience an ad
gets shown to can be discriminatory with respect to sensitive attributes such
as gender or ethnicity, inadvertently crossing ethical and/or legal boundaries.
To prevent this, we propose a constrained optimization framework that allows
the platform to control of the fraction of each sensitive type an advertiser's
ad gets shown to while maximizing its ad revenues. Building upon Myerson's
classic work, we first present an optimal auction mechanism for a large class
of fairness constraints. Finding the parameters of this optimal auction,
however, turns out to be a non-convex problem. We show how this non-convex
problem can be reformulated as a more structured non-convex problem with no
saddle points or local-maxima; allowing us to develop a gradient-descent-based
algorithm to solve it. Our empirical results on the A1 Yahoo! dataset
demonstrate that our algorithm can obtain uniform coverage across different
user attributes for each advertiser at a minor loss to the revenue of the
platform, and a small change in the total number of advertisements each
advertiser shows on the platform.


On the Optimality of a Class of LP-based Algorithms

  In this paper we will be concerned with a class of packing and covering
problems which includes Vertex Cover and Independent Set. Typically, one can
write an LP relaxation and then round the solution. In this paper, we explain
why the simple LP-based rounding algorithm for the \\VC problem is optimal
assuming the UGC. Complementing Raghavendra's result, our result generalizes to
a class of strict, covering/packing type CSPs.


A quadratically tight partition bound for classical communication
  complexity and query complexity

  In this work we introduce, both for classical communication complexity and
query complexity, a modification of the 'partition bound' introduced by Jain
and Klauck [2010]. We call it the 'public-coin partition bound'. We show that
(the logarithm to the base two of) its communication complexity and query
complexity versions form, for all relations, a quadratically tight lower bound
on the public-coin randomized communication complexity and randomized query
complexity respectively.


$2^{\log^{1-\eps} n}$ Hardness for Closest Vector Problem with
  Preprocessing

  We prove that for an arbitrarily small constant $\eps>0,$ assuming NP$\not
\subseteq$DTIME$(2^{{\log^{O(1/\eps)} n}})$, the preprocessing versions of the
closest vector problem and the nearest codeword problem are hard to approximate
within a factor better than $2^{\log ^{1-\eps}n}.$ This improves upon the
previous hardness factor of $(\log n)^\delta$ for some $\delta > 0$ due to
\cite{AKKV05}.


Matrix Inversion Is As Easy As Exponentiation

  We prove that the inverse of a positive-definite matrix can be approximated
by a weighted-sum of a small number of matrix exponentials. Combining this with
a previous result [OSV12], we establish an equivalence between matrix inversion
and exponentiation up to polylogarithmic factors. In particular, this
connection justifies the use of Laplacian solvers for designing fast
semi-definite programming based algorithms for certain graph problems. The
proof relies on the Euler-Maclaurin formula and certain bounds derived from the
Riemann zeta function.


The Mixing Time of the Dikin Walk in a Polytope - A Simple Proof

  We study the mixing time of the Dikin walk in a polytope - a random walk
based on the log-barrier from the interior point method literature. This walk,
and a close variant, were studied by Narayanan (2016) and Kannan-Narayanan
(2012). Bounds on its mixing time are important for algorithms for sampling and
optimization over polytopes. Here, we provide a simple proof of their result
that this random walk mixes in time O(mn) for an n-dimensional polytope
described using m inequalities.


On Convex Programming Relaxations for the Permanent

  In recent years, several convex programming relaxations have been proposed to
estimate the permanent of a non-negative matrix, notably in the works of
Gurvits and Samorodnitsky. However, the origins of these relaxations and their
relationships to each other have remained somewhat mysterious. We present a
conceptual framework, implicit in the belief propagation literature, to
systematically arrive at these convex programming relaxations for estimating
the permanent -- as approximations to an exponential-sized max-entropy convex
program for computing the permanent. Further, using standard convex programming
techniques such as duality, we establish equivalence of these aforementioned
relaxations to those based on capacity-like quantities studied by Gurvits and
Anari et al.


Fair Personalization

  Personalization is pervasive in the online space as, when combined with
learning, it leads to higher efficiency and revenue by allowing the most
relevant content to be served to each user. However, recent studies suggest
that such personalization can propagate societal or systemic biases, which has
led to calls for regulatory mechanisms and algorithms to combat inequality.
Here we propose a rigorous algorithmic framework that allows for the
possibility to control biased or discriminatory personalization with respect to
sensitive attributes of users without losing all of the benefits of
personalization.


Balanced News Using Constrained Bandit-based Personalization

  We present a prototype for a news search engine that presents balanced
viewpoints across liberal and conservative articles with the goal of
de-polarizing content and allowing users to escape their filter bubble. The
balancing is done according to flexible user-defined constraints, and leverages
recent advances in constrained bandit optimization. We showcase our balanced
news feed by displaying it side-by-side with the news feed produced by a
traditional (polarized) feed.


On the Number of Circuits in Regular Matroids (with Connections to
  Lattices and Codes)

  We show that for any regular matroid on $m$ elements and any $\alpha \geq 1$,
the number of $\alpha$-minimum circuits, or circuits whose size is at most an
$\alpha$-multiple of the minimum size of a circuit in the matroid is bounded by
$m^{O(\alpha^2)}$. This generalizes a result of Karger for the number of
$\alpha$-minimum cuts in a graph. As a consequence, we obtain similar bounds on
the number of $\alpha$-shortest vectors in "totally unimodular" lattices and on
the number of $\alpha$-minimum weight codewords in "regular" codes.


The Unique Games Conjecture, Integrality Gap for Cut Problems and
  Embeddability of Negative Type Metrics into $\ell_1$

  In this paper, we disprove a conjecture of Goemans and Linial; namely, that
every negative type metric embeds into $\ell_1$ with constant distortion. We
show that for an arbitrarily small constant $\delta> 0$, for all large enough
$n$, there is an $n$-point negative type metric which requires distortion at
least $(\log\log n)^{1/6-\delta}$ to embed into $\ell_1.$
  Surprisingly, our construction is inspired by the Unique Games Conjecture
(UGC) of Khot, establishing a previously unsuspected connection between
probabilistically checkable proof systems (PCPs) and the theory of metric
embeddings. We first prove that the UGC implies a super-constant hardness
result for the (non-uniform) Sparsest Cut problem. Though this hardness result
relies on the UGC, we demonstrate, nevertheless, that the corresponding PCP
reduction can be used to construct an "integrality gap instance" for Sparsest
Cut. Towards this, we first construct an integrality gap instance for a natural
SDP relaxation of Unique Games. Then we "simulate" the PCP reduction and
"translate" the integrality gap instance of Unique Games to an integrality gap
instance of Sparsest Cut. This enables us to prove a $(\log \log
n)^{1/6-\delta}$ integrality gap for Sparsest Cut, which is known to be
equivalent to the metric embedding lower bound.


Algorithms and Hardness for Subspace Approximation

  The subspace approximation problem Subspace($k$,$p$) asks for a
$k$-dimensional linear subspace that fits a given set of points optimally,
where the error for fitting is a generalization of the least squares fit and
uses the $\ell_{p}$ norm instead. Most of the previous work on subspace
approximation has focused on small or constant $k$ and $p$, using coresets and
sampling techniques from computational geometry.
  In this paper, extending another line of work based on convex relaxation and
rounding, we give a polynomial time algorithm, \emph{for any $k$ and any $p
\geq 2$}, with the approximation guarantee roughly $\gamma_{p} \sqrt{2 -
\frac{1}{n-k}}$, where $\gamma_{p}$ is the $p$-th moment of a standard normal
random variable N(0,1). We show that the convex relaxation we use has an
integrality gap (or "rank gap") of $\gamma_{p} (1 - \epsilon)$, for any
constant $\epsilon > 0$. Finally, we show that assuming the Unique Games
Conjecture, the subspace approximation problem is hard to approximate within a
factor better than $\gamma_{p} (1 - \epsilon)$, for any constant $\epsilon >
0$.


A Distributed Learning Dynamics in Social Groups

  We study a distributed learning process observed in human groups and other
social animals. This learning process appears in settings in which each
individual in a group is trying to decide over time, in a distributed manner,
which option to select among a shared set of options. Specifically, we consider
a stochastic dynamics in a group in which every individual selects an option in
the following two-step process: (1) select a random individual and observe the
option that individual chose in the previous time step, and (2) adopt that
option if its stochastic quality was good at that time step. Various
instantiations of such distributed learning appear in nature, and have also
been studied in the social science literature. From the perspective of an
individual, an attractive feature of this learning process is that it is a
simple heuristic that requires extremely limited computational capacities. But
what does it mean for the group -- could such a simple, distributed and
essentially memoryless process lead the group as a whole to perform optimally?
We show that the answer to this question is yes -- this distributed learning is
highly effective at identifying the best option and is close to optimal for the
group overall. Our analysis also gives quantitative bounds that show fast
convergence of these stochastic dynamics. Prior to our work the only
theoretical work related to such learning dynamics has been either in
deterministic special cases or in the asymptotic setting. Finally, we observe
that our infinite population dynamics is a stochastic variant of the classic
multiplicative weights update (MWU) method. Consequently, we arrive at the
following interesting converse: the learning dynamics on a finite population
considered here can be viewed as a novel distributed and low-memory
implementation of the classic MWU method.


Geodesic Convex Optimization: Differentiation on Manifolds, Geodesics,
  and Convexity

  Convex optimization is a vibrant and successful area due to the existence of
a variety of efficient algorithms that leverage the rich structure provided by
convexity. Convexity of a smooth set or a function in a Euclidean space is
defined by how it interacts with the standard differential structure in this
space -- the Hessian of a convex function has to be positive semi-definite
everywhere. However, in recent years, there is a growing demand to understand
non-convexity and develop computational methods to optimize non-convex
functions. Intriguingly, there is a type of non-convexity that disappears once
one introduces a suitable differentiable structure and redefines convexity with
respect to the straight lines, or {\em geodesics}, with respect to this
structure. Such convexity is referred to as {\em geodesic convexity}. Interest
in studying it arises due to recent reformulations of some non-convex problems
as geodesically convex optimization problems over geodesically convex sets.
Geodesics on manifolds have been extensively studied in various branches of
Mathematics and Physics. However, unlike convex optimization, understanding
geodesics and geodesic convexity from a computational point of view largely
remains a mystery. The goal of this exposition is to introduce the first part
of geodesic convex optimization -- geodesic convexity -- in a self-contained
manner. We first present a variety of notions from differential and Riemannian
geometry such as differentiation on manifolds, geodesics, and then introduce
geodesic convexity. We conclude by showing that certain non-convex optimization
problems such as computing the Brascamp-Lieb constant and the operator scaling
problem have geodesically convex formulations.


Entropy, Optimization and Counting

  In this paper we study the problem of computing max-entropy distributions
over a discrete set of objects subject to observed marginals. Interest in such
distributions arises due to their applicability in areas such as statistical
physics, economics, biology, information theory, machine learning,
combinatorics and, more recently, approximation algorithms. A key difficulty in
computing max-entropy distributions has been to show that they have
polynomially-sized descriptions. We show that such descriptions exist under
general conditions. Subsequently, we show how algorithms for (approximately)
counting the underlying discrete set can be translated into efficient
algorithms to (approximately) compute max-entropy distributions. In the reverse
direction, we show how access to algorithms that compute max-entropy
distributions can be used to count, which establishes an equivalence between
counting and computing max-entropy distributions.


On a Natural Dynamics for Linear Programming

  In this paper we study dynamics inspired by Physarum polycephalum (a slime
mold) for solving linear programs [NTY00, IJNT11, JZ12]. These dynamics are
arrived at by a local and mechanistic interpretation of the inner workings of
the slime mold and a global optimization perspective has been lacking even in
the simplest of instances. Our first result is an interpretation of the
dynamics as an optimization process. We show that Physarum dynamics can be seen
as a steepest-descent type algorithm on a certain Riemannian manifold.
Moreover, we prove that the trajectories of Physarum are in fact paths of
optimizers to a parametrized family of convex programs, in which the objective
is a linear cost function regularized by an entropy barrier. Subsequently, we
rigorously establish several important properties of solution curves of
Physarum. We prove global existence of such solutions and show that they have
limits, being optimal solutions of the underlying LP. Finally, we show that the
discretization of the Physarum dynamics is efficient for a class of linear
programs, which include unimodular constraint matrices. Thus, together, our
results shed some light on how nature might be solving instances of perhaps the
most complex problem in P: linear programming.


IRLS and Slime Mold: Equivalence and Convergence

  In this paper we present a connection between two dynamical systems arising
in entirely different contexts: one in signal processing and the other in
biology. The first is the famous Iteratively Reweighted Least Squares (IRLS)
algorithm used in compressed sensing and sparse recovery while the second is
the dynamics of a slime mold (Physarum polycephalum). Both of these dynamics
are geared towards finding a minimum l1-norm solution in an affine subspace.
Despite its simplicity the convergence of the IRLS method has been shown only
for a certain regularization of it and remains an important open problem. Our
first result shows that the two dynamics are projections of the same dynamical
system in higher dimensions. As a consequence, and building on the recent work
on Physarum dynamics, we are able to prove convergence and obtain complexity
bounds for a damped version of the IRLS algorithm.


Subdeterminant Maximization via Nonconvex Relaxations and
  Anti-concentration

  Several fundamental problems that arise in optimization and computer science
can be cast as follows: Given vectors $v_1,\ldots,v_m \in \mathbb{R}^d$ and a
constraint family ${\cal B}\subseteq 2^{[m]}$, find a set $S \in \cal{B}$ that
maximizes the squared volume of the simplex spanned by the vectors in $S$. A
motivating example is the data-summarization problem in machine learning where
one is given a collection of vectors that represent data such as documents or
images. The volume of a set of vectors is used as a measure of their diversity,
and partition or matroid constraints over $[m]$ are imposed in order to ensure
resource or fairness constraints. Recently, Nikolov and Singh presented a
convex program and showed how it can be used to estimate the value of the most
diverse set when ${\cal B}$ corresponds to a partition matroid. This result was
recently extended to regular matroids in works of Straszak and Vishnoi, and
Anari and Oveis Gharan. The question of whether these estimation algorithms can
be converted into the more useful approximation algorithms -- that also output
a set -- remained open.
  The main contribution of this paper is to give the first approximation
algorithms for both partition and regular matroids. We present novel
formulations for the subdeterminant maximization problem for these matroids;
this reduces them to the problem of finding a point that maximizes the absolute
value of a nonconvex function over a Cartesian product of probability
simplices. The technical core of our results is a new anti-concentration
inequality for dependent random variables that allows us to relate the optimal
value of these nonconvex functions to their value at a random point. Unlike
prior work on the constrained subdeterminant maximization problem, our proofs
do not rely on real-stability or convexity and could be of independent interest
both in algorithms and complexity.


Towards an SDP-based Approach to Spectral Methods: A Nearly-Linear-Time
  Algorithm for Graph Partitioning and Decomposition

  In this paper, we consider the following graph partitioning problem: The
input is an undirected graph $G=(V,E),$ a balance parameter $b \in (0,1/2]$ and
a target conductance value $\gamma \in (0,1).$ The output is a cut which, if
non-empty, is of conductance at most $O(f),$ for some function $f(G, \gamma),$
and which is either balanced or well correlated with all cuts of conductance at
most $\gamma.$ Spielman and Teng gave an $\tilde{O}(|E|/\gamma^{2})$-time
algorithm for $f= \sqrt{\gamma \log^{3}|V|}$ and used it to decompose graphs
into a collection of near-expanders. We present a new spectral algorithm for
this problem which runs in time $\tilde{O}(|E|/\gamma)$ for $f=\sqrt{\gamma}.$
Our result yields the first nearly-linear time algorithm for the classic
Balanced Separator problem that achieves the asymptotically optimal
approximation guarantee for spectral methods. Our method has the advantage of
being conceptually simple and relies on a primal-dual semidefinite-programming
SDP approach. We first consider a natural SDP relaxation for the Balanced
Separator problem. While it is easy to obtain from this SDP a certificate of
the fact that the graph has no balanced cut of conductance less than $\gamma,$
somewhat surprisingly, we can obtain a certificate for the stronger correlation
condition. This is achieved via a novel separation oracle for our SDP and by
appealing to Arora and Kale's framework to bound the running time. Our result
contains technical ingredients that may be of independent interest.


A Finite Population Model of Molecular Evolution: Theory and Computation

  This paper is concerned with the evolution of haploid organisms that
reproduce asexually. In a seminal piece of work, Eigen and coauthors proposed
the quasispecies model in an attempt to understand such an evolutionary
process. Their work has impacted antiviral treatment and vaccine design
strategies. Yet, predictions of the quasispecies model are at best viewed as a
guideline, primarily because it assumes an infinite population size, whereas
realistic population sizes can be quite small. In this paper we consider a
population genetics-based model aimed at understanding the evolution of such
organisms with finite population sizes and present a rigorous study of the
convergence and computational issues that arise therein. Our first result is
structural and shows that, at any time during the evolution, as the population
size tends to infinity, the distribution of genomes predicted by our model
converges to that predicted by the quasispecies model. This justifies the
continued use of the quasispecies model to derive guidelines for intervention.
While the stationary state in the quasispecies model is readily obtained, due
to the explosion of the state space in our model, exact computations are
prohibitive. Our second set of results are computational in nature and address
this issue. We derive conditions on the parameters of evolution under which our
stochastic model mixes rapidly. Further, for a class of widely used fitness
landscapes we give a fast deterministic algorithm which computes the stationary
distribution of our model. These computational tools are expected to serve as a
framework for the modeling of strategies for the deployment of mutagenic drugs.


How to be Fair and Diverse?

  Due to the recent cases of algorithmic bias in data-driven decision-making,
machine learning methods are being put under the microscope in order to
understand the root cause of these biases and how to correct them. Here, we
consider a basic algorithmic task that is central in machine learning:
subsampling from a large data set. Subsamples are used both as an end-goal in
data summarization (where fairness could either be a legal, political or moral
requirement) and to train algorithms (where biases in the samples are often a
source of bias in the resulting model). Consequently, there is a growing effort
to modify either the subsampling methods or the algorithms themselves in order
to ensure fairness. However, in doing so, a question that seems to be
overlooked is whether it is possible to produce fair subsamples that are also
adequately representative of the feature space of the data set - an important
and classic requirement in machine learning. Can diversity and fairness be
simultaneously ensured? We start by noting that, in some applications,
guaranteeing one does not necessarily guarantee the other, and a new approach
is required. Subsequently, we present an algorithmic framework which allows us
to produce both fair and diverse samples. Our experimental results on an image
summarization task show marked improvements in fairness without compromising
feature diversity by much, giving us the best of both the worlds.


Isolating a Vertex via Lattices: Polytopes with Totally Unimodular Faces

  We present a geometric approach towards derandomizing the Isolation Lemma by
Mulmuley, Vazirani, and Vazirani. In particular, our approach produces a
quasi-polynomial family of weights, where each weight is an integer and
quasi-polynomially bounded, that can isolate a vertex in any 0/1 polytope for
which each face lies in an affine space defined by a totally unimodular matrix.
This includes the polytopes given by totally unimodular constraints and
generalizes the recent derandomization of the Isolation Lemma for bipartite
perfect matching and matroid intersection. We prove our result by associating a
lattice to each face of the polytope and showing that if there is a totally
unimodular kernel matrix for this lattice, then the number of vectors of length
within 3/2 of the shortest vector in it is polynomially bounded. The proof of
this latter geometric fact is combinatorial and follows from a polynomial bound
on the number of circuits of size within 3/2 of the shortest circuit in a
regular matroid. This is the technical core of the paper and relies on a
variant of Seymour's decomposition theorem for regular matroids. It generalizes
an influential result by Karger on the number of minimum cuts in a graph to
regular matroids.


Belief Propagation, Bethe Approximation and Polynomials

  Factor graphs are important models for succinctly representing probability
distributions in machine learning, coding theory, and statistical physics.
Several computational problems, such as computing marginals and partition
functions, arise naturally when working with factor graphs. Belief propagation
is a widely deployed iterative method for solving these problems. However,
despite its significant empirical success, not much is known about the
correctness and efficiency of belief propagation.
  Bethe approximation is an optimization-based framework for approximating
partition functions. While it is known that the stationary points of the Bethe
approximation coincide with the fixed points of belief propagation, in general,
the relation between the Bethe approximation and the partition function is not
well understood. It has been observed that for a few classes of factor graphs,
the Bethe approximation always gives a lower bound to the partition function,
which distinguishes them from the general case, where neither a lower bound,
nor an upper bound holds universally. This has been rigorously proved for
permanents and for attractive graphical models.
  Here we consider bipartite normal factor graphs and show that if the local
constraints satisfy a certain analytic property, the Bethe approximation is a
lower bound to the partition function. We arrive at this result by viewing
factor graphs through the lens of polynomials. In this process, we reformulate
the Bethe approximation as a polynomial optimization problem. Our sufficient
condition for the lower bound property to hold is inspired by recent
developments in the theory of real stable polynomials. We believe that this way
of viewing factor graphs and its connection to real stability might lead to a
better understanding of belief propagation and factor graphs in general.


Multiwinner Voting with Fairness Constraints

  Multiwinner voting rules are used to select a small representative subset of
candidates or items from a larger set given the preferences of voters. However,
if candidates have sensitive attributes such as gender or ethnicity (when
selecting a committee), or specified types such as political leaning (when
selecting a subset of news items), an algorithm that chooses a subset by
optimizing a multiwinner voting rule may be unbalanced in its selection -- it
may under or over represent a particular gender or political orientation in the
examples above. We introduce an algorithmic framework for multiwinner voting
problems when there is an additional requirement that the selected subset
should be "fair" with respect to a given set of attributes. Our framework
provides the flexibility to (1) specify fairness with respect to multiple,
non-disjoint attributes (e.g., ethnicity and gender) and (2) specify a score
function. We study the computational complexity of this constrained multiwinner
voting problem for monotone and submodular score functions and present several
approximation algorithms and matching hardness of approximation results for
various attribute group structure and types of score functions. We also present
simulations that suggest that adding fairness constraints may not affect the
scores significantly when compared to the unconstrained case.


Convex Optimization with Unbounded Nonconvex Oracles using Simulated
  Annealing

  We consider the problem of minimizing a convex objective function $F$ when
one can only evaluate its noisy approximation $\hat{F}$. Unless one assumes
some structure on the noise, $\hat{F}$ may be an arbitrary nonconvex function,
making the task of minimizing $F$ intractable. To overcome this, prior work has
often focused on the case when $F(x)-\hat{F}(x)$ is uniformly-bounded. In this
paper we study the more general case when the noise has magnitude $\alpha F(x)
+ \beta$ for some $\alpha, \beta > 0$, and present a polynomial time algorithm
that finds an approximate minimizer of $F$ for this noise model. Previously,
Markov chains, such as the stochastic gradient Langevin dynamics, have been
used to arrive at approximate solutions to these optimization problems.
However, for the noise model considered in this paper, no single temperature
allows such a Markov chain to both mix quickly and concentrate near the global
minimizer. We bypass this by combining "simulated annealing" with the
stochastic gradient Langevin dynamics, and gradually decreasing the temperature
of the chain in order to approach the global minimizer. As a corollary one can
approximately minimize a nonconvex function that is close to a convex function;
however, the closeness can deteriorate as one moves away from the optimum.


Fair and Diverse DPP-based Data Summarization

  Sampling methods that choose a subset of the data proportional to its
diversity in the feature space are popular for data summarization. However,
recent studies have noted the occurrence of bias (under- or over-representation
of a certain gender or race) in such data summarization methods. In this paper
we initiate a study of the problem of outputting a diverse and fair summary of
a given dataset. We work with a well-studied determinantal measure of diversity
and corresponding distributions (DPPs) and present a framework that allows us
to incorporate a general class of fairness constraints into such distributions.
Coming up with efficient algorithms to sample from these constrained
determinantal distributions, however, suffers from a complexity barrier and we
present a fast sampler that is provably good when the input vectors satisfy a
natural property. Our experimental results on a real-world and an image dataset
show that the diversity of the samples produced by adding fairness constraints
is not too far from the unconstrained case, and we also provide a theoretical
explanation of it.


An Algorithmic Framework to Control Bias in Bandit-based Personalization

  Personalization is pervasive in the online space as it leads to higher
efficiency and revenue by allowing the most relevant content to be served to
each user. However, recent studies suggest that personalization methods can
propagate societal or systemic biases and polarize opinions; this has led to
calls for regulatory mechanisms and algorithms to combat bias and inequality.
Algorithmically, bandit optimization has enjoyed great success in learning user
preferences and personalizing content or feeds accordingly. We propose an
algorithmic framework that allows for the possibility to control bias or
discrimination in such bandit-based personalization. Our model allows for the
specification of general fairness constraints on the sensitive types of the
content that can be displayed to a user. The challenge, however, is to come up
with a scalable and low regret algorithm for the constrained optimization
problem that arises. Our main technical contribution is a provably fast and
low-regret algorithm for the fairness-constrained bandit optimization problem.
Our proofs crucially leverage the special structure of our problem. Experiments
on synthetic and real-world data sets show that our algorithmic framework can
control bias with only a minor loss to revenue.


Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo

  Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from
high-dimensional distributions in Statistics and Machine learning. HMC is known
to run very efficiently in practice and its popular second-order "leapfrog"
implementation has long been conjectured to run in $d^{1/4}$ gradient
evaluations. Here we show that this conjecture is true when sampling from
strongly log-concave target distributions that satisfy a weak third-order
regularity property associated with the input data. Our regularity condition is
weaker than the Lipschitz Hessian property and allows us to show faster
convergence bounds for a much larger class of distributions than would be
possible with the usual Lipschitz Hessian constant alone. Important
distributions that satisfy our regularity condition include posterior
distributions used in Bayesian logistic regression for which the data satisfies
an "incoherence" property. Our result compares favorably with the best
available bounds for the class of strongly log-concave distributions, which
grow like $d^{{1}/{2}}$ gradient evaluations with the dimension. Moreover, our
simulations on synthetic data suggest that, when our regularity condition is
satisfied, leapfrog HMC performs better than its competitors -- both in terms
of accuracy and in terms of the number of gradient evaluations it requires.


Classification with Fairness Constraints: A Meta-Algorithm with Provable
  Guarantees

  Developing classification algorithms that are fair with respect to sensitive
attributes of the data has become an important problem due to the growing
deployment of classification algorithms in various social contexts. Several
recent works have focused on fairness with respect to a specific metric,
modeled the corresponding fair classification problem as a constrained
optimization problem, and developed tailored algorithms to solve them. Despite
this, there still remain important metrics for which we do not have fair
classifiers and many of the aforementioned algorithms do not come with
theoretical guarantees; perhaps because the resulting optimization problem is
non-convex. The main contribution of this paper is a new meta-algorithm for
classification that takes as input a large class of fairness constraints, with
respect to multiple non-disjoint sensitive attributes, and which comes with
provable guarantees. This is achieved by first developing a meta-algorithm for
a large family of classification problems with convex constraints, and then
showing that classification problems with general types of fairness constraints
can be reduced to those in this family. We present empirical results that show
that our algorithm can achieve near-perfect fairness with respect to various
fairness metrics, and that the loss in accuracy due to the imposed fairness
constraints is often small. Overall, this work unifies several prior works on
fair classification, presents a practical algorithm with theoretical
guarantees, and can handle fairness metrics that were previously not possible.


Dynamic Sampling from Graphical Models

  In this paper, we study the problem of sampling from a graphical model when
the model itself is changing dynamically with time. This problem derives its
interest from a variety of inference, learning, and sampling settings in
machine learning, computer vision, statistical physics, and theoretical
computer science. While the problem of sampling from a static graphical model
has received considerable attention, theoretical works for its dynamic variants
have been largely lacking. The main contribution of this paper is an algorithm
that can sample dynamically from a broad class of graphical models over
discrete random variables. Our algorithm is parallel and Las Vegas: it knows
when to stop and it outputs samples from the exact distribution. We also
provide sufficient conditions under which this algorithm runs in time
proportional to the size of the update, on general graphical models as well as
well-studied specific spin systems. In particular we obtain, for the Ising
model (ferromagnetic or anti-ferromagnetic) and for the hardcore model the
first dynamic sampling algorithms that can handle both edge and vertex updates
(addition, deletion, change of functions), both efficient within regimes that
are close to the respective uniqueness regimes, beyond which, even for the
static and approximate sampling, no local algorithms were known or the problem
itself is intractable. Our dynamic sampling algorithm relies on a local
resampling algorithm and a new "equilibrium" property that is shown to be
satisfied by our algorithm at each step, and enables us to prove its
correctness. This equilibrium property is robust enough to guarantee the
correctness of our algorithm, helps us improve bounds on fast convergence on
specific models, and should be of independent interest.


Stable and Fair Classification

  Fair classification has been a topic of intense study in machine learning,
and several algorithms have been proposed towards this important task. However,
in a recent study, Friedler et al. observed that fair classification algorithms
may not be stable with respect to variations in the training dataset -- a
crucial consideration in several real-world applications. Motivated by their
work, we study the problem of designing classification algorithms that are both
fair and stable. We propose an extended framework based on fair classification
algorithms that are formulated as optimization problems, by introducing a
stability-focused regularization term. Theoretically, we prove a stability
guarantee, that was lacking in fair classification algorithms, and also provide
an accuracy guarantee for our extended framework. Our accuracy guarantee can be
used to inform the selection of the regularization parameter in our framework.
To the best of our knowledge, this is the first work that combines stability
and fairness in automated decision-making tasks. We assess the benefits of our
approach empirically by extending several fair classification algorithms that
are shown to achieve the best balance between fairness and accuracy over the
Adult dataset. Our empirical results show that our framework indeed improves
the stability at only a slight sacrifice in accuracy.


Ranking with Fairness Constraints

  Ranking algorithms are deployed widely to order a set of items in
applications such as search engines, news feeds, and recommendation systems.
Recent studies, however, have shown that, left unchecked, the output of ranking
algorithms can result in decreased diversity in the type of content presented,
promote stereotypes, and polarize opinions. In order to address such issues, we
study the following variant of the traditional ranking problem when, in
addition, there are fairness or diversity constraints. Given a collection of
items along with 1) the value of placing an item in a particular position in
the ranking, 2) the collection of sensitive attributes (such as gender, race,
political opinion) of each item and 3) a collection of constraints that, for
each k, bound the number of items with each attribute that are allowed to
appear in the top k positions of the ranking, the goal is to output a ranking
that maximizes the value with respect to the original rank quality metric while
respecting the constraints. This problem encapsulates various well-studied
problems related to bipartite and hypergraph matching as special cases and
turns out to be hard to approximate even with simple constraints. Our main
technical contributions are fast exact and approximation algorithms along with
complementary hardness results that, together, come close to settling the
approximability of this constrained ranking maximization problem. Unlike prior
work on the constrained matching problems, our algorithm runs in linear time,
even when the number of constraints is large, its approximation ratio does not
depend on the number of constraints, and it produces solutions with small
constraint violations. Our results rely on insights about the constrained
matching problem when the objective satisfies properties that appear in common
ranking metrics such as Discounted Cumulative Gain, Spearman's rho or
Bradley-Terry.


A Local Spectral Method for Graphs: with Applications to Improving Graph
  Partitions and Exploring Data Graphs Locally

  The second eigenvalue of the Laplacian matrix and its associated eigenvector
are fundamental features of an undirected graph, and as such they have found
widespread use in scientific computing, machine learning, and data analysis. In
many applications, however, graphs that arise have several \emph{local} regions
of interest, and the second eigenvector will typically fail to provide
information fine-tuned to each local region. In this paper, we introduce a
locally-biased analogue of the second eigenvector, and we demonstrate its
usefulness at highlighting local properties of data graphs in a semi-supervised
manner. To do so, we first view the second eigenvector as the solution to a
constrained optimization problem, and we incorporate the local information as
an additional constraint; we then characterize the optimal solution to this new
problem and show that it can be interpreted as a generalization of a
Personalized PageRank vector; and finally, as a consequence, we show that the
solution can be computed in nearly-linear time. In addition, we show that this
locally-biased vector can be used to compute an approximation to the best
partition \emph{near} an input seed set in a manner analogous to the way in
which the second eigenvector of the Laplacian can be used to obtain an
approximation to the best partition in the entire input graph. Such a primitive
is useful for identifying and refining clusters locally, as it allows us to
focus on a local region of interest in a semi-supervised manner. Finally, we
provide a detailed empirical evaluation of our method by showing how it can
applied to finding locally-biased sparse cuts around an input vertex seed set
in social and information networks.


Approximating the Exponential, the Lanczos Method and an
  \tilde{O}(m)-Time Spectral Algorithm for Balanced Separator

  We give a novel spectral approximation algorithm for the balanced separator
problem that, given a graph G, a constant balance b \in (0,1/2], and a
parameter \gamma, either finds an \Omega(b)-balanced cut of conductance
O(\sqrt(\gamma)) in G, or outputs a certificate that all b-balanced cuts in G
have conductance at least \gamma, and runs in time \tilde{O}(m). This settles
the question of designing asymptotically optimal spectral algorithms for
balanced separator. Our algorithm relies on a variant of the heat kernel random
walk and requires, as a subroutine, an algorithm to compute \exp(-L)v where L
is the Laplacian of a graph related to G and v is a vector. Algorithms for
computing the matrix-exponential-vector product efficiently comprise our next
set of results. Our main result here is a new algorithm which computes a good
approximation to \exp(-A)v for a class of PSD matrices A and a given vector u,
in time roughly \tilde{O}(m_A), where m_A is the number of non-zero entries of
A. This uses, in a non-trivial way, the result of Spielman and Teng on
inverting SDD matrices in \tilde{O}(m_A) time. Finally, we prove e^{-x} can be
uniformly approximated up to a small additive error, in a non-negative interval
[a,b] with a polynomial of degree roughly \sqrt{b-a}. While this result is of
independent interest in approximation theory, we show that, via the Lanczos
method from numerical analysis, it yields a simple algorithm to compute
\exp(-A)v for PSD matrices that runs in time roughly O(t_A \sqrt{||A||}), where
t_A is the time required for computation of the vector Aw for given vector w.
As an application, we obtain a simple and practical algorithm, with output
conductance O(\sqrt(\gamma)), for balanced separator that runs in time
\tilde{O}(m/\sqrt(\gamma)). This latter algorithm matches the running time, but
improves on the approximation guarantee of the algorithm by Andersen and Peres.


On the Complexity of Constrained Determinantal Point Processes

  Determinantal Point Processes (DPPs) are probabilistic models that arise in
quantum physics and random matrix theory and have recently found numerous
applications in computer science. DPPs define distributions over subsets of a
given ground set, they exhibit interesting properties such as negative
correlation, and, unlike other models, have efficient algorithms for sampling.
When applied to kernel methods in machine learning, DPPs favor subsets of the
given data with more diverse features. However, many real-world applications
require efficient algorithms to sample from DPPs with additional constraints on
the subset, e.g., partition or matroid constraints that are important to ensure
priors, resource or fairness constraints on the sampled subset. Whether one can
efficiently sample from DPPs in such constrained settings is an important
problem that was first raised in a survey of DPPs by \cite{KuleszaTaskar12} and
studied in some recent works in the machine learning literature.
  The main contribution of our paper is the first resolution of the complexity
of sampling from DPPs with constraints. We give exact efficient algorithms for
sampling from constrained DPPs when their description is in unary. Furthermore,
we prove that when the constraints are specified in binary, this problem is
#P-hard via a reduction from the problem of computing mixed discriminants
implying that it may be unlikely that there is an FPRAS. Our results benefit
from viewing the constrained sampling problem via the lens of polynomials.
Consequently, we obtain a few algorithms of independent interest: 1) to count
over the base polytope of regular matroids when there are additional (succinct)
budget constraints and, 2) to evaluate and compute the mixed characteristic
polynomials, that played a central role in the resolution of the Kadison-Singer
problem, for certain special cases.


Real Stable Polynomials and Matroids: Optimization and Counting

  A great variety of fundamental optimization and counting problems arising in
computer science, mathematics and physics can be reduced to one of the
following computational tasks involving polynomials and set systems: given an
$m$-variate real polynomial $g$ and a family of subsets $B$ of $[m]$, (1) find
$S\in B$ such that the monomial in $g$ corresponding to $S$ has the largest
coefficient in $g$, or (2) compute the sum of coefficients of monomials in $g$
corresponding to all the sets in $B$. Special cases of these problems, such as
computing permanents, sampling from DPPs and maximizing subdeterminants have
been topics of recent interest in theoretical computer science.
  In this paper we present a general convex programming framework geared to
solve both of these problems. We show that roughly, when $g$ is a real stable
polynomial with non-negative coefficients and $B$ is a matroid, the integrality
gap of our relaxation is finite and depends only on $m$ (and not on the
coefficients of g).
  Prior to our work, such results were known only in sporadic cases that relied
on the structure of $g$ and $B$; it was not even clear if one could formulate a
convex relaxation that has a finite integrality gap beyond these special cases.
Two notable examples are a result by Gurvits on the van der Waerden conjecture
for real stable $g$ when $B$ is a single element and a result by Nikolov and
Singh for multilinear real stable polynomials when $B$ is a partition matroid.
Our work, which encapsulates most interesting cases of $g$ and $B$, benefits
from both - we were inspired by the latter in deriving the right convex
programming relaxation and the former in establishing the integrality gap.
However, proving our results requires significant extensions of both; in that
process we come up with new notions and connections between stable polynomials
and matroids which should be of independent interest.


Computing Maximum Entropy Distributions Everywhere

  We study the problem of computing the maximum entropy distribution with a
specified expectation over a large discrete domain. Maximum entropy
distributions arise and have found numerous applications in economics, machine
learning and various sub-disciplines of mathematics and computer science. The
key computational questions related to maximum entropy distributions are
whether they have succinct descriptions and whether they can be efficiently
computed. Here we provide positive answers to both of these questions for very
general domains and, importantly, with no restriction on the expectation. This
completes the picture left open by the prior work on this problem which
requires that the expectation vector is polynomially far in the interior of the
convex hull of the domain. As a consequence we obtain a general algorithmic
tool and show how it can be applied to derive several old and new results in a
unified manner. In particular, our results imply that certain recent continuous
optimization formulations, for instance, for discrete counting and optimization
problems, the matrix scaling problem, and the worst case Brascamp-Lieb
constants in the rank-1 regime, are efficiently computable. Attaining these
implications requires reformulating the underlying problem as a version of
maximum entropy computation where optimization also involves the expectation
vector and, hence, cannot be assumed to be sufficiently deep in the interior.
The key new technical ingredient in our work is a polynomial bound on the bit
complexity of near-optimal dual solutions to the maximum entropy convex
program. This result is obtained by a geometrical reasoning that involves
convex analysis and polyhedral geometry, avoiding combinatorial arguments based
on the specific structure of the domain. We also provide a lower bound on the
bit complexity of near-optimal solutions showing the tightness of our results.


Online Sampling from Log-Concave Distributions

  Given a sequence of convex functions $f_0, f_1, \ldots, f_T$, we study the
problem of sampling from the Gibbs distribution $\pi_t \propto e^{-\sum_{k=0}^t
f_k}$ for each epoch $t$ in an online manner. This problem occurs in
applications to machine learning, Bayesian statistics, and optimization where
one constantly acquires new data, and must continuously update the
distribution. Our main result is an algorithm that generates independent
samples from a distribution that is a fixed $\varepsilon$ TV-distance from
$\pi_t$ for every $t$ and, under mild assumptions on the functions, makes
poly$\log(T)$ gradient evaluations per epoch. All previous results for this
problem imply a bound on the number of gradient or function evaluations which
is at least linear in $T$. While we assume the functions have bounded second
moment, we do not assume strong convexity. In particular, we show that our
assumptions hold for online Bayesian logistic regression, when the data satisfy
natural regularity properties. In simulations, our algorithm achieves accuracy
comparable to that of a Markov chain specialized to logistic regression. Our
main result also implies the first algorithm to sample from a $d$-dimensional
log-concave distribution $\pi_T \propto e^{-\sum_{k=0}^T f_k}$ where the
$f_k$'s are not assumed to be strongly convex and the total number of gradient
evaluations is roughly $T\log(T)+\mathrm{poly}(d),$ as opposed to $T\cdot
\mathrm{poly}(d)$ implied by prior works. Key to our algorithm is a novel
stochastic gradient Langevin dynamics Markov chain that has a carefully
designed variance reduction step built-in with fixed constant batch size.
Technically, lack of strong convexity is a significant barrier to the analysis,
and, here, our main contribution is a martingale exit time argument showing the
chain is constrained to a ball of radius roughly poly$\log(T)$ for the duration
of the algorithm.


Nonconvex sampling with the Metropolis-adjusted Langevin algorithm

  The Langevin Markov chain algorithms are widely deployed methods to sample
from distributions in challenging high-dimensional and non-convex statistics
and machine learning applications. Despite this, current bounds for the
Langevin algorithms are slower than those of competing algorithms in many
important situations, for instance when sampling from weakly log-concave
distributions, or when sampling or optimizing non-convex log-densities. In this
paper, we obtain improved bounds in many of these situations, showing that the
Metropolis-adjusted Langevin algorithm (MALA) is faster than the best bounds
for its competitor algorithms when the target distribution satisfies weak
third- and fourth- order regularity properties associated with the input data.
In many settings, our regularity conditions are weaker than the usual Euclidean
operator norm regularity properties, allowing us to show faster bounds for a
much larger class of distributions than would be possible with the usual
Euclidean operator norm approach, including in statistics and machine learning
applications where the data satisfy a certain incoherence condition. In
particular, we show that using our regularity conditions one can obtain faster
bounds for applications which include sampling problems in Bayesian logistic
regression with weakly convex priors, and the nonconvex optimization problem of
learning linear classifiers with zero-one loss functions.
  Our main technical contribution in this paper is our analysis of the
Metropolis acceptance probability of MALA in terms of its "energy-conservation
error," and our bound for this error in terms of third- and fourth- order
regularity conditions. Our combination of this higher-order analysis of the
energy conservation error with the conductance method is key to obtaining
bounds which have a sub-linear dependence on the dimension $d$ in the
non-strongly logconcave setting.


