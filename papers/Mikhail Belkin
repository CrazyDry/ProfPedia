Does data interpolation contradict statistical optimality?

  We show that learning methods interpolating the training data can achieveoptimal rates for the problems of nonparametric regression and prediction withsquare loss.

Temperature performance analysis of terahertz quantum cascade lasers:  Vertical versus diagonal designs

  Resonant phonon depopulation terahertz quantum cascade lasers based onvertical and diagonal lasing transitions are systematically compared using awell established ensemble Monte Carlo approach. The analysis shows that foroperating temperatures below 200 K, diagonal designs may offer superiortemperature performance at lasing frequencies of about 3.5 THz and above;however, vertical structures are more advantageous for good temperatureperformance at lower frequencies.

Probabilistic Zero-shot Classification with Semantic Rankings

  In this paper we propose a non-metric ranking-based representation ofsemantic similarity that allows natural aggregation of semantic informationfrom multiple heterogeneous sources. We apply the ranking-based representationto zero-shot learning problems, and present deterministic and probabilisticzero-shot classifiers which can be built from pre-trained classifiers withoutretraining. We demonstrate their the advantages on two large real-world imagedatasets. In particular, we show that aggregating different sources of semanticinformation, including crowd-sourcing, leads to more accurate classification.

Gradient Nonlinear Pancharatnam-Berry Metasurfaces

  We apply the Pancharatnam-Berry phase approach to plasmonic metasurfacesloaded by highly nonlinear multi-quantum well substrates, establishing aplatform to control the nonlinear wavefront at will based on giant localizednonlinear effects. We apply this approach to design flat nonlinear metasurfacesfor efficient second-harmonic radiation, including beam steering, focusing, andpolarization manipulation. Our findings open a new direction for nonlinearoptics, in which phase matching issues are relaxed, and an unprecedented levelof local wavefront control is achieved over thin devices with giant nonlinearresponses.

Parametrized Accelerated Methods Free of Condition Number

  Analyses of accelerated (momentum-based) gradient descent usually assumebounded condition number to obtain exponential convergence rates. However, inmany real problems, e.g., kernel methods or deep neural networks, the conditionnumber, even locally, can be unbounded, unknown or mis-estimated. This posesproblems in both implementing and analyzing accelerated algorithms. In thispaper, we address this issue by proposing parametrized accelerated methods byconsidering the condition number as a free parameter. We provide spectral-levelanalysis for several important accelerated algorithms, obtain explicitexpressions and improve worst case convergence rates. Moreover, we show thatthose algorithm converge exponentially even when the condition number isunknown or mis-estimated.

Two models of double descent for weak features

  The "double descent" risk curve was recently proposed to qualitativelydescribe the out-of-sample prediction accuracy of variably-parameterizedmachine learning models. This article provides a precise mathematical analysisfor the shape of this curve in two simple data models with the leastsquares/least norm predictor. Specifically, it is shown that the risk peakswhen the number of features $p$ is close to the sample size $n$, but also thatthe risk decreases towards its minimum as $p$ increases beyond $n$. Thisbehavior is contrasted with that of "prescient" models that select features inan a priori optimal order.

Approximation beats concentration? An approximation view on inference  with smooth radial kernels

  Positive definite kernels and their associated Reproducing Kernel HilbertSpaces provide a mathematically compelling and practically competitiveframework for learning from data.  In this paper we take the approximation theory point of view to explorevarious aspects of smooth kernels related to their inferential properties. Weanalyze eigenvalue decay of kernels operators and matrices, properties ofeigenfunctions/eigenvectors and "Fourier" coefficients of functions in thekernel space restricted to a discrete set of data points. We also investigatethe fitting capacity of kernels, giving explicit bounds on the fat shatteringdimension of the balls in Reproducing Kernel Hilbert spaces. Interestingly, thesame properties that make kernels very effective approximators for functions intheir "native" kernel space, also limit their capacity to represent arbitraryfunctions. We discuss various implications, including those for gradientdescent type methods.  It is important to note that most of our bounds are measure independent.Moreover, at least in moderate dimension, the bounds for eigenvalues are muchtighter than the bounds which can be obtained from the usual matrixconcentration results. For example, we see that the eigenvalues of kernelmatrices show nearly exponential decay with constants depending only on thekernel and the domain. We call this "approximation beats concentration"phenomenon as even when the data are sampled from a probability distribution,some of their aspects are better understood in terms of approximation theory.

Enhancement of the spontaneous emission in subwavelength  quasi-two-dimensional waveguides and resonators

  We consider a quantum-electrodynamic problem of the spontaneous emission froma two-dimensional (2D) emitter, such as a quantum well or a 2D semiconductor,placed in a quasi-2D waveguide or cavity with subwavelength confinement in onedirection. We apply the Heisenberg-Langevin approach which includes dissipationand fluctuations in the electron ensemble and in the electromagnetic field of acavity on equal footing. The Langevin noise operators that we introduce do notdepend on any particular model of dissipative reservoir and can be applied toany dissipation mechanism. Moreover, our approach is applicable tononequilibrium electron systems, e.g. in the presence of pumping, beyond theapplicability of the standard fluctuation-dissipation theorem. We deriveanalytic results for simple but practically important geometries: strip linesand rectangular cavities. Our results show that a significant enhancement ofthe spontaneous emission, by a factor of order 100 or higher, is possible forquantum wells and other 2D emitters in a subwavelength cavity.

Using eigenvectors of the bigram graph to infer morpheme identity

  This paper describes the results of some experiments exploring statisticalmethods to infer syntactic behavior of words and morphemes from a raw corpus inan unsupervised fashion. It shares certain points in common with Brown et al(1992) and work that has grown out of that: it employs statistical techniquesto analyze syntactic behavior based on what words occur adjacent to a givenword. However, we use an eigenvector decomposition of a nearest-neighbor graphto produce a two-dimensional rendering of the words of a corpus in which wordsof the same syntactic category tend to form neighborhoods. We exploit thistechnique for extending the value of automatic learning of morphology. Inparticular, we look at the suffixes derived from a corpus by unsupervisedlearning of morphology, and we ask which of these suffixes have a consistentsyntactic function (e.g., in English, -tion is primarily a mark of nouns, but-s marks both noun plurals and 3rd person present on verbs), and we determinethat this method works well for this task.

Consistency of spectral clustering

  Consistency is a key property of all statistical procedures analyzingrandomly sampled data. Surprisingly, despite decades of work, little is knownabout consistency of most clustering algorithms. In this paper we investigateconsistency of the popular family of spectral clustering algorithms, whichclusters the data with the help of eigenvectors of graph Laplacian matrices. Wedevelop new methods to establish that, for increasing sample size, thoseeigenvectors converge to the eigenvectors of certain limit operators. As aresult, we can prove that one of the two major classes of spectral clustering(normalized clustering) converges under very general conditions, while theother (unnormalized clustering) is only consistent under strong additionalassumptions, which are not always satisfied in real data. We conclude that ouranalysis provides strong evidence for the superiority of normalized spectralclustering.

Polynomial Learning of Distribution Families

  The question of polynomial learnability of probability distributions,particularly Gaussian mixture distributions, has recently received significantattention in theoretical computer science and machine learning. However,despite major progress, the general question of polynomial learnability ofGaussian mixture distributions still remained open. The current work resolvesthe question of polynomial learnability for Gaussian mixtures in high dimensionwith an arbitrary fixed number of components. The result on learning Gaussianmixtures relies on an analysis of distributions belonging to what we call"polynomial families" in low dimension. These families are characterized bytheir moments being polynomial in parameters and include almost all commonprobability distributions as well as their mixtures and products. Using toolsfrom real algebraic geometry, we show that parameters of any distributionbelonging to such a family can be learned in polynomial time and using apolynomial number of sample points. The result on learning polynomial familiesis quite general and is of independent interest. To estimate parameters of aGaussian mixture distribution in high dimensions, we provide a deterministicalgorithm for dimensionality reduction. This allows us to reduce learning ahigh-dimensional mixture to a polynomial number of parameter estimations in lowdimension. Combining this reduction with the results on polynomial familiesyields our result on learning arbitrary Gaussian mixtures in high dimensions.

Behavior of Graph Laplacians on Manifolds with Boundary

  In manifold learning, algorithms based on graph Laplacians constructed fromdata have received considerable attention both in practical applications andtheoretical analysis. In particular, the convergence of graph Laplaciansobtained from sampled data to certain continuous operators has become an activeresearch topic recently. Most of the existing work has been done under theassumption that the data is sampled from a manifold without boundary or thatthe functions of interests are evaluated at a point away from the boundary.However, the question of boundary behavior is of considerable practical andtheoretical interest. In this paper we provide an analysis of the behavior ofgraph Laplacians at a point near or on the boundary, discuss their convergencerates and their implications and provide some numerical results. It turns outthat while points near the boundary occupy only a small part of the totalvolume of a manifold, the behavior of graph Laplacian there has differentscaling properties from its behavior elsewhere on the manifold, with globaleffects on the whole manifold, an observation with potentially importantimplications for the general problem of learning on manifolds.

The Hidden Convexity of Spectral Clustering

  In recent years, spectral clustering has become a standard method for dataanalysis used in a broad range of applications. In this paper we propose a newclass of algorithms for multiway spectral clustering based on optimization of acertain "contrast function" over the unit sphere. These algorithms, partlyinspired by certain Independent Component Analysis techniques, are simple, easyto implement and efficient.  Geometrically, the proposed algorithms can be interpreted as hidden basisrecovery by means of function optimization. We give a complete characterizationof the contrast functions admissible for provable basis recovery. We show howthese conditions can be interpreted as a "hidden convexity" of our optimizationproblem on the sphere; interestingly, we use efficient convex maximizationrather than the more common convex minimization. We also show encouragingexperimental results on real and simulated data.

Crowd-ML: A Privacy-Preserving Learning Framework for a Crowd of Smart  Devices

  Smart devices with built-in sensors, computational capabilities, and networkconnectivity have become increasingly pervasive. The crowds of smart devicesoffer opportunities to collectively sense and perform computing tasks in anunprecedented scale. This paper presents Crowd-ML, a privacy-preserving machinelearning framework for a crowd of smart devices, which can solve a wide rangeof learning problems for crowdsensing data with differential privacyguarantees. Crowd-ML endows a crowdsensing system with an ability to learnclassifiers or predictors online from crowdsensing data privately with minimalcomputational overheads on devices and servers, suitable for a practical andlarge-scale employment of the framework. We analyze the performance and thescalability of Crowd-ML, and implement the system with off-the-shelfsmartphones as a proof of concept. We demonstrate the advantages of Crowd-MLwith real and simulated experiments under various conditions.

Learning Privately from Multiparty Data

  Learning a classifier from private data collected by multiple parties is animportant problem that has many potential applications. How can we build anaccurate and differentially private global classifier by combininglocally-trained classifiers from different parties, without access to anyparty's private data? We propose to transfer the `knowledge' of the localclassifier ensemble by first creating labeled data from auxiliary unlabeleddata, and then train a global $\epsilon$-differentially private classifier. Weshow that majority voting is too sensitive and therefore propose a new riskweighted by class probabilities estimated from the ensemble. Relative to anon-private solution, our private solution has a generalization error boundedby $O(\epsilon^{-2}M^{-2})$ where $M$ is the number of parties. This allowsstrong privacy without performance loss when $M$ is large, such as incrowdsensing applications. We demonstrate the performance of our method withrealistic tasks of activity recognition, network intrusion detection, andmalicious URL detection.

Graphons, mergeons, and so on!

  In this work we develop a theory of hierarchical clustering for graphs. Ourmodeling assumption is that graphs are sampled from a graphon, which is apowerful and general model for generating graphs and analyzing large networks.Graphons are a far richer class of graph models than stochastic blockmodels,the primary setting for recent progress in the statistical theory of graphclustering. We define what it means for an algorithm to produce the "correct"clustering, give sufficient conditions in which a method is statisticallyconsistent, and provide an explicit algorithm satisfying these properties.

Electrical Tuning of Polarizaion-state Using Graphene-Integrated  Metasurfaces

  Plasmonic metasurfaces have been employed for tuning and controlling lightenabling various novel applications. Their appeal is enhanced with theincorporation of an active element with the metasurfaces paving the way fordynamic control. In this letter, we realize a dynamic polarization stategenerator using graphene-integrated anisotropic metasurface (GIAM), where alinear incidence polarization is controllably converted into an elliptical one.The anisotropic metasurface leads to an intrinsic polarization conversion whenilluminated with non-orthogonal incident polarization. Additionally, thesingle-layer graphene allows us to tune the phase and intensity of thereflected light on the application of a gate voltage, enabling dynamicpolarization control. The stokes polarization parameters of the reflected lightare measured using rotating polarizer method and it is demonstrated that alarge change in the ellipticity as well as orientation angle can be induced bythis device. We also provide experimental evidence that the titl angle canchange independent of the ellipticity going from positive values to nearly zeroto negative values while ellipticity is constant.

Unperturbed: spectral analysis beyond Davis-Kahan

  Classical matrix perturbation results, such as Weyl's theorem for eigenvaluesand the Davis-Kahan theorem for eigenvectors, are general purpose. Theseclassical bounds are tight in the worst case, but in many settings sub-optimalin the typical case. In this paper, we present perturbation bounds whichconsider the nature of the perturbation and its interaction with theunperturbed structure in order to obtain significant improvements over theclassical theory in many scenarios, such as when the perturbation is random. Wedemonstrate the utility of these new results by analyzing perturbations in thestochastic blockmodel where we derive much tighter bounds than provided by theclassical theory. We use our new perturbation theory to show that a very simpleand natural clustering algorithm -- whose analysis was difficult using theclassical tools -- nevertheless recovers the communities of the blockmodelexactly even in very sparse graphs.

Memorization in Overparameterized Autoencoders

  Memorization of data in deep neural networks has become a subject ofsignificant research interest. We prove that over-parameterized single layerfully connected autoencoders memorize training data: they produce outputs in (anon-linear version of) the span of the training examples. In contrast to fullyconnected autoencoders, we prove that depth is necessary for memorization inconvolutional autoencoders. Moreover, we observe that adding nonlinearity todeep convolutional autoencoders results in a stronger form of memorization:instead of outputting points in the span of the training images, deepconvolutional autoencoders tend to output individual training images. Sinceconvolutional autoencoder components are building blocks of deep convolutionalnetworks, we envision that our findings will shed light on the importantphenomenon of memorization in over-parameterized deep networks.

Accelerating Stochastic Training for Over-parametrized Learning

  We introduce MaSS (Momentum-added Stochastic Solver), an accelerated SGDmethod for optimizing over-parametrized models. Our method is simple andefficient to implement and does not require adapting hyper-parameters orcomputing full gradients in the course of optimization.  Experimental evaluation of MaSS for several standard architectures of deepnetworks, including ResNet and convolutional networks, shows improvedperformance over Adam and SGD both in optimization and generalization.  We prove accelerated convergence of MaSS over SGD and provide analysis forhyper-parameter selection in the quadratic case as well as some results ingeneral strongly convex setting. In contrast, we show theoretically and verifyempirically that the standard SGD+Nesterov can diverge for common choices ofhyper-parameter values.  We also analyze the practically important question of the dependence of theconvergence rate and optimal hyper-parameters as functions of the mini-batchsize, demonstrating three distinct regimes: linear scaling, diminishing returnsand saturation.

Kernel Machines Beat Deep Neural Networks on Mask-based Single-channel  Speech Enhancement

  We apply a fast kernel method for mask-based single-channel speechenhancement. Specifically, our method solves a kernel regression problemassociated to a non-smooth kernel function (exponential power kernel) with ahighly efficient iterative method (EigenPro). Due to the simplicity of thismethod, its hyper-parameters such as kernel bandwidth can be automatically andefficiently selected using line search with subsamples of training data. Weobserve an empirical correlation between the regression loss (mean squareerror) and regular metrics for speech enhancement. This observation justifiesour training target and motivates us to achieve lower regression loss bytraining separate kernel model per frequency subband. We compare our methodwith the state-of-the-art deep neural networks on mask-based HINT and TIMIT.Experimental results show that our kernel method consistently outperforms deepneural networks while requiring less training time.

On exponential convergence of SGD in non-convex over-parametrized  learning

  Large over-parametrized models learned via stochastic gradient descent (SGD)methods have become a key element in modern machine learning. Although SGDmethods are very effective in practice, most theoretical analyses of SGDsuggest slower convergence than what is empirically observed. In our recentwork [8] we analyzed how interpolation, common in modern over-parametrizedlearning, results in exponential convergence of SGD with constant step size forconvex loss functions. In this note, we extend those results to a much broadernon-convex function class satisfying the Polyak-Lojasiewicz (PL) condition. Anumber of important non-convex problems in machine learning, including someclasses of neural networks, have been recently shown to satisfy the PLcondition. We argue that the PL condition provides a relevant and attractivesetting for many machine learning problems, particularly in theover-parametrized regime.

Purcell enhancement of the parametric down-conversion in two-dimensional  nonlinear materials

  Ultracompact nonlinear optical devices utilizing two-dimensional (2D)materials and nanostructures are emerging as important elements of photoniccircuits. Integration of the nonlinear material into a subwavelength cavity orwaveguide leads to a strong Purcell enhancement of the nonlinear processes andcompensates for a small interaction volume. The generic feature of such deviceswhich makes them especially challenging for analysis is strong dissipation ofboth the nonlinear polarization and highly confined modes of a subwavelengthcavity. Here we solve a quantum-electrodynamic problem of the spontaneous andstimulated parametric down-conversion in a nonlinear quasi-2D waveguide orcavity. We develop a rigorous Heisenberg-Langevin approach which includesdissipation and fluctuations in the electron ensemble and in theelectromagnetic field of a cavity on equal footing. Within a relatively simplemodel, we take into account the nonlinear coupling of the quantized cavitymodes, their interaction with a dissipative reservoir and the outside world,amplification of thermal noise and zero-point fluctuations of theelectromagnetic field, and other relevant effects. We derive closed-formanalytic results for relevant quantities such as the spontaneous parametricsignal power and the threshold for parametric instability. We find a strongreduction in the parametric instability threshold for 2D nonlinear materials ina subwavelength cavity and provide a comparison with conventional nonlinearphotonic devices.

Data spectroscopy: Eigenspaces of convolution operators and clustering

  This paper focuses on obtaining clustering information about a distributionfrom its i.i.d. samples. We develop theoretical results to understand and useclustering information contained in the eigenvectors of data adjacency matricesbased on a radial kernel function with a sufficiently fast tail decay. Inparticular, we provide population analyses to gain insights into whicheigenvectors should be used and when the clustering information for thedistribution can be recovered from the sample. We learn that a fixed number oftop eigenvectors might at the same time contain redundant clusteringinformation and miss relevant clustering information. We use this insight todesign the data spectroscopic clustering (DaSpec) algorithm that utilizesproperly selected eigenvectors to determine the number of clustersautomatically and to group the data accordingly. Our findings extend theintuitions underlying existing spectral techniques such as spectral clusteringand Kernel Principal Components Analysis, and provide new understanding intotheir usability and modes of failure. Simulation studies and experiments onreal-world data are conducted to show the potential of our algorithm. Inparticular, DaSpec is found to handle unbalanced groups and recover clusters ofdifferent shapes better than the competing methods.

Learning Gaussian Mixtures with Arbitrary Separation

  In this paper we present a method for learning the parameters of a mixture of$k$ identical spherical Gaussians in $n$-dimensional space with an arbitrarilysmall separation between the components. Our algorithm is polynomial in allparameters other than $k$. The algorithm is based on an appropriate grid searchover the space of parameters. The theoretical analysis of the algorithm hingeson a reduction of the problem to 1 dimension and showing that two 1-dimensionalmixtures whose densities are close in the $L^2$ norm must have similar meansand mixing coefficients. To produce such a lower bound for the $L^2$ norm interms of the distances between the corresponding means, we analyze the behaviorof the Fourier transform of a mixture of Gaussians in 1 dimension around theorigin, which turns out to be closely related to the properties of theVandermonde matrix obtained from the component means. Analysis of this matrixtogether with basic function approximation results allows us to provide a lowerbound for the norm of the mixture in the Fourier domain.  In recent years much research has been aimed at understanding thecomputational aspects of learning parameters of Gaussians mixture distributionsin high dimension. To the best of our knowledge all existing work on learningparameters of Gaussian mixtures assumes minimum separation between componentsof the mixture which is an increasing function of either the dimension of thespace $n$ or the number of components $k$. In our paper we prove the firstresult showing that parameters of a $n$-dimensional Gaussian mixture model witharbitrarily small component separation can be learned in time polynomial in$n$.

Laplacian Support Vector Machines Trained in the Primal

  In the last few years, due to the growing ubiquity of unlabeled data, mucheffort has been spent by the machine learning community to develop betterunderstanding and improve the quality of classifiers exploiting unlabeled data.Following the manifold regularization approach, Laplacian Support VectorMachines (LapSVMs) have shown the state of the art performance insemi--supervised classification. In this paper we present two strategies tosolve the primal LapSVM problem, in order to overcome some issues of theoriginal dual formulation. Whereas training a LapSVM in the dual requires twosteps, using the primal form allows us to collapse training to a single step.Moreover, the computational complexity of the training algorithm is reducedfrom O(n^3) to O(n^2) using preconditioned conjugate gradient, where n is thecombined number of labeled and unlabeled examples. We speed up training byusing an early stopping strategy based on the prediction on unlabeled data or,if available, on labeled validation examples. This allows the algorithm toquickly compute approximate solutions with roughly the same classificationaccuracy as the optimal ones, considerably reducing the training time. Due toits simplicity, training LapSVM in the primal can be the starting point foradditional enhancements of the original LapSVM formulation, such as those fordealing with large datasets. We present an extensive experimental evaluation onreal world data showing the benefits of the proposed approach.

Blind Signal Separation in the Presence of Gaussian Noise

  A prototypical blind signal separation problem is the so-called cocktailparty problem, with n people talking simultaneously and n different microphoneswithin a room. The goal is to recover each speech signal from the microphoneinputs. Mathematically this can be modeled by assuming that we are givensamples from an n-dimensional random variable X=AS, where S is a vector whosecoordinates are independent random variables corresponding to each speaker. Theobjective is to recover the matrix A^{-1} given random samples from X. A rangeof techniques collectively known as Independent Component Analysis (ICA) havebeen proposed to address this problem in the signal processing and machinelearning literature. Many of these techniques are based on using the kurtosisor other cumulants to recover the components.  In this paper we propose a new algorithm for solving the blind signalseparation problem in the presence of additive Gaussian noise, when we aregiven samples from X=AS+\eta, where \eta is drawn from an unknown, notnecessarily spherical n-dimensional Gaussian distribution. Our approach isbased on a method for decorrelating a sample with additive Gaussian noise underthe assumption that the underlying distribution is a linear transformation of adistribution with independent components. Our decorrelation routine is based onthe properties of cumulant tensors and can be combined with any standardcumulant-based method for ICA to get an algorithm that is provably robust inthe presence of Gaussian noise. We derive polynomial bounds for the samplecomplexity and error propagation of our method.

Eigenvectors of Orthogonally Decomposable Functions

  The Eigendecomposition of quadratic forms (symmetric matrices) guaranteed bythe spectral theorem is a foundational result in applied mathematics. Motivatedby a shared structure found in inferential problems of recent interest---namelyorthogonal tensor decompositions, Independent Component Analysis (ICA), topicmodels, spectral clustering, and Gaussian mixture learning---we generalize theeigendecomposition from quadratic forms to a broad class of "orthogonallydecomposable" functions. We identify a key role of convexity in our extension,and we generalize two traditional characterizations of eigenvectors: First, theeigenvectors of a quadratic form arise from the optima structure of thequadratic form on the sphere. Second, the eigenvectors are the fixed points ofthe power iteration.  In our setting, we consider a simple first order generalization of the powermethod which we call gradient iteration. It leads to efficient and easilyimplementable methods for basis recovery. It includes influential MachineLearning methods such as cumulant-based FastICA and the tensor power iterationfor orthogonally decomposable tensors as special cases.  We provide a complete theoretical analysis of gradient iteration using thestructure theory of discrete dynamical systems to show almost sure convergenceand fast (super-linear) convergence rates. The analysis also extends to thecase when the observed function is only approximately orthogonallydecomposable, with bounds that are polynomial in dimension and other relevantparameters, such as perturbation size. Our perturbation results can beconsidered as a non-linear version of the classical Davis-Kahan theorem forperturbations of eigenvectors of symmetric matrices.

A Pseudo-Euclidean Iteration for Optimal Recovery in Noisy ICA

  Independent Component Analysis (ICA) is a popular model for blind signalseparation. The ICA model assumes that a number of independent source signalsare linearly mixed to form the observed signals. We propose a new algorithm,PEGI (for pseudo-Euclidean Gradient Iteration), for provable model recovery forICA with Gaussian noise. The main technical innovation of the algorithm is touse a fixed point iteration in a pseudo-Euclidean (indefinite "inner product")space. The use of this indefinite "inner product" resolves technical issuescommon to several existing algorithms for noisy ICA. This leads to an algorithmwhich is conceptually simple, efficient and accurate in testing.  Our second contribution is combining PEGI with the analysis of objectives foroptimal recovery in the noisy ICA model. It has been observed that the directapproach of demixing with the inverse of the mixing matrix is suboptimal forsignal recovery in terms of the natural Signal to Interference plus Noise Ratio(SINR) criterion. There have been several partial solutions proposed in the ICAliterature. It turns out that any solution to the mixing matrix reconstructionproblem can be used to construct an SINR-optimal ICA demixing, despite the factthat SINR itself cannot be computed from data. That allows us to obtain apractical and provably SINR-optimal recovery method for ICA with arbitraryGaussian noise.

Beyond Hartigan Consistency: Merge Distortion Metric for Hierarchical  Clustering

  Hierarchical clustering is a popular method for analyzing data whichassociates a tree to a dataset. Hartigan consistency has been used extensivelyas a framework to analyze such clustering algorithms from a statistical pointof view. Still, as we show in the paper, a tree which is Hartigan consistentwith a given density can look very different than the correct limit tree.Specifically, Hartigan consistency permits two types of undesirableconfigurations which we term over-segmentation and improper nesting. Moreover,Hartigan consistency is a limit property and does not directly quantifydifference between trees.  In this paper we identify two limit properties, separation and minimality,which address both over-segmentation and improper nesting and together imply(but are not implied by) Hartigan consistency. We proceed to introduce a mergedistortion metric between hierarchical clusterings and show that convergence inour distance implies both separation and minimality. We also prove that uniformseparation and minimality imply convergence in the merge distortion metric.Furthermore, we show that our merge distortion metric is stable underperturbations of the density.  Finally, we demonstrate applicability of these concepts by provingconvergence results for two clustering algorithms. First, we show convergence(and hence separation and minimality) of the recent robust single linkagealgorithm of Chaudhuri and Dasgupta (2010). Second, we provide convergenceresults on manifolds for topological split tree clustering.

Experimental Demonstration of Phase Modulation and Motion Sensing Using  Graphene-Integrated Metasurfaces

  Plasmonic metasurfaces are able to modify the wavefront by altering the lightintensity, phase and polarization state. Active plasmonic metasurfaces wouldallow dynamic modulation of the wavefront which give rise to interestingapplication such as beam-steering, holograms and tunable waveplates. Grapheneis an interesting material with dynamic property which can be controlled byelectrical gating at an ultra-fast speed. We use a graphene-integratedmetasurface to induce a tunable phase change to the wavefront. The metasurfacesupports a Fano resonance which produces high-quality resonances around 7.7microns. The phase change is measured using a Michleson interferometry setup.It is shown that the reflection phase can change up to 55 degrees. Inparticular the phase can change by 28 degrees while the amplitude is nearlyconstant. The anisotropic optical response of the metasurface is used tomodulate the ellipticity of the reflected wave in response to an incident fieldat 45 degree. We show a proof of concept application of our system inpotentially ultra-fast laser interferometry with sub-micron accuracy.

Diving into the shallows: a computational perspective on large-scale  shallow learning

  In this paper we first identify a basic limitation in gradient descent-basedoptimization methods when used in conjunctions with smooth kernels. An analysisbased on the spectral properties of the kernel demonstrates that only avanishingly small portion of the function space is reachable after a polynomialnumber of gradient descent iterations. This lack of approximating powerdrastically limits gradient descent for a fixed computational budget leading toserious over-regularization/underfitting. The issue is purely algorithmic,persisting even in the limit of infinite data.  To address this shortcoming in practice, we introduce EigenPro iteration,based on a preconditioning scheme using a small number of approximatelycomputed eigenvectors. It can also be viewed as learning a new kernel optimizedfor gradient descent. It turns out that injecting this small (computationallyinexpensive and SGD-compatible) amount of approximate second-order informationleads to major improvements in convergence. For large data, this translatesinto significant performance boost over the standard kernel methods. Inparticular, we are able to consistently match or improve the state-of-the-artresults recently reported in the literature with a small fraction of theircomputational budget.  Finally, we feel that these results show a need for a broader computationalperspective on modern large-scale learning to complement more traditionalstatistical and convergence analyses. In particular, many phenomena oflarge-scale high-dimensional inference are best understood in terms ofoptimization on infinite dimensional Hilbert spaces, where standard algorithmscan sometimes have properties at odds with finite-dimensional intuition. Asystematic analysis concentrating on the approximation power of such algorithmswithin a budget of computation may lead to progress both in theory andpractice.

The Power of Interpolation: Understanding the Effectiveness of SGD in  Modern Over-parametrized Learning

  In this paper we aim to formally explain the phenomenon of fast convergenceof SGD observed in modern machine learning. The key observation is that mostmodern learning architectures are over-parametrized and are trained tointerpolate the data by driving the empirical loss (classification andregression) close to zero. While it is still unclear why these interpolatedsolutions perform well on test data, we show that these regimes allow for fastconvergence of SGD, comparable in number of iterations to full gradientdescent.  For convex loss functions we obtain an exponential convergence bound for {\itmini-batch} SGD parallel to that for full gradient descent. We show that thereis a critical batch size $m^*$ such that: (a) SGD iteration with mini-batchsize $m\leq m^*$ is nearly equivalent to $m$ iterations of mini-batch size $1$(\emph{linear scaling regime}). (b) SGD iteration with mini-batch $m> m^*$ isnearly equivalent to a full gradient descent iteration (\emph{saturationregime}).  Moreover, for the quadratic loss, we derive explicit expressions for theoptimal mini-batch and step size and explicitly characterize the two regimesabove. The critical mini-batch size can be viewed as the limit for effectivemini-batch parallelization. It is also nearly independent of the data size,implying $O(n)$ acceleration over GD per unit of computation. We giveexperimental evidence on real data which closely follows our theoreticalanalyses.  Finally, we show how our results fit in the recent developments in trainingdeep neural networks and discuss connections to adaptive rates for SGD andvariance reduction.

Fast Interactive Image Retrieval using large-scale unlabeled data

  An interactive image retrieval system learns which images in the databasebelong to a user's query concept, by analyzing the example images and feedbackprovided by the user. The challenge is to retrieve the relevant images withminimal user interaction. In this work, we propose to solve this problem byposing it as a binary classification task of classifying all images in thedatabase as being relevant or irrelevant to the user's query concept. Ourmethod combines active learning with graph-based semi-supervised learning(GSSL) to tackle this problem. Active learning reduces the number of userinteractions by querying the labels of the most informative points and GSSLallows to use abundant unlabeled data along with the limited labeled dataprovided by the user. To efficiently find the most informative point, we use anuncertainty sampling based method that queries the label of the point nearestto the decision boundary of the classifier. We estimate this decision boundaryusing our heuristic of adaptive threshold. To utilize huge volumes of unlabeleddata we use an efficient approximation based method that reduces the complexityof GSSL from $O(n^3)$ to $O(n)$, making GSSL scalable. We make the classifierrobust to the diversity and noisy labels associated with images in largedatabases by incorporating information from multiple modalities such as visualinformation extracted from deep learning based models and semantic informationextracted from the WordNet. High F1 scores within few relevance feedback roundsin our experiments with concepts defined on AnimalWithAttributes and Imagenet(1.2 million images) datasets indicate the effectiveness and scalability of ourapproach.

Unveiling spectral purity and tunability of terahertz quantum cascade  laser sources based on intra-cavity difference frequency generation

  Terahertz sources based on intra-cavity difference-frequency generation inmid-infrared quantum cascade lasers (THz DFG-QCLs) have recently emerged as thefirst monolithic electrically-pumped semiconductor sources capable of operatingat room-temperature (RT) across the 1-6 THz range. Despite tremendous progressin power output, that now exceeds 1mW in pulsed and 10 {\mu}W incontinuous-wave regime at room-temperature, knowledge of the major figure ofmerits of these devices for high precision spectroscopy, such as spectralpurity and absolute frequency tunability, is still lacking. Here, by exploitinga metrological grade system comprising a terahertz frequency comb synthesizer,we measure, for the first time, the free-running emission linewidth (LW), thetuning characteristics, and the absolute frequency of individual emission linesof these sources with an uncertainty of 4 x 10-10. The unveiled emission LW(400 kHz at 1ms integration time) indicates that DFG-QCLs are well suited tooperate as local oscillators and to be used for a variety of metrological,spectroscopic, communication, and imaging applications requiringnarrow-linewidth THz sources.

Overfitting or perfect fitting? Risk bounds for classification and  regression rules that interpolate

  Many modern machine learning models are trained to achieve zero or near-zerotraining error in order to obtain near-optimal (but non-zero) test error. Thisphenomenon of strong generalization performance for "overfitted" / interpolatedclassifiers appears to be ubiquitous in high-dimensional data, having beenobserved in deep networks, kernel machines, boosting and random forests. Theirperformance is consistently robust even when the data contain large amounts oflabel noise.  Very little theory is available to explain these observations. The vastmajority of theoretical analyses of generalization allows for interpolationonly when there is little or no label noise. This paper takes a step toward atheoretical foundation for interpolated classifiers by analyzing localinterpolating schemes, including geometric simplicial interpolation algorithmand singularly weighted $k$-nearest neighbor schemes. Consistency ornear-consistency is proved for these schemes in classification and regressionproblems. Moreover, the nearest neighbor schemes exhibit optimal rates undersome standard statistical assumptions.  Finally, this paper suggests a way to explain the phenomenon of adversarialexamples, which are seemingly ubiquitous in modern machine learning, and alsodiscusses some connections to kernel machines and random forests in theinterpolated regime.

Kernel machines that adapt to GPUs for effective large batch training

  Modern machine learning models are typically trained using StochasticGradient Descent (SGD) on massively parallel computing resources such as GPUs.Increasing mini-batch size is a simple and direct way to utilize the parallelcomputing capacity. For small batch an increase in batch size results in theproportional reduction in the training time, a phenomenon known as linearscaling. However, increasing batch size beyond a certain value leads to nofurther improvement in training time. In this paper we develop the firstanalytical framework that extends linear scaling to match the parallelcomputing capacity of a resource. The framework is designed for a class ofclassical kernel machines. It automatically modifies a standard kernel machineto output a mathematically equivalent prediction function, yet allowing forextended linear scaling, i.e., higher effective parallelization and fastertraining time on given hardware.  The resulting algorithms are accurate, principled and very fast. For example,using a single Titan Xp GPU, training on ImageNet with $1.3\times 10^6$ datapoints and $1000$ labels takes under an hour, while smaller datasets, such asMNIST, take seconds. As the parameters are chosen analytically, based on thetheoretical bounds, little tuning beyond selecting the kernel and the kernelparameter is needed, further facilitating the practical use of these methods.

Reconciling modern machine learning and the bias-variance trade-off

  The question of generalization in machine learning---how algorithms are ableto learn predictors from a training sample to make accurate predictionsout-of-sample---is revisited in light of the recent breakthroughs in modernmachine learning technology.  The classical approach to understanding generalization is based onbias-variance trade-offs, where model complexity is carefully calibrated sothat the fit on the training sample reflects performance out-of-sample.  However, it is now common practice to fit highly complex models like deepneural networks to data with (nearly) zero training error, and yet theseinterpolating predictors are observed to have good out-of-sample accuracy evenfor noisy data.  How can the classical understanding of generalization be reconciled withthese observations from modern machine learning practice?  In this paper, we bridge the two regimes by exhibiting a new "double descent"risk curve that extends the traditional U-shaped bias-variance curve beyond thepoint of interpolation.  Specifically, the curve shows that as soon as the model complexity is highenough to achieve interpolation on the training sample---a point that we callthe "interpolation threshold"---the risk of suitably chosen interpolatingpredictors from these models can, in fact, be decreasing as the modelcomplexity increases, often below the risk achieved using non-interpolatingmodels.  The double descent risk curve is demonstrated for a broad range of models,including neural networks and random forests, and a mechanism for producingthis behavior is posited.

Graph Laplacians on Singular Manifolds: Toward understanding complex  spaces: graph Laplacians on manifolds with singularities and boundaries

  Recently, much of the existing work in manifold learning has been done underthe assumption that the data is sampled from a manifold without boundaries andsingularities or that the functions of interest are evaluated away from suchpoints. At the same time, it can be argued that singularities and boundariesare an important aspect of the geometry of realistic data.  In this paper we consider the behavior of graph Laplacians at points at ornear boundaries and two main types of other singularities: intersections, wheredifferent manifolds come together and sharp "edges", where a manifold sharplychanges direction. We show that the behavior of graph Laplacian near thesesingularities is quite different from that in the interior of the manifolds. Infact, a phenomenon somewhat reminiscent of the Gibbs effect in the analysis ofFourier series, can be observed in the behavior of graph Laplacian near suchpoints. Unlike in the interior of the domain, where graph Laplacian convergesto the Laplace-Beltrami operator, near singularities graph Laplacian tends to afirst-order differential operator, which exhibits different scaling behavior asa function of the kernel width. One important implication is that while pointsnear the singularities occupy only a small part of the total volume, thedifference in scaling results in a disproportionately large contribution to thetotal behavior. Another significant finding is that while the scaling behaviorof the operator is the same near different types of singularities, they arevery distinct at a more refined level of analysis.  We believe that a comprehensive understanding of these structures in additionto the standard case of a smooth manifold can take us a long way toward bettermethods for analysis of complex non-linear data and can lead to significantprogress in algorithm design.

Inverse Density as an Inverse Problem: The Fredholm Equation Approach

  In this paper we address the problem of estimating the ratio $\frac{q}{p}$where $p$ is a density function and $q$ is another density, or, more generallyan arbitrary function. Knowing or approximating this ratio is needed in variousproblems of inference and integration, in particular, when one needs to averagea function with respect to one probability distribution, given a sample fromanother. It is often referred as {\it importance sampling} in statisticalinference and is also closely related to the problem of {\it covariate shift}in transfer learning as well as to various MCMC methods. It may also be usefulfor separating the underlying geometry of a space, say a manifold, from thedensity function defined on it.  Our approach is based on reformulating the problem of estimating$\frac{q}{p}$ as an inverse problem in terms of an integral operatorcorresponding to a kernel, and thus reducing it to an integral equation, knownas the Fredholm problem of the first kind. This formulation, combined with thetechniques of regularization and kernel methods, leads to a principledkernel-based framework for constructing algorithms and for analyzing themtheoretically.  The resulting family of algorithms (FIRE, for Fredholm Inverse RegularizedEstimator) is flexible, simple and easy to implement.  We provide detailed theoretical analysis including concentration bounds andconvergence rates for the Gaussian kernel in the case of densities defined on$\R^d$, compact domains in $\R^d$ and smooth $d$-dimensional sub-manifolds ofthe Euclidean space.  We also show experimental results including applications to classificationand semi-supervised learning within the covariate shift framework anddemonstrate some encouraging experimental comparisons. We also show how theparameters of our algorithms can be chosen in a completely unsupervised manner.

The More, the Merrier: the Blessing of Dimensionality for Learning Large  Gaussian Mixtures

  In this paper we show that very large mixtures of Gaussians are efficientlylearnable in high dimension. More precisely, we prove that a mixture with knownidentical covariance matrices whose number of components is a polynomial of anyfixed degree in the dimension n is polynomially learnable as long as a certainnon-degeneracy condition on the means is satisfied. It turns out that thiscondition is generic in the sense of smoothed complexity, as soon as thedimensionality of the space is high enough. Moreover, we prove that no suchcondition can possibly exist in low dimension and the problem of learning theparameters is generically hard. In contrast, much of the existing work onGaussian Mixtures relies on low-dimensional projections and thus hits anartificial barrier. Our main result on mixture recovery relies on a new"Poissonization"-based technique, which transforms a mixture of Gaussians to alinear map of a product distribution. The problem of learning this map can beefficiently solved using some recent results on tensor decompositions andIndependent Component Analysis (ICA), thus giving an algorithm for recoveringthe mixture. In addition, we combine our low-dimensional hardness results forGaussian mixtures with Poissonization to show how to embed difficult instancesof low-dimensional Gaussian mixtures into the ICA setting, thus establishingexponential information-theoretic lower bounds for underdetermined ICA in lowdimension. To the best of our knowledge, this is the first such result in theliterature. In addition to contributing to the problem of Gaussian mixturelearning, we believe that this work is among the first steps toward betterunderstanding the rare phenomenon of the "blessing of dimensionality" in thecomputational aspects of statistical inference.

To understand deep learning we need to understand kernel learning

  Generalization performance of classifiers in deep learning has recentlybecome a subject of intense study. Deep models, typically over-parametrized,tend to fit the training data exactly. Despite this "overfitting", they performwell on test data, a phenomenon not yet fully understood.  The first point of our paper is that strong performance of overfittedclassifiers is not a unique feature of deep learning. Using six real-world andtwo synthetic datasets, we establish experimentally that kernel machinestrained to have zero classification or near zero regression error perform verywell on test data, even when the labels are corrupted with a high level ofnoise. We proceed to give a lower bound on the norm of zero loss solutions forsmooth kernels, showing that they increase nearly exponentially with data size.We point out that this is difficult to reconcile with the existinggeneralization bounds. Moreover, none of the bounds produce non-trivial resultsfor interpolating solutions.  Second, we show experimentally that (non-smooth) Laplacian kernels easily fitrandom labels, a finding that parallels results for ReLU neural networks. Incontrast, fitting noisy data requires many more epochs for smooth Gaussiankernels. Similar performance of overfitted Laplacian and Gaussian classifierson test, suggests that generalization is tied to the properties of the kernelfunction rather than the optimization process.  Certain key phenomena of deep learning are manifested similarly in kernelmethods in the modern "overfitted" regime. The combination of the experimentaland theoretical results presented in this paper indicates a need for newtheoretical ideas for understanding properties of classical kernel methods. Weargue that progress on understanding deep learning will be difficult until moretractable "shallow" kernel methods are better understood.

