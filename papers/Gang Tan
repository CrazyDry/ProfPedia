A possible signature of non-uniform Be-αrelationships for the  Galaxy

  Most of the previous studies on beryllium abundances in metal-poor stars havetaken different Galactic populations as a whole when investigating theproduction and evolution of Be. In this Letter, we report on the detection ofsystematic differences in [\alpha/H]-A(Be) relationships between the low- andhigh-\alpha\ stars which were identified by previous works. We remind that oneshould be more careful in investigating the Galactic evolution of Be with asample comprising different Galactic populations, because such a mixed samplemay lead to inaccurate Be-Fe/Be-O relationships.

Supersymmetric Electroweak Corrections to Sbottom Decay into Lighter  Stop and Charged Higgs Boson

  The Yukawa corrections of order ${\cal O}(\alpha_{ew}m_{t(b)}^2/m_W^2)$,${\cal O}(\alpha_{ew}m_{t(b)}^3/m_W^3)$ and ${\calO}(\alpha_{ew}m_{t(b)}^4/m_W^4)$ to the width of sbottom decay into lighterstop plus charged Higgs boson are calculated in the Minimal SupersymmetricStandard Model. These corrections depend on the masses of charged Higgs bosonand lighter stop, and the parameters $\tan\beta$ and $\mu$. For favorableparameter values, the corrections decrease or increase the decay widthssignificantly. Especially for high values of $\tan\beta$(=30) the correctionsexceed at least 10% for both $\tilde b_1$ and $\tilde b_2$ decay. But for lowvalues of $\tan\beta$(=4,10) the corrections are small and the magnitudes areless than 10%. The numerical calculations also show that using the runningbottom quark mass which includes the QCD effects and resums all high order$\tan\beta$-enhanced effects can improve much the convergence of theperturbation expansion.

Supersymmetric Electroweak Corrections to Charged Higgs Boson Production  in Association with a Top Quark at Hadron Colliders

  We calculate the $O(\alpha_{ew}m_{t(b)}^{2}/m_{W}^{2})$ and $O(\alpha_{ew}m_{t(b)}^4/m_W^4)$ supersymmetric electroweak corrections to the cross sectionfor the charged Higgs boson production in association with a top quark at theTevatron and the LHC. These corrections arise from the quantum effects whichare induced by potentially large Yukawa couplings from the Higgs sector and thechargino-top(bottom)-sbottom(stop) couplings,neutralino-top(bottom)-stop(sbottom) couplings and charged Higgs-stop-sbottomcouplings. They can decrease or increase the cross section depending on$\tan\beta$ but are not very sensitive to the mass of the charged Higgs bosonfor high $\tan\beta$. At low $\tan\beta(=2)$ the corrections decrease the totalcross sections significantly, which exceed -12% for $m_{H^{\pm}}$ below$300GeV$ at both the Tevatron and the LHC, but for $m_{H^{\pm}}>300GeV$ thecorrections can become very small at the LHC. For high $\tan\beta(=10,30)$these corrections can decrease or increase the total cross sections, and themagnitude of the corrections are at most a few percent at both the Tevatron andthe LHC.

Supersymmetric Electroweak Corrections to $W^{\pm}H^{\mp}$ Associated  Production at the CERN Large Hadron Collider

  The $O(\alpha_{ew}m_{t(b)}^{2}/m_{W}^{2})$ and $O(\alpha_{ew}m_{t(b)}^4/m_W^4)$ supersymmetric electroweak corrections to the cross sectionfor $W^{\pm}H^{\mp}$ associated production at the LHC are calculated in theminimal supersymmetric standard model. Those corrections arise from the quantumeffects which are induced by the Yukawa couplings from the Higgs sector and thegenuine supersymmetric electroweak couplings involving supersymmetricparticles, i.e. chargino-top(bottom)-sbottom(stop) couplings,neutralino-top(bottom)-stop(sbottom) couplings and charged Higgs-stop-sbottomcouplings. The Yukawa corrections can decrease the total cross sectionssignificantly for low $\tan\beta(<4)$ when $m_{H^+}<300$GeV, which exceed -12%.For high $\tan\beta$ the Yukawa corrections become negligibly small. Thegenuine supersymmetric electroweak corrections can increase or decrease thetotal cross sections depending on the supersymmetric parameters, which are atmost a few percent, except the region near the threshold. We also show that thegenuine supersymmetric electroweak corrections depend strongly on the choice of$\tan\beta$, $A_t$, $M_{\tilde Q}$ and $\mu$. For large values of $A_t$, orlarge values of $\mu$ and $\tan\beta$, one can get larger corrections. Thecorrections can become very small, in contrast, for larger values of $M_{\tildeQ}$.

The Casimir force between parallel plates separated by anisotropic media

  The Casimir force between two parallel plates separated by anisotropic mediais investigated. We theoretically calculate the Casimir force between twoparallel plates when the interspace between the plates is filled withanisotropic media. Our result shows that the anisotropy of the material betweenthe plates can significantly affect the Casimir force, especially the directionof the force. If ignoring the anisotropy of the in-between material makes theforce to be repulsive (attractive), by contrast, taking the anisotropy intoaccount may produce an extra attractive (repulsive) force. The physicalexplanation for this phenomenon is also discussed.

Yukawa Corrections to Charged Higgs Boson Production in Association with  a Top Quark at Hadron Colliders

  We calculate the Yukawa corrections of order$O(\alpha_{ew}m_{t(b)}^{2}/m_{W}^{2})$ to charged Higgs boson production inassociation with a top quark at the Tevatron and the LHC. The corrections arenot very sensitive to the mass of the charged Higgs boson and can exceed -20%for low values of $\tan\beta$, where the contribution of the top quark islarge, and high values of $\tan\beta$ where the contribution of the bottomquark becomes large. These Yukawa corrections could be significant for chargedHiggs boson discovery searches based on this production process, particularlyat the LHC where the cross section is relatively large.

A non-LTE study of silicon abundances in giant stars from the Si I  infrared lines in the zJ-band

  We investigate the feasibility of the Si I infrared (IR) lines as Siabundance indicators for giant stars. We find that Si abundances obtained fromthe Si I IR lines based on the local thermodynamic equilibrium (LTE) analysisshow large line-to-line scatter (mean value of 0.13dex), and are higher thanthose from the optical lines. However, when the non-LTE effects are taken intoaccount, the line-to-line scatter reduces significantly (mean value of0.06dex), and the Si abundances are consistent with those from the opticallines. The typical average non-LTE correction of [Si/Fe] for our sample starsis about $-$0.35dex. Our results demonstrate that the Si I IR lines could bereliable abundance indicators provided that the non-LTE effects are properlytaken into account.

Isolate First, Then Share: a New OS Architecture for Datacenter  Computing

  This paper presents the "isolate first, then share" OS model in which theprocessor cores, memory, and devices are divided up between disparate OSinstances and a new abstraction, subOS, is proposed to encapsulate an OSinstance that can be created, destroyed, and resized on-the-fly. The intuitionis that this avoids shared kernel states between applications, which in turnreduces performance loss caused by contention. We decompose the OS into thesupervisor and several subOSes running at the same privilege level: a subOSdirectly manages physical resources, while the supervisor can create, destroy,resize a subOS on-the-fly. The supervisor and subOSes have few state sharing,but fast inter-subOS communication mechanisms are provided on demand.  We present the first implementation, RainForest, which supports unmodifiedLinux binaries. Our comprehensive evaluation shows RainForest outperforms Linuxwith four different kernels, LXC, and Xen in terms of worst-case and averageperformance most of time when running a large number of benchmarks. The sourcecode is available soon.

Supersymmetric Electroweak Corrections to Heavier Top Squark Decay into  Lighter Top Squark and Neutral Higgs Boson

  We calculate the Yukawa corrections of order ${\calO}(\alpha_{ew}m_{t(b)}^2/m_W^2)$, ${\cal O}(\alpha_{ew}m_{t(b)}^3/m_W^3)$ and${\cal O}(\alpha_{ew}m_{t(b)}^4/m_W^4)$ to the widths of the decays $\tildet_2\to \tilde t_1 + (h^0,H^0,A^0)$ in the Minimal Supersymmetric StandardModel, and perform a detailed numerical analysis. We also compare the resultswith the ones presented in an earlier literature, where the ${\calO}(\alpha_{s})$ SUSY-QCD corrections to the same three decay processes havebeen calculated.  Our numerical results show that for the decays $\tilde t_2\to \tilde t_1 +h^{0}$, $\tilde t_2\to \tilde t_1 + H^{0}$, the Yukawa corrections aresignificant in most of the parameter range, which can reach a few ten percent,and for the decay $\tilde t_2\to\tilde t_1 + A^{0}$, the Yukawa corrections arerelatively smaller, which are only a few percent. The numerical calculationsalso show that using the running quark masses and the running trilinearcoupling $A_t$, which include the QCD, SUSY-QCD, SUSY-Electroweak effects andresume all high order ($\tan\beta$)-enhanced effects, can vastly improve theconvergence of the perturbation expansion. We also discuss the effects of therunning of the higgsino mass parameter $\mu$ on the corrections, and find thatthey are significant, too, especially for large $\tan\beta$.

Full one-loop QCD and electroweak corrections to sfermion pair  production in $γγ$ collisions

  We have calculated the full one-loop electroweak (EW) and QCD corrections tothe third generation scalar-fermion pair production processes $e^+e^- \to\gamma \gamma \to \tilde{f_i}\bar{\tilde{f_i}} (f=t,b,\tau)$ at anelectron-positron linear collider(LC) in the minimal supersymmetric standardmodel (MSSM). We analyze the dependence of the radiative corrections on theparameters such as the colliding energy $\sqrt{\hat s}$ and the SUSYfundamental parameters $A_f$, $\tan \beta$, $\mu$, $M_{SUSY}$ and so forth. Thenumerical results show that the EW corrections to the squark-, stau-pairproduction processes and QCD corrections to the squark-pair productionprocesses give substantial contributions in some parameter space. The EWrelative corrections to squark-pair production processes can be comparable withQCD corrections at high energies. Therefore, these EW and QCD correctionscannot be neglected in precise measurement of sfermion pair productions via$\gamma\gamma$ collision at future linear colliders.

The Morphologic Properties of Magnetic networks over the Solar Cycle 23

  The morphologic properties of the magnetic networks during CarringtonRotations (CR) 1955 to 2091 (from 1999 to 2010) have been analyzed by applyingthe watershed algorithm to magnetograms observed by the Michelson DopplerInterferometer (MDI) on board the Solar and Heliospheric Observatory (SOHO)spacecraft. We find that the average area of magnetic cells on the solarsurface at lower latitudes (within +-50 degree) are smaller than those athigher latitudes (beyond +-50 degree). Statistical analysis of these dataindicates that the magnetic networks are of fractal in nature, and the averagefractal dimension is D_f = 1.253+-0.011. We also find that both the fractaldimension and the size of the magnetic networks are anti-correlated with thesunspot area. This is perhaps because a strong magnetic field can suppressspatially modulated oscillation, compress the boundaries of network cells,leading to smoother cell boundaries. The fractal dimension of the cell deviatesthat predicted from an isobar of Kolmogorov homogeneous turbulence.

Three Moving Groups Detected in the LAMOST DR1 Archive

  We analyze the kinematics of thick disk and halo stars observed by the Largesky Area Multi-Object Fiber Spectroscopic Telescope. We have constructed asample of 7,993 F, G and K nearby main-sequence stars (\textit{d} $<$ 2 kpc)with estimates of position (x, y, z) and space velocity ($U$, $V$, $W$) basedon color and proper motion from the SDSS DR9 catalog. Three `phase-spaceoverdensities' are identified in [\textit{V}, $\sqrt{U^{2}+2V^{2}}$] withsignificance levels of $\sigma$ $>$ 3. %[L$_{Z}$, eccentricity], [L$_{Z}$,L$_{\bot}$], and [V$_{az}$, V$_{\triangle}E$].  Two of them (Hyades-Pleiades stream, Arcturus-AF06 stream) have beenidentified previously. We also find evidence for a new stream (centered at\textit{V} $\sim$ -180 km s$^{-1}$) in the halo. The formation mechanisms ofthese three streams are analyzed. Our results support the hypothesis theArcturus-AF06 stream and the new stream originated from the debris of adisrupted satellite, while Hyades-Pleiades stream has a dynamical origin.

Thermal conductivity of a new carbon nanotube analogue: the diamond  nanothread

  Based on the non-equilibrium molecular dynamics simulations, we have studiedthe thermal conductivities of a novel ultra-thin one-dimensional carbonnanomaterial - diamond nanothread (DNT). Unlike single-wall carbon nanotube(CNT), the existence of the Stone-Wales transformations in DNT endows it withricher thermal transport characteristics. There is a transition fromwave-dominated to particle-dominated transport region, which depends on thelength of poly-benzene rings. However, independent of the transport region,strong length dependence in thermal conductivity is observed in DNTs withdifferent lengths of poly-benzene ring. The distinctive SW characteristic inDNT provides more degrees of freedom to tune the thermal conductivity not foundin the homogeneous structure of CNT. Therefore, DNT is an ideal platform toinvestigate various thermal transport mechanisms at the nanoscale. Its hightunability raises the potential to design DNTs for different applications, suchas thermal connection and temperature management.

Cohort Query Processing

  Modern Internet applications often produce a large volume of user activityrecords. Data analysts are interested in cohort analysis, or finding unusualuser behavioral trends, in these large tables of activity records. In atraditional database system, cohort analysis queries are both painful tospecify and expensive to evaluate. We propose to extend database systems tosupport cohort analysis. We do so by extending SQL with three new operators. Wedevise three different evaluation schemes for cohort query processing. Two ofthem adopt a non-intrusive approach. The third approach employs a columnarbased evaluation scheme with optimizations specifically designed for cohortquery processing. Our experimental results confirm the performance benefits ofour proposed columnar database system, compared against the two non-intrusiveapproaches that implement cohort queries on top of regular relationaldatabases.

DelugeNets: Deep Networks with Efficient and Flexible Cross-layer  Information Inflows

  Deluge Networks (DelugeNets) are deep neural networks which efficientlyfacilitate massive cross-layer information inflows from preceding layers tosucceeding layers. The connections between layers in DelugeNets are establishedthrough cross-layer depthwise convolutional layers with learnable filters,acting as a flexible yet efficient selection mechanism. DelugeNets canpropagate information across many layers with greater flexibility and utilizenetwork parameters more effectively compared to ResNets, whilst being moreefficient than DenseNets. Remarkably, a DelugeNet model with just modelcomplexity of 4.31 GigaFLOPs and 20.2M network parameters, achieveclassification errors of 3.76% and 19.02% on CIFAR-10 and CIFAR-100 datasetrespectively. Moreover, DelugeNet-122 performs competitively to ResNet-200 onImageNet dataset, despite costing merely half of the computations needed by thelatter.

Stochastic Downsampling for Cost-Adjustable Inference and Improved  Regularization in Convolutional Networks

  It is desirable to train convolutional networks (CNNs) to run moreefficiently during inference. In many cases however, the computational budgetthat the system has for inference cannot be known beforehand during training,or the inference budget is dependent on the changing real-time resourceavailability. Thus, it is inadequate to train just inference-efficient CNNs,whose inference costs are not adjustable and cannot adapt to varied inferencebudgets. We propose a novel approach for cost-adjustable inference in CNNs -Stochastic Downsampling Point (SDPoint). During training, SDPoint appliesfeature map downsampling to a random point in the layer hierarchy, with arandom downsampling ratio. The different stochastic downsampling configurationsknown as SDPoint instances (of the same model) have computational costsdifferent from each other, while being trained to minimize the same predictionloss. Sharing network parameters across different instances providessignificant regularization boost. During inference, one may handpick a SDPointinstance that best fits the inference budget. The effectiveness of SDPoint, asboth a cost-adjustable inference approach and a regularizer, is validatedthrough extensive experiments on image classification.

Soteria: Automated IoT Safety and Security Analysis

  Broadly defined as the Internet of Things (IoT), the growth of commoditydevices that integrate physical processes with digital systems have changed theway we live, play and work. Yet existing IoT platforms cannot evaluate whetheran IoT app or environment is safe, secure, and operates correctly. In thispaper, we present Soteria, a static analysis system for validating whether anIoT app or IoT environment (collection of apps working in concert) adheres toidentified safety, security, and functional properties. Soteria operates inthree phases; (a) translation of platform-specific IoT source code into anintermediate representation (IR), (b) extracting a state model from the IR, (c)applying model checking to verify desired properties. We evaluate Soteria on 65SmartThings market apps through 35 properties and find nine (14%) individualapps violate ten (29%) properties. Further, our study of combined appenvironments uncovered eleven property violations not exhibited in the isolatedapps. Lastly, we demonstrate Soteria on MalIoT, a novel open-source test suitecontaining 17 apps with 20 unique violations.

Testing Area of the SAGE Survey

  Sky survey is one of the most important motivations to improve theastrophysics development, especially when using new photometric bands. We areperforming the SAGE (Stellar Abundance and Galactic Evolution) survey with aself-designed SAGE photometric system, which is composed of eight photometricbands. The project mainly aims to study the stellar atmospheric parameters of$\sim$0.5 billion stars in the $\sim12,000$ deg$^2$ of the northern sky, whichmainly focuses on the Galactic sciences, as well as some extragalacticsciences. This work introduces the detailed data reduction process of thetesting field NGC\,6791, including the data reduction of single-exposure imageand stacking multi-exposure images, and properties of the final catalogue.

Wireless Compressive Sensing for Energy Harvesting Sensor Nodes

  We consider the scenario in which multiple sensors send spatially correlateddata to a fusion center (FC) via independent Rayleigh-fading channels withadditive noise. Assuming that the sensor data is sparse in some basis, we showthat the recovery of this sparse signal can be formulated as a compressivesensing (CS) problem. To model the scenario in which the sensors operate withintermittently available energy that is harvested from the environment, wepropose that each sensor transmits independently with some probability, andadapts the transmit power to its harvested energy. Due to the probabilistictransmissions, the elements of the equivalent sensing matrix are not Gaussian.Besides, since the sensors have different energy harvesting rates and differentsensor-to-FC distances, the FC has different receive signal-to-noise ratios(SNRs) for each sensor. This is referred to as the inhomogeneity of SNRs. Thus,the elements of the sensing matrix are also not identically distributed. Forthis unconventional setting, we provide theoretical guarantees on the number ofmeasurements for reliable and computationally efficient recovery, by showingthat the sensing matrix satisfies the restricted isometry property (RIP), underreasonable conditions. We then compute an achievable system delay under anallowable mean-squared-error (MSE). Furthermore, using techniques from largedeviations theory, we analyze the impact of inhomogeneity of SNRs on theso-called k-restricted eigenvalues, which governs the number of measurementsrequired for the RIP to hold. We conclude that the number of measurementsrequired for the RIP is not sensitive to the inhomogeneity of SNRs, when thenumber of sensors n is large and the sparsity of the sensor data (signal) kgrows slower than the square root of n. Our analysis is corroborated byextensive numerical results.

A NLTE analysis of boron abundances in metal-poor stars

  The non-local thermodynamic equilibrium (NLTE) line formation of neutralboron in the atmospheres of cool stars are investigated. Our results confirmthat NLTE effects for the B I resonance lines, which are due to a combinationof overionization and optical pumping effects, are most important for hot,metalpoor, and low-gravity stars; however, the amplitude of departures from LTEfound by this work are smaller than that of previous studies. In addition, ourcalculation shows that the line formation of B I will get closer to LTE if thestrength of collisions with neutral hydrogen increases, which is contrary tothe result of previous studies. The NLTE line formation results are applied tothe determination of boron abundances for a sample of 16 metal-poor stars withthe method of spectrum synthesis of the B I 2497 A resonance lines using thearchived HST/GHRS spectra. Beryllium and oxygen abundances are also determinedfor these stars. The abundances of the nine stars which are not depleted in Beor B show that, no matter the strength of collisions with neutral hydrogen maybe, both Be and B increase with O quasi-linearly in the logarithmic plane,which confirms the conclusions that Be and B are mainly produced by primaryprocess in the early Galaxy. The most noteworthy result of this work is that Bincreases with Fe or O at a very similar speed as, or a bit faster than Bedoes, which is in accord with the theoretical models. The B/Be ratios remainalmost constant over the metallicity range investigated here. Our average B/Beratio falls in the interval [13+-4, 17+-4], which is consistent with thepredictions of spallation process. The contribution of B from the nu-processmay be required if the 11B/10B isotopic ratios in metal-poor stars are the sameas the meteoric value.

Production of Scalar Higgs Bosons Associated with $Z^0$ Boson at the  CERN LHC in the MSSM

  We investigate the associated production of a scalar Higgs boson ($h^0$ or$H^0$) with $Z^0$ boson in the minimal supersymmetric extension of the standardmodel (MSSM) at the CERN Large Hadron Collider (LHC), including thecontributions from $b\bar{b}$ annihilation at the tree level and gluon fusionvia quark and squark loops. We quantitatively analyze the total cross sectionsin the mSUGRA scenario. For the production of $h^0$ associated with $Z^0$, wefind that in most of the parameter regions, the contributions from initial$b\bar{b}$ and $gg$ are at a level of one percent of the total cross sectionand therefore almost insignificant. For the production of $H^0$ associated with$Z^0$, the contributions from $b\bar{b}$ channel can be much larger than thosefrom light quark initial states. Especially for large $\tan\beta$, theincrement can reach about one order of magnitude. Thus, when considering theassociated production of $H^0$ and $Z^0$ at the LHC, the contributions from$b\bar{b}$ annihilation should be taken into account seriously.

Next-to-leading order QCD predictions for pair production of neutral  Higgs bosons at the CERN Large Hadron Collider

  We present the calculations of the complete NLO inclusive total crosssections for pair production of neutral Higgs bosons through $b\bar b$annihilation in the minimal supersymmetric standard model at the CERN LargeHadron Collider. In our calculations, we used both the DREG scheme and the DREDscheme and found that the NLO total cross sections in the above two schemes arethe same. Our results show that the $b\bar b$-annihilation contributions canexceed ones of $gg$ fusion and $q\bar q$ annihilation for $h^0H^0$, $A^0h^0$and $A^0H^0$ productions when $\tan\beta$ is large. In the case of $\mu>0$, theNLO corrections enhance the LO total cross sections significantly, which canreach a few tens percent, while for $\mu<0$, the corrections are relativelysmall, and are negative in most parameter space. Moreover, the NLO QCDcorrections can reduce the dependence of the total cross sections on therenormalization/factorization scale, especially for $\mu<0$. We also use theCTEQ6.1 PDF sets to estimate the uncertainty of LO and NLO total crosssections, and find that the uncertainty arising from the choice of PDFsincreases with the increasing $m_{A^0}$.

Diamond nanothread as a new reinforcement for nanocomposites

  This work explores the application of a new one-dimensional carbonnanomaterial, the diamond nanothread (DNT), as a reinforcement fornanocomposites. Owing to the existence of Stone-Wales transformation defects,the DNT intrinsically possesses irregular surfaces, which is expected toenhance the non-covalent interfacial load transfer. Through a series of insilico pull-out studies of the DNT in polyethylene (PE) matrix, we found thatthe load transfer between DNT and PE matrix is dominated by the non-covalentinteractions, in particular the van der Waals interactions. Although thehydrogenated surface of the DNT reduces the strength of the van der Waalsinteractions at the interface, the irregular surface of the DNT can compensatefor the weak bonds. These factors lead to an interfacial shear strength of theDNT/PE interface comparable with that of the carbon nanotube (CNT)/PEinterface. Our results show that the DNT/PE interfacial shear strength remainshigh even as the number of Stone-Wales transformation defects decreases. It canbe enhanced further by increasing the PE density or introduction of functionalgroups to the DNT, both of which greatly increase the non-covalentinteractions.

From Brittle to Ductile: A Structure Dependent Ductility of Diamond  Nanothread

  As a potential building block for the next generation of devices ormultifunctional materials that are spreading almost every technology sector,one-dimensional (1D) carbon nanomaterial has received intensive researchinterests. Recently, a new ultra-thin diamond nanothread (DNT) has joined thispalette, which is a 1D structure with poly-benzene sections connected byStone-Wales (SW) transformation defects. Using large-scale molecular dynamicssimulations, we found that this sp3 bonded DNT can transit from a brittle to aductile characteristic by varying the length of the poly-benzene sections,suggesting that DNT possesses entirely different mechanical responses thanother 1D carbon allotropies. Analogously, the SW defects behave like a grainboundary that interrupts the consistency of the poly-benzene sections. For aDNT with a fixed length, the yield strength fluctuates in the vicinity of acertain value and is independent of the "grain size". On the other hand, bothyield strength and yield strain show a clear dependence on the total length ofDNT, which is due to the fact that the failure of the DNT is dominated by theSW defects. Its highly tunable ductility together with its ultra-light densityand high Young's modulus makes diamond nanothread ideal for creation ofextremely strong three-dimensional nano-architectures.

Deep Learning At Scale and At Ease

  Recently, deep learning techniques have enjoyed success in various multimediaapplications, such as image classification and multi-modal data analysis. Largedeep learning models are developed for learning rich representations of complexdata. There are two challenges to overcome before deep learning can be widelyadopted in multimedia and other applications. One is usability, namely theimplementation of different models and training algorithms must be done bynon-experts without much effort especially when the model is large and complex.The other is scalability, that is the deep learning system must be able toprovision for a huge demand of computing resources for training large modelswith massive datasets. To address these two challenges, in this paper, wedesign a distributed deep learning platform called SINGA which has an intuitiveprogramming model based on the common layer abstraction of deep learningmodels. Good scalability is achieved through flexible distributed trainingarchitecture and specific optimization techniques. SINGA runs on GPUs as wellas on CPUs, and we show that it outperforms many other state-of-the-art deeplearning systems. Our experience with developing and training deep learningmodels for real-life multimedia applications in SINGA shows that the platformis both usable and scalable.

UStore: A Distributed Storage With Rich Semantics

  Today's storage systems expose abstractions which are either too low-level(e.g., key-value store, raw-block store) that they require developers tore-invent the wheels, or too high-level (e.g., relational databases, Git) thatthey lack generality to support many classes of applications. In this work, wepropose and implement a general distributed data storage system, called UStore,which has rich semantics. UStore delivers three key properties, namelyimmutability, sharing and security, which unify and add values to many classesof today's applications, and which also open the door for new applications. Bykeeping the core properties within the storage, UStore helps reduce applicationdevelopment efforts while offering high performance at hand. The storageembraces current hardware trends as key enablers. It is built around adata-structure similar to that of Git, a popular source code versioning system,but it also synthesizes many designs from distributed systems and databases.Our current implementation of UStore has better performance than generalin-memory key-value storage systems, especially for version scan operations. Weport and evaluate four applications on top of UStore: a Git-like application, acollaborative data science application, a transaction management application,and a blockchain application. We demonstrate that UStore enables fasterdevelopment and the UStore-backed applications can have better performance thanthe existing implementations.

The Best Features of Diamond Nanothread for Nanofiber Application

  Carbon fibers, especially those constructed from carbon nanotubes (CNTs),have attracted intensive interests from both scientific and engineeringcommunities due to their outstanding physical properties. In this workHere wereport, we find that the recently synthesized recently synthesized ultrathindiamond nanothread (DNT) not only possesses excellent torsional deformationcapability, but also has excellent interfacial load transfer efficiency.Comparing with the (10,10) carbon nanotube bundles, (1) By considering a sevenstrand fiber, the flattening of nanotubes as observed in (10,10) CNT bundles isnot observed in DNTdiamond nanothread bundle, which . This endows the DNTbundle withleads to a high torsional elastic limit that is almost three timeshigherfour times as obtained from the (10,10) CNT bundle. Pull-out tests revealthat (2) Pull-out tests reveal that tthe DNT diamond nanothread bundle has hasan interface transfer load of more than twice that of the CNT carbon naontubebundle, corresponding to an order of magnitude higher in terms of . (3) Ttheinterfacial shear strength of the DNT bundle is an order of magnitude higherthan that of the CNT bundle. Such high interface load transfer efficiency isattributed to the zigzag morphology of DNT, which introduces a strongmechanical interlocking effect at the interface through the stick-slip motion(totally different from the load transfer mechanism in CNT bundle). Theaforementioned three aspects are commonly used to gauge the performance offibers. Obviously,These intriguing features enable DNT diamond nanothread asexhibits excellent potential candidate for constructing next generation carbonfibers.

Possible gapless spin liquid in a rare-earth kagomé lattice magnet  Tm$_{3}$Sb$_{3}$Zn$_{2}$O$_{14}$

  We report the thermodynamic and muon spin relaxation ($\mu$SR) evidences fora possible gapless spin liquid in Tm$_{3}$Sb$_{3}$Zn$_{2}$O$_{14}$, with therare-earth ions Tm$^{3+}$ forming a two-dimensional kagom\'{e} lattice. Weextract the magnetic specific heat of Tm$_{3}$Sb$_{3}$Zn$_{2}$O$_{14}$ bysubtracting the phonon contribution of the non-magnetic isostructural materialLa$_{3}$Sb$_{3}$Zn$_{2}$O$_{14}$. We obtain a clear linear-$T$ temperaturedependence of magnetic specific heat at low temperatures, with theheat-capacity coefficient $\gamma$ = 26.6(1) mJ mol-Tm$^{-1}$ K$^{-2}$ in thezero temperature limit. No long-range magnetic order was observed down to 0.35K in the heat capacity measurement. A broad hump around 9 K was observed in thezero field magnetic specific heat and is gradually suppressed in the magneticfields that also create a spin gap in the specific heat. The absence ofmagnetic order is further confirmed by the $\mu$SR measurement down to 20 mK.We find that the spin-lattice relaxation time remains constant down to thelowest temperatures. We point out that the physics inTm$_{3}$Sb$_{3}$Zn$_{2}$O$_{14}$ is fundamentally different from the Cu-basedherbertsmithite and propose spin liquid ground states with non-Kramers doubletson the kagom\'{e} lattice to account for the experimental results.

Sensitive Information Tracking in Commodity IoT

  Broadly defined as the Internet of Things (IoT), the growth of commoditydevices that integrate physical processes with digital connectivity has hadprofound effects on society--smart homes, personal monitoring devices, enhancedmanufacturing and other IoT apps have changed the way we live, play, and work.Yet extant IoT platforms provide few means of evaluating the use (and potentialavenues for misuse) of sensitive information. Thus, consumers and organizationshave little information to assess the security and privacy risks these devicespresent. In this paper, we present SainT, a static taint analysis tool for IoTapplications. SainT operates in three phases; (a) translation ofplatform-specific IoT source code into an intermediate representation (IR), (b)identifying sensitive sources and sinks, and (c) performing static analysis toidentify sensitive data flows. We evaluate SainT on 230 SmartThings market appsand find 138 (60%) include sensitive data flows. In addition, we demonstrateSainT on IoTBench, a novel open-source test suite containing 19 apps with 27unique data leaks. Through this effort, we introduce a rigorously groundedframework for evaluating the use of sensitive information in IoT apps---andtherein provide developers, markets, and consumers a means of identifyingpotential threats to security and privacy.

The SAGE Photometric Sky Survey: Technical Description

  To investigate in more details of Stellar Abundance and Galactic Evolution(SAGE) and in a huge sample, we are performing a northern sky photometricsurvey named SAGES with the SAGE photometric system, which consists of 8filters: Str\"omgren-$u$, SAGE-$v$, SDSS $g$, $r$, $i$, DDO-$51$,$H\alpha_{wide}$, and $H\alpha _{narrow}$, including three Sloan broadbandfilters, three intermediate-band filters and two narrow-band filters, and onenewly-designed narrow-band filter. SAGES covers $\sim$12,000 square degrees ofthe northern sky with $\delta > -5 ^{\circ}$, excluding the Galactic disk($|b|<10^{\circ}$) and the sky area of 12 hr $<$ R.A. $<$ 18\,hr. Thephotometric detection limit depth at signal-to-noise ratio $5\sigma$ can be asdeep as $V\sim$20\,mag. The SAGES will produce a depth-uniformed photometriccatalogue for $\sim$500 million stars with atmospheric parameters includingeffective temperature $T_{\rm eff}$, surface gravity log\,g, and metallicity[Fe/H], as well as interstellar extinction to each individual target. In thiswork, we will briefly introduce the SAGE photometric system, the SAGE survey,and a preliminary test field of the open cluster NGC\,6791 and around.

Design and characterization of high energy micro-CT with a laser-based  X-ray source

  The increasingly demand for machining accuracy and product quality excites agreat interest in high-resolution non-destructive testing (NDT) methods, butspatial resolution of conventional high-energy computed tomography (CT) islimited to sub-millimeter because of large X-ray spot size. Therefore, wepropose a novel high-resolution high-energy CT based on laser-driven X-raysource and prove its feasibility to allow high-spatial-resolution tomographicimaging of dense objects. A numerical model is developed with a considerationof realistic factors including parameter fluctuations, statistical noise anddetecting efficiency. By using modulation transfer functions, the systemperformance is quantitatively characterized and optimized in terms of sourcecharacteristics, detector aperture, geometrical configuration and projectionparameters. As a result, the simulated tomography for a high-density object (upto 19.35g/cm3) achieves a basic spatial resolution of 64.9{\mu}m. This conceptexpands the prospects of laser-based compact X-ray sources and shows a greatpotential to achieve high-perspectivity micro-CT imaging for various industrialapplications.

Program Analysis of Commodity IoT Applications for Security and Privacy:  Challenges and Opportunities

  Recent advances in Internet of Things (IoT) have enabled myriad domains suchas smart homes, personal monitoring devices, and enhanced manufacturing. IoT isnow pervasive---new applications are being used in nearly every conceivableenvironment, which leads to the adoption of device-based interaction andautomation. However, IoT has also raised issues about the security and privacyof these digitally augmented spaces. Program analysis is crucial in identifyingthose issues, yet the application and scope of program analysis in IoT remainslargely unexplored by the technical community. In this paper, we study privacyand security issues in IoT that require program-analysis techniques with anemphasis on identified attacks against these systems and defenses implementedso far. Based on a study of five IoT programming platforms, we identify the keyinsights that result from research efforts in both the program analysis andsecurity communities and relate the efficacy of program-analysis techniques tosecurity and privacy issues. We conclude by studying recent IoT analysissystems and exploring their implementations. Through these explorations, wehighlight key challenges and opportunities in calibrating for the environmentsin which IoT systems will be used.

Deep Reinforcement Learning based Modulation and Coding Scheme Selection  in Cognitive Heterogeneous Networks

  We consider a cognitive heterogeneous network (HetNet), in which multiplepairs of secondary users adopt sensing-based approaches to coexist with a pairof primary users on a certain spectrum band. Due to imperfect spectrum sensing,secondary transmitters (STs) may cause interference to the primary receiver(PR) and make it difficult for the PR to select a proper modulation and/orcoding scheme (MCS). To deal with this issue, we exploit deep reinforcementlearning (DRL) and propose an intelligent MCS selection algorithm for theprimary transmission. To reduce the system overhead caused by MCS switchings,we further introduce a switching cost factor in the proposed algorithm.Simulation results show that the primary transmission rate of the proposedalgorithm without the switching cost factor is 90 percent to 100 percent of theoptimal MCS selection scheme, which assumes that the interference from the STsis perfectly known at the PR as prior information, and is 30 percent to 100percent higher than those of the benchmark algorithms. Meanwhile, the proposedalgorithm with the switching cost factor can achieve a better balance betweenthe primary transmission rate and system overheads than both the optimalalgorithm and benchmark algorithms.

ZAIGA: Zhaoshan Long-baseline Atom Interferometer Gravitation Antenna

  The Zhaoshan long-baseline Atom Interferometer Gravitation Antenna (ZAIGA) isa new type of underground laser-linked interferometer facility, and iscurrently under construction. It is in the 200-meter-on-average underground ofa mountain named Zhaoshan which is about 80 km southeast to Wuhan. ZAIGA willbe equipped with long-baseline atom interferometers, high-precision atomclocks, and large-scale gyros. ZAIGA facility will take an equilateral triangleconfiguration with two 1-km-apart atom interferometers in each arm, a 300-metervertical tunnel with atom fountain and atom clocks mounted, and atracking-and-ranging 1-km-arm-length prototype with lattice optical clockslinked by locked lasers. The ZAIGA facility will be used for experimentalresearch on gravitation and related problems including gravitational wavedetection, high-precision test of the equivalence principle of micro-particles,clock based gravitational red-shift measurement, rotation measurement andgravito-magnetic effect.

Systematic non-LTE study of the $-2.6 \le$ [Fe/H] $\le 0.2$ F and G  dwarfs in the solar neighbourhood. II. Abundance patterns from Li to Eu

  For the first time, we present an extensive study of stars with individualnon-local thermodynamic equilibrium (NLTE) abundances for 17 chemical elementsfrom Li to Eu in a sample of stars uniformly distributed over the $-2.62 \le$[Fe/H] $\le +0.24$ metallicity range that is suitable for the Galactic chemicalevolution research. The star sample has been kinematically selected to tracethe Galactic thin and thick disks and halo. We find new and improve earlierresults as follows. (i) The element-to-iron ratios for Mg, Si, Ca, and Ti forma MP plateau at a similar height of 0.3~dex, and the knee occurs at common[Fe/H] $\simeq -0.8$. The knee at the same metallicity is observed for [O/Fe],and the MP plateau is formed at [O/Fe] = 0.61. (ii) The upward trend of [C/O]with decreasing metallicity exists at [Fe/H] $< -1.2$, supporting the earlierfinding of Akerman et al. (iii) An underabundance of Na relative to Mg in the[Fe/H] $< -1$ stars is nearly constant, with the mean [Na/Mg] $\simeq -0.5$.(iv) The K/Sc, Ca/Sc, and Ti/Sc ratios form well-defined trends, suggesting acommon site of the K-Ti production. (v) Sr follows the Fe abundance down to[Fe/H] $\simeq -2.5$, while Zr is enhanced in MP stars. (vi) The comparisons ofour results with some widely used Galactic evolution models are given. The useof the NLTE element abundances raises credit to the interpretation of the datain the context of the chemical evolution of the Galaxy.

BLOCKBENCH: A Framework for Analyzing Private Blockchains

  Blockchain technologies are taking the world by storm. Public blockchains,such as Bitcoin and Ethereum, enable secure peer-to-peer applications likecrypto-currency or smart contracts. Their security and performance are wellstudied. This paper concerns recent private blockchain systems designed withstronger security (trust) assumption and performance requirement. These systemstarget and aim to disrupt applications which have so far been implemented ontop of database systems, for example banking, finance applications. Multipleplatforms for private blockchains are being actively developed and fine tuned.However, there is a clear lack of a systematic framework with which differentsystems can be analyzed and compared against each other. Such a framework canbe used to assess blockchains' viability as another distributed data processingplatform, while helping developers to identify bottlenecks and accordinglyimprove their platforms.  In this paper, we first describe BlockBench, the first evaluation frameworkfor analyzing private blockchains. It serves as a fair means of comparison fordifferent platforms and enables deeper understanding of different system designchoices. Any private blockchain can be integrated to BlockBench via simple APIsand benchmarked against workloads that are based on real and synthetic smartcontracts. BlockBench measures overall and component-wise performance in termsof throughput, latency, scalability and fault-tolerance. Next, we useBlockBench to conduct comprehensive evaluation of three major privateblockchains: Ethereum, Parity and Hyperledger Fabric. The results demonstratethat these systems are still far from displacing current database systems intraditional data processing workloads. Furthermore, there are gaps inperformance among the three systems which are attributed to the design choicesat different layers of the software stack.

Insight-HXMT observations of the first binary neutron star merger  GW170817

  Finding the electromagnetic (EM) counterpart of binary compact star merger,especially the binary neutron star (BNS) merger, is critically important forgravitational wave (GW) astronomy, cosmology and fundamental physics. On Aug.17, 2017, Advanced LIGO and \textit{Fermi}/GBM independently triggered thefirst BNS merger, GW170817, and its high energy EM counterpart, GRB 170817A,respectively, resulting in a global observation campaign covering gamma-ray,X-ray, UV, optical, IR, radio as well as neutrinos. The High Energy X-raytelescope (HE) onboard \textit{Insight}-HXMT (Hard X-ray Modulation Telescope)is the unique high-energy gamma-ray telescope that monitored the entire GWlocalization area and especially the optical counterpart (SSS17a/AT2017gfo)with very large collection area ($\sim$1000 cm$^2$) and microsecond timeresolution in 0.2-5 MeV. In addition, \textit{Insight}-HXMT quickly implementeda Target of Opportunity (ToO) observation to scan the GW localization area forpotential X-ray emission from the GW source. Although it did not detect anysignificant high energy (0.2-5 MeV) radiation from GW170817, its observationhelped to confirm the unexpected weak and soft nature of GRB 170817A.Meanwhile, \textit{Insight}-HXMT/HE provides one of the most stringentconstraints (~10$^{-7}$ to 10$^{-6}$ erg/cm$^2$/s) for both GRB170817A and anyother possible precursor or extended emissions in 0.2-5 MeV, which help us tobetter understand the properties of EM radiation from this BNS merger.Therefore the observation of \textit{Insight}-HXMT constitutes an importantchapter in the full context of multi-wavelength and multi-messenger observationof this historical GW event.

The enhanced X-ray Timing and Polarimetry mission - eXTP

  In this paper we present the enhanced X-ray Timing and Polarimetry mission -eXTP. eXTP is a space science mission designed to study fundamental physicsunder extreme conditions of density, gravity and magnetism. The mission aims atdetermining the equation of state of matter at supra-nuclear density, measuringeffects of QED, and understanding the dynamics of matter in strong-fieldgravity. In addition to investigating fundamental physics, eXTP will be a verypowerful observatory for astrophysics that will provide observations ofunprecedented quality on a variety of galactic and extragalactic objects. Inparticular, its wide field monitoring capabilities will be highly instrumentalto detect the electro-magnetic counterparts of gravitational wave sources. Thepaper provides a detailed description of: (1) the technological and technicalaspects, and the expected performance of the instruments of the scientificpayload; (2) the elements and functions of the mission, from the spacecraft tothe ground segment.

