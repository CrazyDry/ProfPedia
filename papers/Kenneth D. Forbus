Neural Symbolic Machines: Learning Semantic Parsers on Freebase with  Weak Supervision

  Harnessing the statistical power of neural networks to perform languageunderstanding and symbolic reasoning is difficult, when it requires executingefficient discrete operations against a large knowledge-base. In this work, weintroduce a Neural Symbolic Machine, which contains (a) a neural "programmer",i.e., a sequence-to-sequence model that maps language utterances to programsand utilizes a key-variable memory to handle compositionality (b) a symbolic"computer", i.e., a Lisp interpreter that performs program execution, and helpsfind good programs by pruning the search space. We apply REINFORCE to directlyoptimize the task reward of this structured prediction problem. To train withweak supervision and improve the stability of REINFORCE, we augment it with aniterative maximum-likelihood training process. NSM outperforms thestate-of-the-art on the WebQuestionsSP dataset when trained fromquestion-answer pairs only, without requiring any feature engineering ordomain-specific knowledge.

Neural Symbolic Machines: Learning Semantic Parsers on Freebase with  Weak Supervision (Short Version)

  Extending the success of deep neural networks to natural languageunderstanding and symbolic reasoning requires complex operations and externalmemory. Recent neural program induction approaches have attempted to addressthis problem, but are typically limited to differentiable memory, andconsequently cannot scale beyond small synthetic tasks. In this work, wepropose the Manager-Programmer-Computer framework, which integrates neuralnetworks with non-differentiable memory to support abstract, scalable andprecise operations through a friendly neural computer interface. Specifically,we introduce a Neural Symbolic Machine, which contains a sequence-to-sequenceneural "programmer", and a non-differentiable "computer" that is a Lispinterpreter with code assist. To successfully apply REINFORCE for training, weaugment it with approximate gold programs found by an iterative maximumlikelihood training process. NSM is able to learn a semantic parser from weaksupervision over a large knowledge base. It achieves new state-of-the-artperformance on WebQuestionsSP, a challenging semantic parsing dataset, withweak supervision. Compared to previous approaches, NSM is end-to-end, thereforedoes not rely on feature engineering or domain specific knowledge.

