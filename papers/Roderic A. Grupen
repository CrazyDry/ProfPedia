Intrinsically Motivated Multimodal Structure Learning

  We present a long-term intrinsically motivated structure learning method formodeling transition dynamics during controlled interactions between a robot andsemi-permanent structures in the world. In particular, we discuss howpartially-observable state is represented using distributions over a Markovianstate and build models of objects that predict how state distributions changein response to interactions with such objects. These structures serve as thebasis for a number of possible future tasks defined as Markov DecisionProcesses (MDPs). The approach is an example of a structure learning techniqueapplied to a multimodal affordance representation that yields a population offorward models for use in planning. We evaluate the approach using experimentson a bimanual mobile manipulator (uBot-6) that show the performance of modelacquisition as the number of transition actions increases.

