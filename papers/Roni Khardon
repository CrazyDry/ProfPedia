Stochastic Planning and Lifted Inference

  Lifted probabilistic inference (Poole, 2003) and symbolic dynamic programmingfor lifted stochastic planning (Boutilier et al, 2001) were introduced aroundthe same time as algorithmic efforts to use abstraction in stochastic systems.Over the years, these ideas evolved into two distinct lines of research, eachsupported by a rich literature. Lifted probabilistic inference focused onefficient arithmetic operations on template-based graphical models under afinite domain assumption while symbolic dynamic programming focused onsupporting sequential decision-making in rich quantified logical action modelsand on open domain reasoning. Given their common motivation but different focalpoints, both lines of research have yielded highly complementary innovations.In this chapter, we aim to help close the gap between these two research areasby providing an overview of lifted stochastic planning from the perspective ofprobabilistic inference, showing strong connections to other chapters in thisbook. This also allows us to define Generalized Lifted Inference as a paradigmthat unifies these areas and elucidates open problems for future research thatcan benefit both lifted inference and stochastic planning.

Solving Relational MDPs with Exogenous Events and Additive Rewards

  We formalize a simple but natural subclass of service domains for relationalplanning problems with object-centered, independent exogenous events andadditive rewards capturing, for example, problems in inventory control.Focusing on this subclass, we present a new symbolic planning algorithm whichis the first algorithm that has explicit performance guarantees for relationalMDPs with exogenous events. In particular, under some technical conditions, ourplanning algorithm provides a monotonic lower bound on the optimal valuefunction. To support this algorithm we present novel evaluation and reductiontechniques for generalized first order decision diagrams, a knowledgerepresentation for real-valued functions over relational world states. Ourplanning algorithm uses a set of focus states, which serves as a training set,to simplify and approximate the symbolic solution, and can thus be seen toperform learning for planning. A preliminary experimental evaluationdemonstrates the validity of our approach.

The Complexity of Reasoning with FODD and GFODD

  Recent work introduced Generalized First Order Decision Diagrams (GFODD) as aknowledge representation that is useful in mechanizing decision theoreticplanning in relational domains. GFODDs generalize function-free first orderlogic and include numerical values and numerical generalizations of existentialand universal quantification. Previous work presented heuristic inferencealgorithms for GFODDs and implemented these heuristics in systems for decisiontheoretic planning. In this paper, we study the complexity of the computationalproblems addressed by such implementations. In particular, we study theevaluation problem, the satisfiability problem, and the equivalence problem forGFODDs under the assumption that the size of the intended model is given withthe problem, a restriction that guarantees decidability. Our results provide acomplete characterization placing these problems within the polynomialhierarchy. The same characterization applies to the corresponding restrictionof problems in first order logic, giving an interesting new avenue forefficient inference when the number of objects is bounded. Our results showthat for $\Sigma_k$ formulas, and for corresponding GFODDs, evaluation andsatisfiability are $\Sigma_k^p$ complete, and equivalence is $\Pi_{k+1}^p$complete. For $\Pi_k$ formulas evaluation is $\Pi_k^p$ complete, satisfiabilityis one level higher and is $\Sigma_{k+1}^p$ complete, and equivalence is$\Pi_{k+1}^p$ complete.

First Order Decision Diagrams for Relational MDPs

  Markov decision processes capture sequential decision making underuncertainty, where an agent must choose actions so as to optimize long termreward. The paper studies efficient reasoning mechanisms for Relational MarkovDecision Processes (RMDP) where world states have an internal relationalstructure that can be naturally described in terms of objects and relationsamong them. Two contributions are presented. First, the paper develops FirstOrder Decision Diagrams (FODD), a new compact representation for functions overrelational structures, together with a set of operators to combine FODDs, andnovel reduction techniques to keep the representation small. Second, the papershows how FODDs can be used to develop solutions for RMDPs, where reasoning isperformed at the abstract level and the resulting optimal policy is independentof domain size (number of objects) or instantiation. In particular, a variantof the value iteration algorithm is developed by using special operations overFODDs, and the algorithm is shown to converge to the optimal policy.

Policy Iteration for Relational MDPs

  Relational Markov Decision Processes are a useful abstraction for complexreinforcement learning problems and stochastic planning problems. Recent workdeveloped representation schemes and algorithms for planning in such problemsusing the value iteration algorithm. However, exact versions of more complexalgorithms, including policy iteration, have not been developed or analyzed.The paper investigates this potential and makes several contributions. First weobserve two anomalies for relational representations showing that the value ofsome policies is not well defined or cannot be calculated for restrictedrepresentation schemes used in the literature. On the other hand, we develop avariant of policy iteration that can get around these anomalies. The algorithmincludes an aspect of policy improvement in the process of policy evaluationand thus differs from the original algorithm. We show that despite thisdifference the algorithm converges to the optimal policy.

Nonparametric Bayesian Mixed-effect Model: a Sparse Gaussian Process  Approach

  Multi-task learning models using Gaussian processes (GP) have been developedand successfully applied in various applications. The main difficulty with thisapproach is the computational cost of inference using the union of examplesfrom all tasks. Therefore sparse solutions, that avoid using the entire datadirectly and instead use a set of informative "representatives" are desirable.The paper investigates this problem for the grouped mixed-effect GP model whereeach individual response is given by a fixed-effect, taken from one of a set ofunknown groups, plus a random individual effect function that capturesvariations among individuals. Such models have been widely used in previouswork but no sparse solutions have been developed. The paper presents the firstsparse solution for such problems, showing how the sparse approximation can beobtained by maximizing a variational lower bound on the marginal likelihood,generalizing ideas from single-task Gaussian processes to handle themixed-effect model as well as grouping. Experiments using artificial and realdata validate the approach showing that it can recover the performance ofinference with the full sample, that it outperforms baseline methods, and thatit outperforms state of the art sparse solutions for other multi-task GPformulations.

Online Learning with Pairwise Loss Functions

  Efficient online learning with pairwise loss functions is a crucial componentin building large-scale learning system that maximizes the area under theReceiver Operator Characteristic (ROC) curve. In this paper we investigate thegeneralization performance of online learning algorithms with pairwise lossfunctions. We show that the existing proof techniques for generalization boundsof online algorithms with a univariate loss can not be directly applied topairwise losses. In this paper, we derive the first result providingdata-dependent bounds for the average risk of the sequence of hypothesesgenerated by an arbitrary online learner in terms of an easily computablestatistic, and show how to extract a low risk hypothesis from the sequence. Wedemonstrate the generality of our results by applying it to two importantproblems in machine learning. First, we analyze two online algorithms forbipartite ranking; one being a natural extension of the perceptron algorithmand the other using online convex optimization. Secondly, we provide ananalysis for the risk bound for an online algorithm for supervised metriclearning.

Probabilistic Relational Planning with First Order Decision Diagrams

  Dynamic programming algorithms have been successfully applied topropositional stochastic planning problems by using compact representations, inparticular algebraic decision diagrams, to capture domain dynamics and valuefunctions. Work on symbolic dynamic programming lifted these ideas to firstorder logic using several representation schemes. Recent work introduced afirst order variant of decision diagrams (FODD) and developed a value iterationalgorithm for this representation. This paper develops several improvements tothe FODD algorithm that make the approach practical. These include, newreduction operators that decrease the size of the representation, severalspeedup techniques, and techniques for value approximation. Incorporatingthese, the paper presents a planning system, FODD-Planner, for solvingrelational stochastic planning problems. The system is evaluated on severaldomains, including problems from the recent international planning competition,and shows competitive performance with top ranking systems. This is the firstdemonstration of feasibility of this approach and it shows that abstractionthrough compact representation is a promising approach to stochastic planning.

Monte Carlo Structured SVI for Two-Level Non-Conjugate Models

  The stochastic variational inference (SVI) paradigm, which combinesvariational inference, natural gradients, and stochastic updates, was recentlyproposed for large-scale data analysis in conjugate Bayesian models anddemonstrated to be effective in several problems. This paper studies a familyof Bayesian latent variable models with two levels of hidden variables butwithout any conjugacy requirements, making several contributions in thiscontext. The first is observing that SVI, with an improved structuredvariational approximation, is applicable under more general conditions thanpreviously thought with the only requirement being that the approximatingvariational distribution be in the same family as the prior. The resultingapproach, Monte Carlo Structured SVI (MC-SSVI), significantly extends the scopeof SVI, enabling large-scale learning in non-conjugate models. For models withlatent Gaussian variables we propose a hybrid algorithm, using both standardand natural gradients, which is shown to improve stability and convergence.Applications in mixed effects models, sparse Gaussian processes, probabilisticmatrix factorization and correlated topic models demonstrate the generality ofthe approach and the advantages of the proposed algorithms.

QSO Selection Algorithm Using Time Variability and Machine Learning:  Selection of 1,620 QSO Candidates from MACHO LMC Database

  We present a new QSO selection algorithm using a Support Vector Machine(SVM), a supervised classification method, on a set of extracted times seriesfeatures including period, amplitude, color, and autocorrelation value. Wetrain a model that separates QSOs from variable stars, non-variable stars andmicrolensing events using 58 known QSOs, 1,629 variable stars and 4,288non-variables using the MAssive Compact Halo Object (MACHO) database as atraining set. To estimate the efficiency and the accuracy of the model, weperform a cross-validation test using the training set. The test shows that themodel correctly identifies ~80% of known QSOs with a 25% false positive rate.The majority of the false positives are Be stars.  We applied the trained model to the MACHO Large Magellanic Cloud (LMC)dataset, which consists of 40 million lightcurves, and found 1,620 QSOcandidates. During the selection none of the 33,242 known MACHO variables weremisclassified as QSO candidates. In order to estimate the true false positiverate, we crossmatched the candidates with astronomical catalogs including theSpitzer Surveying the Agents of a Galaxy's Evolution (SAGE) LMC catalog and afew X-ray catalogs. The results further suggest that the majority of thecandidates, more than 70%, are QSOs.

A Refined QSO Selection Method Using Diagnostics Tests: 663 QSO  Candidates in the LMC

  We present 663 QSO candidates in the Large Magellanic Cloud (LMC) selectedusing multiple diagnostics. We started with a set of 2,566 QSO candidates fromour previous work selected using time variability of the MACHO LMC lightcurves.We then obtained additional information for the candidates by crossmatchingthem with the Spitzer SAGE, the MACHO UBVI, the 2MASS, the Chandra and the XMMcatalogs. Using this information, we specified six diagnostic features based onmid-IR colors, photometric redshifts using SED template fitting, and X-rayluminosities in order to further discriminate high confidence QSO candidates inthe absence of spectra information. We then trained a one-class SVM (SupportVector Machine) model using the diagnostics features of the confirmed 58 MACHOQSOs. We applied the trained model to the original candidates and finallyselected 663 high confidence QSO candidates. Furthermore, we crossmatched these663 QSO candidates with the newly confirmed 144 QSOs and 275 non-QSOs in theLMC fields. On the basis of the counterpart analysis, we found that the falsepositive rate is less than 1%.

Nonparametric Bayesian Estimation of Periodic Functions

  Many real world problems exhibit patterns that have periodic behavior. Forexample, in astrophysics, periodic variable stars play a pivotal role inunderstanding our universe. An important step when analyzing data from suchprocesses is the problem of identifying the period: estimating the period of aperiodic function based on noisy observations made at irregularly spaced timepoints. This problem is still a difficult challenge despite extensive study indifferent disciplines. The paper makes several contributions toward solvingthis problem. First, we present a nonparametric Bayesian model for periodfinding, based on Gaussian Processes (GP), that does not make strongassumptions on the shape of the periodic function. As our experimentsdemonstrate, the new model leads to significantly better results in periodestimation when the target function is non-sinusoidal. Second, we develop a newalgorithm for parameter optimization for GP which is useful when the likelihoodfunction is very sensitive to the setting of the hyper-parameters with numerouslocal minima, as in the case of period estimation. The algorithm combinesgradient optimization with grid search and incorporates several mechanisms toovercome the high complexity of inference with GP. Third, we develop a novelapproach for using domain knowledge, in the form of a probabilistic generativemodel, and incorporate it into the period estimation algorithm. Experimentalresults on astrophysics data validate our approach showing significantimprovement over the state of the art in this domain.

Infinite Shift-invariant Grouped Multi-task Learning for Gaussian  Processes

  Multi-task learning leverages shared information among data sets to improvethe learning performance of individual tasks. The paper applies this frameworkfor data where each task is a phase-shifted periodic time series. Inparticular, we develop a novel Bayesian nonparametric model capturing a mixtureof Gaussian processes where each task is a sum of a group-specific function anda component capturing individual variation, in addition to each task beingphase shifted. We develop an efficient \textsc{em} algorithm to learn theparameters of the model. As a special case we obtain the Gaussian mixture modeland \textsc{em} algorithm for phased-shifted periodic time series. Furthermore,we extend the proposed model by using a Dirichlet Process prior and therebyleading to an infinite mixture model that is capable of doing automatic modelselection. A Variational Bayesian approach is developed for inference in thismodel. Experiments in regression, classification and class discoverydemonstrate the performance of the proposed models using both synthetic dataand real-world time series data from astrophysics. Our methods are particularlyuseful when the time series are sparsely and non-synchronously sampled.

