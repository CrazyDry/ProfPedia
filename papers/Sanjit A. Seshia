Towards Verified Artificial Intelligence

  Verified artificial intelligence (AI) is the goal of designing AI-basedsystems that are provably correct with respect to mathematically-specifiedrequirements. This paper considers Verified AI from a formal methodsperspective. We describe five challenges for achieving Verified AI, and fivecorresponding principles for addressing these challenges.

Sciduction: Combining Induction, Deduction, and Structure for  Verification and Synthesis

  Even with impressive advances in automated formal methods, certain problemsin system verification and synthesis remain challenging. Examples include theverification of quantitative properties of software involving constraints ontiming and energy consumption, and the automatic synthesis of systems fromspecifications. The major challenges include environment modeling,incompleteness in specifications, and the complexity of underlying decisionproblems.  This position paper proposes sciduction, an approach to tackle thesechallenges by integrating inductive inference, deductive reasoning, andstructure hypotheses. Deductive reasoning, which leads from general rules orconcepts to conclusions about specific problem instances, includes techniquessuch as logical inference and constraint solving. Inductive inference, whichgeneralizes from specific instances to yield a concept, includes algorithmiclearning from examples. Structure hypotheses are used to define the class ofartifacts, such as invariants or program fragments, generated duringverification or synthesis. Sciduction constrains inductive and deductivereasoning using structure hypotheses, and actively combines inductive anddeductive reasoning: for instance, deductive techniques generate examples forlearning, and inductive reasoning is used to guide the deductive engines.  We illustrate this approach with three applications: (i) timing analysis ofsoftware; (ii) synthesis of loop-free programs, and (iii) controller synthesisfor hybrid systems. Some future applications are also discussed.

A Formalization of Robustness for Deep Neural Networks

  Deep neural networks have been shown to lack robustness to small inputperturbations. The process of generating the perturbations that expose the lackof robustness of neural networks is known as adversarial input generation. Thisprocess depends on the goals and capabilities of the adversary, In this paper,we propose a unifying formalization of the adversarial input generation processfrom a formal methods perspective. We provide a definition of robustness thatis general enough to capture different formulations. The expressiveness of ourformalization is shown by modeling and comparing a variety of adversarialattack techniques.

Language to Specify Syntax-Guided Synthesis Problems

  We present a language to specify syntax guided synthesis (SyGuS) problems.Syntax guidance is a prominent theme in contemporary program synthesisapproaches, and SyGuS was first described in [1]. This paper describesconcretely the input format of a SyGuS solver.  [1] Rajeev Alur, Rastislav Bodik, Garvit Juniwal, Milo M. K. Martin, MukundRaghothaman, Sanjit A. Seshia, Rishabh Singh, Armando Solar-Lezama, EminaTorlak, and Abhishek Udupa. Syntax-guided synthesis. In FMCAD, pages 1--17,2013.

Model Predictive Control for Signal Temporal Logic Specification

  We present a mathematical programming-based method for model predictivecontrol of cyber-physical systems subject to signal temporal logic (STL)specifications. We describe the use of STL to specify a wide range ofproperties of these systems, including safety, response and bounded liveness.For synthesis, we encode STL specifications as mixed integer-linear constraintson the system variables in the optimization problem at each step of a recedinghorizon control framework. We prove correctness of our algorithms, and presentexperimental results for controller synthesis for building energy and climatecontrol.

Systematic Testing of Convolutional Neural Networks for Autonomous  Driving

  We present a framework to systematically analyze convolutional neuralnetworks (CNNs) used in classification of cars in autonomous vehicles. Ouranalysis procedure comprises an image generator that produces syntheticpictures by sampling in a lower dimension image modification subspace and asuite of visualization tools. The image generator produces images which can beused to test the CNN and hence expose its vulnerabilities. The presentedframework can be used to extract insights of the CNN classifier, compare acrossclassification models, or generate training and validation datasets.

Learning Heuristics for Automated Reasoning through Deep Reinforcement  Learning

  We demonstrate how to learn efficient heuristics for automated reasoningalgorithms through deep reinforcement learning. We consider search algorithmsfor quantified Boolean logics, that already can solve formulas of impressivesize - up to 100s of thousands of variables. The main challenge is to find arepresentation which lends to making predictions in a scalable way. Theheuristics learned through our approach significantly improve over thehandwritten heuristics for several sets of formulas.

A Model Counter's Guide to Probabilistic Systems

  In this paper, we systematize the modeling of probabilistic systems for thepurpose of analyzing them with model counting techniques. Starting fromunbiased coin flips, we show how to model biased coins, correlated coins, anddistributions over finite sets. From there, we continue with modelingsequential systems, such as Markov chains, and revisit the relationship betweenweighted and unweighted model counting. Thereby, this work provides aconceptual framework for deriving #SAT encodings for probabilistic inference.

Deciding Quantifier-Free Presburger Formulas Using Parameterized  Solution Bounds

  Given a formula in quantifier-free Presburger arithmetic, if it has asatisfying solution, there is one whose size, measured in bits, is polynomiallybounded in the size of the formula. In this paper, we consider a special classof quantifier-free Presburger formulas in which most linear constraints aredifference (separation) constraints, and the non-difference constraints aresparse. This class has been observed to commonly occur in softwareverification. We derive a new solution bound in terms of parameterscharacterizing the sparseness of linear constraints and the number ofnon-difference constraints, in addition to traditional measures of formulasize. In particular, we show that the number of bits needed per integervariable is linear in the number of non-difference constraints and logarithmicin the number and size of non-zero coefficients in them, but is otherwiseindependent of the total number of linear constraints in the formula. Thederived bound can be used in a decision procedure based on instantiatinginteger variables over a finite domain and translating the inputquantifier-free Presburger formula to an equi-satisfiable Boolean formula,which is then checked using a Boolean satisfiability solver. In addition to ourmain theoretical result, we discuss several optimizations for deriving tighterbounds in practice. Empirical evidence indicates that our decision procedurecan greatly outperform other decision procedures.

Distribution-Aware Sampling and Weighted Model Counting for SAT

  Given a CNF formula and a weight for each assignment of values to variables,two natural problems are weighted model counting and distribution-awaresampling of satisfying assignments. Both problems have a wide variety ofimportant applications. Due to the inherent complexity of the exact versions ofthe problems, interest has focused on solving them approximately. Prior work inthis area scaled only to small problems in practice, or failed to providestrong theoretical guarantees, or employed a computationally-expensive maximuma posteriori probability (MAP) oracle that assumes prior knowledge of afactored representation of the weight distribution. We present a novel approachthat works with a black-box oracle for weights of assignments and requires onlyan {\NP}-oracle (in practice, a SAT-solver) to solve both the counting andsampling problems. Our approach works under mild assumptions on thedistribution of weights of satisfying assignments, provides strong theoreticalguarantees, and scales to problems involving several thousand variables. Wealso show that the assumptions can be significantly relaxed while improvingcomputational efficiency if a factored representation of the weights is known.

Automatic Generation of Communication Requirements for Enforcing  Multi-Agent Safety

  Distributed controllers are often necessary for a multi-agent system tosatisfy safety properties such as collision avoidance. Communication andcoordination are key requirements in the implementation of a distributedcontrol protocol, but maintaining an all-to-all communication topology isunreasonable and not always necessary. Given a safety objective and acontroller implementation, we consider the problem of identifying when agentsneed to communicate with one another and coordinate their actions to satisfythe safety constraint. We define a coordination-free controllable predecessoroperator that is used to derive a subset of the state space that allows agentsto act independently, without consulting other agents to double check that theaction is safe. Applications are shown for identifying an upper bound onconnection delays and a self-triggered coordination scheme. Examples areprovided which showcase the potential for designers to visually interpret asystem's ability to tolerate delays when initializing a network connection.

A Learning Based Approach to Control Synthesis of Markov Decision  Processes for Linear Temporal Logic Specifications

  We propose to synthesize a control policy for a Markov decision process (MDP)such that the resulting traces of the MDP satisfy a linear temporal logic (LTL)property. We construct a product MDP that incorporates a deterministic Rabinautomaton generated from the desired LTL property. The reward function of theproduct MDP is defined from the acceptance condition of the Rabin automaton.This construction allows us to apply techniques from learning theory to theproblem of synthesis for LTL specifications even when the transitionprobabilities are not known a priori. We prove that our method is guaranteed tofind a controller that satisfies the LTL property with probability one if sucha policy exists, and we suggest empirically with a case study in trafficcontrol that our method produces reasonable control strategies even when theLTL property cannot be satisfied with probability one.

On Systematic Testing for Execution-Time Analysis

  Given a program and a time deadline, does the program finish before thedeadline when executed on a given platform? With the requirement to produce atest case when such a violation can occur, we refer to this problem as theworst-case execution-time testing (WCETT) problem.  In this paper, we present an approach for solving the WCETT problem forloop-free programs by timing the execution of a program on a small number ofcarefully calculated inputs. We then create a sequence of integer linearprograms the solutions of which encode the best timing model consistent withthe measurements. By solving the programs we can find the worst-case input aswell as estimate execution time of any other input. Our solution is moreaccurate than previous approaches and, unlikely previous work, by increasingthe number of measurements we can produce WCETT bounds up to any desiredaccuracy.  Timing of a program depends on the properties of the platform it executes on.We further show how our approach can be used to quantify the timingrepeatability of the underlying platform.

Context-Specific Validation of Data-Driven Models

  With an increasing use of data-driven models to control robotic systems, ithas become important to develop a methodology for validating such models beforethey can be deployed to design a controller for the actual system.Specifically, it must be ensured that the controller designed for a learnedmodel would perform as expected on the actual physical system. We propose acontext-specific validation framework to quantify the quality of a learnedmodel based on a distance measure between the closed-loop actual system and thelearned model. We then propose an active sampling scheme to compute aprobabilistic upper bound on this distance in a sample-efficient manner. Theproposed framework validates the learned model against only those behaviors ofthe system that are relevant for the purpose for which we intend to use thismodel, and does not require any a priori knowledge of the system dynamics.Several simulations illustrate the practicality of the proposed framework forvalidating the models of real-world systems, and consequently, for controllersynthesis.

Control Improvisation

  We formalize and analyze a new problem in formal language theory termedcontrol improvisation. Given a specification language, the problem is toproduce an improviser, a probabilistic algorithm that randomly generates wordsin the language, subject to two additional constraints: the satisfaction of aquantitative soft constraint, and the exhibition of a specified amount ofrandomness. Control improvisation has many applications, including for examplesystematically generating random test vectors satisfying format constraints orpreconditions while being similar to a library of seed inputs. Otherapplications include robotic surveillance, machine improvisation of music, andrandomized variants of the supervisory control problem. We describe a generalframework for solving the control improvisation problem, and use it to giveefficient algorithms for several practical classes of instances with finiteautomaton and context-free grammar specifications. We also provide a detailedcomplexity analysis, establishing #P-hardness of the problem in many othercases. For these intractable cases, we show how symbolic techniques based onBoolean satisfiability (SAT) solvers can be used to find approximate solutions.Finally, we discuss an extension of control improvisation to multiple softconstraints that is useful in some applications.

On the Computational Complexity of Satisfiability Solving for String  Theories

  Satisfiability solvers are increasingly playing a key role in softwareverification, with particularly effective use in the analysis of securityvulnerabilities. String processing is a key part of many software applications,such as browsers and web servers. These applications are susceptible to attacksthrough malicious data received over network. Automated tools for analyzing thesecurity of such applications, thus need to reason about strings. Forefficiency reasons, it is desirable to have a solver that treats strings asfirst-class types. In this paper, we present some theories of strings that areuseful in a software security context and analyze the computational complexityof the presented theories. We use this complexity analysis to motivate abyte-blast approach which employs a Boolean encoding of the string constraintsto a corresponding Boolean satisfiability problem.

Robust Online Monitoring of Signal Temporal Logic

  Signal Temporal Logic (STL) is a formalism used to rigorously specifyrequirements of cyberphysical systems (CPS), i.e., systems mixing digital ordiscrete components in interaction with a continuous environment or analog com-ponents. STL is naturally equipped with a quantitative semantics which can beused for various purposes: from assessing the robustness of a specification toguiding searches over the input and parameter space with the goal of falsifyingthe given property over system behaviors. Algorithms have been proposed andimplemented for offline computation of such quantitative semantics, but onlyfew methods exist for an online setting, where one would want to monitor thesatisfaction of a formula during simulation. In this paper, we formalize asemantics for robust online monitoring of partial traces, i.e., traces forwhich there might not be enough data to decide the Boolean satisfaction (and tocompute its quantitative counterpart). We propose an efficient algorithm tocompute it and demonstrate its usage on two large scale real-world case studiescoming from the automotive domain and from CPS education in a Massively OpenOnline Course (MOOC) setting. We show that savings in computationally expensivesimulations far outweigh any overheads incurred by an online approach.

Robust Subspace System Identification via Weighted Nuclear Norm  Optimization

  Subspace identification is a classical and very well studied problem insystem identification. The problem was recently posed as a convex optimizationproblem via the nuclear norm relaxation. Inspired by robust PCA, we extend thisframework to handle outliers. The proposed framework takes the form of a convexoptimization problem with an objective that trades off fit, rank and sparsity.As in robust PCA, it can be problematic to find a suitable regularizationparameter. We show how the space in which a suitable parameter should be soughtcan be limited to a bounded open set of the two dimensional parameter space. Inpractice, this is very useful since it restricts the parameter space that isneeded to be surveyed.

Speeding Up SMT-Based Quantitative Program Analysis

  Quantitative program analysis involves computing numerical quantities aboutindividual or collections of program executions. An example of such acomputation is quantitative information flow analysis, where one estimates theamount of information leaked about secret data through a program's outputchannels. Such information can be quantified in several ways, including channelcapacity and (Shannon) entropy. In this paper, we formalize a class ofquantitative analysis problems defined over a weighted control flow graph of aloop-free program. These problems can be solved using a combination of pathenumeration, SMT solving, and model counting. However, existing methods canonly handle very small programs, primarily because the number of executionpaths can be exponential in the program size. We show how path explosion can bemitigated in some practical cases by taking advantage of special branchingstructure and by novel algorithm design. We demonstrate our techniques bycomputing the channel capacities of the timing side-channels of two programswith extremely large numbers of paths.

Compositional Falsification of Cyber-Physical Systems with Machine  Learning Components

  Cyber-physical systems (CPS), such as automotive systems, are starting toinclude sophisticated machine learning (ML) components. Their correctness,therefore, depends on properties of the inner ML modules. While learningalgorithms aim to generalize from examples, they are only as good as theexamples provided, and recent efforts have shown that they can produceinconsistent output under small adversarial perturbations. This raises thequestion: can the output from learning components can lead to a failure of theentire CPS? In this work, we address this question by formulating it as aproblem of falsifying signal temporal logic (STL) specifications for CPS withML components. We propose a compositional falsification framework where atemporal logic falsifier and a machine learning analyzer cooperate with the aimof finding falsifying executions of the considered model. The efficacy of theproposed technique is shown on an automatic emergency braking system model witha perception component based on deep neural networks.

Tunable Reactive Synthesis for Lipschitz-Bounded Systems with Temporal  Logic Specifications

  We address the problem of synthesizing reactive controllers forcyber-physical systems subject to Signal Temporal Logic (STL) specifications inthe presence of adversarial inputs. Given a finite horizon, we define areactive hierarchy of control problems that differ in the degree of informationavailable to the system about the adversary's actions over the horizon. We showhow to construct reactive controllers at various levels of the hierarchy,leveraging the existence of Lipschitz bounds on system dynamics and thequantitative semantics of STL. Our approach, a counterexample-guided inductivesynthesis (CEGIS) scheme based on optimization and satisfiability modulotheories (SMT) solving, builds a strategy tree representing the interactionbetween the system and its environment. In every iteration of the CEGIS loop,we use a mix of optimization and SMT to maximally discard controllers falsifiedby a given counterexample. Our approach can be applied to any system with localLipschitz-bounded dynamics, including linear, piecewise-linear anddifferentially-flat systems. Finally we show an application in the autonomouscar domain.

Time Series Learning using Monotonic Logical Properties

  Cyber-physical systems of today are generating large volumes of time-seriesdata. As manual inspection of such data is not tractable, the need for learningmethods to help discover logical structure in the data has increased. Wepropose a logic-based framework that allows domain-specific knowledge to beembedded into formulas in a parametric logical specification over time-seriesdata. The key idea is to then map a time series to a surface in the parameterspace of the formula. Given this mapping, we identify the Hausdorff distancebetween boundaries as a natural distance metric between two time-series dataunder the lens of the parametric specification. This enables embeddingnon-trivial domain-specific knowledge into the distance metric and then usingoff-the-shelf machine learning tools to label the data. After labeling thedata, we demonstrate how to extract a logical specification for each label.Finally, we showcase our technique on real world traffic data to learnclassifiers/monitors for slow-downs and traffic jams.

A Satisfiability Modulo Theory Approach to Secure State Reconstruction  in Differentially Flat Systems Under Sensor Attacks

  We address the problem of estimating the state of a differentially flatsystem from measurements that may be corrupted by an adversarial attack. Incyber-physical systems, malicious attacks can directly compromise the system'ssensors or manipulate the communication between sensors and controllers. Weconsider attacks that only corrupt a subset of sensor measurements. We showthat the possibility of reconstructing the state under such attacks ischaracterized by a suitable generalization of the notion of s-sparseobservability, previously introduced by some of the authors in the linear case.We also extend our previous work on the use of Satisfiability Modulo Theorysolvers to estimate the state under sensor attacks to the context ofdifferentially flat systems. The effectiveness of our approach is illustratedon the problem of controlling a quadrotor under sensor attacks.

Control Improvisation with Probabilistic Temporal Specifications

  We consider the problem of generating randomized control sequences forcomplex networked systems typically actuated by human agents. Our approachleverages a concept known as control improvisation, which is based on acombination of data-driven learning and controller synthesis from formalspecifications. We learn from existing data a generative model (for instance,an explicit-duration hidden Markov model, or EDHMM) and then supervise thismodel in order to guarantee that the generated sequences satisfy some desirablespecifications given in Probabilistic Computation Tree Logic (PCTL). We presentan implementation of our approach and apply it to the problem of mimicking theuse of lighting appliances in a residential unit, with potential applicationsto home security and resource management. We present experimental resultsshowing that our approach produces realistic control sequences, similar torecorded data based on human actuation, while satisfying suitable formalrequirements.

Diagnosis and Repair for Synthesis from Signal Temporal Logic  Specifications

  We address the problem of diagnosing and repairing specifications for hybridsystems formalized in signal temporal logic (STL). Our focus is on the settingof automatic synthesis of controllers in a model predictive control (MPC)framework. We build on recent approaches that reduce the controller synthesisproblem to solving one or more mixed integer linear programs (MILPs), whereinfeasibility of a MILP usually indicates unrealizability of the controllersynthesis problem. Given an infeasible STL synthesis problem, we presentalgorithms that provide feedback on the reasons for unrealizability, andsuggestions for making it realizable. Our algorithms are sound and complete,i.e., they provide a correct diagnosis, and always terminate with a non-trivialspecification that is feasible using the chosen synthesis method, when such asolution exists. We demonstrate the effectiveness of our approach on thesynthesis of controllers for various cyber-physical systems, including anautonomous driving application and an aircraft electric power system.

Unsupervised Domain Adaptation: from Simulation Engine to the RealWorld

  Large-scale labeled training datasets have enabled deep neural networks toexcel on a wide range of benchmark vision tasks. However, in many applicationsit is prohibitively expensive or time-consuming to obtain large quantities oflabeled data. To cope with limited labeled training data, many have attemptedto directly apply models trained on a large-scale labeled source domain toanother sparsely labeled target domain. Unfortunately, direct transfer acrossdomains often performs poorly due to domain shift and dataset bias. Domainadaptation is the machine learning paradigm that aims to learn a model from asource domain that can perform well on a different (but related) target domain.In this paper, we summarize and compare the latest unsupervised domainadaptation methods in computer vision applications. We classify the non-deepapproaches into sample re-weighting and intermediate subspace transformationcategories, while the deep strategy includes discrepancy-based methods,adversarial generative models, adversarial discriminative models andreconstruction-based methods. We also discuss some potential directions.

Synthesizing Switching Logic to Minimize Long-Run Cost

  Given a multi-modal dynamical system, optimal switching logic synthesisinvolves generating the conditions for switching between the system modes suchthat the resulting hybrid system satisfies a quantitative specification. Weformalize and solve the problem of optimal switching logic synthesis forquantitative specifications over long run behavior. Each trajectory of thesystem, and each state of the system, is associated with a cost. Our goal is tosynthesize a system that minimizes this cost from each initial state. Our papergeneralizes earlier work on synthesis for safety as safety specifications canbe encoded as quantitative specifications. We present an approach forspecifying quantitative measures using reward and penalty functions, andillustrate its effectiveness using several examples. We present an automatedtechnique to synthesize switching logic for such quantitative measures. Ouralgorithm is based on reducing the synthesis problem to an unconstrainednumerical optimization problem which can be solved by any off-the-shelfnumerical optimization engines. We demonstrate the effectiveness of thisapproach with experimental results.

Control Improvisation

  We formalize and analyze a new automata-theoretic problem termed controlimprovisation. Given an automaton, the problem is to produce an improviser, aprobabilistic algorithm that randomly generates words in its language, subjectto two additional constraints: the satisfaction of an admissibility predicate,and the exhibition of a specified amount of randomness. Control improvisationhas multiple applications, including, for example, generating musicalimprovisations that satisfy rhythmic and melodic constraints, whereadmissibility is determined by some bounded divergence from a reference melody.We analyze the complexity of the control improvisation problem, giving caseswhere it is efficiently solvable and cases where it is #P-hard or undecidable.We also show how symbolic techniques based on Boolean satisfiability (SAT)solvers can be used to approximately solve some of the intractable cases.

Secure State Estimation For Cyber Physical Systems Under Sensor Attacks:  A Satisfiability Modulo Theory Approach

  We address the problem of detecting and mitigating the effect of maliciousattacks to the sensors of a linear dynamical system. We develop a novel,efficient algorithm that uses a Satisfiability-Modulo-Theory approach toisolate the compromised sensors and estimate the system state despite thepresence of the attack, thus harnessing the intrinsic combinatorial complexityof the problem. By leveraging results from formal methods over real numbers, weprovide guarantees on the soundness and completeness of our algorithm. We thenreport simulation results to compare its runtime performance with alternativetechniques. Finally, we demonstrate its application to the problem ofcontrolling an unmanned ground vehicle.

Counterexample-Guided Data Augmentation

  We present a novel framework for augmenting data sets for machine learningbased on counterexamples. Counterexamples are misclassified examples that haveimportant properties for retraining and improving the model. Key components ofour framework include a counterexample generator, which produces data itemsthat are misclassified by the model and error tables, a novel data structurethat stores information pertaining to misclassifications. Error tables can beused to explain the model's vulnerabilities and are used to efficientlygenerate counterexamples for augmentation. We show the efficacy of the proposedframework by comparing it to classical augmentation techniques on a case studyof object detection in autonomous driving based on deep neural networks.

SWATI: Synthesizing Wordlengths Automatically Using Testing and  Induction

  In this paper, we present an automated technique SWATI: SynthesizingWordlengths Automatically Using Testing and Induction, which uses a combinationof Nelder-Mead optimization based testing, and induction from examples toautomatically synthesize optimal fixedpoint implementation of numericalroutines. The design of numerical software is commonly done usingfloating-point arithmetic in design-environments such as Matlab. However, thesedesigns are often implemented using fixed-point arithmetic for speed andefficiency reasons especially in embedded systems. The fixed-pointimplementation reduces implementation cost, provides better performance, andreduces power consumption. The conversion from floating-point designs tofixed-point code is subject to two opposing constraints: (i) the word-width offixed-point types must be minimized, and (ii) the outputs of the fixed-pointprogram must be accurate. In this paper, we propose a new solution to thisproblem. Our technique takes the floating-point program, specified accuracy andan implementation cost model and provides the fixed-point program withspecified accuracy and optimal implementation cost. We demonstrate theeffectiveness of our approach on a set of examples from the domain of automatedcontrol, robotics and digital signal processing.

Semantic Adversarial Deep Learning

  Fueled by massive amounts of data, models produced by machine-learning (ML)algorithms, especially deep neural networks, are being used in diverse domainswhere trustworthiness is a concern, including automotive systems, finance,health care, natural language processing, and malware detection. Of particularconcern is the use of ML algorithms in cyber-physical systems (CPS), such asself-driving cars and aviation, where an adversary can cause seriousconsequences. However, existing approaches to generating adversarial examplesand devising robust ML algorithms mostly ignore the semantics and context ofthe overall system containing the ML component. For example, in an autonomousvehicle using deep learning for perception, not every adversarial example forthe neural network might lead to a harmful consequence. Moreover, one may wantto prioritize the search for adversarial examples towards those thatsignificantly modify the desired semantics of the overall system. Along thesame lines, existing algorithms for constructing robust ML algorithms ignorethe specification of the overall system. In this paper, we argue that thesemantics and specification of the overall system has a crucial role to play inthis line of research. We present preliminary research results that supportthis claim.

Constrained Sampling and Counting: Universal Hashing Meets SAT Solving

  Constrained sampling and counting are two fundamental problems in artificialintelligence with a diverse range of applications, spanning probabilisticreasoning and planning to constrained-random verification. While the theory ofthese problems was thoroughly investigated in the 1980s, prior work either didnot scale to industrial size instances or gave up correctness guarantees toachieve scalability. Recently, we proposed a novel approach that combinesuniversal hashing and SAT solving and scales to formulas with hundreds ofthousands of variables without giving up correctness guarantees. This paperprovides an overview of the key ingredients of the approach and discusseschallenges that need to be overcome to handle larger real-world instances.

Logic-based Clustering and Learning for Time-Series Data

  To effectively analyze and design cyberphysical systems (CPS), designerstoday have to combat the data deluge problem, i.e., the burden of processingintractably large amounts of data produced by complex models and experiments.In this work, we utilize monotonic Parametric Signal Temporal Logic (PSTL) todesign features for unsupervised classification of time series data. Thisenables using off-the-shelf machine learning tools to automatically clustersimilar traces with respect to a given PSTL formula. We demonstrate how thistechnique produces interpretable formulas that are amenable to analysis andunderstanding using a few representative examples. We illustrate this with casestudies related to automotive engine testing, highway traffic analysis, andauto-grading massively open online courses.

VERIFAI: A Toolkit for the Design and Analysis of Artificial  Intelligence-Based Systems

  We present VERIFAI, a software toolkit for the formal design and analysis ofsystems that include artificial intelligence (AI) and machine learning (ML)components. VERIFAI particularly seeks to address challenges with applyingformal methods to perception and ML components, including those based on neuralnetworks, and to model and analyze system behavior in the presence ofenvironment uncertainty. We describe the initial version of VERIFAI whichcenters on simulation guided by formal models and specifications. Several usecases are illustrated with examples, including temporal-logic falsification,model-based systematic fuzz testing, parameter synthesis, counterexampleanalysis, and data set augmentation.

A New Simulation Metric to Determine Safe Environments and Controllers  for Systems with Unknown Dynamics

  We consider the problem of extracting safe environments and controllers forreach-avoid objectives for systems with known state and control spaces, butunknown dynamics. In a given environment, a common approach is to synthesize acontroller from an abstraction or a model of the system (potentially learnedfrom data). However, in many situations, the relationship between the dynamicsof the model and the \textit{actual system} is not known; and hence it isdifficult to provide safety guarantees for the system. In such cases, theStandard Simulation Metric (SSM), defined as the worst-case norm distancebetween the model and the system output trajectories, can be used to modify areach-avoid specification for the system into a more stringent specificationfor the abstraction. Nevertheless, the obtained distance, and hence themodified specification, can be quite conservative. This limits the set ofenvironments for which a safe controller can be obtained. We propose SPEC, aspecification-centric simulation metric, which overcomes these limitations bycomputing the distance using only the trajectories that violate thespecification for the system. We show that modifying a reach-avoidspecification with SPEC allows us to synthesize a safe controller for a largerset of environments compared to SSM. We also propose a probabilistic method tocompute SPEC for a general class of systems. Case studies using simulators forquadrotors and autonomous cars illustrate the advantages of the proposed metricfor determining safe environment sets and controllers.

Reactive Control Improvisation

  Reactive synthesis is a paradigm for automatically buildingcorrect-by-construction systems that interact with an unknown or adversarialenvironment. We study how to do reactive synthesis when part of thespecification of the system is that its behavior should be random. Randomnesscan be useful, for example, in a network protocol fuzz tester whose outputshould be varied, or a planner for a surveillance robot whose route should beunpredictable. However, existing reactive synthesis techniques do not provide away to ensure random behavior while maintaining functional correctness. Towardsthis end, we generalize the recently-proposed framework of controlimprovisation (CI) to add reactivity. The resulting framework of reactivecontrol improvisation provides a natural way to integrate a randomnessrequirement with the usual functional specifications of reactive synthesis overa finite window. We theoretically characterize when such problems arerealizable, and give a general method for solving them. For specificationsgiven by reachability or safety games or by deterministic finite automata, ourmethod yields a polynomial-time synthesis algorithm. For various other types ofspecifications including temporal logic formulas, we obtain a polynomial-spacealgorithm and prove matching PSPACE-hardness results. We show that all of theserandomized variants of reactive synthesis are no harder in acomplexity-theoretic sense than their non-randomized counterparts.

A Theory of Formal Synthesis via Inductive Learning

  Formal synthesis is the process of generating a program satisfying ahigh-level formal specification. In recent times, effective formal synthesismethods have been proposed based on the use of inductive learning. We refer tothis class of methods that learn programs from examples as formal inductivesynthesis. In this paper, we present a theoretical framework for formalinductive synthesis. We discuss how formal inductive synthesis differs fromtraditional machine learning. We then describe oracle-guided inductivesynthesis (OGIS), a framework that captures a family of synthesizers thatoperate by iteratively querying an oracle. An instance of OGIS that has hadmuch practical impact is counterexample-guided inductive synthesis (CEGIS). Wepresent a theoretical characterization of CEGIS for learning any program thatcomputes a recursive language. In particular, we analyze the relative power ofCEGIS variants where the types of counterexamples generated by the oraclevaries. We also consider the impact of bounded versus unbounded memoryavailable to the learning algorithm. In the special case where the universe ofcandidate programs is finite, we relate the speed of convergence to the notionof teaching dimension studied in machine learning theory. Altogether, theresults of the paper take a first step towards a theoretical foundation for theemerging field of formal inductive synthesis.

SOTER: Programming Safe Robotics System using Runtime Assurance

  The recent drive towards achieving greater autonomy and intelligence inrobotics has led to high levels of complexity. Autonomous robots increasinglydepend on third party off-the-shelf components and complex machine-learningtechniques. This trend makes it challenging to provide strong design-timecertification of correct operation.  To address these challenges, we present SOTER, a robotics programmingframework with two key components: (1) a programming language for implementingand testing high-level reactive robotics software and (2) an integrated runtimeassurance (RTA) system that helps enable the use of uncertified components,while still providing safety guarantees. SOTER provides language primitives todeclaratively construct a RTA module consisting of an advanced,high-performance controller (uncertified), a safe, lower-performance controller(certified), and the desired safety specification. The framework provides aformal guarantee that a well-formed RTA module always satisfies the safetyspecification, without completely sacrificing performance by using higherperformance uncertified components whenever safe. SOTER allows the complexrobotics software stack to be constructed as a composition of RTA modules,where each uncertified component is protected using a RTA module.  To demonstrate the efficacy of our framework, we consider a real-worldcase-study of building a safe drone surveillance system. Our experiments bothin simulation and on actual drones show that the SOTER-enabled RTA ensures thesafety of the system, including when untrusted third-party components have bugsor deviate from the desired behavior.

Formal Policy Learning from Demonstrations for Reachability Properties

  We consider the problem of learning structured, closed-loop policies(feedback laws) from demonstrations in order to control under-actuated roboticsystems, so that formal behavioral specifications such as reaching a target setof states are satisfied. Our approach uses a ``counterexample-guided''iterative loop that involves the interaction between a policy learner, ademonstrator and a verifier. The learner is responsible for querying thedemonstrator in order to obtain the training data to guide the construction ofa policy candidate. This candidate is analyzed by the verifier and eitheraccepted as correct, or rejected with a counterexample. In the latter case, thecounterexample is used to update the training data and further refine thepolicy.  The approach is instantiated using receding horizon model-predictivecontrollers (MPCs) as demonstrators. Rather than using regression to fit apolicy to the demonstrator actions, we extend the MPC formulation with thegradient of the cost-to-go function evaluated at sample states in order toconstrain the set of policies compatible with the behavior of the demonstrator.We demonstrate the successful application of the resulting policy learningschemes on two case studies and we show how simple, formally-verified policiescan be inferred starting from a complex and unverified nonlinear MPCimplementations. As a further benefit, the policies are many orders ofmagnitude faster to implement when compared to the original MPCs.

What's Decidable about Syntax-Guided Synthesis?

  Syntax-guided synthesis (SyGuS) is a recently proposed framework for programsynthesis problems. The SyGuS problem is to find an expression or programgenerated by a given grammar that meets a correctness specification.Correctness specifications are given as formulas in suitable logical theories,typically amongst those studied in satisfiability modulo theories (SMT).  In this work, we analyze the decidability of the SyGuS problem for differentclasses of grammars and correctness specifications. We prove that the SyGuSproblem is undecidable for the theory of equality with uninterpreted functions(EUF).We identify a fragment of EUF, which we call regular-EUF, for which theSyGuS problem is decidable. We prove that this restricted problem isEXPTIME-complete and that the sets of solution expressions are precisely theregular tree languages. For theories that admit a unique, finite domain, wegive a general algorithm to solve the SyGuS problem on tree grammars.Finite-domain theories include the bit-vector theory without concatenation. Weprove SyGuS undecidable for a very simple bit-vector theory with concatenation,both for context-free grammars and for tree grammars. Finally, we give someadditional results for linear arithmetic and bit-vector arithmetic along with adiscussion of the implication of these results.

A LiDAR Point Cloud Generator: from a Virtual World to Autonomous  Driving

  3D LiDAR scanners are playing an increasingly important role in autonomousdriving as they can generate depth information of the environment. However,creating large 3D LiDAR point cloud datasets with point-level labels requires asignificant amount of manual annotation. This jeopardizes the efficientdevelopment of supervised deep learning algorithms which are often data-hungry.We present a framework to rapidly create point clouds with accurate point-levellabels from a computer game. The framework supports data collection from bothauto-driving scenes and user-configured scenes. Point clouds from auto-drivingscenes can be used as training data for deep learning algorithms, while pointclouds from user-configured scenes can be used to systematically test thevulnerability of a neural network, and use the falsifying examples to make theneural network more robust through retraining. In addition, the scene imagescan be captured simultaneously in order for sensor fusion tasks, with a methodproposed to do automatic calibration between the point clouds and capturedscene images. We show a significant improvement in accuracy (+9%) in pointcloud segmentation by augmenting the training dataset with the generatedsynthesized data. Our experiments also show by testing and retraining thenetwork using point clouds from user-configured scenes, the weakness/blindspots of the neural network can be fixed.

Scenic: Language-Based Scene Generation

  Synthetic data has proved increasingly useful in both training and testingmachine learning models such as neural networks. The major problem in syntheticdata generation is producing meaningful data that is not simply random butreflects properties of real-world data or covers particular cases of interest.In this paper, we show how a probabilistic programming language can be used toguide data synthesis by encoding domain knowledge about what data is useful.Specifically, we focus on data sets arising from "scenes", configurations ofphysical objects; for example, images of cars on a road. We design adomain-specific language, Scenic, for describing "scenarios" that aredistributions over scenes. The syntax of Scenic makes it easy to specifycomplex relationships between the positions and orientations of objects. As aprobabilistic programming language, Scenic allows assigning distributions tofeatures of the scene, as well as declaratively imposing hard and softconstraints over the scene. A Scenic scenario thereby implicitly defines adistribution over scenes, and we formulate the problem of sampling from thisdistribution as "scene improvisation". We implement an improviser for Scenicscenarios and apply it in a case study generating synthetic data sets for aconvolutional neural network designed to detect cars in road images. Ourexperiments demonstrate the usefulness of our approach by using Scenic toanalyze and improve the performance of the network in various scenarios.

On the Hardness of SAT with Community Structure

  Recent attempts to explain the effectiveness of Boolean satisfiability (SAT)solvers based on conflict-driven clause learning (CDCL) on large industrialbenchmarks have focused on the concept of community structure. Specifically,industrial benchmarks have been empirically found to have good communitystructure, and experiments seem to show a correlation between such structureand the efficiency of CDCL. However, in this paper we establish hardnessresults suggesting that community structure is not sufficient to explain thesuccess of CDCL in practice. First, we formally characterize a property sharedby a wide class of metrics capturing community structure, including"modularity". Next, we show that the SAT instances with good communitystructure according to any metric with this property are still NP-hard.Finally, we study a class of random instances generated from the"pseudo-industrial" community attachment model of Gir\'aldez-Cru and Levy. Weprove that, with high probability, instances from this model that haverelatively few communities but are still highly modular require exponentiallylong resolution proofs and so are hard for CDCL. We also present experimentalevidence that our result continues to hold for instances with many morecommunities. This indicates that actual industrial instances easily solved byCDCL may have some other relevant structure not captured by the communityattachment model.

Are There Good Mistakes? A Theoretical Analysis of CEGIS

  Counterexample-guided inductive synthesis CEGIS is used to synthesizeprograms from a candidate space of programs. The technique is guaranteed toterminate and synthesize the correct program if the space of candidate programsis finite. But the technique may or may not terminate with the correct programif the candidate space of programs is infinite. In this paper, we perform atheoretical analysis of counterexample-guided inductive synthesis technique. Weinvestigate whether the set of candidate spaces for which the correct programcan be synthesized using CEGIS depends on the counterexamples used in inductivesynthesis, that is, whether there are good mistakes which would increase thesynthesis power. We investigate whether the use of minimal counterexamplesinstead of arbitrary counterexamples expands the set of candidate spaces ofprograms for which inductive synthesis can successfully synthesize a correctprogram. We consider two kinds of counterexamples: minimal counterexamples andhistory bounded counterexamples. The history bounded counterexample used in anyiteration of CEGIS is bounded by the examples used in previous iterations ofinductive synthesis. We examine the relative change in power of inductivesynthesis in both cases. We show that the synthesis technique using minimalcounterexamples MinCEGIS has the same synthesis power as CEGIS but thesynthesis technique using history bounded counterexamples HCEGIS has differentpower than that of CEGIS, but none dominates the other.

Learning Task Specifications from Demonstrations

  Real world applications often naturally decompose into several sub-tasks. Inmany settings (e.g., robotics) demonstrations provide a natural way to specifythe sub-tasks. However, most methods for learning from demonstrations either donot provide guarantees that the artifacts learned for the sub-tasks can besafely recombined or limit the types of composition available. Motivated bythis deficit, we consider the problem of inferring Boolean non-Markovianrewards (also known as logical trace properties or specifications) fromdemonstrations provided by an agent operating in an uncertain, stochasticenvironment. Crucially, specifications admit well-defined composition rulesthat are typically easy to interpret. In this paper, we formulate thespecification inference task as a maximum a posteriori (MAP) probabilityinference problem, apply the principle of maximum entropy to derive an analyticdemonstration likelihood model and give an efficient approach to search for themost likely specification in a large candidate pool of specifications. In ourexperiments, we demonstrate how learning specifications can help avoid commonproblems that often arise due to ad-hoc reward composition.

Cloud-based Quadratic Optimization with Partially Homomorphic Encryption

  The development of large-scale distributed control systems has led to theoutsourcing of costly computations to cloud-computing platforms, as well as toconcerns about privacy of the collected sensitive data. This paper develops acloud-based protocol for a quadratic optimization problem involving multipleparties, each holding information it seeks to maintain private. The protocol isbased on the projected gradient ascent on the Lagrange dual problem andexploits partially homomorphic encryption and secure multi-party computationtechniques. Using formal cryptographic definitions of indistinguishability, theprotocol is shown to achieve computational privacy, i.e., there is nocomputationally efficient algorithm that any involved party can employ toobtain private information beyond what can be inferred from the party's inputsand outputs only. In order to reduce the communication complexity of theproposed protocol, we introduced a variant that achieves this objective at theexpense of weaker privacy guarantees. We discuss in detail the computationaland communication complexity properties of both algorithms theoretically andalso through implementations. We conclude the paper with a discussion oncomputational privacy and other notions of privacy such as the non-uniqueretrieval of the private information from the protocol outputs.

