Discussion of "2004 IMS Medallion Lecture: Local Rademacher complexities
  and oracle inequalities in risk minimization" by V. Koltchinskii

  Discussion of "2004 IMS Medallion Lecture: Local Rademacher complexities and
oracle inequalities in risk minimization" by V. Koltchinskii [arXiv:0708.0083]


Local Rademacher complexities

  We propose new bounds on the error of learning algorithms in terms of a
data-dependent notion of complexity. The estimates we establish give optimal
rates and are based on a local and empirical version of Rademacher averages, in
the sense that the Rademacher averages are computed from the data, on a subset
of functions with small empirical error. We present some applications to
classification and prediction with convex function classes, and with kernel
classes in particular.


REGAL: A Regularization based Algorithm for Reinforcement Learning in
  Weakly Communicating MDPs

  We provide an algorithm that achieves the optimal regret rate in an unknown
weakly communicating Markov Decision Process (MDP). The algorithm proceeds in
episodes where, in each episode, it picks a policy using regularization based
on the span of the optimal bias vector. For an MDP with S states and A actions
whose optimal bias vector has span bounded by H, we show a regret bound of
~O(HSpAT). We also relate the span to various diameter-like quantities
associated with the MDP, demonstrating how our results improve on previous
regret bounds.


Photon-number superselection and the entangled coherent-state
  representation

  We introduce the entangled coherent state representation, which provides a
powerful technique for efficiently and elegantly describing and analyzing
quantum optics sources and detectors while respecting the photon number
superselection rule that is satisfied by all known quantum optics experiments.
We apply the entangled coherent state representation to elucidate and resolve
the longstanding puzzles of the coherence of a laser output field, interference
between two number states, and dichotomous interpretations of quantum
teleportation of coherent states.


Comment on "Support Vector Machines with Applications"

  Comment on "Support Vector Machines with Applications" [math.ST/0612817]


Quantum quincunx in cavity quantum electrodynamics

  We introduce the quantum quincunx, which physically demonstrates the quantum
walk and is analogous to Galton's quincunx for demonstrating the random walk.
In contradistinction to the theoretical studies of quantum walks over
orthogonal lattice states, we introduce quantum walks over nonorthogonal
lattice states (specifically, coherent states on a circle) to demonstrate that
the key features of a quantum walk are observable albeit for strict parameter
ranges. A quantum quincunx may be realized with current cavity quantum
electrodynamics capabilities, and precise control over decoherence in such
experiments allows a remarkable decrease in the position noise, or spread, with
increasing decoherence.


A Unifying View of Multiple Kernel Learning

  Recent research on multiple kernel learning has lead to a number of
approaches for combining kernels in regularized risk minimization. The proposed
approaches include different formulations of objectives and varying
regularization strategies. In this paper we present a unifying general
optimization criterion for multiple kernel learning and show how existing
formulations are subsumed as special cases. We also derive the criterion's dual
representation, which is suitable for general smooth optimization algorithms.
Finally, we evaluate multiple kernel learning in this framework analytically
using a Rademacher complexity bound on the generalization error and empirically
in a set of experiments.


Information-theoretic lower bounds on the oracle complexity of
  stochastic convex optimization

  Relative to the large literature on upper bounds on complexity of convex
optimization, lesser attention has been paid to the fundamental hardness of
these problems. Given the extensive use of convex optimization in machine
learning and statistics, gaining an understanding of these complexity-theoretic
issues is important. In this paper, we study the complexity of stochastic
convex optimization in an oracle model of computation. We improve upon known
results and obtain tight minimax complexity estimates for various function
classes.


Blackwell Approachability and Low-Regret Learning are Equivalent

  We consider the celebrated Blackwell Approachability Theorem for two-player
games with vector payoffs. We show that Blackwell's result is equivalent, via
efficient reductions, to the existence of "no-regret" algorithms for Online
Linear Optimization. Indeed, we show that any algorithm for one such problem
can be efficiently converted into an algorithm for the other. We provide a
useful application of this reduction: the first efficient algorithm for
calibrated forecasting.


Online Learning in Markov Decision Processes with Adversarially Chosen
  Transition Probability Distributions

  We study the problem of learning Markov decision processes with finite state
and action spaces when the transition probability distributions and loss
functions are chosen adversarially and are allowed to change with time. We
introduce an algorithm whose regret with respect to any policy in a comparison
class grows as the square root of the number of rounds of the game, provided
the transition probabilities satisfy a uniform mixing condition. Our approach
is efficient as long as the comparison class is polynomial and we can compute
expectations over sample paths for each policy. Designing an efficient
algorithm with small regret for the general case remains an open problem.


Oracle inequalities for computationally adaptive model selection

  We analyze general model selection procedures using penalized empirical loss
minimization under computational constraints. While classical model selection
approaches do not consider computational aspects of performing model selection,
we argue that any practical model selection procedure must not only trade off
estimation and approximation error, but also the computational effort required
to compute empirical minimizers for different function classes. We provide a
framework for analyzing such problems, and we give algorithms for model
selection under a computational budget. These algorithms satisfy oracle
inequalities that show that the risk of the selected model is not much worse
than if we had devoted all of our omputational budget to the optimal function
class.


Hit-and-Run for Sampling and Planning in Non-Convex Spaces

  We propose the Hit-and-Run algorithm for planning and sampling problems in
non-convex spaces. For sampling, we show the first analysis of the Hit-and-Run
algorithm in non-convex spaces and show that it mixes fast as long as certain
smoothness conditions are satisfied. In particular, our analysis reveals an
intriguing connection between fast mixing and the existence of smooth
measure-preserving mappings from a convex space to the non-convex space. For
planning, we show advantages of Hit-and-Run compared to state-of-the-art
planning methods such as Rapidly-Exploring Random Trees.


Gen-Oja: A Simple and Efficient Algorithm for Streaming Generalized
  Eigenvector Computation

  In this paper, we study the problems of principal Generalized Eigenvector
computation and Canonical Correlation Analysis in the stochastic setting. We
propose a simple and efficient algorithm, Gen-Oja, for these problems. We prove
the global convergence of our algorithm, borrowing ideas from the theory of
fast-mixing Markov chains and two-time-scale stochastic approximation, showing
that it achieves the optimal rate of convergence. In the process, we develop
tools for understanding stochastic processes with Markovian noise which might
be of independent interest.


Quantitative Central Limit Theorems for Discrete Stochastic Processes

  In this paper, we establish a generalization of the classical Central Limit
Theorem for a family of stochastic processes that includes stochastic gradient
descent and related gradient-based algorithms. Under certain regularity
assumptions, we show that the iterates of these stochastic processes converge
to an invariant distribution at a rate of $O\lrp{1/\sqrt{k}}$ where $k$ is the
number of steps; this rate is provably tight.


Fast Mean Estimation with Sub-Gaussian Rates

  We propose an estimator for the mean of a random vector in $\mathbb{R}^d$
that can be computed in time $O(n^4+n^2d)$ for $n$ i.i.d.~samples and that has
error bounds matching the sub-Gaussian case. The only assumptions we make about
the data distribution are that it has finite mean and covariance; in
particular, we make no assumptions about higher-order moments. Like the
polynomial time estimator introduced by Hopkins, 2018, which is based on the
sum-of-squares hierarchy, our estimator achieves optimal statistical efficiency
in this challenging setting, but it has a significantly faster runtime and a
simpler analysis.


Sharp Convergence Rates for Langevin Dynamics in the Nonconvex Setting

  We study the problem of sampling from a distribution where the negative
logarithm of the target density is $L$-smooth everywhere and $m$-strongly
convex outside a ball of radius $R$, but potentially non-convex inside this
ball. We study both overdamped and underdamped Langevin MCMC and prove upper
bounds on the time required to obtain a sample from a distribution that is
within $\epsilon$ of the target distribution in $1$-Wasserstein distance. For
the first-order method (overdamped Langevin MCMC), the time complexity is
$\tilde{\mathcal{O}}\left(e^{cLR^2}\frac{d}{\epsilon^2}\right)$, where $d$ is
the dimension of the underlying space. For the second-order method (underdamped
Langevin MCMC), the time complexity is
$\tilde{\mathcal{O}}\left(e^{cLR^2}\frac{\sqrt{d}}{\epsilon}\right)$ for some
explicit positive constant $c$. Surprisingly, the convergence rate is only
polynomial in the dimension $d$ and the target accuracy $\epsilon$. It is
however exponential in the problem parameter $LR^2$, which is a measure of
non-logconcavity of the target distribution.


Margin-adaptive model selection in statistical learning

  A classical condition for fast learning rates is the margin condition, first
introduced by Mammen and Tsybakov. We tackle in this paper the problem of
adaptivity to this condition in the context of model selection, in a general
learning framework. Actually, we consider a weaker version of this condition
that allows one to take into account that learning within a small model can be
much easier than within a large one. Requiring this "strong margin adaptivity"
makes the model selection problem more challenging. We first prove, in a
general framework, that some penalization procedures (including local
Rademacher complexities) exhibit this adaptivity when the models are nested.
Contrary to previous results, this holds with penalties that only depend on the
data. Our second main result is that strong margin adaptivity is not always
possible when the models are not nested: for every model selection procedure
(even a randomized one), there is a problem for which it does not demonstrate
strong margin adaptivity.


A Stochastic View of Optimal Regret through Minimax Duality

  We study the regret of optimal strategies for online convex optimization
games. Using von Neumann's minimax theorem, we show that the optimal regret in
this adversarial setting is closely related to the behavior of the empirical
minimization algorithm in a stochastic process setting: it is equal to the
maximum, over joint distributions of the adversary's action sequence, of the
difference between a sum of minimal expected losses and the minimal empirical
loss. We show that the optimal regret has a natural geometric interpretation,
since it can be viewed as the gap in Jensen's inequality for a concave
functional--the minimizer over the player's actions of expected loss--defined
on a set of probability distributions. We use this expression to obtain upper
and lower bounds on the regret of an optimal strategy for a variety of online
learning problems. Our method provides upper bounds without the need to
construct a learning algorithm; the lower bounds provide explicit optimal
strategies for the adversary.


A Learning-Based Approach to Reactive Security

  Despite the conventional wisdom that proactive security is superior to
reactive security, we show that reactive security can be competitive with
proactive security as long as the reactive defender learns from past attacks
instead of myopically overreacting to the last attack. Our game-theoretic model
follows common practice in the security literature by making worst-case
assumptions about the attacker: we grant the attacker complete knowledge of the
defender's strategy and do not require the attacker to act rationally. In this
model, we bound the competitive ratio between a reactive defense algorithm
(which is inspired by online learning theory) and the best fixed proactive
defense. Additionally, we show that, unlike proactive defenses, this reactive
strategy is robust to a lack of information about the attacker's incentives and
knowledge.


Randomized Smoothing for Stochastic Optimization

  We analyze convergence rates of stochastic optimization procedures for
non-smooth convex optimization problems. By combining randomized smoothing
techniques with accelerated gradient methods, we obtain convergence rates of
stochastic optimization procedures, both in expectation and with high
probability, that have optimal dependence on the variance of the gradient
estimates. To the best of our knowledge, these are the first variance-based
rates for non-smooth optimization. We give several applications of our results
to statistical estimation problems, and provide experimental results that
demonstrate the effectiveness of the proposed algorithms. We also describe how
a combination of our algorithm with recent work on decentralized optimization
yields a distributed stochastic optimization algorithm that is order-optimal.


Linear Programming for Large-Scale Markov Decision Problems

  We consider the problem of controlling a Markov decision process (MDP) with a
large state space, so as to minimize average cost. Since it is intractable to
compete with the optimal policy for large scale problems, we pursue the more
modest goal of competing with a low-dimensional family of policies. We use the
dual linear programming formulation of the MDP average cost problem, in which
the variable is a stationary distribution over state-action pairs, and we
consider a neighborhood of a low-dimensional subset of the set of stationary
distributions (defined in terms of state-action features) as the comparison
class. We propose two techniques, one based on stochastic convex optimization,
and one based on constraint sampling. In both cases, we give bounds that show
that the performance of our algorithms approaches the best achievable by any
policy in the comparison class. Most importantly, these results depend on the
size of the comparison class, but not on the size of the state space.
Preliminary experiments show the effectiveness of the proposed algorithms in a
queuing application.


FLAG n' FLARE: Fast Linearly-Coupled Adaptive Gradient Methods

  We consider first order gradient methods for effectively optimizing a
composite objective in the form of a sum of smooth and, potentially, non-smooth
functions. We present accelerated and adaptive gradient methods, called FLAG
and FLARE, which can offer the best of both worlds. They can achieve the
optimal convergence rate by attaining the optimal first-order oracle complexity
for smooth convex optimization. Additionally, they can adaptively and
non-uniformly re-scale the gradient direction to adapt to the limited curvature
available and conform to the geometry of the domain. We show theoretically and
empirically that, through the compounding effects of acceleration and
adaptivity, FLAG and FLARE can be highly effective for many data fitting and
machine learning applications.


Convergence of Langevin MCMC in KL-divergence

  Langevin diffusion is a commonly used tool for sampling from a given
distribution. In this work, we establish that when the target density $p^*$ is
such that $\log p^*$ is $L$ smooth and $m$ strongly convex, discrete Langevin
diffusion produces a distribution $p$ with $KL(p||p^*)\leq \epsilon$ in
$\tilde{O}(\frac{d}{\epsilon})$ steps, where $d$ is the dimension of the sample
space. We also study the convergence rate when the strong-convexity assumption
is absent. By considering the Langevin diffusion as a gradient flow in the
space of probability distributions, we obtain an elegant analysis that applies
to the stronger property of convergence in KL-divergence and gives a
conceptually simpler proof of the best-known convergence results in weaker
metrics.


Underdamped Langevin MCMC: A non-asymptotic analysis

  We study the underdamped Langevin diffusion when the log of the target
distribution is smooth and strongly concave. We present a MCMC algorithm based
on its discretization and show that it achieves $\varepsilon$ error (in
2-Wasserstein distance) in $\mathcal{O}(\sqrt{d}/\varepsilon)$ steps. This is a
significant improvement over the best known rate for overdamped Langevin MCMC,
which is $\mathcal{O}(d/\varepsilon^2)$ steps under the same
smoothness/concavity assumptions.
  The underdamped Langevin MCMC scheme can be viewed as a version of
Hamiltonian Monte Carlo (HMC) which has been observed to outperform overdamped
Langevin MCMC methods in a number of application areas. We provide quantitative
rates that support this empirical wisdom.


Acceleration and Averaging in Stochastic Mirror Descent Dynamics

  We formulate and study a general family of (continuous-time) stochastic
dynamics for accelerated first-order minimization of smooth convex functions.
Building on an averaging formulation of accelerated mirror descent, we propose
a stochastic variant in which the gradient is contaminated by noise, and study
the resulting stochastic differential equation. We prove a bound on the rate of
change of an energy function associated with the problem, then use it to derive
estimates of convergence rates of the function values, (a.s. and in
expectation) both for persistent and asymptotically vanishing noise. We discuss
the interaction between the parameters of the dynamics (learning rate and
averaging weights) and the covariation of the noise process, and show, in
particular, how the asymptotic rate of covariation affects the choice of
parameters and, ultimately, the convergence rate.


On the Theory of Variance Reduction for Stochastic Gradient Monte Carlo

  We provide convergence guarantees in Wasserstein distance for a variety of
variance-reduction methods: SAGA Langevin diffusion, SVRG Langevin diffusion
and control-variate underdamped Langevin diffusion. We analyze these methods
under a uniform set of assumptions on the log-posterior distribution, assuming
it to be smooth, strongly convex and Hessian Lipschitz. This is achieved by a
new proof technique combining ideas from finite-sum optimization and the
analysis of sampling methods. Our sharp theoretical bounds allow us to identify
regimes of interest where each method performs better than the others. Our
theory is verified with experiments on real-world and synthetic datasets.


Online learning with kernel losses

  We present a generalization of the adversarial linear bandits framework,
where the underlying losses are kernel functions (with an associated
reproducing kernel Hilbert space) rather than linear functions. We study a
version of the exponential weights algorithm and bound its regret in this
setting. Under conditions on the eigendecay of the kernel we provide a sharp
characterization of the regret for this algorithm. When we have polynomial
eigendecay $\mu_j \le \mathcal{O}(j^{-\beta})$, we find that the regret is
bounded by $\mathcal{R}_n \le \mathcal{O}(n^{\beta/(2(\beta-1))})$; while under
the assumption of exponential eigendecay $\mu_j \le \mathcal{O}(e^{-\beta j
})$, we get an even tighter bound on the regret $\mathcal{R}_n \le
\mathcal{O}(n^{1/2}\log(n)^{1/2})$. We also study the full information setting
when the underlying losses are kernel functions and present an adapted
exponential weights algorithm and a conditional gradient descent algorithm.


Best of many worlds: Robust model selection for online supervised
  learning

  We introduce algorithms for online, full-information prediction that are
competitive with contextual tree experts of unknown complexity, in both
probabilistic and adversarial settings. We show that by incorporating a
probabilistic framework of structural risk minimization into existing adaptive
algorithms, we can robustly learn not only the presence of stochastic structure
when it exists (leading to constant as opposed to $\mathcal{O}(\sqrt{T})$
regret), but also the correct model order. We thus obtain regret bounds that
are competitive with the regret of an optimal algorithm that possesses strong
side information about both the complexity of the optimal contextual tree
expert and whether the process generating the data is stochastic or
adversarial. These are the first constructive guarantees on simultaneous
adaptivity to the model and the presence of stochasticity.


Derivative-Free Methods for Policy Optimization: Guarantees for Linear
  Quadratic Systems

  We study derivative-free methods for policy optimization over the class of
linear policies. We focus on characterizing the convergence rate of these
methods when applied to linear-quadratic systems, and study various settings of
driving noise and reward feedback. We show that these methods provably converge
to within any pre-specified tolerance of the optimal policy with a number of
zero-order evaluations that is an explicit polynomial of the error tolerance,
dimension, and curvature properties of the problem. Our analysis reveals some
interesting differences between the settings of additive driving noise and
random initialization, as well as the settings of one-point and two-point
reward feedback. Our theory is corroborated by extensive simulations of
derivative-free methods on these systems. Along the way, we derive convergence
rates for stochastic zero-order optimization algorithms when applied to a
certain class of non-convex problems.


Large-Scale Markov Decision Problems via the Linear Programming Dual

  We consider the problem of controlling a fully specified Markov decision
process (MDP), also known as the planning problem, when the state space is very
large and calculating the optimal policy is intractable. Instead, we pursue the
more modest goal of optimizing over some small family of policies.
Specifically, we show that the family of policies associated with a
low-dimensional approximation of occupancy measures yields a tractable
optimization. Moreover, we propose an efficient algorithm, scaling with the
size of the subspace but not the state space, that is able to find a policy
with low excess loss relative to the best policy in this class. To the best of
our knowledge, such results did not exist in the literature previously. We
bound excess loss in the average cost and discounted cost cases, which are
treated separately. Preliminary experiments show the effectiveness of the
proposed algorithms in a queueing application.


Testing Markov Chains without Hitting

  We study the problem of identity testing of markov chains. In this setting,
we are given access to a single trajectory from a markov chain with unknown
transition matrix $Q$ and the goal is to determine whether $Q = P$ for some
known matrix $P$ or $\text{Dist}(P, Q) \geq \epsilon$ where $\text{Dist}$ is
suitably defined. In recent work by Daskalakis, Dikkala and Gravin, 2018, it
was shown that it is possible to distinguish between the two cases provided the
length of the observed trajectory is at least super-linear in the hitting time
of $P$ which may be arbitrarily large.
  In this paper, we propose an algorithm that avoids this dependence on hitting
time thus enabling efficient testing of markov chains even in cases where it is
infeasible to observe every state in the chain. Our algorithm is based on
combining classical ideas from approximation algorithms with techniques for the
spectral analysis of markov chains.


Nearly-tight VC-dimension and pseudodimension bounds for piecewise
  linear neural networks

  We prove new upper and lower bounds on the VC-dimension of deep neural
networks with the ReLU activation function. These bounds are tight for almost
the entire range of parameters. Letting $W$ be the number of weights and $L$ be
the number of layers, we prove that the VC-dimension is $O(W L \log(W))$, and
provide examples with VC-dimension $\Omega( W L \log(W/L) )$. This improves
both the previously known upper bounds and lower bounds. In terms of the number
$U$ of non-linear units, we prove a tight bound $\Theta(W U)$ on the
VC-dimension. All of these bounds generalize to arbitrary piecewise linear
activation functions, and also hold for the pseudodimensions of these function
classes.
  Combined with previous results, this gives an intriguing range of
dependencies of the VC-dimension on depth for networks with different
non-linearities: there is no dependence for piecewise-constant, linear
dependence for piecewise-linear, and no more than quadratic dependence for
general piecewise-polynomial.


Learning in a Large Function Space: Privacy-Preserving Mechanisms for
  SVM Learning

  Several recent studies in privacy-preserving learning have considered the
trade-off between utility or risk and the level of differential privacy
guaranteed by mechanisms for statistical query processing. In this paper we
study this trade-off in private Support Vector Machine (SVM) learning. We
present two efficient mechanisms, one for the case of finite-dimensional
feature mappings and one for potentially infinite-dimensional feature mappings
with translation-invariant kernels. For the case of translation-invariant
kernels, the proposed mechanism minimizes regularized empirical risk in a
random Reproducing Kernel Hilbert Space whose kernel uniformly approximates the
desired kernel with high probability. This technique, borrowed from large-scale
learning, allows the mechanism to respond with a finite encoding of the
classifier, even when the function class is of infinite VC dimension.
Differential privacy is established using a proof technique from algorithmic
stability. Utility--the mechanism's response function is pointwise
epsilon-close to non-private SVM with probability 1-delta--is proven by
appealing to the smoothness of regularized empirical risk minimization with
respect to small perturbations to the feature mapping. We conclude with a lower
bound on the optimal differential privacy of the SVM. This negative result
states that for any delta, no mechanism can be simultaneously
(epsilon,delta)-useful and beta-differentially private for small epsilon and
small beta.


Bounding Embeddings of VC Classes into Maximum Classes

  One of the earliest conjectures in computational learning theory-the Sample
Compression conjecture-asserts that concept classes (equivalently set systems)
admit compression schemes of size linear in their VC dimension. To-date this
statement is known to be true for maximum classes---those that possess maximum
cardinality for their VC dimension. The most promising approach to positively
resolving the conjecture is by embedding general VC classes into maximum
classes without super-linear increase to their VC dimensions, as such
embeddings would extend the known compression schemes to all VC classes. We
show that maximum classes can be characterised by a local-connectivity property
of the graph obtained by viewing the class as a cubical complex. This geometric
characterisation of maximum VC classes is applied to prove a negative embedding
result which demonstrates VC-d classes that cannot be embedded in any maximum
class of VC dimension lower than 2d. On the other hand, we show that every VC-d
class C embeds in a VC-(d+D) maximum class where D is the deficiency of C,
i.e., the difference between the cardinalities of a maximum VC-d class and of
C. For VC-2 classes in binary n-cubes for 4 <= n <= 6, we give best possible
results on embedding into maximum classes. For some special classes of Boolean
functions, relationships with maximum classes are investigated. Finally we give
a general recursive procedure for embedding VC-d classes into VC-(d+k) maximum
classes for smallest k.


RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning

  Deep reinforcement learning (deep RL) has been successful in learning
sophisticated behaviors automatically; however, the learning process requires a
huge number of trials. In contrast, animals can learn new tasks in just a few
trials, benefiting from their prior knowledge about the world. This paper seeks
to bridge this gap. Rather than designing a "fast" reinforcement learning
algorithm, we propose to represent it as a recurrent neural network (RNN) and
learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in
the weights of the RNN, which are learned slowly through a general-purpose
("slow") RL algorithm. The RNN receives all information a typical RL algorithm
would receive, including observations, actions, rewards, and termination flags;
and it retains its state across episodes in a given Markov Decision Process
(MDP). The activations of the RNN store the state of the "fast" RL algorithm on
the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both
small-scale and large-scale problems. On the small-scale side, we train it to
solve randomly generated multi-arm bandit problems and finite MDPs. After
RL$^2$ is trained, its performance on new MDPs is close to human-designed
algorithms with optimality guarantees. On the large-scale side, we test RL$^2$
on a vision-based navigation task and show that it scales up to
high-dimensional problems.


Recovery Guarantees for One-hidden-layer Neural Networks

  In this paper, we consider regression problems with one-hidden-layer neural
networks (1NNs). We distill some properties of activation functions that lead
to $\mathit{local~strong~convexity}$ in the neighborhood of the ground-truth
parameters for the 1NN squared-loss objective. Most popular nonlinear
activation functions satisfy the distilled properties, including rectified
linear units (ReLUs), leaky ReLUs, squared ReLUs and sigmoids. For activation
functions that are also smooth, we show $\mathit{local~linear~convergence}$
guarantees of gradient descent under a resampling rule. For homogeneous
activations, we show tensor methods are able to initialize the parameters to
fall into the local strong convexity region. As a result, tensor initialization
followed by gradient descent is guaranteed to recover the ground truth with
sample complexity $ d \cdot \log(1/\epsilon) \cdot \mathrm{poly}(k,\lambda )$
and computational complexity $n\cdot d \cdot \mathrm{poly}(k,\lambda) $ for
smooth homogeneous activations with high probability, where $d$ is the
dimension of the input, $k$ ($k\leq d$) is the number of hidden nodes,
$\lambda$ is a conditioning property of the ground-truth parameter matrix
between the input layer and the hidden layer, $\epsilon$ is the targeted
precision and $n$ is the number of samples. To the best of our knowledge, this
is the first work that provides recovery guarantees for 1NNs with both sample
complexity and computational complexity $\mathit{linear}$ in the input
dimension and $\mathit{logarithmic}$ in the precision.


Alternating minimization for dictionary learning with random
  initialization

  We present theoretical guarantees for an alternating minimization algorithm
for the dictionary learning/sparse coding problem. The dictionary learning
problem is to factorize vector samples $y^{1},y^{2},\ldots, y^{n}$ into an
appropriate basis (dictionary) $A^*$ and sparse vectors $x^{1*},\ldots,x^{n*}$.
Our algorithm is a simple alternating minimization procedure that switches
between $\ell_1$ minimization and gradient descent in alternate steps.
Dictionary learning and specifically alternating minimization algorithms for
dictionary learning are well studied both theoretically and empirically.
However, in contrast to previous theoretical analyses for this problem, we
replace the condition on the operator norm (that is, the largest magnitude
singular value) of the true underlying dictionary $A^*$ with a condition on the
matrix infinity norm (that is, the largest magnitude term). This not only
allows us to get convergence rates for the error of the estimated dictionary
measured in the matrix infinity norm, but also ensures that a random
initialization will provably converge to the global optimum. Our guarantees are
under a reasonable generative model that allows for dictionaries with growing
operator norms, and can handle an arbitrary level of overcompleteness, while
having sparsity that is information theoretically optimal. We also establish
upper bounds on the sample complexity of our algorithm.


Representing smooth functions as compositions of near-identity functions
  with implications for deep network optimization

  We show that any smooth bi-Lipschitz $h$ can be represented exactly as a
composition $h_m \circ ... \circ h_1$ of functions $h_1,...,h_m$ that are close
to the identity in the sense that each $\left(h_i-\mathrm{Id}\right)$ is
Lipschitz, and the Lipschitz constant decreases inversely with the number $m$
of functions composed. This implies that $h$ can be represented to any accuracy
by a deep residual network whose nonlinear layers compute functions with a
small Lipschitz constant. Next, we consider nonlinear regression with a
composition of near-identity nonlinear maps. We show that, regarding Fr\'echet
derivatives with respect to the $h_1,...,h_m$, any critical point of a
quadratic criterion in this near-identity region must be a global minimizer. In
contrast, if we consider derivatives with respect to parameters of a fixed-size
residual network with sigmoid activation functions, we show that there are
near-identity critical points that are suboptimal, even in the realizable case.
Informally, this means that functional gradient methods for residual networks
cannot get stuck at suboptimal critical points corresponding to near-identity
layers, whereas parametric gradient methods for sigmoidal residual networks
suffer from suboptimal critical points in the near-identity region.


A simple parameter-free and adaptive approach to optimization under a
  minimal local smoothness assumption

  We study the problem of optimizing a function under a \emph{budgeted number
of evaluations}. We only assume that the function is \emph{locally} smooth
around one of its global optima. The difficulty of optimization is measured in
terms of 1) the amount of \emph{noise} $b$ of the function evaluation and 2)
the local smoothness, $d$, of the function. A smaller $d$ results in smaller
optimization error. We come with a new, simple, and parameter-free approach.
First, for all values of $b$ and $d$, this approach recovers at least the
state-of-the-art regret guarantees. Second, our approach additionally obtains
these results while being \textit{agnostic} to the values of both $b$ and $d$.
This leads to the first algorithm that naturally adapts to an \textit{unknown}
range of noise $b$ and leads to significant improvements in a moderate and
low-noise regime. Third, our approach also obtains a remarkable improvement
over the state-of-the-art SOO algorithm when the noise is very low which
includes the case of optimization under deterministic feedback ($b=0$). There,
under our minimal local smoothness assumption, this improvement is of
exponential magnitude and holds for a class of functions that covers the vast
majority of functions that practitioners optimize ($d=0$). We show that our
algorithmic improvement is borne out in experiments as we empirically show
faster convergence on common benchmarks.


Gradient descent with identity initialization efficiently learns
  positive definite linear transformations by deep residual networks

  We analyze algorithms for approximating a function $f(x) = \Phi x$ mapping
$\Re^d$ to $\Re^d$ using deep linear neural networks, i.e. that learn a
function $h$ parameterized by matrices $\Theta_1,...,\Theta_L$ and defined by
$h(x) = \Theta_L \Theta_{L-1} ... \Theta_1 x$. We focus on algorithms that
learn through gradient descent on the population quadratic loss in the case
that the distribution over the inputs is isotropic.
  We provide polynomial bounds on the number of iterations for gradient descent
to approximate the least squares matrix $\Phi$, in the case where the initial
hypothesis $\Theta_1 = ... = \Theta_L = I$ has excess loss bounded by a small
enough constant. On the other hand, we show that gradient descent fails to
converge for $\Phi$ whose distance from the identity is a larger constant, and
we show that some forms of regularization toward the identity in each layer do
not help.
  If $\Phi$ is symmetric positive definite, we show that an algorithm that
initializes $\Theta_i = I$ learns an $\epsilon$-approximation of $f$ using a
number of updates polynomial in $L$, the condition number of $\Phi$, and
$\log(d/\epsilon)$. In contrast, we show that if the least squares matrix
$\Phi$ is symmetric and has a negative eigenvalue, then all members of a class
of algorithms that perform gradient descent with identity initialization, and
optionally regularize toward the identity in each layer, fail to converge.
  We analyze an algorithm for the case that $\Phi$ satisfies $u^{\top} \Phi u >
0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:
one that maintains the invariant $u^{\top} \Theta_L \Theta_{L-1} ... \Theta_1 u
> 0$ for all $u$, and another that "balances" $\Theta_1, ..., \Theta_L$ so that
they have the same singular values.


The Near-Infrared Sky Surveyor

  [NIRSS is one of three concepts that contributed to the Wide-Field Infrared
Survey Telescope (WFIRST) mission advocated by the Decadal Survey.] Operating
beyond the reaches of the Earth's atmosphere, free of its limiting absorption
and thermal background, the Near-Infrared Sky Surveyor (NIRSS) will deeply map
the entire sky at near-infrared wavelengths, thereby enabling new and
fundamental discoveries ranging from the identification of extrasolar planets
to probing the reionization epoch by identifying thousands of quasars at z>10.
NIRSS will directly address the NASA scientific objective of studying cosmic
origins by using a 1.5-meter telescope to reach full-sky 0.2 uJy (25.6 mag AB)
sensitivities in four passbands from 1 to 4 microns in a 4-yr mission. At the
three shorter passbands (1 - 2.5 microns), the proposed depth is comparable to
the deepest pencil-beam surveys done to date and is 3000 times more sensitive
than the only previous all-sky near-infrared survey, 2MASS. At the longest
passband (3.5 micron), which is not feasible from the ground, NIRSS will be 500
times more sensitive than WISE. NIRSS fills a pivotal gap in our knowledge of
the celestial sphere, is a natural complement to WISE, and is well matched to
the next generation of deep (0.1 uJy), wide-area (>2 pi ster), ground-based
optical surveys (LSST and Pan-Starrs). With the high thermal backgrounds of
ground-based infrared observations, a near-infrared full sky survey at sub-uJy
sensitivity is only feasible from space.


The GRIFFIN Facility for Decay-Spectroscopy Studies at TRIUMF-ISAC

  Gamma-Ray Infrastructure For Fundamental Investigations of Nuclei, GRIFFIN,
is a new high-efficiency $\gamma$-ray spectrometer designed for use in decay
spectroscopy experiments with low-energy radioactive ion beams provided by
TRIUMF's Isotope Separator and Accelerator (ISAC-I) facility. GRIFFIN is
composed of sixteen Compton-suppressed large-volume clover-type high-purity
germanium (HPGe) $\gamma$-ray detectors combined with a suite of ancillary
detection systems and coupled to a custom digital data acquisition system. The
infrastructure and detectors of the spectrometer as well as the performance
characteristics and the analysis techniques applied to the experimental data
are described.


CMB-S4 Science Book, First Edition

  This book lays out the scientific goals to be addressed by the
next-generation ground-based cosmic microwave background experiment, CMB-S4,
envisioned to consist of dedicated telescopes at the South Pole, the high
Chilean Atacama plateau and possibly a northern hemisphere site, all equipped
with new superconducting cameras. CMB-S4 will dramatically advance cosmological
studies by crossing critical thresholds in the search for the B-mode
polarization signature of primordial gravitational waves, in the determination
of the number and masses of the neutrinos, in the search for evidence of new
light relics, in constraining the nature of dark energy, and in testing general
relativity on large scales.


Observing the Evolution of the Universe

  How did the universe evolve? The fine angular scale (l>1000) temperature and
polarization anisotropies in the CMB are a Rosetta stone for understanding the
evolution of the universe. Through detailed measurements one may address
everything from the physics of the birth of the universe to the history of star
formation and the process by which galaxies formed. One may in addition track
the evolution of the dark energy and discover the net neutrino mass.
  We are at the dawn of a new era in which hundreds of square degrees of sky
can be mapped with arcminute resolution and sensitivities measured in
microKelvin. Acquiring these data requires the use of special purpose
telescopes such as the Atacama Cosmology Telescope (ACT), located in Chile, and
the South Pole Telescope (SPT). These new telescopes are outfitted with a new
generation of custom mm-wave kilo-pixel arrays. Additional instruments are in
the planning stages.


Precise measurement of the top quark mass in the dilepton channel at D0

  We measure the top quark mass (mt) in ppbar collisions at a center of mass
energy of 1.96 TeV using dilepton ttbar->W+bW-bbar->l+nubl-nubarbbar events,
where l denotes an electron, a muon, or a tau that decays leptonically. The
data correspond to an integrated luminosity of 5.4 fb-1 collected with the D0
detector at the Fermilab Tevatron Collider. We obtain mt = 174.0 +- 1.8(stat)
+- 2.4(syst) GeV, which is in agreement with the current world average mt =
173.3 +- 1.1 GeV. This is currently the most precise measurement of mt in the
dilepton channel.


Measurement of the W boson helicity in top quark decays using 5.4 fb^-1
  of ppbar collision data

  We present a measurement of the helicity of the W boson produced in top quark
decays using ttbar decays in the l+jets and dilepton final states selected from
a sample of 5.4 fb^-1 of collisions recorded using the D0 detector at the
Fermilab Tevatron ppbar collider. We measure the fractions of longitudinal and
right-handed W bosons to be f_0 = 0.669 +- 0.102 [ +- 0.078 (stat.) +- 0.065
(syst.)] and f_+ = 0.023 +- 0.053 [+- 0.041 (stat.) +- 0.034 (syst.)],
respectively. This result is consistent at the 98% level with the standard
model. A measurement with f_0 fixed to the value from the standard model yields
f_+ = 0.010 +- 0.037 [+- 0.022 (stat.) +- 0.030 (syst.) ].


Determination of the width of the top quark

  We extract the total width of the top quark, Gamma_t, from the partial decay
width Gamma(t -> W b) measured using the t-channel cross section for single top
quark production and from the branching fraction B(t -> W b) measured in ttbar
events using up to 2.3 fb^-1 of integrated luminosity collected by the D0
Collaboration at the Tevatron ppbar Collider. The result is Gamma_t = 1.99
+0.69 -0.55 GeV, which translates to a top-quark lifetime of tau_t = (3.3 +1.3
-0.9) x 10^-25 s. Assuming a high mass fourth generation b' quark and unitarity
of the four-generation quark-mixing matrix, we set the first upper limit on
|Vtb'| < 0.63 at 95% C.L.


Search for pair production of the scalar top quark in the electron-muon
  final state

  We report the result of a search for the pair production of the lightest
supersymmetric partner of the top quark ($\tilde{t}_1$) in $p\bar{p}$
collisions at a center-of-mass energy of 1.96 TeV at the Fermilab Tevatron
collider corresponding to an integrated luminosity of 5.4 fb$^{-1}$. The scalar
top quarks are assumed to decay into a $b$ quark, a charged lepton, and a
scalar neutrino ($\tilde{\nu}$), and the search is performed in the electron
plus muon final state. No significant excess of events above the standard model
prediction is detected, and improved exclusion limits at the 95% C.L. are set
in the the ($M_{\tilde{t}_1}$,$M_{\tilde{\nu}}$) mass plane.


Measurement of the differential cross section dσ/dt in elastic
  $p\bar{p}$ scattering at sqrt(s)=1.96 TeV

  We present a measurement of the elastic differential cross section
$d\sigma(p\bar{p}\rightarrow p\bar{p})/dt$ as a function of the
four-momentum-transfer squared t. The data sample corresponds to an integrated
luminosity of $\approx 31 nb^{-1}$ collected with the D0 detector using
dedicated Tevatron $p\bar{p} $ Collider operating conditions at sqrt(s) = 1.96
TeV and covers the range $0.26 <|t|< 1.2 GeV^2$. For $|t|<0.6 GeV^2$,
d\sigma/dt is described by an exponential function of the form $Ae^{-b|t|}$
with a slope parameter $ b = 16.86 \pm 0.10(stat) \pm 0.20(syst) GeV^{-2}$. A
change in slope is observed at $|t| \approx 0.6 GeV^2$, followed by a more
gradual |t| dependence with increasing values of |t|.


Search for pair production of the scalar top quark in muon+tau final
  states

  We present a search for the pair production of scalar top quarks
($\tilde{t}_{1}$), the lightest supersymmetric partners of the top quarks, in
$p\bar{p}$ collisions at a center-of-mass energy of 1.96 TeV, using data
corresponding to an integrated luminosity of {7.3 $fb^{-1}$} collected with the
\dzero experiment at the Fermilab Tevatron Collider. Each scalar top quark is
assumed to decay into a $b$ quark, a charged lepton, and a scalar neutrino
($\tilde{\nu}$). We investigate final states arising from $\tilde{t}_{1}
\bar{\tilde{t}_{1}} \rightarrow b\bar{b}\mu\tau \tilde{\nu} \tilde{\nu}$ and
$\tilde{t}_{1} \bar{\tilde{t}_{1}} \rightarrow b\bar{b}\tau\tau \tilde{\nu}
\tilde{\nu}$. With no significant excess of events observed above the
background expected from the standard model, we set exclusion limits on this
production process in the ($m_{\tilde{t}_{1}}$,$m_{\tilde{\nu}}$) plane.


