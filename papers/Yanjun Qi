Memory Matching Networks for Genomic Sequence Classification

  When analyzing the genome, researchers have discovered that proteins bind to
DNA based on certain patterns of the DNA sequence known as "motifs". However,
it is difficult to manually construct motifs due to their complexity. Recently,
externally learned memory models have proven to be effective methods for
reasoning over inputs and supporting sets. In this work, we present memory
matching networks (MMN) for classifying DNA sequences as protein binding sites.
Our model learns a memory bank of encoded motifs, which are dynamic memory
modules, and then matches a new test sequence to each of the motifs to classify
the sequence as a binding or nonbinding site.


Style Transfer Generative Adversarial Networks: Learning to Play Chess
  Differently

  The idea of style transfer has largely only been explored in image-based
tasks, which we attribute in part to the specific nature of loss functions used
for style transfer. We propose a general formulation of style transfer as an
extension of generative adversarial networks, by using a discriminator to
regularize a generator with an otherwise separate loss function. We apply our
approach to the task of learning to play chess in the style of a specific
player, and present empirical evidence for the viability of our approach.


Feature Squeezing Mitigates and Detects Carlini/Wagner Adversarial
  Examples

  Feature squeezing is a recently-introduced framework for mitigating and
detecting adversarial examples. In previous work, we showed that it is
effective against several earlier methods for generating adversarial examples.
In this short note, we report on recent results showing that simple feature
squeezing techniques also make deep learning models significantly more robust
against the Carlini/Wagner attacks, which are the best known adversarial
methods discovered to date.


MUST-CNN: A Multilayer Shift-and-Stitch Deep Convolutional Architecture
  for Sequence-based Protein Structure Prediction

  Predicting protein properties such as solvent accessibility and secondary
structure from its primary amino acid sequence is an important task in
bioinformatics. Recently, a few deep learning models have surpassed the
traditional window based multilayer perceptron. Taking inspiration from the
image classification domain we propose a deep convolutional neural network
architecture, MUST-CNN, to predict protein properties. This architecture uses a
novel multilayer shift-and-stitch (MUST) technique to generate fully dense
per-position predictions on protein sequences. Our model is significantly
simpler than the state-of-the-art, yet achieves better results. By combining
MUST and the efficient convolution operation, we can consider far more
parameters while retaining very fast prediction speeds. We beat the
state-of-the-art performance on two large protein property prediction datasets.


A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse
  Gaussian Graphical Models

  Estimating multiple sparse Gaussian Graphical Models (sGGMs) jointly for many
related tasks (large $K$) under a high-dimensional (large $p$) situation is an
important task. Most previous studies for the joint estimation of multiple
sGGMs rely on penalized log-likelihood estimators that involve expensive and
difficult non-smooth optimizations. We propose a novel approach, FASJEM for
\underline{fa}st and \underline{s}calable \underline{j}oint
structure-\underline{e}stimation of \underline{m}ultiple sGGMs at a large
scale. As the first study of joint sGGM using the Elementary Estimator
framework, our work has three major contributions: (1) We solve FASJEM through
an entry-wise manner which is parallelizable. (2) We choose a proximal
algorithm to optimize FASJEM. This improves the computational efficiency from
$O(Kp^3)$ to $O(Kp^2)$ and reduces the memory requirement from $O(Kp^2)$ to
$O(K)$. (3) We theoretically prove that FASJEM achieves a consistent estimation
with a convergence rate of $O(\log(Kp)/n_{tot})$. On several synthetic and four
real-world datasets, FASJEM shows significant improvements over baselines on
accuracy, computational complexity, and memory costs.


Adversarial-Playground: A Visualization Suite for Adversarial Sample
  Generation

  With growing interest in adversarial machine learning, it is important for
machine learning practitioners and users to understand how their models may be
attacked. We propose a web-based visualization tool, Adversarial-Playground, to
demonstrate the efficacy of common adversarial methods against a deep neural
network (DNN) model, built on top of the TensorFlow library.
Adversarial-Playground provides users an efficient and effective experience in
exploring techniques generating adversarial examples, which are inputs crafted
by an adversary to fool a machine learning system. To enable
Adversarial-Playground to generate quick and accurate responses for users, we
use two primary tactics: (1) We propose a faster variant of the
state-of-the-art Jacobian saliency map approach that maintains a comparable
evasion rate. (2) Our visualization does not transmit the generated adversarial
images to the client, but rather only the matrix describing the sample and the
vector representing classification likelihoods.
  The source code along with the data from all of our experiments are available
at \url{https://github.com/QData/AdversarialDNN-Playground}.


A Constrained, Weighted-L1 Minimization Approach for Joint Discovery of
  Heterogeneous Neural Connectivity Graphs

  Determining functional brain connectivity is crucial to understanding the
brain and neural differences underlying disorders such as autism. Recent
studies have used Gaussian graphical models to learn brain connectivity via
statistical dependencies across brain regions from neuroimaging. However,
previous studies often fail to properly incorporate priors tailored to
neuroscience, such as preferring shorter connections. To remedy this problem,
the paper here introduces a novel, weighted-$\ell_1$, multi-task graphical
model (W-SIMULE). This model elegantly incorporates a flexible prior, along
with a parallelizable formulation. Additionally, W-SIMULE extends the
often-used Gaussian assumption, leading to considerable performance increases.
Here, applications to fMRI data show that W-SIMULE succeeds in determining
functional connectivity in terms of (1) log-likelihood, (2) finding edges that
differentiate groups, and (3) classifying different groups based on their
connectivity, achieving 58.6\% accuracy on the ABIDE dataset. Having
established W-SIMULE's effectiveness, it links four key areas to autism, all of
which are consistent with the literature. Due to its elegant domain adaptivity,
W-SIMULE can be readily applied to various data types to effectively estimate
connectivity.


Fast and Scalable Learning of Sparse Changes in High-Dimensional
  Gaussian Graphical Model Structure

  We focus on the problem of estimating the change in the dependency structures
of two $p$-dimensional Gaussian Graphical models (GGMs). Previous studies for
sparse change estimation in GGMs involve expensive and difficult non-smooth
optimization. We propose a novel method, DIFFEE for estimating DIFFerential
networks via an Elementary Estimator under a high-dimensional situation. DIFFEE
is solved through a faster and closed form solution that enables it to work in
large-scale settings. We conduct a rigorous statistical analysis showing that
surprisingly DIFFEE achieves the same asymptotic convergence rates as the
state-of-the-art estimators that are much more difficult to compute. Our
experimental results on multiple synthetic datasets and one real-world data
about brain connectivity show strong performance improvements over baselines,
as well as significant computational benefits.


Deep Motif: Visualizing Genomic Sequence Classifications

  This paper applies a deep convolutional/highway MLP framework to classify
genomic sequences on the transcription factor binding site task. To make the
model understandable, we propose an optimization driven strategy to extract
"motifs", or symbolic patterns which visualize the positive class learned by
the network. We show that our system, Deep Motif (DeMo), extracts motifs that
are similar to, and in some cases outperform the current well known motifs. In
addition, we find that a deeper model consisting of multiple convolutional and
highway layers can outperform a single convolutional and fully connected layer
in the previous state-of-the-art.


GaKCo: a Fast GApped k-mer string Kernel using COunting

  String Kernel (SK) techniques, especially those using gapped $k$-mers as
features (gk), have obtained great success in classifying sequences like DNA,
protein, and text. However, the state-of-the-art gk-SK runs extremely slow when
we increase the dictionary size ($\Sigma$) or allow more mismatches ($M$). This
is because current gk-SK uses a trie-based algorithm to calculate co-occurrence
of mismatched substrings resulting in a time cost proportional to
$O(\Sigma^{M})$. We propose a \textbf{fast} algorithm for calculating
\underline{Ga}pped $k$-mer \underline{K}ernel using \underline{Co}unting
(GaKCo). GaKCo uses associative arrays to calculate the co-occurrence of
substrings using cumulative counting. This algorithm is fast, scalable to
larger $\Sigma$ and $M$, and naturally parallelizable. We provide a rigorous
asymptotic analysis that compares GaKCo with the state-of-the-art gk-SK.
Theoretically, the time cost of GaKCo is independent of the $\Sigma^{M}$ term
that slows down the trie-based approach. Experimentally, we observe that GaKCo
achieves the same accuracy as the state-of-the-art and outperforms its speed by
factors of 2, 100, and 4, on classifying sequences of DNA (5 datasets), protein
(12 datasets), and character-based English text (2 datasets), respectively.
  GaKCo is shared as an open source tool at
\url{https://github.com/QData/GaKCo-SVM}


A constrained L1 minimization approach for estimating multiple Sparse
  Gaussian or Nonparanormal Graphical Models

  Identifying context-specific entity networks from aggregated data is an
important task, arising often in bioinformatics and neuroimaging.
Computationally, this task can be formulated as jointly estimating multiple
different, but related, sparse Undirected Graphical Models (UGM) from
aggregated samples across several contexts. Previous joint-UGM studies have
mostly focused on sparse Gaussian Graphical Models (sGGMs) and can't identify
context-specific edge patterns directly. We, therefore, propose a novel
approach, SIMULE (detecting Shared and Individual parts of MULtiple graphs
Explicitly) to learn multi-UGM via a constrained L1 minimization. SIMULE
automatically infers both specific edge patterns that are unique to each
context and shared interactions preserved among all the contexts. Through the
L1 constrained formulation, this problem is cast as multiple independent
subtasks of linear programming that can be solved efficiently in parallel. In
addition to Gaussian data, SIMULE can also handle multivariate Nonparanormal
data that greatly relaxes the normality assumption that many real-world
applications do not follow. We provide a novel theoretical proof showing that
SIMULE achieves a consistent result at the rate O(log(Kp)/n_{tot}). On multiple
synthetic datasets and two biomedical datasets, SIMULE shows significant
improvement over state-of-the-art multi-sGGM and single-UGM baselines.


Deep Motif Dashboard: Visualizing and Understanding Genomic Sequences
  Using Deep Neural Networks

  Deep neural network (DNN) models have recently obtained state-of-the-art
prediction accuracy for the transcription factor binding (TFBS) site
classification task. However, it remains unclear how these approaches identify
meaningful DNA sequence signals and give insights as to why TFs bind to certain
locations. In this paper, we propose a toolkit called the Deep Motif Dashboard
(DeMo Dashboard) which provides a suite of visualization strategies to extract
motifs, or sequence patterns from deep neural network models for TFBS
classification. We demonstrate how to visualize and understand three important
DNN models: convolutional, recurrent, and convolutional-recurrent networks. Our
first visualization method is finding a test sequence's saliency map which uses
first-order derivatives to describe the importance of each nucleotide in making
the final prediction. Second, considering recurrent models make predictions in
a temporal manner (from one end of a TFBS sequence to the other), we introduce
temporal output scores, indicating the prediction score of a model over time
for a sequential input. Lastly, a class-specific visualization strategy finds
the optimal input sequence for a given TFBS positive class via stochastic
gradient optimization. Our experimental results indicate that a
convolutional-recurrent architecture performs the best among the three
architectures. The visualization techniques indicate that CNN-RNN makes
predictions by modeling both motifs as well as dependencies among them.


A Theoretical Framework for Robustness of (Deep) Classifiers against
  Adversarial Examples

  Most machine learning classifiers, including deep neural networks, are
vulnerable to adversarial examples. Such inputs are typically generated by
adding small but purposeful modifications that lead to incorrect outputs while
imperceptible to human eyes. The goal of this paper is not to introduce a
single method, but to make theoretical steps towards fully understanding
adversarial examples. By using concepts from topology, our theoretical analysis
brings forth the key reasons why an adversarial example can fool a classifier
($f_1$) and adds its oracle ($f_2$, like human eyes) in such analysis. By
investigating the topological relationship between two (pseudo)metric spaces
corresponding to predictor $f_1$ and oracle $f_2$, we develop necessary and
sufficient conditions that can determine if $f_1$ is always robust
(strong-robust) against adversarial examples according to $f_2$. Interestingly
our theorems indicate that just one unnecessary feature can make $f_1$ not
strong-robust, and the right feature representation learning is the key to
getting a classifier that is both accurate and strong-robust.


Attend and Predict: Understanding Gene Regulation by Selective Attention
  on Chromatin

  The past decade has seen a revolution in genomic technologies that enable a
flood of genome-wide profiling of chromatin marks. Recent literature tried to
understand gene regulation by predicting gene expression from large-scale
chromatin measurements. Two fundamental challenges exist for such learning
tasks: (1) genome-wide chromatin signals are spatially structured,
high-dimensional and highly modular; and (2) the core aim is to understand what
are the relevant factors and how they work together? Previous studies either
failed to model complex dependencies among input signals or relied on separate
feature analysis to explain the decisions. This paper presents an
attention-based deep learning approach; we call AttentiveChrome, that uses a
unified architecture to model and to interpret dependencies among chromatin
factors for controlling gene regulation. AttentiveChrome uses a hierarchy of
multiple Long short-term memory (LSTM) modules to encode the input signals and
to model how various chromatin marks cooperate automatically. AttentiveChrome
trains two levels of attention jointly with the target prediction, enabling it
to attend differentially to relevant marks and to locate important positions
per mark. We evaluate the model across 56 different cell types (tasks) in
human. Not only is the proposed architecture more accurate, but its attention
scores also provide a better interpretation than state-of-the-art feature
visualization methods such as saliency map.
  Code and data are shared at www.deepchrome.org


Adversarial-Playground: A Visualization Suite Showing How Adversarial
  Examples Fool Deep Learning

  Recent studies have shown that attackers can force deep learning models to
misclassify so-called "adversarial examples": maliciously generated images
formed by making imperceptible modifications to pixel values. With growing
interest in deep learning for security applications, it is important for
security experts and users of machine learning to recognize how learning
systems may be attacked. Due to the complex nature of deep learning, it is
challenging to understand how deep models can be fooled by adversarial
examples. Thus, we present a web-based visualization tool,
Adversarial-Playground, to demonstrate the efficacy of common adversarial
methods against a convolutional neural network (CNN) system.
Adversarial-Playground is educational, modular and interactive. (1) It enables
non-experts to compare examples visually and to understand why an adversarial
example can fool a CNN-based image classifier. (2) It can help security experts
explore more vulnerability of deep learning as a software module. (3) Building
an interactive visualization is challenging in this domain due to the large
feature space of image classification (generating adversarial examples is slow
in general and visualizing images are costly). Through multiple novel design
choices, our tool can provide fast and accurate responses to user requests.
Empirically, we find that our client-server division strategy reduced the
response time by an average of 1.5 seconds per sample. Our other innovation, a
faster variant of JSMA evasion algorithm, empirically performed twice as fast
as JSMA and yet maintains a comparable evasion rate.
  Project source code and data from our experiments available at:
https://github.com/QData/AdversarialDNN-Playground


Prototype Matching Networks for Large-Scale Multi-label Genomic Sequence
  Classification

  One of the fundamental tasks in understanding genomics is the problem of
predicting Transcription Factor Binding Sites (TFBSs). With more than hundreds
of Transcription Factors (TFs) as labels, genomic-sequence based TFBS
prediction is a challenging multi-label classification task. There are two
major biological mechanisms for TF binding: (1) sequence-specific binding
patterns on genomes known as "motifs" and (2) interactions among TFs known as
co-binding effects. In this paper, we propose a novel deep architecture, the
Prototype Matching Network (PMN) to mimic the TF binding mechanisms. Our PMN
model automatically extracts prototypes ("motif"-like features) for each TF
through a novel prototype-matching loss. Borrowing ideas from few-shot matching
models, we use the notion of support set of prototypes and an LSTM to learn how
TFs interact and bind to genomic sequences. On a reference TFBS dataset with
$2.1$ $million$ genomic sequences, PMN significantly outperforms baselines and
validates our design choices empirically. To our knowledge, this is the first
deep learning architecture that introduces prototype learning and considers
TF-TF interactions for large-scale TFBS prediction. Not only is the proposed
architecture accurate, but it also models the underlying biology.


Black-box Generation of Adversarial Text Sequences to Evade Deep
  Learning Classifiers

  Although various techniques have been proposed to generate adversarial
samples for white-box attacks on text, little attention has been paid to
black-box attacks, which are more realistic scenarios. In this paper, we
present a novel algorithm, DeepWordBug, to effectively generate small text
perturbations in a black-box setting that forces a deep-learning classifier to
misclassify a text input. We employ novel scoring strategies to identify the
critical tokens that, if modified, cause the classifier to make an incorrect
prediction. Simple character-level transformations are applied to the
highest-ranked tokens in order to minimize the edit distance of the
perturbation, yet change the original classification. We evaluated DeepWordBug
on eight real-world text datasets, including text classification, sentiment
analysis, and spam detection. We compare the result of DeepWordBug with two
baselines: Random (Black-box) and Gradient (White-box). Our experimental
results indicate that DeepWordBug reduces the prediction accuracy of current
state-of-the-art deep-learning models, including a decrease of 68\% on average
for a Word-LSTM model and 48\% on average for a Char-CNN model.


A Fast and Scalable Joint Estimator for Integrating Additional Knowledge
  in Learning Multiple Related Sparse Gaussian Graphical Models

  We consider the problem of including additional knowledge in estimating
sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often
in bioinformatics and neuroimaging applications. Previous joint sGGM estimators
either fail to use existing knowledge or cannot scale-up to many tasks (large
$K$) under a high-dimensional (large $p$) situation. In this paper, we propose
a novel \underline{J}oint \underline{E}lementary \underline{E}stimator
incorporating additional \underline{K}nowledge (JEEK) to infer multiple related
sparse Gaussian Graphical models from large-scale heterogeneous data. Using
domain knowledge as weights, we design a novel hybrid norm as the minimization
objective to enforce the superposition of two weighted sparsity constraints,
one on the shared interactions and the other on the task-specific structural
patterns. This enables JEEK to elegantly consider various forms of existing
knowledge based on the domain at hand and avoid the need to design
knowledge-specific optimization. JEEK is solved through a fast and entry-wise
parallelizable solution that largely improves the computational efficiency of
the state-of-the-art $O(p^5K^4)$ to $O(p^2K^4)$. We conduct a rigorous
statistical analysis showing that JEEK achieves the same convergence rate
$O(\log(Kp)/n_{tot})$ as the state-of-the-art estimators that are much harder
to compute. Empirically, on multiple synthetic datasets and two real-world
data, JEEK outperforms the speed of the state-of-arts significantly while
achieving the same level of prediction accuracy. Available as R tool "jeek"


DeepDiff: Deep-learning for predicting Differential gene expression from
  histone modifications

  Computational methods that predict differential gene expression from histone
modification signals are highly desirable for understanding how histone
modifications control the functional heterogeneity of cells through influencing
differential gene regulation. Recent studies either failed to capture
combinatorial effects on differential prediction or primarily only focused on
cell type-specific analysis. In this paper, we develop a novel attention-based
deep learning architecture, DeepDiff, that provides a unified and end-to-end
solution to model and to interpret how dependencies among histone modifications
control the differential patterns of gene regulation. DeepDiff uses a hierarchy
of multiple Long short-term memory (LSTM) modules to encode the spatial
structure of input signals and to model how various histone modifications
cooperate automatically. We introduce and train two levels of attention jointly
with the target prediction, enabling DeepDiff to attend differentially to
relevant modifications and to locate important genome positions for each
modification. Additionally, DeepDiff introduces a novel deep-learning based
multi-task formulation to use the cell-type-specific gene expression
predictions as auxiliary tasks, encouraging richer feature embeddings in our
primary task of differential expression prediction. Using data from Roadmap
Epigenomics Project (REMC) for ten different pairs of cell types, we show that
DeepDiff significantly outperforms the state-of-the-art baselines for
differential gene expression prediction. The learned attention weights are
validated by observations from previous studies about how epigenetic mechanisms
connect to differential gene expression. Codes and results are available at
\url{deepchrome.org}


Feature Squeezing: Detecting Adversarial Examples in Deep Neural
  Networks

  Although deep neural networks (DNNs) have achieved great success in many
tasks, they can often be fooled by \emph{adversarial examples} that are
generated by adding small but purposeful distortions to natural examples.
Previous studies to defend against adversarial examples mostly focused on
refining the DNN models, but have either shown limited success or required
expensive computation. We propose a new strategy, \emph{feature squeezing},
that can be used to harden DNN models by detecting adversarial examples.
Feature squeezing reduces the search space available to an adversary by
coalescing samples that correspond to many different feature vectors in the
original space into a single sample. By comparing a DNN model's prediction on
the original input with that on squeezed inputs, feature squeezing detects
adversarial examples with high accuracy and few false positives. This paper
explores two feature squeezing methods: reducing the color bit depth of each
pixel and spatial smoothing. These simple strategies are inexpensive and
complementary to other defenses, and can be combined in a joint detection
framework to achieve high detection rates against state-of-the-art attacks.


Unsupervised Feature Learning by Deep Sparse Coding

  In this paper, we propose a new unsupervised feature learning framework,
namely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer
architecture for visual object recognition tasks. The main innovation of the
framework is that it connects the sparse-encoders from different layers by a
sparse-to-dense module. The sparse-to-dense module is a composition of a local
spatial pooling step and a low-dimensional embedding process, which takes
advantage of the spatial smoothness information in the image. As a result, the
new method is able to learn several levels of sparse representation of the
image which capture features at a variety of abstraction levels and
simultaneously preserve the spatial smoothness between the neighboring image
patches. Combining the feature representations from multiple layers, DeepSC
achieves the state-of-the-art performance on multiple object recognition tasks.


Electrical Oscillation in Pt/VO2 Bilayer Strips

  We report on the observation of stable electrical oscillation in Pt/VO2
bilayer strips, in which the Pt overlayer serves the dual purposes of heating
up the VO2 and weakening the electric field in the VO2 layer. Systematic
measurements in an ultrahigh vacuum nanoprobe system show that the oscillation
frequency increases with the bias current and/or with decreasing device
dimension. In contrast to most VO2-based oscillators reported to date, which
are electrically triggered, current-induced Joule heating in the Pt overlayer
is found to play a dominant role in the generation of oscillation in Pt/VO2
bilayers. A simple model involving thermally triggered transition of VO2 on a
heat sink is able to account for the experimental observations. The results in
this work provide an alternative view of the triggering mechanism in VO2-based
oscillators.


Transfer String Kernel for Cross-Context DNA-Protein Binding Prediction

  Through sequence-based classification, this paper tries to accurately predict
the DNA binding sites of transcription factors (TFs) in an unannotated cellular
context. Related methods in the literature fail to perform such predictions
accurately, since they do not consider sample distribution shift of sequence
segments from an annotated (source) context to an unannotated (target) context.
We, therefore, propose a method called "Transfer String Kernel" (TSK) that
achieves improved prediction of transcription factor binding site (TFBS) using
knowledge transfer via cross-context sample adaptation. TSK maps sequence
segments to a high-dimensional feature space using a discriminative mismatch
string kernel framework. In this high-dimensional space, labeled examples of
the source context are re-weighted so that the revised sample distribution
matches the target context more closely. We have experimentally verified TSK
for TFBS identifications on fourteen different TFs under a cross-organism
setting. We find that TSK consistently outperforms the state-of the-art TFBS
tools, especially when working with TFs whose binding sequences are not
conserved across contexts. We also demonstrate the generalizability of TSK by
showing its cutting-edge performance on a different set of cross-context tasks
for the MHC peptide binding predictions.


DeepCloak: Masking Deep Neural Network Models for Robustness Against
  Adversarial Samples

  Recent studies have shown that deep neural networks (DNN) are vulnerable to
adversarial samples: maliciously-perturbed samples crafted to yield incorrect
model outputs. Such attacks can severely undermine DNN systems, particularly in
security-sensitive settings. It was observed that an adversary could easily
generate adversarial samples by making a small perturbation on irrelevant
feature dimensions that are unnecessary for the current classification task. To
overcome this problem, we introduce a defensive mechanism called DeepCloak. By
identifying and removing unnecessary features in a DNN model, DeepCloak limits
the capacity an attacker can use generating adversarial samples and therefore
increase the robustness against such inputs. Comparing with other defensive
approaches, DeepCloak is easy to implement and computationally efficient.
Experimental results show that DeepCloak can increase the performance of
state-of-the-art DNN models against adversarial samples.


Unveiling the role of Co-O-Mg bond in magnetic anisotropy of Pt/Co/MgO
  using atomically controlled deposition and in-situ electrical measurement

  Despite the crucial role of interfacial perpendicular magnetic anisotropy in
Co(Fe)/MgO based magnetic tunnel junction, the underlying mechanism is still
being debated. Here, we report an anatomical study of oxygen and Mg effect on
Pt/Co bilayers through repeated in-situ anomalous Hall effect measurements,
controlled oxygen exposure and Mg deposition in an ultrahigh vacuum system. We
found that chemisorbed oxygen not only quenches the effective magnetic moment
of the Co surface layer, but also softens its magnetic anisotropy. However, a
subsequent Mg dusting on the oxygen pre-exposed Pt/Co surface can recover the
magnetic anisotropy. The ab initio calculations on the exchange splitting and
orbital hybridization near the Fermi level give a clear physical explanation of
the experimental observations. Our results suggest that Co(Fe)-O-M bond plays a
more important role than the widely perceived Co(Fe)-O bond does in realizing
interfacial perpendicular magnetic anisotropy in Co(Fe)/MgO heterostructures.


Reconciling Enumerative and Symbolic Search in Syntax-Guided Synthesis

  Syntax-guided synthesis aims to find a program satisfying semantic
specification as well as user-provided structural hypothesis. For syntax-guided
synthesis there are two main search strategies: concrete search, which
systematically or stochastically enumerates all possible solutions, and
symbolic search, which interacts with a constraint solver to solve the
synthesis problem. In this paper, we propose a concolic synthesis framework
which combines the best of the two worlds. Based on a decision tree
representation, our framework works by enumerating tree heights from the
smallest possible one to larger ones. For each fixed height, the framework
symbolically searches a solution through the counterexample-guided inductive
synthesis approach. To compensate the exponential blow-up problem with the
concolic synthesis framework, we identify two fragments of synthesis problems
and develop purely symbolic and more efficient procedures. The two fragments
are decidable as these procedures are terminating and complete. We implemented
our synthesis procedures and compared with state-of-the-art synthesizers on a
range of benchmarks. Experiments show that our algorithms are promising.


Cancer Diagnosis with QUIRE: QUadratic Interactions among infoRmative
  fEatures

  Responsible for many complex human diseases including cancers, disrupted or
abnormal gene interactions can be identified through their expression changes
correlating with the progression of a disease. However, the examination of all
possible combinatorial interactions between gene features in a genome-wide
case-control study is computationally infeasible as the search space is
exponential in nature.
  In this paper, we propose a novel computational approach, QUIRE, to identify
discriminative complex interactions among informative gene features for cancer
diagnosis. QUIRE works in two stages, where it first identifies functionally
relevant feature groups for the disease and, then explores the search space
capturing the combinatorial relationships among the genes from the selected
informative groups. Using QUIRE, we explore the differential patterns and the
interactions among informative gene features in three different types of
cancers, Renal Cell Carcinoma(RCC), Ovarian Cancer(OVC) and Colorectal Cancer
(CRC). Our experimental results show that QUIRE identifies gene-gene
interactions that can better identify the different cancer stages of samples
and can predict CRC recurrence and death from CRC more successfully, as
compared to other state-of-the-art feature selection methods. A literature
survey shows that many of the interactions identified by QUIRE play important
roles in the development of cancer.


DeepChrome: Deep-learning for predicting gene expression from histone
  modifications

  Motivation: Histone modifications are among the most important factors that
control gene regulation. Computational methods that predict gene expression
from histone modification signals are highly desirable for understanding their
combinatorial effects in gene regulation. This knowledge can help in developing
'epigenetic drugs' for diseases like cancer. Previous studies for quantifying
the relationship between histone modifications and gene expression levels
either failed to capture combinatorial effects or relied on multiple methods
that separate predictions and combinatorial analysis. This paper develops a
unified discriminative framework using a deep convolutional neural network to
classify gene expression using histone modification data as input. Our system,
called DeepChrome, allows automatic extraction of complex interactions among
important features. To simultaneously visualize the combinatorial interactions
among histone modifications, we propose a novel optimization-based technique
that generates feature pattern maps from the learnt deep model. This provides
an intuitive description of underlying epigenetic mechanisms that regulate
genes. Results: We show that DeepChrome outperforms state-of-the-art models
like Support Vector Machines and Random Forests for gene expression
classification task on 56 different cell-types from REMC database. The output
of our visualization technique not only validates the previous observations but
also allows novel insights about combinatorial interactions among histone
modification marks, some of which have recently been observed by experimental
studies.


Data Priming Network for Automatic Check-Out

  Automatic Check-Out (ACO) receives increased interests in recent years. An
important component of the ACO system is the visual item counting, which
recognize the categories and counts of the items chosen by the customers.
However, the training of such a system is challenged by the domain adaptation
problem, in which the training data are images from isolated items while the
testing images are for collections of items. Existing methods solve this
problem with data augmentation using synthesized images, but the image
synthesis leads to unreal images that affect the training process. In this
paper, we propose a new data priming method to solve the domain adaptation
problem. Specifically, we first use pre-augmentation data priming, in which we
remove distracting background from the training images and select images with
realistic view angles by the pose pruning method. In the post-augmentation
step, we train a data priming network using detection and counting
collaborative learning, and select more reliable images from testing data to
train the final visual item tallying network. Experiments on the large scale
Retail Product Checkout (RPC) dataset demonstrate the superiority of the
proposed method, i.e., we achieve 80.51% checkout accuracy compared with 56.68%
of the baseline methods.


