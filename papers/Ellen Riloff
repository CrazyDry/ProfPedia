A Corpus-Based Approach for Building Semantic Lexicons

  Semantic knowledge can be a great asset to natural language processing
systems, but it is usually hand-coded for each application. Although some
semantic information is available in general-purpose knowledge bases such as
WordNet and Cyc, many applications require domain-specific lexicons that
represent words and categories for a particular topic. In this paper, we
present a corpus-based method that can be used to build semantic lexicons for
specific categories. The input to the system is a small set of seed words for a
category and a representative text corpus. The output is a ranked list of words
that are associated with the category. A user then reviews the top-ranked words
and decides which ones should be entered in the semantic lexicon. In
experiments with five categories, users typically found about 60 words per
category in 10-15 minutes to build a core semantic lexicon.


Looking Under the Hood : Tools for Diagnosing your Question Answering
  Engine

  In this paper we analyze two question answering tasks : the TREC-8 question
answering task and a set of reading comprehension exams. First, we show that
Q/A systems perform better when there are multiple answer opportunities per
question. Next, we analyze common approaches to two subproblems: term overlap
for answer sentence identification, and answer typing for short answer
extraction. We present general tools for analyzing the strengths and
limitations of techniques for these subproblems. Our results quantify the
limitations of both term overlap and answer typing to distinguish between
competing answer candidates.


And That's A Fact: Distinguishing Factual and Emotional Argumentation in
  Online Dialogue

  We investigate the characteristics of factual and emotional argumentation
styles observed in online debates. Using an annotated set of "factual" and
"feeling" debate forum posts, we extract patterns that are highly correlated
with factual and emotional arguments, and then apply a bootstrapping
methodology to find new patterns in a larger pool of unannotated forum posts.
This process automatically produces a large set of patterns representing
linguistic expressions that are highly correlated with factual and emotional
language. Finally, we analyze the most discriminating patterns to better
understand the defining characteristics of factual and emotional arguments.


Are you serious?: Rhetorical Questions and Sarcasm in Social Media
  Dialog

  Effective models of social dialog must understand a broad range of rhetorical
and figurative devices. Rhetorical questions (RQs) are a type of figurative
language whose aim is to achieve a pragmatic goal, such as structuring an
argument, being persuasive, emphasizing a point, or being ironic. While there
are computational models for other forms of figurative language, rhetorical
questions have received little attention to date. We expand a small dataset
from previous work, presenting a corpus of 10,270 RQs from debate forums and
Twitter that represent different discourse functions. We show that we can
clearly distinguish between RQs and sincere questions (0.76 F1). We then show
that RQs can be used both sarcastically and non-sarcastically, observing that
non-sarcastic (other) uses of RQs are frequently argumentative in forums, and
persuasive in tweets. We present experiments to distinguish between these uses
of RQs using SVM and LSTM models that represent linguistic features and
post-level context, achieving results as high as 0.76 F1 for "sarcastic" and
0.77 F1 for "other" in forums, and 0.83 F1 for both "sarcastic" and "other" in
tweets. We supplement our quantitative experiments with an in-depth
characterization of the linguistic variation in RQs.


Creating and Characterizing a Diverse Corpus of Sarcasm in Dialogue

  The use of irony and sarcasm in social media allows us to study them at scale
for the first time. However, their diversity has made it difficult to construct
a high-quality corpus of sarcasm in dialogue. Here, we describe the process of
creating a large- scale, highly-diverse corpus of online debate forums
dialogue, and our novel methods for operationalizing classes of sarcasm in the
form of rhetorical questions and hyperbole. We show that we can use
lexico-syntactic cues to reliably retrieve sarcastic utterances with high
accuracy. To demonstrate the properties and quality of our corpus, we conduct
supervised learning experiments with simple features, and show that we achieve
both higher precision and F than previous work on sarcasm in debate forums
dialogue. We apply a weakly-supervised linguistic pattern learner and
qualitatively analyze the linguistic differences in each class.


