Unique strong solutions of Levy processes driven stochastic differential
  equations with discontinuous coefficients

  We establish the existence and uniqueness for a one-dimensional stochastic
differential equation driven by a Brownian motion and a pure jump {\levy}
process. It is shown that under fairly general conditions on the coefficients,
pathwise uniqueness holds based on the methods of weak uniqueness and local
time technique.


Mean-variance portfolio selection under partial information with drift
  uncertainty

  This paper studies a mean-variance portfolio selection problem under partial
information with drift uncertainty. It is proved that all the contingent claims
in this model are attainable in the sense of Xiong and Zhou. Further, we
propose a numerical scheme to approximate the optimal portfolio. Malliavin
calculus and the strong law of large numbers play important roles in this
scheme.


Decentralized Recommender Systems

  This paper proposes a decentralized recommender system by formulating the
popular collaborative filleting (CF) model into a decentralized matrix
completion form over a set of users. In such a way, data storages and
computations are fully distributed. Each user could exchange limited
information with its local neighborhood, and thus it avoids the centralized
fusion. Advantages of the proposed system include a protection on user privacy,
as well as better scalability and robustness. We compare our proposed algorithm
with several state-of-the-art algorithms on the FlickerUserFavor dataset, and
demonstrate that the decentralized algorithm can gain a competitive performance
to others.


The Multilevel Finite Element Discretizations Based on Local
  Defect-Correction for Nonsymmetric Eigenvalue Problems

  Based on the work of Xu and Zhou [Math.Comput., 69(2000), pp.881-909], we
establish new three-level and multilevel finite element discretizations by
local defect-correction technique. Theoretical analysis and numerical
experiments show that the schemes are simple and easy to carry out, and can be
used to solve singular nonsymmetric eigenvalue problems efficiently. We also
discuss the local error estimates of finite element approximations; it's a new
feature here that the estimates apply to the local domains containing corner
points.


Distributed Data Vending on Blockchain

  Recent advances in blockchain technologies have provided exciting
opportunities for decentralized applications. Specifically, blockchain-based
smart contracts enable credible transactions without authorized third parties.
The attractive properties of smart contracts facilitate distributed data
vending, allowing for proprietary data to be securely exchanged on a
blockchain. Distributed data vending can transform domains such as healthcare
by encouraging data distribution from owners and enabling large-scale data
aggregation. However, one key challenge in distributed data vending is the
trade-off dilemma between the effectiveness of data retrieval, and the leakage
risk from indexing the data. In this paper, we propose a framework for
distributed data vending through a combination of data embedding and similarity
learning. We illustrate our framework through a practical scenario of
distributing and aggregating electronic medical records on a blockchain.
Extensive empirical results demonstrate the effectiveness of our framework.


Using Inverse lambda and Generalization to Translate English to Formal
  Languages

  We present a system to translate natural language sentences to formulas in a
formal or a knowledge representation language. Our system uses two inverse
lambda-calculus operators and using them can take as input the semantic
representation of some words, phrases and sentences and from that derive the
semantic representation of other words and phrases. Our inverse lambda operator
works on many formal languages including first order logic, database query
languages and answer set programming. Our system uses a syntactic combinatorial
categorial parser to parse natural language sentences and also to construct the
semantic meaning of the sentences as directed by their parsing. The same parser
is used for both. In addition to the inverse lambda-calculus operators, our
system uses a notion of generalization to learn semantic representation of
words from the semantic representation of other words that are of the same
category. Together with this, we use an existing statistical learning approach
to assign weights to deal with multiple meanings of words. Our system produces
improved results on standard corpora on natural language interfaces for robot
command and control and database queries.


A Safe Screening Rule for Sparse Logistic Regression

  The l1-regularized logistic regression (or sparse logistic regression) is a
widely used method for simultaneous classification and feature selection.
Although many recent efforts have been devoted to its efficient implementation,
its application to high dimensional data still poses significant challenges. In
this paper, we present a fast and effective sparse logistic regression
screening rule (Slores) to identify the 0 components in the solution vector,
which may lead to a substantial reduction in the number of features to be
entered to the optimization. An appealing feature of Slores is that the data
set needs to be scanned only once to run the screening and its computational
cost is negligible compared to that of solving the sparse logistic regression
problem. Moreover, Slores is independent of solvers for sparse logistic
regression, thus Slores can be integrated with any existing solver to improve
the efficiency. We have evaluated Slores using high-dimensional data sets from
different applications. Extensive experimental results demonstrate that Slores
outperforms the existing state-of-the-art screening rules and the efficiency of
solving sparse logistic regression is improved by one magnitude in general.


Physical Design and Monte Carlo Simulations of a Space Radiation
  Detector onboard the SJ-10 satellite

  A radiation gene box (RGB) onboard the SJ-10 satellite is a device carrying
mice and drosophila cells to determine the biological effects of space
radiation environment. The shielded fluxes of different radioactive sources
were calculated and the linear energy transfers of gamma-rays, electrons,
protons and alpha-particles in tissue were acquired using A-150
tissue-equivalent plastic. Then, a conceptual model of a space radiation
instrument employing three semiconductor sub-detectors for deriving the charged
and uncharged radiation environment of the RGB was designed. The energy
depositions in the three sub-detectors were classified into fifteen channels
(bins) in an algorithm derived from the Monte Carlo method. The physical
feasibility of the conceptual instrument was also verified by Monte Carlo
simulations.


Learning A Task-Specific Deep Architecture For Clustering

  While sparse coding-based clustering methods have shown to be successful,
their bottlenecks in both efficiency and scalability limit the practical usage.
In recent years, deep learning has been proved to be a highly effective,
efficient and scalable feature learning tool. In this paper, we propose to
emulate the sparse coding-based clustering pipeline in the context of deep
learning, leading to a carefully crafted deep model benefiting from both. A
feed-forward network structure, named TAGnet, is constructed based on a
graph-regularized sparse coding algorithm. It is then trained with
task-specific loss functions from end to end. We discover that connecting deep
learning to sparse coding benefits not only the model performance, but also its
initialization and interpretation. Moreover, by introducing auxiliary
clustering tasks to the intermediate feature hierarchy, we formulate DTAGnet
and obtain a further performance boost. Extensive experiments demonstrate that
the proposed model gains remarkable margins over several state-of-the-art
methods.


Collaborative Deep Reinforcement Learning

  Besides independent learning, human learning process is highly improved by
summarizing what has been learned, communicating it with peers, and
subsequently fusing knowledge from different sources to assist the current
learning goal. This collaborative learning procedure ensures that the knowledge
is shared, continuously refined, and concluded from different perspectives to
construct a more profound understanding. The idea of knowledge transfer has led
to many advances in machine learning and data mining, but significant
challenges remain, especially when it comes to reinforcement learning,
heterogeneous model structures, and different learning tasks. Motivated by
human collaborative learning, in this paper we propose a collaborative deep
reinforcement learning (CDRL) framework that performs adaptive knowledge
transfer among heterogeneous learning agents. Specifically, the proposed CDRL
conducts a novel deep knowledge distillation method to address the
heterogeneity among different learning tasks with a deep alignment network.
Furthermore, we present an efficient collaborative Asynchronous Advantage
Actor-Critic (cA3C) algorithm to incorporate deep knowledge distillation into
the online training of agents, and demonstrate the effectiveness of the CDRL
framework using extensive empirical evaluation on OpenAI gym.


Two Birds with One Stone: Transforming and Generating Facial Images with
  Iterative GAN

  Generating high fidelity identity-preserving faces with different facial
attributes has a wide range of applications. Although a number of generative
models have been developed to tackle this problem, there is still much room for
further improvement.In paticular, the current solutions usually ignore the
perceptual information of images, which we argue that it benefits the output of
a high-quality image while preserving the identity information, especially in
facial attributes learning area.To this end, we propose to train GAN
iteratively via regularizing the min-max process with an integrated loss, which
includes not only the per-pixel loss but also the perceptual loss. In contrast
to the existing methods only deal with either image generation or
transformation, our proposed iterative architecture can achieve both of them.
Experiments on the multi-label facial dataset CelebA demonstrate that the
proposed model has excellent performance on recognizing multiple attributes,
generating a high-quality image, and transforming image with controllable
attributes.


Efficient Large-Scale Fleet Management via Multi-Agent Deep
  Reinforcement Learning

  Large-scale online ride-sharing platforms have substantially transformed our
lives by reallocating transportation resources to alleviate traffic congestion
and promote transportation efficiency. An efficient fleet management strategy
not only can significantly improve the utilization of transportation resources
but also increase the revenue and customer satisfaction. It is a challenging
task to design an effective fleet management strategy that can adapt to an
environment involving complex dynamics between demand and supply. Existing
studies usually work on a simplified problem setting that can hardly capture
the complicated stochastic demand-supply variations in high-dimensional space.
In this paper we propose to tackle the large-scale fleet management problem
using reinforcement learning, and propose a contextual multi-agent
reinforcement learning framework including two concrete algorithms, namely
contextual deep Q-learning and contextual multi-agent actor-critic, to achieve
explicit coordination among a large number of agents adaptive to different
contexts. We show significant improvements of the proposed framework over
state-of-the-art approaches through extensive empirical studies.


Differentially Private Generative Adversarial Network

  Generative Adversarial Network (GAN) and its variants have recently attracted
intensive research interests due to their elegant theoretical foundation and
excellent empirical performance as generative models. These tools provide a
promising direction in the studies where data availability is limited. One
common issue in GANs is that the density of the learned generative distribution
could concentrate on the training data points, meaning that they can easily
remember training samples due to the high model complexity of deep networks.
This becomes a major concern when GANs are applied to private or sensitive data
such as patient medical records, and the concentration of distribution may
divulge critical patient information. To address this issue, in this paper we
propose a differentially private GAN (DPGAN) model, in which we achieve
differential privacy in GANs by adding carefully designed noise to gradients
during the learning procedure. We provide rigorous proof for the privacy
guarantee, as well as comprehensive empirical evidence to support our analysis,
where we demonstrate that our method can generate high quality data points at a
reasonable privacy level.


Drug Similarity Integration Through Attentive Multi-view Graph
  Auto-Encoders

  Drug similarity has been studied to support downstream clinical tasks such as
inferring novel properties of drugs (e.g. side effects, indications,
interactions) from known properties. The growing availability of new types of
drug features brings the opportunity of learning a more comprehensive and
accurate drug similarity that represents the full spectrum of underlying drug
relations. However, it is challenging to integrate these heterogeneous, noisy,
nonlinear-related information to learn accurate similarity measures especially
when labels are scarce. Moreover, there is a trade-off between accuracy and
interpretability. In this paper, we propose to learn accurate and interpretable
similarity measures from multiple types of drug features. In particular, we
model the integration using multi-view graph auto-encoders, and add attentive
mechanism to determine the weights for each view with respect to corresponding
tasks and features for better interpretability. Our model has flexible design
for both semi-supervised and unsupervised settings. Experimental results
demonstrated significant predictive accuracy improvement. Case studies also
showed better model capacity (e.g. embed node features) and interpretability.


Multi-View Graph Convolutional Network and Its Applications on
  Neuroimage Analysis for Parkinson's Disease

  Parkinson's Disease (PD) is one of the most prevalent neurodegenerative
diseases that affects tens of millions of Americans. PD is highly progressive
and heterogeneous. Quite a few studies have been conducted in recent years on
predictive or disease progression modeling of PD using clinical and biomarkers
data. Neuroimaging, as another important information source for
neurodegenerative disease, has also arisen considerable interests from the PD
community. In this paper, we propose a deep learning method based on Graph
Convolutional Networks (GCN) for fusing multiple modalities of brain images in
relationship prediction which is useful for distinguishing PD cases from
controls. On Parkinson's Progression Markers Initiative (PPMI) cohort, our
approach achieved $0.9537\pm 0.0587$ AUC, compared with $0.6443\pm 0.0223$ AUC
achieved by traditional approaches such as PCA.


Boosted Sparse and Low-Rank Tensor Regression

  We propose a sparse and low-rank tensor regression model to relate a
univariate outcome to a feature tensor, in which each unit-rank tensor from the
CP decomposition of the coefficient tensor is assumed to be sparse. This
structure is both parsimonious and highly interpretable, as it implies that the
outcome is related to the features through a few distinct pathways, each of
which may only involve subsets of feature dimensions. We take a
divide-and-conquer strategy to simplify the task into a set of sparse unit-rank
tensor regression problems. To make the computation efficient and scalable, for
the unit-rank tensor regression, we propose a stagewise estimation procedure to
efficiently trace out its entire solution path. We show that as the step size
goes to zero, the stagewise solution paths converge exactly to those of the
corresponding regularized regression. The superior performance of our approach
is demonstrated on various real-world and synthetic examples.


Asynchronous Multi-Task Learning

  Many real-world machine learning applications involve several learning tasks
which are inter-related. For example, in healthcare domain, we need to learn a
predictive model of a certain disease for many hospitals. The models for each
hospital may be different because of the inherent differences in the
distributions of the patient populations. However, the models are also closely
related because of the nature of the learning tasks modeling the same disease.
By simultaneously learning all the tasks, multi-task learning (MTL) paradigm
performs inductive knowledge transfer among tasks to improve the generalization
performance. When datasets for the learning tasks are stored at different
locations, it may not always be feasible to transfer the data to provide a
data-centralized computing environment due to various practical issues such as
high data volume and privacy. In this paper, we propose a principled MTL
framework for distributed and asynchronous optimization to address the
aforementioned challenges. In our framework, gradient update does not wait for
collecting the gradient information from all the tasks. Therefore, the proposed
method is very efficient when the communication delay is too high for some task
nodes. We show that many regularized MTL formulations can benefit from this
framework, including the low-rank MTL for shared subspace learning. Empirical
studies on both synthetic and real-world datasets demonstrate the efficiency
and effectiveness of the proposed framework.


EdgeChain: Blockchain-based Multi-vendor Mobile Edge Application
  Placement

  The state-of-the-art mobile edge applications are generating intense traffic
and posing rigorous latency requirements to service providers. While resource
sharing across multiple service providers can be a way to maximize the
utilization of limited resources at the network edge, it requires a centralized
repository maintained by all parties for service providers to share status.
Moreover, service providers have to trust each other for resource allocation
fairness, which is difficult because of potential conflicts of interest. We
propose EdgeChain, a blockchain-based architecture to make mobile edge
application placement decisions for multiple service providers. We first
formulate a stochastic programming problem minimizing the placement cost for
mobile edge application placement scenarios. Based on our model, we present a
heuristic mobile edge application placement algorithm. As a decentralized
public ledger, the blockchain then takes the logic of our algorithm as the
smart contract, with the consideration of resources from all mobile edge hosts
participating in the system. The algorithm is agreed by all parties and the
results will only be accepted by majority of the mining nodes on the
blockchain. When a placement decision is made, an edge host meeting the
consumer's latency and budget requirements will be selected at the lowest cost.
All placement transactions are stored on the blockchain and are traceable by
every mobile edge service provider and application vendor who consumes
resources at the mobile edge.


Identify Susceptible Locations in Medical Records via Adversarial
  Attacks on Deep Predictive Models

  The surging availability of electronic medical records (EHR) leads to
increased research interests in medical predictive modeling. Recently many deep
learning based predicted models are also developed for EHR data and
demonstrated impressive performance. However, a series of recent studies showed
that these deep models are not safe: they suffer from certain vulnerabilities.
In short, a well-trained deep network can be extremely sensitive to inputs with
negligible changes. These inputs are referred to as adversarial examples. In
the context of medical informatics, such attacks could alter the result of a
high performance deep predictive model by slightly perturbing a patient's
medical records. Such instability not only reflects the weakness of deep
architectures, more importantly, it offers guide on detecting susceptible parts
on the inputs. In this paper, we propose an efficient and effective framework
that learns a time-preferential minimum attack targeting the LSTM model with
EHR inputs, and we leverage this attack strategy to screen medical records of
patients and identify susceptible events and measurements. The efficient
screening procedure can assist decision makers to pay extra attentions to the
locations that can cause severe consequence if not measured correctly. We
conduct extensive empirical studies on a real-world urgent care cohort and
demonstrate the effectiveness of the proposed screening approach.


Improving Mild Cognitive Impairment Prediction via Reinforcement
  Learning and Dialogue Simulation

  Mild cognitive impairment (MCI) is a prodromal phase in the progression from
normal aging to dementia, especially Alzheimers disease. Even though there is
mild cognitive decline in MCI patients, they have normal overall cognition and
thus is challenging to distinguish from normal aging. Using transcribed data
obtained from recorded conversational interactions between participants and
trained interviewers, and applying supervised learning models to these data, a
recent clinical trial has shown a promising result in differentiating MCI from
normal aging. However, the substantial amount of interactions with medical
staff can still incur significant medical care expenses in practice. In this
paper, we propose a novel reinforcement learning (RL) framework to train an
efficient dialogue agent on existing transcripts from clinical trials.
Specifically, the agent is trained to sketch disease-specific lexical
probability distribution, and thus to converse in a way that maximizes the
diagnosis accuracy and minimizes the number of conversation turns. We evaluate
the performance of the proposed reinforcement learning framework on the MCI
diagnosis from a real clinical trial. The results show that while using only a
few turns of conversation, our framework can significantly outperform
state-of-the-art supervised learning approaches.


Subspace Network: Deep Multi-Task Censored Regression for Modeling
  Neurodegenerative Diseases

  Over the past decade a wide spectrum of machine learning models have been
developed to model the neurodegenerative diseases, associating biomarkers,
especially non-intrusive neuroimaging markers, with key clinical scores
measuring the cognitive status of patients. Multi-task learning (MTL) has been
commonly utilized by these studies to address high dimensionality and small
cohort size challenges. However, most existing MTL approaches are based on
linear models and suffer from two major limitations: 1) they cannot explicitly
consider upper/lower bounds in these clinical scores; 2) they lack the
capability to capture complicated non-linear interactions among the variables.
In this paper, we propose Subspace Network, an efficient deep modeling approach
for non-linear multi-task censored regression. Each layer of the subspace
network performs a multi-task censored regression to improve upon the
predictions from the last layer via sketching a low-dimensional subspace to
perform knowledge transfer among learning tasks. Under mild assumptions, for
each layer the parametric subspace can be recovered using only one pass of
training data. Empirical results demonstrate that the proposed subspace network
quickly picks up the correct parameter subspaces, and outperforms
state-of-the-arts in predicting neurodegenerative clinical scores using
information in brain imaging.


Model-Protected Multi-Task Learning

  Multi-task learning (MTL) refers to the paradigm of learning multiple related
tasks together. By contrast, single-task learning (STL) learns each individual
task independently. MTL often leads to better trained models because they can
leverage the commonalities among related tasks. However, because MTL algorithms
will "transmit" information on different models across different tasks, MTL
poses a potential security risk. Specifically, an adversary may participate in
the MTL process through a participating task, thereby acquiring the model
information for another task. Previously proposed privacy-preserving MTL
methods protect data instances rather than models, and some of them may
underperform in comparison with STL methods. In this paper, we propose a
privacy-preserving MTL framework to prevent the information on each model from
leaking to other models based on a perturbation of the covariance matrix of the
model matrix, and we study two popular MTL approaches for instantiation,
namely, MTL approaches for learning the low-rank and group-sparse patterns of
the model matrix. Our methods are built upon tools for differential privacy.
Privacy guarantees and utility bounds are provided. Heterogeneous privacy
budgets are considered. Our algorithms can be guaranteed not to underperform
comparing with STL methods. Experiments demonstrate that our algorithms
outperform existing privacy-preserving MTL methods on the proposed
model-protection problem.


Study of electron emission from 1D nanomaterials under super high field

  Photoemission driven by a strong electric field of near-infrared or visible
light, referred to as strong-field photoemission, produces attosecond electron
pulses that are synchronized to the waveform of the incident light, and this
principle lies at the heart of current attosecond technologies. However, full
access to strong-field photoemission regimes at near-infrared wavelengths based
on solid-state materials is restricted by space-charge screening and material
damage at high optical-field strengths, which significantly hampers the
realization of predicted attosecond technologies, such as ultra-sensitive
optical phase modulation. Here, we demonstrate a new type of strong-field
photoemission behaviour with extreme nonlinearity -- photoemission current
scales follow a 40th power law of the optical-field strength, making use of
sub-nanometric carbon nanotubes and 800 nm pulses. As a result, the total
photoemission current depends on the carrier-envelope phase with a greatly
improved photoemission current modulation depth of up to 100%, which has not
previously been achieved. Time-dependent density functional calculations reveal
the completely new behaviour of the optical-field induced tunnelling emission
process directly from the valence band of the carbon nanotubes, which is an
indication of full access to a strong-field photoemission regime. Furthermore,
the nonlinear dynamics are observed to be tunable by changing the binding
energy of the valence-band-maximum, as confirmed by Simpleman model
calculations. We believe that such extreme nonlinear photoemission from
nanotips offers a new means of producing extreme temporal-spatial resolved
electron pulses. These results additionally provide a new design philosophy for
attosecond electronics and optics by making use of tunable band structures in
nanomaterials.


