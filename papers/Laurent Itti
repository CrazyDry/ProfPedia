Computational models of attention

  This chapter reviews recent computational models of visual attention. We
begin with models for the bottom-up or stimulus-driven guidance of attention to
salient visual items, which we examine in seven different broad categories. We
then examine more complex models which address the top-down or goal-oriented
guidance of attention towards items that are more relevant to the task at hand.


6th International Symposium on Attention in Cognitive Systems 2013

  This volume contains the papers accepted at the 6th International Symposium
on Attention in Cognitive Systems (ISACS 2013), held in Beijing, August 5,
2013. The aim of this symposium is to highlight the central role of attention
on various kinds of performance in cognitive systems processing. It brings
together researchers and developers from both academia and industry, from
computer vision, robotics, perception psychology, psychophysics and
neuroscience, in order to provide an interdisciplinary forum to present and
communicate on computational models of attention, with the focus on
interdependencies with visual cognition. Furthermore, it intends to investigate
relevant objectives for performance comparison, to document and to investigate
promising application domains, and to discuss visual attention with reference
to other aspects of AI enabled systems.


CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research

  Saliency modeling has been an active research area in computer vision for
about two decades. Existing state of the art models perform very well in
predicting where people look in natural scenes. There is, however, the risk
that these models may have been overfitting themselves to available small scale
biased datasets, thus trapping the progress in a local minimum. To gain a
deeper insight regarding current issues in saliency modeling and to better
gauge progress, we recorded eye movements of 120 observers while they freely
viewed a large number of naturalistic and artificial images. Our stimuli
includes 4000 images; 200 from each of 20 categories covering different types
of scenes such as Cartoons, Art, Objects, Low resolution images, Indoor,
Outdoor, Jumbled, Random, and Line drawings. We analyze some basic properties
of this dataset and compare some successful models. We believe that our dataset
opens new challenges for the next generation of saliency models and helps
conduct behavioral studies on bottom-up visual attention.


metricDTW: local distance metric learning in Dynamic Time Warping

  We propose to learn multiple local Mahalanobis distance metrics to perform
k-nearest neighbor (kNN) classification of temporal sequences. Temporal
sequences are first aligned by dynamic time warping (DTW); given the alignment
path, similarity between two sequences is measured by the DTW distance, which
is computed as the accumulated distance between matched temporal point pairs
along the alignment path. Traditionally, Euclidean metric is used for distance
computation between matched pairs, which ignores the data regularities and
might not be optimal for applications at hand. Here we propose to learn
multiple Mahalanobis metrics, such that DTW distance becomes the sum of
Mahalanobis distances. We adapt the large margin nearest neighbor (LMNN)
framework to our case, and formulate multiple metric learning as a linear
programming problem. Extensive sequence classification results show that our
proposed multiple metrics learning approach is effective, insensitive to the
preceding alignment qualities, and reaches the state-of-the-art performances on
UCR time series datasets.


Computational models: Bottom-up and top-down aspects

  Computational models of visual attention have become popular over the past
decade, we believe primarily for two reasons: First, models make testable
predictions that can be explored by experimentalists as well as theoreticians,
second, models have practical and technological applications of interest to the
applied science and engineering communities. In this chapter, we take a
critical look at recent attention modeling efforts. We focus on {\em
computational models of attention} as defined by Tsotsos \& Rothenstein
\shortcite{Tsotsos_Rothenstein11}: Models which can process any visual stimulus
(typically, an image or video clip), which can possibly also be given some task
definition, and which make predictions that can be compared to human or animal
behavioral or physiological responses elicited by the same stimulus and task.
Thus, we here place less emphasis on abstract models, phenomenological models,
purely data-driven fitting or extrapolation models, or models specifically
designed for a single task or for a restricted class of stimuli. For
theoretical models, we refer the reader to a number of previous reviews that
address attention theories and models more generally
\cite{Itti_Koch01nrn,Paletta_etal05,Frintrop_etal10,Rothenstein_Tsotsos08,Gottlieb_Balan10,Toet11,Borji_Itti12pami}.


Detecting "Smart" Spammers On Social Network: A Topic Model Approach

  Spammer detection on social network is a challenging problem. The rigid
anti-spam rules have resulted in emergence of "smart" spammers. They resemble
legitimate users who are difficult to identify. In this paper, we present a
novel spammer classification approach based on Latent Dirichlet
Allocation(LDA), a topic model. Our approach extracts both the local and the
global information of topic distribution patterns, which capture the essence of
spamming. Tested on one benchmark dataset and one self-collected dataset, our
proposed method outperforms other state-of-the-art methods in terms of averaged
F1-score.


What can we learn about CNNs from a large scale controlled object
  dataset?

  Tolerance to image variations (e.g. translation, scale, pose, illumination)
is an important desired property of any object recognition system, be it human
or machine. Moving towards increasingly bigger datasets has been trending in
computer vision specially with the emergence of highly popular deep learning
models. While being very useful for learning invariance to object inter- and
intra-class shape variability, these large-scale wild datasets are not very
useful for learning invariance to other parameters forcing researchers to
resort to other tricks for training a model. In this work, we introduce a
large-scale synthetic dataset, which is freely and publicly available, and use
it to answer several fundamental questions regarding invariance and selectivity
properties of convolutional neural networks. Our dataset contains two parts: a)
objects shot on a turntable: 16 categories, 8 rotation angles, 11 cameras on a
semicircular arch, 5 lighting conditions, 3 focus levels, variety of
backgrounds (23.4 per instance) generating 1320 images per instance (over 20
million images in total), and b) scenes: in which a robot arm takes pictures of
objects on a 1:160 scale scene. We study: 1) invariance and selectivity of
different CNN layers, 2) knowledge transfer from one object category to
another, 3) systematic or random sampling of images to build a train set, 4)
domain adaptation from synthetic to natural scenes, and 5) order of knowledge
delivery to CNNs. We also explore how our analyses can lead the field to
develop more efficient CNNs.


shapeDTW: shape Dynamic Time Warping

  Dynamic Time Warping (DTW) is an algorithm to align temporal sequences with
possible local non-linear distortions, and has been widely applied to audio,
video and graphics data alignments. DTW is essentially a point-to-point
matching method under some boundary and temporal consistency constraints.
Although DTW obtains a global optimal solution, it does not necessarily achieve
locally sensible matchings. Concretely, two temporal points with entirely
dissimilar local structures may be matched by DTW. To address this problem, we
propose an improved alignment algorithm, named shape Dynamic Time Warping
(shapeDTW), which enhances DTW by taking point-wise local structural
information into consideration. shapeDTW is inherently a DTW algorithm, but
additionally attempts to pair locally similar structures and to avoid matching
points with distinct neighborhood structures. We apply shapeDTW to align audio
signal pairs having ground-truth alignments, as well as artificially simulated
pairs of aligned sequences, and obtain quantitatively much lower alignment
errors than DTW and its two variants. When shapeDTW is used as a distance
measure in a nearest neighbor classifier (NN-shapeDTW) to classify time series,
it beats DTW on 64 out of 84 UCR time series datasets, with significantly
improved classification accuracies. By using a properly designed local
structure descriptor, shapeDTW improves accuracies by more than 10% on 18
datasets. To the best of our knowledge, shapeDTW is the first distance measure
under the nearest neighbor classifier scheme to significantly outperform DTW,
which had been widely recognized as the best distance measure to date. Our code
is publicly accessible at: https://github.com/jiapingz/shapeDTW.


Active Long Term Memory Networks

  Continual Learning in artificial neural networks suffers from interference
and forgetting when different tasks are learned sequentially. This paper
introduces the Active Long Term Memory Networks (A-LTM), a model of sequential
multi-task deep learning that is able to maintain previously learned
association between sensory input and behavioral output while acquiring knew
knowledge. A-LTM exploits the non-convex nature of deep neural networks and
actively maintains knowledge of previously learned, inactive tasks using a
distillation loss. Distortions of the learned input-output map are penalized
but hidden layers are free to transverse towards new local optima that are more
favorable for the multi-task objective. We re-frame the McClelland's seminal
Hippocampal theory with respect to Catastrophic Inference (CI) behavior
exhibited by modern deep architectures trained with back-propagation and
inhomogeneous sampling of latent factors across epochs. We present empirical
results of non-trivial CI during continual learning in Deep Linear Networks
trained on the same task, in Convolutional Neural Networks when the task shifts
from predicting semantic to graphical factors and during domain adaptation from
simple to complex environments. We present results of the A-LTM model's ability
to maintain viewpoint recognition learned in the highly controlled iLab-20M
dataset with 10 object categories and 88 camera viewpoints, while adapting to
the unstructured domain of Imagenet with 1,000 object categories.


Improved Deep Learning of Object Category using Pose Information

  Despite significant recent progress, the best available computer vision
algorithms still lag far behind human capabilities, even for recognizing
individual discrete objects under various poses, illuminations, and
backgrounds. Here we present a new approach to using object pose information to
improve deep network learning. While existing large-scale datasets, e.g.
ImageNet, do not have pose information, we leverage the newly published
turntable dataset, iLab-20M, which has ~22M images of 704 object instances shot
under different lightings, camera viewpoints and turntable rotations, to do
more controlled object recognition experiments. We introduce a new
convolutional neural network architecture, what/where CNN (2W-CNN), built on a
linear-chain feedforward CNN (e.g., AlexNet), augmented by hierarchical layers
regularized by object poses. Pose information is only used as feedback signal
during training, in addition to category information; during test, the
feedforward network only predicts category. To validate the approach, we train
both 2W-CNN and AlexNet using a fraction of the dataset, and 2W-CNN achieves 6%
performance improvement in category prediction. We show mathematically that
2W-CNN has inherent advantages over AlexNet under the stochastic gradient
descent (SGD) optimization procedure. Further more, we fine-tune object
recognition on ImageNet by using the pretrained 2W-CNN and AlexNet features on
iLab-20M, results show that significant improvements have been achieved,
compared with training AlexNet from scratch. Moreover, fine-tuning 2W-CNN
features performs even better than fine-tuning the pretrained AlexNet features.
These results show pretrained features on iLab- 20M generalizes well to natural
image datasets, and 2WCNN learns even better features for object recognition
than AlexNet.


Learning to Recognize Objects by Retaining other Factors of Variation

  Natural images are generated under many factors, including shape, pose,
illumination etc. Most existing ConvNets formulate object recognition from
natural images as a single task classification problem, and attempt to learn
features useful for object categories, but invariant to other factors of
variation as much as possible. These architectures do not explicitly learn
other factors, like pose and lighting, instead, they usually discard them by
pooling and normalization. In this work, we take the opposite approach: we
train ConvNets for object recognition by retaining other factors (pose in our
case) and learn them jointly with object category. We design a new multi-task
leaning (MTL) ConvNet, named disentangling CNN (disCNN), which explicitly
enforces the disentangled representations of object identity and pose, and is
trained to predict object categories and pose transformations. We show that
disCNN achieves significantly better object recognition accuracies than AlexNet
trained solely to predict object categories on the iLab-20M dataset, which is a
large scale turntable dataset with detailed object pose and lighting
information. We further show that the pretrained disCNN/AlexNet features on
iLab- 20M generalize to object recognition on both Washington RGB-D and
ImageNet datasets, and the pretrained disCNN features are significantly better
than the pretrained AlexNet features for fine-tuning object recognition on the
ImageNet dataset.


Born Again Neural Networks

  Knowledge distillation (KD) consists of transferring knowledge from one
machine learning model (the teacher}) to another (the student). Commonly, the
teacher is a high-capacity model with formidable performance, while the student
is more compact. By transferring knowledge, one hopes to benefit from the
student's compactness. %we desire a compact model with performance close to the
teacher's. We study KD from a new perspective: rather than compressing models,
we train students parameterized identically to their teachers. Surprisingly,
these {Born-Again Networks (BANs), outperform their teachers significantly,
both on computer vision and language modeling tasks. Our experiments with BANs
based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10
(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional
experiments explore two distillation objectives: (i) Confidence-Weighted by
Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).
Both methods elucidate the essential components of KD, demonstrating a role of
the teacher outputs on both predicted and non-predicted classes. We present
experiments with students of various capacities, focusing on the under-explored
case where students overpower teachers. Our experiments show significant
advantages from transferring knowledge between DenseNets and ResNets in either
direction.


Overcoming catastrophic forgetting problem by weight consolidation and
  long-term memory

  Sequential learning of multiple tasks in artificial neural networks using
gradient descent leads to catastrophic forgetting, whereby previously learned
knowledge is erased during learning of new, disjoint knowledge. Here, we
propose a new approach to sequential learning which leverages the recent
discovery of adversarial examples. We use adversarial subspaces from previous
tasks to enable learning of new tasks with less interference. We apply our
method to sequentially learning to classify digits 0, 1, 2 (task 1), 4, 5, 6,
(task 2), and 7, 8, 9 (task 3) in MNIST (disjoint MNIST task). We compare and
combine our Adversarial Direction (AD) method with the recently proposed
Elastic Weight Consolidation (EWC) method for sequential learning. We train
each task for 20 epochs, which yields good initial performance (99.24% correct
task 1 performance). After training task 2, and then task 3, both plain
gradient descent (PGD) and EWC largely forget task 1 (task 1 accuracy 32.95%
for PGD and 41.02% for EWC), while our combined approach (AD+EWC) still
achieves 94.53% correct on task 1. We obtain similar results with a much more
difficult disjoint CIFAR10 task, which to our knowledge had not been attempted
before (70.10% initial task 1 performance, 67.73% after learning tasks 2 and 3
for AD+EWC, while PGD and EWC both fall to chance level). Our results suggest
that AD+EWC can provide better sequential learning performance than either PGD
or EWC.


Closed-Loop GAN for continual Learning

  Sequential learning of tasks using gradient descent leads to an unremitting
decline in the accuracy of tasks for which training data is no longer
available, termed catastrophic forgetting. Generative models have been explored
as a means to approximate the distribution of old tasks and bypass storage of
real data. Here we propose a cumulative closed-loop generator and embedded
classifier using an AC-GAN architecture provided with external regularization
by a small buffer. We evaluate incremental learning using a notoriously hard
paradigm, single headed learning, in which each task is a disjoint subset of
classes in the overall dataset, and performance is evaluated on all previous
classes. First, we show that the variability contained in a small percentage of
a dataset (memory buffer) accounts for a significant portion of the reported
accuracy, both in multi-task and continual learning settings. Second, we show
that using a generator to continuously output new images while training
provides an up-sampling of the buffer, which prevents catastrophic forgetting
and yields superior performance when compared to a fixed buffer. We achieve an
average accuracy for all classes of 92.26% in MNIST and 76.15% in FASHION-MNIST
after 5 tasks using GAN sampling with a buffer of only 0.17% of the entire
dataset size. We compare to a network with regularization (EWC) which shows a
deteriorated average performance of 29.19% (MNIST) and 26.5% (FASHION). The
baseline of no regularization (plain gradient descent) performs at 99.84%
(MNIST) and 99.79% (FASHION) for the last task, but below 3% for all previous
tasks. Our method has very low long-term memory cost, the buffer, as well as
negligible intermediate memory storage.


