Computational models of attention

  This chapter reviews recent computational models of visual attention. Webegin with models for the bottom-up or stimulus-driven guidance of attention tosalient visual items, which we examine in seven different broad categories. Wethen examine more complex models which address the top-down or goal-orientedguidance of attention towards items that are more relevant to the task at hand.

6th International Symposium on Attention in Cognitive Systems 2013

  This volume contains the papers accepted at the 6th International Symposiumon Attention in Cognitive Systems (ISACS 2013), held in Beijing, August 5,2013. The aim of this symposium is to highlight the central role of attentionon various kinds of performance in cognitive systems processing. It bringstogether researchers and developers from both academia and industry, fromcomputer vision, robotics, perception psychology, psychophysics andneuroscience, in order to provide an interdisciplinary forum to present andcommunicate on computational models of attention, with the focus oninterdependencies with visual cognition. Furthermore, it intends to investigaterelevant objectives for performance comparison, to document and to investigatepromising application domains, and to discuss visual attention with referenceto other aspects of AI enabled systems.

CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research

  Saliency modeling has been an active research area in computer vision forabout two decades. Existing state of the art models perform very well inpredicting where people look in natural scenes. There is, however, the riskthat these models may have been overfitting themselves to available small scalebiased datasets, thus trapping the progress in a local minimum. To gain adeeper insight regarding current issues in saliency modeling and to bettergauge progress, we recorded eye movements of 120 observers while they freelyviewed a large number of naturalistic and artificial images. Our stimuliincludes 4000 images; 200 from each of 20 categories covering different typesof scenes such as Cartoons, Art, Objects, Low resolution images, Indoor,Outdoor, Jumbled, Random, and Line drawings. We analyze some basic propertiesof this dataset and compare some successful models. We believe that our datasetopens new challenges for the next generation of saliency models and helpsconduct behavioral studies on bottom-up visual attention.

Computational models: Bottom-up and top-down aspects

  Computational models of visual attention have become popular over the pastdecade, we believe primarily for two reasons: First, models make testablepredictions that can be explored by experimentalists as well as theoreticians,second, models have practical and technological applications of interest to theapplied science and engineering communities. In this chapter, we take acritical look at recent attention modeling efforts. We focus on {\emcomputational models of attention} as defined by Tsotsos \& Rothenstein\shortcite{Tsotsos_Rothenstein11}: Models which can process any visual stimulus(typically, an image or video clip), which can possibly also be given some taskdefinition, and which make predictions that can be compared to human or animalbehavioral or physiological responses elicited by the same stimulus and task.Thus, we here place less emphasis on abstract models, phenomenological models,purely data-driven fitting or extrapolation models, or models specificallydesigned for a single task or for a restricted class of stimuli. Fortheoretical models, we refer the reader to a number of previous reviews thataddress attention theories and models more generally\cite{Itti_Koch01nrn,Paletta_etal05,Frintrop_etal10,Rothenstein_Tsotsos08,Gottlieb_Balan10,Toet11,Borji_Itti12pami}.

Detecting "Smart" Spammers On Social Network: A Topic Model Approach

  Spammer detection on social network is a challenging problem. The rigidanti-spam rules have resulted in emergence of "smart" spammers. They resemblelegitimate users who are difficult to identify. In this paper, we present anovel spammer classification approach based on Latent DirichletAllocation(LDA), a topic model. Our approach extracts both the local and theglobal information of topic distribution patterns, which capture the essence ofspamming. Tested on one benchmark dataset and one self-collected dataset, ourproposed method outperforms other state-of-the-art methods in terms of averagedF1-score.

metricDTW: local distance metric learning in Dynamic Time Warping

  We propose to learn multiple local Mahalanobis distance metrics to performk-nearest neighbor (kNN) classification of temporal sequences. Temporalsequences are first aligned by dynamic time warping (DTW); given the alignmentpath, similarity between two sequences is measured by the DTW distance, whichis computed as the accumulated distance between matched temporal point pairsalong the alignment path. Traditionally, Euclidean metric is used for distancecomputation between matched pairs, which ignores the data regularities andmight not be optimal for applications at hand. Here we propose to learnmultiple Mahalanobis metrics, such that DTW distance becomes the sum ofMahalanobis distances. We adapt the large margin nearest neighbor (LMNN)framework to our case, and formulate multiple metric learning as a linearprogramming problem. Extensive sequence classification results show that ourproposed multiple metrics learning approach is effective, insensitive to thepreceding alignment qualities, and reaches the state-of-the-art performances onUCR time series datasets.

What can we learn about CNNs from a large scale controlled object  dataset?

  Tolerance to image variations (e.g. translation, scale, pose, illumination)is an important desired property of any object recognition system, be it humanor machine. Moving towards increasingly bigger datasets has been trending incomputer vision specially with the emergence of highly popular deep learningmodels. While being very useful for learning invariance to object inter- andintra-class shape variability, these large-scale wild datasets are not veryuseful for learning invariance to other parameters forcing researchers toresort to other tricks for training a model. In this work, we introduce alarge-scale synthetic dataset, which is freely and publicly available, and useit to answer several fundamental questions regarding invariance and selectivityproperties of convolutional neural networks. Our dataset contains two parts: a)objects shot on a turntable: 16 categories, 8 rotation angles, 11 cameras on asemicircular arch, 5 lighting conditions, 3 focus levels, variety ofbackgrounds (23.4 per instance) generating 1320 images per instance (over 20million images in total), and b) scenes: in which a robot arm takes pictures ofobjects on a 1:160 scale scene. We study: 1) invariance and selectivity ofdifferent CNN layers, 2) knowledge transfer from one object category toanother, 3) systematic or random sampling of images to build a train set, 4)domain adaptation from synthetic to natural scenes, and 5) order of knowledgedelivery to CNNs. We also explore how our analyses can lead the field todevelop more efficient CNNs.

shapeDTW: shape Dynamic Time Warping

  Dynamic Time Warping (DTW) is an algorithm to align temporal sequences withpossible local non-linear distortions, and has been widely applied to audio,video and graphics data alignments. DTW is essentially a point-to-pointmatching method under some boundary and temporal consistency constraints.Although DTW obtains a global optimal solution, it does not necessarily achievelocally sensible matchings. Concretely, two temporal points with entirelydissimilar local structures may be matched by DTW. To address this problem, wepropose an improved alignment algorithm, named shape Dynamic Time Warping(shapeDTW), which enhances DTW by taking point-wise local structuralinformation into consideration. shapeDTW is inherently a DTW algorithm, butadditionally attempts to pair locally similar structures and to avoid matchingpoints with distinct neighborhood structures. We apply shapeDTW to align audiosignal pairs having ground-truth alignments, as well as artificially simulatedpairs of aligned sequences, and obtain quantitatively much lower alignmenterrors than DTW and its two variants. When shapeDTW is used as a distancemeasure in a nearest neighbor classifier (NN-shapeDTW) to classify time series,it beats DTW on 64 out of 84 UCR time series datasets, with significantlyimproved classification accuracies. By using a properly designed localstructure descriptor, shapeDTW improves accuracies by more than 10% on 18datasets. To the best of our knowledge, shapeDTW is the first distance measureunder the nearest neighbor classifier scheme to significantly outperform DTW,which had been widely recognized as the best distance measure to date. Our codeis publicly accessible at: https://github.com/jiapingz/shapeDTW.

Active Long Term Memory Networks

  Continual Learning in artificial neural networks suffers from interferenceand forgetting when different tasks are learned sequentially. This paperintroduces the Active Long Term Memory Networks (A-LTM), a model of sequentialmulti-task deep learning that is able to maintain previously learnedassociation between sensory input and behavioral output while acquiring knewknowledge. A-LTM exploits the non-convex nature of deep neural networks andactively maintains knowledge of previously learned, inactive tasks using adistillation loss. Distortions of the learned input-output map are penalizedbut hidden layers are free to transverse towards new local optima that are morefavorable for the multi-task objective. We re-frame the McClelland's seminalHippocampal theory with respect to Catastrophic Inference (CI) behaviorexhibited by modern deep architectures trained with back-propagation andinhomogeneous sampling of latent factors across epochs. We present empiricalresults of non-trivial CI during continual learning in Deep Linear Networkstrained on the same task, in Convolutional Neural Networks when the task shiftsfrom predicting semantic to graphical factors and during domain adaptation fromsimple to complex environments. We present results of the A-LTM model's abilityto maintain viewpoint recognition learned in the highly controlled iLab-20Mdataset with 10 object categories and 88 camera viewpoints, while adapting tothe unstructured domain of Imagenet with 1,000 object categories.

Improved Deep Learning of Object Category using Pose Information

  Despite significant recent progress, the best available computer visionalgorithms still lag far behind human capabilities, even for recognizingindividual discrete objects under various poses, illuminations, andbackgrounds. Here we present a new approach to using object pose information toimprove deep network learning. While existing large-scale datasets, e.g.ImageNet, do not have pose information, we leverage the newly publishedturntable dataset, iLab-20M, which has ~22M images of 704 object instances shotunder different lightings, camera viewpoints and turntable rotations, to domore controlled object recognition experiments. We introduce a newconvolutional neural network architecture, what/where CNN (2W-CNN), built on alinear-chain feedforward CNN (e.g., AlexNet), augmented by hierarchical layersregularized by object poses. Pose information is only used as feedback signalduring training, in addition to category information; during test, thefeedforward network only predicts category. To validate the approach, we trainboth 2W-CNN and AlexNet using a fraction of the dataset, and 2W-CNN achieves 6%performance improvement in category prediction. We show mathematically that2W-CNN has inherent advantages over AlexNet under the stochastic gradientdescent (SGD) optimization procedure. Further more, we fine-tune objectrecognition on ImageNet by using the pretrained 2W-CNN and AlexNet features oniLab-20M, results show that significant improvements have been achieved,compared with training AlexNet from scratch. Moreover, fine-tuning 2W-CNNfeatures performs even better than fine-tuning the pretrained AlexNet features.These results show pretrained features on iLab- 20M generalizes well to naturalimage datasets, and 2WCNN learns even better features for object recognitionthan AlexNet.

Learning to Recognize Objects by Retaining other Factors of Variation

  Natural images are generated under many factors, including shape, pose,illumination etc. Most existing ConvNets formulate object recognition fromnatural images as a single task classification problem, and attempt to learnfeatures useful for object categories, but invariant to other factors ofvariation as much as possible. These architectures do not explicitly learnother factors, like pose and lighting, instead, they usually discard them bypooling and normalization. In this work, we take the opposite approach: wetrain ConvNets for object recognition by retaining other factors (pose in ourcase) and learn them jointly with object category. We design a new multi-taskleaning (MTL) ConvNet, named disentangling CNN (disCNN), which explicitlyenforces the disentangled representations of object identity and pose, and istrained to predict object categories and pose transformations. We show thatdisCNN achieves significantly better object recognition accuracies than AlexNettrained solely to predict object categories on the iLab-20M dataset, which is alarge scale turntable dataset with detailed object pose and lightinginformation. We further show that the pretrained disCNN/AlexNet features oniLab- 20M generalize to object recognition on both Washington RGB-D andImageNet datasets, and the pretrained disCNN features are significantly betterthan the pretrained AlexNet features for fine-tuning object recognition on theImageNet dataset.

Born Again Neural Networks

  Knowledge distillation (KD) consists of transferring knowledge from onemachine learning model (the teacher}) to another (the student). Commonly, theteacher is a high-capacity model with formidable performance, while the studentis more compact. By transferring knowledge, one hopes to benefit from thestudent's compactness. %we desire a compact model with performance close to theteacher's. We study KD from a new perspective: rather than compressing models,we train students parameterized identically to their teachers. Surprisingly,these {Born-Again Networks (BANs), outperform their teachers significantly,both on computer vision and language modeling tasks. Our experiments with BANsbased on DenseNets demonstrate state-of-the-art performance on the CIFAR-10(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additionalexperiments explore two distillation objectives: (i) Confidence-Weighted byTeacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).Both methods elucidate the essential components of KD, demonstrating a role ofthe teacher outputs on both predicted and non-predicted classes. We presentexperiments with students of various capacities, focusing on the under-exploredcase where students overpower teachers. Our experiments show significantadvantages from transferring knowledge between DenseNets and ResNets in eitherdirection.

Overcoming catastrophic forgetting problem by weight consolidation and  long-term memory

  Sequential learning of multiple tasks in artificial neural networks usinggradient descent leads to catastrophic forgetting, whereby previously learnedknowledge is erased during learning of new, disjoint knowledge. Here, wepropose a new approach to sequential learning which leverages the recentdiscovery of adversarial examples. We use adversarial subspaces from previoustasks to enable learning of new tasks with less interference. We apply ourmethod to sequentially learning to classify digits 0, 1, 2 (task 1), 4, 5, 6,(task 2), and 7, 8, 9 (task 3) in MNIST (disjoint MNIST task). We compare andcombine our Adversarial Direction (AD) method with the recently proposedElastic Weight Consolidation (EWC) method for sequential learning. We traineach task for 20 epochs, which yields good initial performance (99.24% correcttask 1 performance). After training task 2, and then task 3, both plaingradient descent (PGD) and EWC largely forget task 1 (task 1 accuracy 32.95%for PGD and 41.02% for EWC), while our combined approach (AD+EWC) stillachieves 94.53% correct on task 1. We obtain similar results with a much moredifficult disjoint CIFAR10 task, which to our knowledge had not been attemptedbefore (70.10% initial task 1 performance, 67.73% after learning tasks 2 and 3for AD+EWC, while PGD and EWC both fall to chance level). Our results suggestthat AD+EWC can provide better sequential learning performance than either PGDor EWC.

Closed-Loop GAN for continual Learning

  Sequential learning of tasks using gradient descent leads to an unremittingdecline in the accuracy of tasks for which training data is no longeravailable, termed catastrophic forgetting. Generative models have been exploredas a means to approximate the distribution of old tasks and bypass storage ofreal data. Here we propose a cumulative closed-loop generator and embeddedclassifier using an AC-GAN architecture provided with external regularizationby a small buffer. We evaluate incremental learning using a notoriously hardparadigm, single headed learning, in which each task is a disjoint subset ofclasses in the overall dataset, and performance is evaluated on all previousclasses. First, we show that the variability contained in a small percentage ofa dataset (memory buffer) accounts for a significant portion of the reportedaccuracy, both in multi-task and continual learning settings. Second, we showthat using a generator to continuously output new images while trainingprovides an up-sampling of the buffer, which prevents catastrophic forgettingand yields superior performance when compared to a fixed buffer. We achieve anaverage accuracy for all classes of 92.26% in MNIST and 76.15% in FASHION-MNISTafter 5 tasks using GAN sampling with a buffer of only 0.17% of the entiredataset size. We compare to a network with regularization (EWC) which shows adeteriorated average performance of 29.19% (MNIST) and 26.5% (FASHION). Thebaseline of no regularization (plain gradient descent) performs at 99.84%(MNIST) and 99.79% (FASHION) for the last task, but below 3% for all previoustasks. Our method has very low long-term memory cost, the buffer, as well asnegligible intermediate memory storage.

