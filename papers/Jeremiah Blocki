Set Families with Low Pairwise Intersection

  A $\left(n,\ell,\gamma\right)$-sharing set family of size $m$ is a family ofsets $S_1,\ldots,S_m\subseteq [n]$ s.t. each set has size $\ell$ and each pairof sets shares at most $\gamma$ elements. We let $m\left(n,\ell,\gamma\right)$denote the maximum size of any such set family and we consider the followingquestion: How large can $m\left(n,\ell,\gamma\right)$ be?$\left(n,\ell,\gamma\right)$-sharing set families have a rich set ofapplications including the construction of pseudorandom number generators andusable and secure password management schemes. We analyze the explicitconstruction of Blocki et al using recent bounds on the value of the $t$'thRamanujan prime. We show that this explicit construction produces a$\left(4\ell^2\ln 4\ell,\ell,\gamma\right)$-sharing set family of size $\left(2\ell \ln 2\ell\right)^{\gamma+1}$ for any $\ell\geq \gamma$. We also show thatthe construction of Blocki et al can be used to obtain a weak$\left(n,\ell,\gamma\right)$-sharing set family of size $m$ for any $m >0$.These results are competitive with the inexplicit construction of Raz et al forweak $\left(n,\ell,\gamma\right)$-sharing families. We show that our explicitconstruction of weak $\left(n,\ell,\gamma\right)$-sharing set families can beused to obtain a parallelizable pseudorandom number generator with a low memoryfootprint by using the pseudorandom number generator of Nisan and Wigderson. Wealso prove that $m\left(n,n/c_1,c_2n\right)$ must be a constant whenever $c_2\leq \frac{2}{c_1^3+c_1^2}$. We show that this bound is nearly tight as$m\left(n,n/c_1,c_2n\right)$ grows exponentially fast whenever $c_2 >c_1^{-2}$.

Resolving the Complexity of Some Data Privacy Problems

  We formally study two methods for data sanitation that have been usedextensively in the database community: k-anonymity and l-diversity. We settleseveral open problems concerning the difficulty of applying these methodsoptimally, proving both positive and negative results:  1. 2-anonymity is in P.  2. The problem of partitioning the edges of a triangle-free graph into4-stars (degree-three vertices) is NP-hard. This yields an alternative proofthat 3-anonymity is NP-hard even when the database attributes are all binary.  3. 3-anonymity with only 27 attributes per record is MAX SNP-hard.  4. For databases with n rows, k-anonymity is in O(4^n poly(n)) time for all k> 1.  5. For databases with n rows and l <= log_{2c+2} log n attributes over analphabet of cardinality c = O(1), k-anonymity is in P. Assuming c, l = O(1),k-anonymity is in O(n).  6. 3-diversity with binary attributes is NP-hard, with one sensitiveattribute.  7. 2-diversity with binary attributes is NP-hard, with three sensitiveattributes.

Optimizing Password Composition Policies

  A password composition policy restricts the space of allowable passwords toeliminate weak passwords that are vulnerable to statistical guessing attacks.Usability studies have demonstrated that existing password composition policiescan sometimes result in weaker password distributions; hence a more principledapproach is needed. We introduce the first theoretical model for optimizingpassword composition policies. We study the computational and sample complexityof this problem under different assumptions on the structure of policies and onusers' preferences over passwords. Our main positive result is an algorithmthat -- with high probability --- constructs almost optimal policies (which arespecified as a union of subsets of allowed passwords), and requires only asmall number of samples of users' preferred passwords. We complement ourtheoretical results with simulations using a real-world dataset of 32 millionpasswords.

Naturally Rehearsing Passwords

  We introduce quantitative usability and security models to guide the designof password management schemes --- systematic strategies to help users createand remember multiple passwords. In the same way that security proofs incryptography are based on complexity-theoretic assumptions (e.g., hardness offactoring and discrete logarithm), we quantify usability by introducingusability assumptions. In particular, password management relies on assumptionsabout human memory, e.g., that a user who follows a particular rehearsalschedule will successfully maintain the corresponding memory. These assumptionsare informed by research in cognitive science and validated through empiricalstudies. Given rehearsal requirements and a user's visitation schedule for eachaccount, we use the total number of extra rehearsals that the user would haveto do to remember all of his passwords as a measure of the usability of thepassword scheme. Our usability model leads us to a key observation: passwordreuse benefits users not only by reducing the number of passwords that the userhas to memorize, but more importantly by increasing the natural rehearsal ratefor each password. We also present a security model which accounts for thecomplexity of password management with multiple accounts and associatedthreats, including online, offline, and plaintext password leak attacks.Observing that current password management schemes are either insecure orunusable, we present Shared Cues--- a new scheme in which the underlying secretis strategically shared across accounts to ensure that most rehearsalrequirements are satisfied naturally while simultaneously providing strongsecurity. The construction uses the Chinese Remainder Theorem to achieve thesecompeting goals.

GOTCHA Password Hackers!

  We introduce GOTCHAs (Generating panOptic Turing Tests to Tell Computers andHumans Apart) as a way of preventing automated offline dictionary attacksagainst user selected passwords. A GOTCHA is a randomized puzzle generationprotocol, which involves interaction between a computer and a human.Informally, a GOTCHA should satisfy two key properties: (1) The puzzles areeasy for the human to solve. (2) The puzzles are hard for a computer to solveeven if it has the random bits used by the computer to generate the finalpuzzle --- unlike a CAPTCHA. Our main theorem demonstrates that GOTCHAs can beused to mitigate the threat of offline dictionary attacks against passwords byensuring that a password cracker must receive constant feedback from a humanbeing while mounting an attack. Finally, we provide a candidate construction ofGOTCHAs based on Inkblot images. Our construction relies on the usabilityassumption that users can recognize the phrases that they originally used todescribe each Inkblot image --- a much weaker usability assumption thanprevious password systems based on Inkblots which required users to recalltheir phrase exactly. We conduct a user study to evaluate the usability of ourGOTCHA construction. We also generate a GOTCHA challenge where we encourageartificial intelligence and security researchers to try to crack severalpasswords protected with our scheme.

Client-CASH: Protecting Master Passwords against Offline Attacks

  Offline attacks on passwords are increasingly commonplace and dangerous. Anoffline adversary is limited only by the amount of computational resources heor she is willing to invest to crack a user's password. The danger iscompounded by the existence of authentication servers who fail to adopt properpassword storage practices like key-stretching. Password managers can helpmitigate these risks by adopting key stretching procedures like hash iterationor memory hard functions to derive site specific passwords from the user'smaster password on the client-side. While key stretching can reduce the offlineadversary's success rate, these procedures also increase computational costsfor a legitimate user. Motivated by the observation that most of the passwordguesses of the offline adversary will be incorrect, we propose a client sidecost asymmetric secure hashing scheme (Client-CASH). Client-CASH randomizes theruntime of client-side key stretching procedure in a way that the expectedcomputational cost of our key derivation function is greater when run with anincorrect master password. We make several contributions. First, we show how tointroduce randomness into a client-side key stretching algorithms through theuse of halting predicates which are selected randomly at the time of accountcreation. Second, we formalize the problem of finding the optimal running timedistribution subject to certain cost constraints for the client and certainsecurity constrains on the halting predicates. Finally, we demonstrate thatClient-CASH can reduce the adversary's success rate by up to $21\%$. Theseresults demonstrate the promise of the Client-CASH mechanism.

Adaptive Regret Minimization in Bounded-Memory Games

  Online learning algorithms that minimize regret provide strong guarantees insituations that involve repeatedly making decisions in an uncertainenvironment, e.g. a driver deciding what route to drive to work every day.While regret minimization has been extensively studied in repeated games, westudy regret minimization for a richer class of games called bounded memorygames. In each round of a two-player bounded memory-m game, both playerssimultaneously play an action, observe an outcome and receive a reward. Thereward may depend on the last m outcomes as well as the actions of the playersin the current round. The standard notion of regret for repeated games is nolonger suitable because actions and rewards can depend on the history of play.To account for this generality, we introduce the notion of k-adaptive regret,which compares the reward obtained by playing actions prescribed by thealgorithm against a hypothetical k-adaptive adversary with the reward obtainedby the best expert in hindsight against the same adversary. Roughly, ahypothetical k-adaptive adversary adapts her strategy to the defender's actionsexactly as the real adversary would within each window of k rounds. Ourdefinition is parametrized by a set of experts, which can include both fixedand adaptive defender strategies.  We investigate the inherent complexity of and design algorithms for adaptiveregret minimization in bounded memory games of perfect and imperfectinformation. We prove a hardness result showing that, with imperfectinformation, any k-adaptive regret minimizing algorithm (with fixed strategiesas experts) must be inefficient unless NP=RP even when playing against anoblivious adversary. In contrast, for bounded memory games of perfect andimperfect information we present approximate 0-adaptive regret minimizationalgorithms against an oblivious adversary running in time n^{O(1)}.

Differentially Private Data Analysis of Social Networks via Restricted  Sensitivity

  We introduce the notion of restricted sensitivity as an alternative to globaland smooth sensitivity to improve accuracy in differentially private dataanalysis. The definition of restricted sensitivity is similar to that of globalsensitivity except that instead of quantifying over all possible datasets, wetake advantage of any beliefs about the dataset that a querier may have, toquantify over a restricted class of datasets. Specifically, given a query f anda hypothesis H about the structure of a dataset D, we show generically how totransform f into a new query f_H whose global sensitivity (over all datasetsincluding those that do not satisfy H) matches the restricted sensitivity ofthe query f. Moreover, if the belief of the querier is correct (i.e., D is inH) then f_H(D) = f(D). If the belief is incorrect, then f_H(D) may beinaccurate.  We demonstrate the usefulness of this notion by considering the task ofanswering queries regarding social-networks, which we model as a combination ofa graph and a labeling of its vertices. In particular, while our genericprocedure is computationally inefficient, for the specific definition of H asgraphs of bounded degree, we exhibit efficient ways of constructing f_H usingdifferent projection-based techniques. We then analyze two important queryclasses: subgraph counting queries (e.g., number of triangles) and localprofile queries (e.g., number of people who know a spy and a computer-scientistwho know each other). We demonstrate that the restricted sensitivity of suchqueries can be significantly lower than their smooth sensitivity. Thus, usingrestricted sensitivity we can maintain privacy whether or not D is in H, whileproviding more accurate results in the event that H holds true.

Towards Human Computable Passwords

  An interesting challenge for the cryptography community is to designauthentication protocols that are so simple that a human can execute themwithout relying on a fully trusted computer. We propose several candidateauthentication protocols for a setting in which the human user can only receiveassistance from a semi-trusted computer --- a computer that stores informationand performs computations correctly but does not provide confidentiality. Ourschemes use a semi-trusted computer to store and display public challenges$C_i\in[n]^k$. The human user memorizes a random secret mapping$\sigma:[n]\rightarrow\mathbb{Z}_d$ and authenticates by computing responses$f(\sigma(C_i))$ to a sequence of public challenges where$f:\mathbb{Z}_d^k\rightarrow\mathbb{Z}_d$ is a function that is easy for thehuman to evaluate. We prove that any statistical adversary needs to sample$m=\tilde{\Omega}(n^{s(f)})$ challenge-response pairs to recover $\sigma$, fora security parameter $s(f)$ that depends on two key properties of $f$. Toobtain our results, we apply the general hypercontractivity theorem to lowerbound the statistical dimension of the distribution over challenge-responsepairs induced by $f$ and $\sigma$. Our lower bounds apply to arbitraryfunctions $f $ (not just to functions that are easy for a human to evaluate),and generalize recent results of Feldman et al. As an application, we propose afamily of human computable password functions $f_{k_1,k_2}$ in which the userneeds to perform $2k_1+2k_2+1$ primitive operations (e.g., adding two digits orremembering $\sigma(i)$), and we show that $s(f) = \min\{k_1+1, (k_2+1)/2\}$.For these schemes, we prove that forging passwords is equivalent to recoveringthe secret mapping. Thus, our human computable password schemes can maintainstrong security guarantees even after an adversary has observed the user loginto many different accounts.

Spaced Repetition and Mnemonics Enable Recall of Multiple Strong  Passwords

  We report on a user study that provides evidence that spaced repetition and aspecific mnemonic technique enable users to successfully recall multiple strongpasswords over time. Remote research participants were asked to memorize 4Person-Action-Object (PAO) stories where they chose a famous person from adrop-down list and were given machine-generated random action-object pairs.Users were also shown a photo of a scene and asked to imagine the PAO storytaking place in the scene (e.g., Bill Gates---swallowing---bike on a beach).Subsequently, they were asked to recall the action-object pairs when promptedwith the associated scene-person pairs following a spaced repetition scheduleover a period of 127+ days. While we evaluated several spaced repetitionschedules, the best results were obtained when users initially returned after12 hours and then in $1.5\times$ increasing intervals: 77% of the participantssuccessfully recalled all 4 stories in 10 tests over a period of 158 days. Muchof the forgetting happened in the first test period (12 hours): 89% ofparticipants who remembered their stories during the first test periodsuccessfully remembered them in every subsequent round. These findings, coupledwith recent results on naturally rehearsing password schemes, suggest that 4PAO stories could be used to create usable and strong passwords for 14sensitive accounts following this spaced repetition schedule, possibly with afew extra upfront rehearsals. In addition, we find that there is aninterference effect across multiple PAO stories: the recall rate of 100% (resp.90%) for participants who were asked to memorize 1 PAO story (resp. 2 PAOstories) is significantly better than the recall rate for participants who wereasked to memorize 4 PAO stories. These findings yield concrete advice forimproving constructions of password management schemes and future user studies.

CASH: A Cost Asymmetric Secure Hash Algorithm for Optimal Password  Protection

  An adversary who has obtained the cryptographic hash of a user's password canmount an offline attack to crack the password by comparing this hash value withthe cryptographic hashes of likely password guesses. This offline attacker islimited only by the resources he is willing to invest to crack the password.Key-stretching tools can help mitigate the threat of offline attacks by makingeach password guess more expensive for the adversary to verify. However,key-stretching increases authentication costs for a legitimate authenticationserver. We introduce a novel Stackelberg game model which captures theessential elements of this interaction between a defender and an offlineattacker. We then introduce Cost Asymmetric Secure Hash (CASH), a randomizedkey-stretching mechanism that minimizes the fraction of passwords that would becracked by a rational offline attacker without increasing amortizedauthentication costs for the legitimate authentication server. CASH ismotivated by the observation that the legitimate authentication server willtypically run the authentication procedure to verify a correct password, whilean offline adversary will typically use incorrect password guesses. By usingrandomization we can ensure that the amortized cost of running CASH to verify acorrect password guess is significantly smaller than the cost of rejecting anincorrect password. Using our Stackelberg game framework we can quantify thequality of the underlying CASH running time distribution in terms of thefraction of passwords that a rational offline adversary would crack. We providean efficient algorithm to compute high quality CASH distributions for thedefender. Finally, we analyze CASH using empirical data from two large scalepassword frequency datasets. Our analysis shows that CASH can significantlyreduce (up to $50\%$) the fraction of password cracked by a rational offlineadversary.

Sustained Space Complexity

  Memory-hard functions (MHF) are functions whose evaluation cost is dominatedby memory cost. MHFs are egalitarian, in the sense that evaluating them ondedicated hardware (like FPGAs or ASICs) is not much cheaper than onoff-the-shelf hardware (like x86 CPUs). MHFs have interesting cryptographicapplications, most notably to password hashing and securing blockchains.  Alwen and Serbinenko [STOC'15] define the cumulative memory complexity (cmc)of a function as the sum (over all time-steps) of the amount of memory requiredto compute the function. They advocate that a good MHF must have high cmc.Unlike previous notions, cmc takes into account that dedicated hardware mightexploit amortization and parallelism. Still, cmc has been critizised asinsufficient, as it fails to capture possible time-memory trade-offs, as memorycost doesn't scale linearly, functions with the same cmc could still have verydifferent actual hardware cost.  In this work we address this problem, and introduce the notion ofsustained-memory complexity, which requires that any algorithm evaluating thefunction must use a large amount of memory for many steps. We constructfunctions (in the parallel random oracle model) whose sustained-memorycomplexity is almost optimal: our function can be evaluated using $n$ steps and$O(n/\log(n))$ memory, in each step making one query to the (fixed-inputlength) random oracle, while any algorithm that can make arbitrary manyparallel queries to the random oracle, still needs $\Omega(n/\log(n))$ memoryfor $\Omega(n)$ steps.  Our main technical contribution is the construction is a family of DAGs on$n$ nodes with constant indegree with high "sustained-space complexity",meaning that any parallel black-pebbling strategy requires $\Omega(n/\log(n))$pebbles for at least $\Omega(n)$ steps.

Audit Games

  Effective enforcement of laws and policies requires expending resources toprevent and detect offenders, as well as appropriate punishment schemes todeter violators. In particular, enforcement of privacy laws and policies inmodern organizations that hold large volumes of personal information (e.g.,hospitals, banks, and Web services providers) relies heavily on internal auditmechanisms. We study economic considerations in the design of these mechanisms,focusing in particular on effective resource allocation and appropriatepunishment schemes. We present an audit game model that is a naturalgeneralization of a standard security game model for resource allocation withan additional punishment parameter. Computing the Stackelberg equilibrium forthis game is challenging because it involves solving an optimization problemwith non-convex quadratic constraints. We present an additive FPTAS thatefficiently computes a solution that is arbitrarily close to the optimalsolution.

Audit Games with Multiple Defender Resources

  Modern organizations (e.g., hospitals, social networks, government agencies)rely heavily on audit to detect and punish insiders who inappropriately accessand disclose confidential information. Recent work on audit games models thestrategic interaction between an auditor with a single audit resource andauditees as a Stackelberg game, augmenting associated well-studied securitygames with a configurable punishment parameter. We significantly generalizethis audit game model to account for multiple audit resources where eachresource is restricted to audit a subset of all potential violations, thusenabling application to practical auditing scenarios. We provide an FPTAS thatcomputes an approximately optimal solution to the resulting non-convexoptimization problem. The main technical novelty is in the design andcorrectness proof of an optimization transformation that enables theconstruction of this FPTAS. In addition, we experimentally demonstrate thatthis transformation significantly speeds up computation of solutions for aclass of audit games and security games.

Optimizing Locally Differentially Private Protocols

  Protocols satisfying Local Differential Privacy (LDP) enable parties tocollect aggregate information about a population while protecting each user'sprivacy, without relying on a trusted third party. LDP protocols (such asGoogle's RAPPOR) have been deployed in real-world scenarios. In theseprotocols, a user encodes his private information and perturbs the encodedvalue locally before sending it to an aggregator, who combines values thatusers contribute to infer statistics about the population. In this paper, weintroduce a framework that generalizes several LDP protocols proposed in theliterature. Our framework yields a simple and fast aggregation algorithm, whoseaccuracy can be precisely analyzed. Our in-depth analysis enables us to chooseoptimal parameters, resulting in two new protocols (i.e., Optimized UnaryEncoding and Optimized Local Hashing) that provide better utility thanprotocols previously proposed. We present precise conditions for when eachproposed protocol should be used, and perform experiments that demonstrate theadvantage of our proposed protocols.

Relaxed Locally Correctable Codes in Computationally Bounded Channels

  Error-correcting codes that admit local decoding and correcting algorithmshave been the focus of much recent research due to their numerous theoreticaland practical applications. An important goal is to obtain the best possibletradeoffs between the number of queries the algorithm makes to its oracle (thelocality of the task), and the amount of redundancy in the encoding (theinformation rate).  In Hamming's classical adversarial channel model, the current tradeoffs aredramatic, allowing either small locality, but superpolynomial blocklength, orsmall blocklength, but high locality. However, in the computationally bounded,adversarial channel model, proposed by Lipton (STACS 1994), constructions oflocally decodable codes suddenly exhibit small locality and small blocklength,but these constructions require strong trusted setup assumptions e.g.,Ostrovsky, Pandey and Sahai (ICALP 2007) construct private locally decodablecodes in the setting where the sender and receiver already share a symmetrickey.  We study variants of locally decodable and locally correctable codes incomputationally bounded, adversarial channels, in a setting with no public-keyor private-key cryptographic setup. The only setup assumption we require is theselection of the public parameters (seed) for a collision-resistant hashfunction. Specifically, we provide constructions of relaxed locally correctableand relaxed locally decodable codes over the binary alphabet, with constantinformation rate, and poly-logarithmic locality.  Our constructions, which compare favorably with their classical analogues inthe computationally unbounded Hamming channel, crucially employcollision-resistant hash functions and local expander graphs, extending ideasfrom recent cryptographic constructions of memory-hard functions.

The Johnson-Lindenstrauss Transform Itself Preserves Differential  Privacy

  This paper proves that an "old dog", namely -- the classicalJohnson-Lindenstrauss transform, "performs new tricks" -- it gives a novel wayof preserving differential privacy. We show that if we take two databases, $D$and $D'$, such that (i) $D'-D$ is a rank-1 matrix of bounded norm and (ii) allsingular values of $D$ and $D'$ are sufficiently large, then multiplying either$D$ or $D'$ with a vector of iid normal Gaussians yields two statisticallyclose distributions in the sense of differential privacy. Furthermore, a small,deterministic and \emph{public} alteration of the input is enough to assertthat all singular values of $D$ are large.  We apply the Johnson-Lindenstrauss transform to the task of approximatingcut-queries: the number of edges crossing a $(S,\bar S)$-cut in a graph. Weshow that the JL transform allows us to \emph{publish a sanitized graph} thatpreserves edge differential privacy (where two graphs are neighbors if theydiffer on a single edge) while adding only $O(|S|/\epsilon)$ random noise toany given query (w.h.p). Comparing the additive noise of our algorithm toexisting algorithms for answering cut-queries in a differentially privatemanner, we outperform all others on small cuts ($|S| = o(n)$).  We also apply our technique to the task of estimating the variance of a givenmatrix in any given direction. The JL transform allows us to \emph{publish asanitized covariance matrix} that preserves differential privacy w.r.t boundedchanges (each row in the matrix can change by at most a norm-1 vector) whileadding random noise of magnitude independent of the size of the matrix (w.h.p).In contrast, existing algorithms introduce an error which depends on the matrixdimensions.

On the Computational Complexity of Minimal Cumulative Cost Graph  Pebbling

  We consider the computational complexity of finding a legal black pebbling ofa DAG $G=(V,E)$ with minimum cumulative cost. A black pebbling is a sequence$P_0,\ldots, P_t \subseteq V$ of sets of nodes which must satisfy the followingproperties: $P_0 = \emptyset$ (we start off with no pebbles on $G$),$\mathsf{sinks}(G) \subseteq \bigcup_{j \leq t} P_j$ (every sink node waspebbled at some point) and $\mathsf{parents}\big(P_{i+1}\backslash P_i\big)\subseteq P_i$ (we can only place a new pebble on a node $v$ if all of $v$'sparents had a pebble during the last round). The cumulative cost of a pebbling$P_0,P_1,\ldots, P_t \subseteq V$ is $\mathsf{cc}(P) = | P_1| + \ldots + |P_t|$. The cumulative pebbling cost is an especially important security metricfor data-independent memory hard functions, an important primitive for passwordhashing. Thus, an efficient (approximation) algorithm would be an invaluabletool for the cryptanalysis of password hash functions as it would provide anautomated tool to establish tight bounds on the amortized space-time cost ofcomputing the function. We show that such a tool is unlikely to exist. Inparticular, we prove the following results. (1) It is$\texttt{NP}\mbox{-}\texttt{Hard}$ to find a pebbling minimizing cumulativecost. (2) The natural linear program relaxation for the problem has integralitygap $\tilde{O}(n)$, where $n$ is the number of nodes in $G$. We conjecture thatthe problem is hard to approximate. (3) We show that a related problem, findthe minimum size subset $S\subseteq V$ such that $\textsf{depth}(G-S) \leq d$,is also $\texttt{NP}\mbox{-}\texttt{Hard}$. In fact, under the unique gamesconjecture there is no $(2-\epsilon)$-approximation algorithm.

